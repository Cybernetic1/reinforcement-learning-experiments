nohup: ignoring input
Using device: cpu
Architecture: 8 concrete rules → 4 abstract rules
Architecture: 8 concrete rules → 4 abstract rules
======================================================================
LOGIC EXPERIMENTS 2: Hierarchical Architecture
- Layer 1: 8 concrete pattern detectors (forced constants)
- Layer 2: 4 abstract rules with variables (compose L1)
- Learning rate: 0.001
- Target network sync every 50 episodes
======================================================================
Episode    50 | Reward:  -9.943 | Epsilon: 0.7783
Episode   100 | Reward: -15.746 | Epsilon: 0.6058 | Loss: 151.3221
Episode   150 | Reward: -15.451 | Epsilon: 0.4715 | Loss: 138.9615
Episode   200 | Reward: -13.826 | Epsilon: 0.3670 | Loss: 101.3842
Episode   250 | Reward: -18.695 | Epsilon: 0.2856 | Loss: 116.7784
Episode   300 | Reward: -11.766 | Epsilon: 0.2223 | Loss: 131.9084
Episode   350 | Reward: -15.717 | Epsilon: 0.1730 | Loss: 105.9625
Episode   400 | Reward: -13.296 | Epsilon: 0.1347 | Loss: 125.9444
Episode   450 | Reward: -13.426 | Epsilon: 0.1048 | Loss: 109.5561
Episode   500 | Reward: -15.543 | Epsilon: 0.0816 | Loss: 106.5123
Episode   550 | Reward: -12.033 | Epsilon: 0.0635 | Loss: 93.4460
Episode   600 | Reward: -10.038 | Epsilon: 0.0494 | Loss: 72.4318
Episode   650 | Reward:  -8.830 | Epsilon: 0.0385 | Loss: 117.6709
Episode   700 | Reward: -10.982 | Epsilon: 0.0299 | Loss: 92.4096
Episode   750 | Reward: -11.589 | Epsilon: 0.0233 | Loss: 84.0238
Episode   800 | Reward: -12.175 | Epsilon: 0.0181 | Loss: 87.2884
Episode   850 | Reward: -13.946 | Epsilon: 0.0141 | Loss: 78.4950
Episode   900 | Reward: -12.685 | Epsilon: 0.0110 | Loss: 70.7249
Episode   950 | Reward: -10.507 | Epsilon: 0.0100 | Loss: 87.3251
Episode  1000 | Reward:  -9.180 | Epsilon: 0.0100 | Loss: 89.3281
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:00).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:00)
Episode  1050 | Reward: -10.503 | Epsilon: 0.0100 | Loss: 75.1784
Episode  1100 | Reward:  -8.176 | Epsilon: 0.0100 | Loss: 73.6942
Episode  1150 | Reward:  -8.935 | Epsilon: 0.0100 | Loss: 96.2967
Episode  1200 | Reward:  -9.784 | Epsilon: 0.0100 | Loss: 66.4231
Episode  1250 | Reward:  -7.640 | Epsilon: 0.0100 | Loss: 79.4269
Episode  1300 | Reward:  -7.396 | Epsilon: 0.0100 | Loss: 85.8515
Episode  1350 | Reward:  -5.728 | Epsilon: 0.0100 | Loss: 79.8547
Episode  1400 | Reward: -11.876 | Epsilon: 0.0100 | Loss: 112.3476
Episode  1450 | Reward: -11.597 | Epsilon: 0.0100 | Loss: 78.0782
Episode  1500 | Reward: -10.192 | Epsilon: 0.0100 | Loss: 54.5094
Episode  1550 | Reward:  -8.939 | Epsilon: 0.0100 | Loss: 95.3971
Episode  1600 | Reward: -12.732 | Epsilon: 0.0100 | Loss: 94.7868
Episode  1650 | Reward: -12.979 | Epsilon: 0.0100 | Loss: 76.4855
Episode  1700 | Reward:  -5.370 | Epsilon: 0.0100 | Loss: 114.3856
Episode  1750 | Reward:  -9.152 | Epsilon: 0.0100 | Loss: 56.3560
Episode  1800 | Reward:  -6.469 | Epsilon: 0.0100 | Loss: 85.7451
Episode  1850 | Reward:  -7.333 | Epsilon: 0.0100 | Loss: 79.6775
Episode  1900 | Reward:  -5.575 | Epsilon: 0.0100 | Loss: 83.7003
Episode  1950 | Reward:  -3.083 | Epsilon: 0.0100 | Loss: 92.8567
Episode  2000 | Reward:  -4.027 | Epsilon: 0.0100 | Loss: 112.6910
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:02).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:02)
Episode  2050 | Reward: -12.390 | Epsilon: 0.0100 | Loss: 88.7201
Episode  2100 | Reward:  -7.722 | Epsilon: 0.0100 | Loss: 68.3580
Episode  2150 | Reward:  -9.084 | Epsilon: 0.0100 | Loss: 75.4343
Episode  2200 | Reward:  -9.321 | Epsilon: 0.0100 | Loss: 123.5836
Episode  2250 | Reward:  -5.610 | Epsilon: 0.0100 | Loss: 81.5936
Episode  2300 | Reward:  -8.147 | Epsilon: 0.0100 | Loss: 77.7693
Episode  2350 | Reward:  -3.621 | Epsilon: 0.0100 | Loss: 97.6184
Episode  2400 | Reward:  -5.972 | Epsilon: 0.0100 | Loss: 93.4858
Episode  2450 | Reward:  -4.897 | Epsilon: 0.0100 | Loss: 137.5959
Episode  2500 | Reward:  -6.909 | Epsilon: 0.0100 | Loss: 108.3685
Episode  2550 | Reward:  -9.412 | Epsilon: 0.0100 | Loss: 83.4260
Episode  2600 | Reward:  -8.712 | Epsilon: 0.0100 | Loss: 79.0322
Episode  2650 | Reward: -11.605 | Epsilon: 0.0100 | Loss: 71.0386
Episode  2700 | Reward:  -9.783 | Epsilon: 0.0100 | Loss: 73.0876
Episode  2750 | Reward: -15.162 | Epsilon: 0.0100 | Loss: 122.9441
Episode  2800 | Reward: -10.818 | Epsilon: 0.0100 | Loss: 106.1787
Episode  2850 | Reward: -11.613 | Epsilon: 0.0100 | Loss: 87.4684
Episode  2900 | Reward:  -9.028 | Epsilon: 0.0100 | Loss: 73.4824
Episode  2950 | Reward:  -7.793 | Epsilon: 0.0100 | Loss: 146.5973
Episode  3000 | Reward:  -9.195 | Epsilon: 0.0100 | Loss: 118.1922
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:03).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:03)
Episode  3050 | Reward: -10.209 | Epsilon: 0.0100 | Loss: 111.3866
Episode  3100 | Reward:  -8.466 | Epsilon: 0.0100 | Loss: 93.2945
Episode  3150 | Reward:  -6.685 | Epsilon: 0.0100 | Loss: 65.2416
Episode  3200 | Reward: -11.698 | Epsilon: 0.0100 | Loss: 108.3246
Episode  3250 | Reward:  -7.217 | Epsilon: 0.0100 | Loss: 59.5845
Episode  3300 | Reward:  -7.672 | Epsilon: 0.0100 | Loss: 85.2969
Episode  3350 | Reward:  -9.488 | Epsilon: 0.0100 | Loss: 71.5605
Episode  3400 | Reward: -10.152 | Epsilon: 0.0100 | Loss: 90.2098
Episode  3450 | Reward: -10.292 | Epsilon: 0.0100 | Loss: 102.7975
Episode  3500 | Reward:  -9.743 | Epsilon: 0.0100 | Loss: 76.4412
Episode  3550 | Reward: -11.307 | Epsilon: 0.0100 | Loss: 67.8121
Episode  3600 | Reward: -10.724 | Epsilon: 0.0100 | Loss: 119.8002
Episode  3650 | Reward:  -8.695 | Epsilon: 0.0100 | Loss: 93.6955
Episode  3700 | Reward:  -8.822 | Epsilon: 0.0100 | Loss: 76.3732
Episode  3750 | Reward:  -7.093 | Epsilon: 0.0100 | Loss: 110.4992
Episode  3800 | Reward: -10.729 | Epsilon: 0.0100 | Loss: 120.0861
Episode  3850 | Reward:  -9.292 | Epsilon: 0.0100 | Loss: 87.5157
Episode  3900 | Reward:  -7.390 | Epsilon: 0.0100 | Loss: 104.3396
Episode  3950 | Reward: -11.802 | Epsilon: 0.0100 | Loss: 102.3315
Episode  4000 | Reward:  -9.643 | Epsilon: 0.0100 | Loss: 98.1827
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:04).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:04)
Episode  4050 | Reward:  -9.548 | Epsilon: 0.0100 | Loss: 76.5862
Episode  4100 | Reward:  -9.467 | Epsilon: 0.0100 | Loss: 93.2340
Episode  4150 | Reward: -10.753 | Epsilon: 0.0100 | Loss: 73.6481
Episode  4200 | Reward: -10.554 | Epsilon: 0.0100 | Loss: 99.6556
Episode  4250 | Reward:  -9.159 | Epsilon: 0.0100 | Loss: 97.4432
Episode  4300 | Reward:  -6.381 | Epsilon: 0.0100 | Loss: 102.1385
Episode  4350 | Reward:  -7.926 | Epsilon: 0.0100 | Loss: 98.6490
Episode  4400 | Reward:  -8.923 | Epsilon: 0.0100 | Loss: 113.5333
Episode  4450 | Reward:  -8.946 | Epsilon: 0.0100 | Loss: 95.0157
Episode  4500 | Reward:  -9.471 | Epsilon: 0.0100 | Loss: 120.1485
Episode  4550 | Reward: -10.105 | Epsilon: 0.0100 | Loss: 94.1458
Episode  4600 | Reward:  -8.686 | Epsilon: 0.0100 | Loss: 125.4272
Episode  4650 | Reward: -11.590 | Epsilon: 0.0100 | Loss: 129.5072
Episode  4700 | Reward:  -9.406 | Epsilon: 0.0100 | Loss: 57.1867
Episode  4750 | Reward: -10.607 | Epsilon: 0.0100 | Loss: 100.6935
Episode  4800 | Reward:  -9.106 | Epsilon: 0.0100 | Loss: 110.2016
Episode  4850 | Reward:  -9.223 | Epsilon: 0.0100 | Loss: 107.3483
Episode  4900 | Reward:  -9.878 | Epsilon: 0.0100 | Loss: 108.2718
Episode  4950 | Reward: -10.525 | Epsilon: 0.0100 | Loss: 83.5187
Episode  5000 | Reward:  -9.014 | Epsilon: 0.0100 | Loss: 117.4527
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:06).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:06)
Episode  5050 | Reward: -10.207 | Epsilon: 0.0100 | Loss: 94.6695
Episode  5100 | Reward: -12.744 | Epsilon: 0.0100 | Loss: 78.7799
Episode  5150 | Reward:  -8.951 | Epsilon: 0.0100 | Loss: 88.5284
Episode  5200 | Reward: -11.476 | Epsilon: 0.0100 | Loss: 89.4752
Episode  5250 | Reward: -12.573 | Epsilon: 0.0100 | Loss: 49.7855
Episode  5300 | Reward:  -9.258 | Epsilon: 0.0100 | Loss: 99.4971
Episode  5350 | Reward: -11.199 | Epsilon: 0.0100 | Loss: 91.9739
Episode  5400 | Reward: -12.383 | Epsilon: 0.0100 | Loss: 83.3104
Episode  5450 | Reward:  -9.440 | Epsilon: 0.0100 | Loss: 91.3249
Episode  5500 | Reward:  -9.052 | Epsilon: 0.0100 | Loss: 73.8672
Episode  5550 | Reward:  -9.482 | Epsilon: 0.0100 | Loss: 83.6938
Episode  5600 | Reward:  -9.049 | Epsilon: 0.0100 | Loss: 110.7352
Episode  5650 | Reward:  -8.550 | Epsilon: 0.0100 | Loss: 64.1629
Episode  5700 | Reward:  -8.641 | Epsilon: 0.0100 | Loss: 97.0172
Episode  5750 | Reward: -12.940 | Epsilon: 0.0100 | Loss: 80.7323
Episode  5800 | Reward: -14.755 | Epsilon: 0.0100 | Loss: 98.9957
Episode  5850 | Reward: -13.739 | Epsilon: 0.0100 | Loss: 94.8689
Episode  5900 | Reward: -10.699 | Epsilon: 0.0100 | Loss: 89.3193
Episode  5950 | Reward: -14.295 | Epsilon: 0.0100 | Loss: 95.8206
Episode  6000 | Reward: -13.222 | Epsilon: 0.0100 | Loss: 64.8994
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:07).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:07)
Episode  6050 | Reward: -14.569 | Epsilon: 0.0100 | Loss: 90.4184
Episode  6100 | Reward:  -8.996 | Epsilon: 0.0100 | Loss: 98.9136
Episode  6150 | Reward: -10.685 | Epsilon: 0.0100 | Loss: 87.7455
Episode  6200 | Reward:  -9.999 | Epsilon: 0.0100 | Loss: 74.1126
Episode  6250 | Reward: -11.102 | Epsilon: 0.0100 | Loss: 66.8463
Episode  6300 | Reward:  -9.104 | Epsilon: 0.0100 | Loss: 97.0723
Episode  6350 | Reward: -11.296 | Epsilon: 0.0100 | Loss: 74.2026
Episode  6400 | Reward:  -8.528 | Epsilon: 0.0100 | Loss: 118.8679
Episode  6450 | Reward:  -9.174 | Epsilon: 0.0100 | Loss: 92.6633
Episode  6500 | Reward: -13.726 | Epsilon: 0.0100 | Loss: 101.6544
Episode  6550 | Reward:  -8.401 | Epsilon: 0.0100 | Loss: 71.1710
Episode  6600 | Reward: -10.078 | Epsilon: 0.0100 | Loss: 72.9491
Episode  6650 | Reward: -10.016 | Epsilon: 0.0100 | Loss: 90.9832
Episode  6700 | Reward:  -8.411 | Epsilon: 0.0100 | Loss: 94.3055
Episode  6750 | Reward:  -9.912 | Epsilon: 0.0100 | Loss: 91.9002
Episode  6800 | Reward: -12.615 | Epsilon: 0.0100 | Loss: 79.8508
Episode  6850 | Reward:  -9.819 | Epsilon: 0.0100 | Loss: 80.2581
Episode  6900 | Reward:  -9.390 | Epsilon: 0.0100 | Loss: 78.2787
Episode  6950 | Reward:  -8.416 | Epsilon: 0.0100 | Loss: 111.3856
Episode  7000 | Reward: -11.616 | Epsilon: 0.0100 | Loss: 98.8705
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:09).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:09)
Episode  7050 | Reward:  -7.062 | Epsilon: 0.0100 | Loss: 91.3746
Episode  7100 | Reward:  -8.649 | Epsilon: 0.0100 | Loss: 87.8132
Episode  7150 | Reward:  -8.647 | Epsilon: 0.0100 | Loss: 74.1774
Episode  7200 | Reward:  -7.242 | Epsilon: 0.0100 | Loss: 54.6050
Episode  7250 | Reward: -11.007 | Epsilon: 0.0100 | Loss: 73.1092
Episode  7300 | Reward:  -9.893 | Epsilon: 0.0100 | Loss: 65.7756
Episode  7350 | Reward:  -7.670 | Epsilon: 0.0100 | Loss: 90.3463
Episode  7400 | Reward:  -7.196 | Epsilon: 0.0100 | Loss: 81.5636
Episode  7450 | Reward:  -7.671 | Epsilon: 0.0100 | Loss: 78.1163
Episode  7500 | Reward:  -6.902 | Epsilon: 0.0100 | Loss: 85.7323
Episode  7550 | Reward:  -8.521 | Epsilon: 0.0100 | Loss: 91.7049
Episode  7600 | Reward:  -9.695 | Epsilon: 0.0100 | Loss: 79.0967
Episode  7650 | Reward:  -7.381 | Epsilon: 0.0100 | Loss: 89.8378
Episode  7700 | Reward:  -7.247 | Epsilon: 0.0100 | Loss: 70.0550
Episode  7750 | Reward:  -3.266 | Epsilon: 0.0100 | Loss: 74.3216
Episode  7800 | Reward:  -5.304 | Epsilon: 0.0100 | Loss: 61.7928
Episode  7850 | Reward:  -9.942 | Epsilon: 0.0100 | Loss: 100.6148
Episode  7900 | Reward: -11.900 | Epsilon: 0.0100 | Loss: 113.1662
Episode  7950 | Reward: -12.117 | Epsilon: 0.0100 | Loss: 46.0757
Episode  8000 | Reward: -12.862 | Epsilon: 0.0100 | Loss: 77.2470
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:10).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:10)
Episode  8050 | Reward: -11.943 | Epsilon: 0.0100 | Loss: 84.0731
Episode  8100 | Reward: -10.654 | Epsilon: 0.0100 | Loss: 68.2652
Episode  8150 | Reward:  -8.395 | Epsilon: 0.0100 | Loss: 60.3184
Episode  8200 | Reward: -11.205 | Epsilon: 0.0100 | Loss: 105.0109
Episode  8250 | Reward: -11.346 | Epsilon: 0.0100 | Loss: 80.5014
Episode  8300 | Reward: -11.600 | Epsilon: 0.0100 | Loss: 77.5067
Episode  8350 | Reward:  -7.557 | Epsilon: 0.0100 | Loss: 89.4293
Episode  8400 | Reward:  -8.498 | Epsilon: 0.0100 | Loss: 99.3422
Episode  8450 | Reward:  -9.479 | Epsilon: 0.0100 | Loss: 72.3873
Episode  8500 | Reward:  -8.145 | Epsilon: 0.0100 | Loss: 98.2873
Episode  8550 | Reward:  -9.413 | Epsilon: 0.0100 | Loss: 58.9189
Episode  8600 | Reward:  -8.590 | Epsilon: 0.0100 | Loss: 62.1140
Episode  8650 | Reward:  -9.834 | Epsilon: 0.0100 | Loss: 68.0177
Episode  8700 | Reward: -11.862 | Epsilon: 0.0100 | Loss: 73.0015
Episode  8750 | Reward: -12.377 | Epsilon: 0.0100 | Loss: 81.8613
Episode  8800 | Reward:  -7.961 | Epsilon: 0.0100 | Loss: 69.7765
Episode  8850 | Reward: -10.276 | Epsilon: 0.0100 | Loss: 102.8646
Episode  8900 | Reward: -10.720 | Epsilon: 0.0100 | Loss: 64.7842
Episode  8950 | Reward: -12.469 | Epsilon: 0.0100 | Loss: 73.2379
Episode  9000 | Reward:  -7.482 | Epsilon: 0.0100 | Loss: 73.0620
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:11).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:11)
Episode  9050 | Reward:  -9.895 | Epsilon: 0.0100 | Loss: 131.1244
Episode  9100 | Reward: -11.420 | Epsilon: 0.0100 | Loss: 70.1436
Episode  9150 | Reward:  -9.665 | Epsilon: 0.0100 | Loss: 73.7771
Episode  9200 | Reward: -12.389 | Epsilon: 0.0100 | Loss: 96.9505
Episode  9250 | Reward:  -9.030 | Epsilon: 0.0100 | Loss: 102.7179
Episode  9300 | Reward: -10.665 | Epsilon: 0.0100 | Loss: 92.7043
Episode  9350 | Reward: -11.753 | Epsilon: 0.0100 | Loss: 52.8887
Episode  9400 | Reward: -10.318 | Epsilon: 0.0100 | Loss: 78.8256
Episode  9450 | Reward:  -7.938 | Epsilon: 0.0100 | Loss: 77.1519
Episode  9500 | Reward:  -8.874 | Epsilon: 0.0100 | Loss: 91.2457
Episode  9550 | Reward: -14.636 | Epsilon: 0.0100 | Loss: 107.0646
Episode  9600 | Reward:  -9.656 | Epsilon: 0.0100 | Loss: 71.5824
Episode  9650 | Reward:  -8.826 | Epsilon: 0.0100 | Loss: 100.9509
Episode  9700 | Reward: -12.669 | Epsilon: 0.0100 | Loss: 70.9840
Episode  9750 | Reward:  -9.251 | Epsilon: 0.0100 | Loss: 96.1187
Episode  9800 | Reward: -11.105 | Epsilon: 0.0100 | Loss: 76.2984
Episode  9850 | Reward: -11.269 | Epsilon: 0.0100 | Loss: 72.5080
Episode  9900 | Reward: -11.128 | Epsilon: 0.0100 | Loss: 85.8806
Episode  9950 | Reward:  -9.935 | Epsilon: 0.0100 | Loss: 83.6755
Episode 10000 | Reward: -12.629 | Epsilon: 0.0100 | Loss: 82.0258
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:13).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:13)
Episode 10050 | Reward:  -8.307 | Epsilon: 0.0100 | Loss: 75.7571
Episode 10100 | Reward: -11.600 | Epsilon: 0.0100 | Loss: 81.8073
Episode 10150 | Reward: -11.429 | Epsilon: 0.0100 | Loss: 72.2773
Episode 10200 | Reward: -13.680 | Epsilon: 0.0100 | Loss: 71.2362
Episode 10250 | Reward: -12.187 | Epsilon: 0.0100 | Loss: 68.0803
Episode 10300 | Reward: -10.439 | Epsilon: 0.0100 | Loss: 83.5779
Episode 10350 | Reward: -13.284 | Epsilon: 0.0100 | Loss: 84.4445
Episode 10400 | Reward:  -9.631 | Epsilon: 0.0100 | Loss: 54.5085
Episode 10450 | Reward:  -9.319 | Epsilon: 0.0100 | Loss: 66.3815
Episode 10500 | Reward:  -7.351 | Epsilon: 0.0100 | Loss: 52.3676
Episode 10550 | Reward: -10.015 | Epsilon: 0.0100 | Loss: 72.8486
Episode 10600 | Reward:  -7.348 | Epsilon: 0.0100 | Loss: 98.2404
Episode 10650 | Reward: -10.879 | Epsilon: 0.0100 | Loss: 64.2130
Episode 10700 | Reward: -12.854 | Epsilon: 0.0100 | Loss: 74.0647
Episode 10750 | Reward: -11.691 | Epsilon: 0.0100 | Loss: 77.2395
Episode 10800 | Reward: -11.097 | Epsilon: 0.0100 | Loss: 62.8591
Episode 10850 | Reward:  -8.605 | Epsilon: 0.0100 | Loss: 85.8048
Episode 10900 | Reward:  -8.873 | Epsilon: 0.0100 | Loss: 66.7351
Episode 10950 | Reward:  -9.698 | Epsilon: 0.0100 | Loss: 80.6429
Episode 11000 | Reward: -11.075 | Epsilon: 0.0100 | Loss: 71.2564
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:14).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:14)
Episode 11050 | Reward: -12.247 | Epsilon: 0.0100 | Loss: 87.5834
Episode 11100 | Reward: -10.041 | Epsilon: 0.0100 | Loss: 56.5179
Episode 11150 | Reward:  -5.142 | Epsilon: 0.0100 | Loss: 108.8777
Episode 11200 | Reward:  -8.217 | Epsilon: 0.0100 | Loss: 86.7085
Episode 11250 | Reward: -10.092 | Epsilon: 0.0100 | Loss: 93.5434
Episode 11300 | Reward:  -9.273 | Epsilon: 0.0100 | Loss: 53.9877
Episode 11350 | Reward:  -9.450 | Epsilon: 0.0100 | Loss: 49.9901
Episode 11400 | Reward:  -5.696 | Epsilon: 0.0100 | Loss: 96.9546
Episode 11450 | Reward:  -7.797 | Epsilon: 0.0100 | Loss: 70.5246
Episode 11500 | Reward: -10.180 | Epsilon: 0.0100 | Loss: 54.0214
Episode 11550 | Reward: -11.273 | Epsilon: 0.0100 | Loss: 54.0166
Episode 11600 | Reward: -12.994 | Epsilon: 0.0100 | Loss: 79.2704
Episode 11650 | Reward: -12.260 | Epsilon: 0.0100 | Loss: 100.9541
Episode 11700 | Reward:  -9.384 | Epsilon: 0.0100 | Loss: 73.2936
Episode 11750 | Reward:  -9.013 | Epsilon: 0.0100 | Loss: 99.8323
Episode 11800 | Reward: -10.812 | Epsilon: 0.0100 | Loss: 114.4815
Episode 11850 | Reward: -10.073 | Epsilon: 0.0100 | Loss: 81.1863
Episode 11900 | Reward:  -9.355 | Epsilon: 0.0100 | Loss: 74.2019
Episode 11950 | Reward:  -8.305 | Epsilon: 0.0100 | Loss: 47.4358
Episode 12000 | Reward:  -8.506 | Epsilon: 0.0100 | Loss: 80.0046
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:16).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:16)
Episode 12050 | Reward:  -6.862 | Epsilon: 0.0100 | Loss: 53.8278
Episode 12100 | Reward:  -9.611 | Epsilon: 0.0100 | Loss: 69.9109
Episode 12150 | Reward: -11.208 | Epsilon: 0.0100 | Loss: 63.7928
Episode 12200 | Reward:  -6.329 | Epsilon: 0.0100 | Loss: 74.1851
Episode 12250 | Reward:  -7.751 | Epsilon: 0.0100 | Loss: 97.8943
Episode 12300 | Reward:  -6.375 | Epsilon: 0.0100 | Loss: 67.9166
Episode 12350 | Reward:  -7.456 | Epsilon: 0.0100 | Loss: 70.7215
Episode 12400 | Reward:  -6.934 | Epsilon: 0.0100 | Loss: 71.2704
Episode 12450 | Reward:  -9.447 | Epsilon: 0.0100 | Loss: 78.4776
Episode 12500 | Reward:  -9.905 | Epsilon: 0.0100 | Loss: 39.6862
Episode 12550 | Reward:  -6.054 | Epsilon: 0.0100 | Loss: 66.1639
Episode 12600 | Reward: -10.394 | Epsilon: 0.0100 | Loss: 71.0086
Episode 12650 | Reward: -10.354 | Epsilon: 0.0100 | Loss: 77.0188
Episode 12700 | Reward:  -8.516 | Epsilon: 0.0100 | Loss: 101.8833
Episode 12750 | Reward: -11.756 | Epsilon: 0.0100 | Loss: 83.6360
Episode 12800 | Reward:  -8.903 | Epsilon: 0.0100 | Loss: 104.7014
Episode 12850 | Reward:  -6.837 | Epsilon: 0.0100 | Loss: 64.2969
Episode 12900 | Reward:  -5.394 | Epsilon: 0.0100 | Loss: 61.4811
Episode 12950 | Reward:  -5.269 | Epsilon: 0.0100 | Loss: 75.9679
Episode 13000 | Reward:  -9.587 | Epsilon: 0.0100 | Loss: 73.8080
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:17).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:17)
Episode 13050 | Reward:  -5.091 | Epsilon: 0.0100 | Loss: 69.9782
Episode 13100 | Reward: -10.962 | Epsilon: 0.0100 | Loss: 51.0354
Episode 13150 | Reward:  -9.467 | Epsilon: 0.0100 | Loss: 68.1595
Episode 13200 | Reward:  -7.466 | Epsilon: 0.0100 | Loss: 83.5542
Episode 13250 | Reward:  -9.445 | Epsilon: 0.0100 | Loss: 53.0122
Episode 13300 | Reward:  -6.385 | Epsilon: 0.0100 | Loss: 88.9093
Episode 13350 | Reward:  -9.546 | Epsilon: 0.0100 | Loss: 79.6020
Episode 13400 | Reward:  -8.542 | Epsilon: 0.0100 | Loss: 97.8291
Episode 13450 | Reward:  -7.851 | Epsilon: 0.0100 | Loss: 99.9631
Episode 13500 | Reward:  -8.313 | Epsilon: 0.0100 | Loss: 48.1429
Episode 13550 | Reward:  -8.381 | Epsilon: 0.0100 | Loss: 55.6705
Episode 13600 | Reward:  -6.124 | Epsilon: 0.0100 | Loss: 84.3408
Episode 13650 | Reward:  -9.279 | Epsilon: 0.0100 | Loss: 92.6107
Episode 13700 | Reward:  -8.221 | Epsilon: 0.0100 | Loss: 54.3256
Episode 13750 | Reward:  -8.730 | Epsilon: 0.0100 | Loss: 52.1895
Episode 13800 | Reward:  -7.351 | Epsilon: 0.0100 | Loss: 65.1464
Episode 13850 | Reward:  -5.552 | Epsilon: 0.0100 | Loss: 89.1469
Episode 13900 | Reward:  -6.945 | Epsilon: 0.0100 | Loss: 77.5335
Episode 13950 | Reward: -11.364 | Epsilon: 0.0100 | Loss: 69.2132
Episode 14000 | Reward:  -7.532 | Epsilon: 0.0100 | Loss: 53.6413
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:19).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:19)
Episode 14050 | Reward:  -8.994 | Epsilon: 0.0100 | Loss: 80.1793
Episode 14100 | Reward:  -7.587 | Epsilon: 0.0100 | Loss: 77.0694
Episode 14150 | Reward:  -8.345 | Epsilon: 0.0100 | Loss: 84.2555
Episode 14200 | Reward:  -4.916 | Epsilon: 0.0100 | Loss: 117.3615
Episode 14250 | Reward:  -7.323 | Epsilon: 0.0100 | Loss: 91.9452
Episode 14300 | Reward:  -7.322 | Epsilon: 0.0100 | Loss: 64.0743
Episode 14350 | Reward:  -8.318 | Epsilon: 0.0100 | Loss: 58.5516
Episode 14400 | Reward:  -6.203 | Epsilon: 0.0100 | Loss: 68.4861
Episode 14450 | Reward:  -7.902 | Epsilon: 0.0100 | Loss: 66.3572
Episode 14500 | Reward: -11.834 | Epsilon: 0.0100 | Loss: 113.8204
Episode 14550 | Reward:  -6.759 | Epsilon: 0.0100 | Loss: 80.8981
Episode 14600 | Reward:  -7.734 | Epsilon: 0.0100 | Loss: 81.0659
Episode 14650 | Reward:  -4.393 | Epsilon: 0.0100 | Loss: 72.8279
Episode 14700 | Reward:  -9.407 | Epsilon: 0.0100 | Loss: 94.1188
Episode 14750 | Reward:  -6.411 | Epsilon: 0.0100 | Loss: 43.0600
Episode 14800 | Reward:  -7.149 | Epsilon: 0.0100 | Loss: 84.8885
Episode 14850 | Reward:  -7.306 | Epsilon: 0.0100 | Loss: 71.3477
Episode 14900 | Reward:  -6.245 | Epsilon: 0.0100 | Loss: 58.1630
Episode 14950 | Reward:  -5.544 | Epsilon: 0.0100 | Loss: 73.1855
Episode 15000 | Reward: -11.940 | Epsilon: 0.0100 | Loss: 74.4906
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:20).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:20)
Episode 15050 | Reward:  -9.376 | Epsilon: 0.0100 | Loss: 86.3570
Episode 15100 | Reward: -10.415 | Epsilon: 0.0100 | Loss: 92.4041
Episode 15150 | Reward:  -6.805 | Epsilon: 0.0100 | Loss: 44.9628
Episode 15200 | Reward:  -6.123 | Epsilon: 0.0100 | Loss: 69.2269
Episode 15250 | Reward:  -5.011 | Epsilon: 0.0100 | Loss: 65.8728
Episode 15300 | Reward:  -9.622 | Epsilon: 0.0100 | Loss: 58.8416
Episode 15350 | Reward: -11.937 | Epsilon: 0.0100 | Loss: 63.0158
Episode 15400 | Reward: -10.862 | Epsilon: 0.0100 | Loss: 89.9394
Episode 15450 | Reward: -10.684 | Epsilon: 0.0100 | Loss: 80.9030
Episode 15500 | Reward:  -8.012 | Epsilon: 0.0100 | Loss: 81.7786
Episode 15550 | Reward:  -9.495 | Epsilon: 0.0100 | Loss: 51.8973
Episode 15600 | Reward: -11.561 | Epsilon: 0.0100 | Loss: 54.1565
Episode 15650 | Reward:  -6.867 | Epsilon: 0.0100 | Loss: 70.4574
Episode 15700 | Reward:  -7.737 | Epsilon: 0.0100 | Loss: 56.4583
Episode 15750 | Reward:  -8.539 | Epsilon: 0.0100 | Loss: 70.1241
Episode 15800 | Reward: -16.310 | Epsilon: 0.0100 | Loss: 65.4350
Episode 15850 | Reward: -14.340 | Epsilon: 0.0100 | Loss: 56.0470
Episode 15900 | Reward: -18.470 | Epsilon: 0.0100 | Loss: 59.8440
Episode 15950 | Reward: -14.627 | Epsilon: 0.0100 | Loss: 61.4871
Episode 16000 | Reward: -16.204 | Epsilon: 0.0100 | Loss: 98.4373
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:22).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:22)
Episode 16050 | Reward: -19.264 | Epsilon: 0.0100 | Loss: 63.4827
Episode 16100 | Reward: -19.630 | Epsilon: 0.0100 | Loss: 72.0823
Episode 16150 | Reward: -14.975 | Epsilon: 0.0100 | Loss: 63.0930
Episode 16200 | Reward: -13.090 | Epsilon: 0.0100 | Loss: 83.4958
Episode 16250 | Reward: -13.484 | Epsilon: 0.0100 | Loss: 79.1622
Episode 16300 | Reward: -13.831 | Epsilon: 0.0100 | Loss: 59.3476
Episode 16350 | Reward: -18.661 | Epsilon: 0.0100 | Loss: 80.5046
Episode 16400 | Reward:  -9.922 | Epsilon: 0.0100 | Loss: 67.6985
Episode 16450 | Reward: -12.271 | Epsilon: 0.0100 | Loss: 94.5008
Episode 16500 | Reward: -16.739 | Epsilon: 0.0100 | Loss: 71.4685
Episode 16550 | Reward: -15.151 | Epsilon: 0.0100 | Loss: 94.2277
Episode 16600 | Reward: -11.950 | Epsilon: 0.0100 | Loss: 54.1812
Episode 16650 | Reward: -10.581 | Epsilon: 0.0100 | Loss: 115.8436
Episode 16700 | Reward: -10.241 | Epsilon: 0.0100 | Loss: 71.4935
Episode 16750 | Reward:  -8.252 | Epsilon: 0.0100 | Loss: 66.8439
Episode 16800 | Reward: -11.716 | Epsilon: 0.0100 | Loss: 63.4724
Episode 16850 | Reward:  -8.679 | Epsilon: 0.0100 | Loss: 73.9093
Episode 16900 | Reward:  -7.051 | Epsilon: 0.0100 | Loss: 86.3496
Episode 16950 | Reward:  -4.345 | Epsilon: 0.0100 | Loss: 80.7939
Episode 17000 | Reward: -10.304 | Epsilon: 0.0100 | Loss: 95.2689
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:23).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:23)
Episode 17050 | Reward: -10.754 | Epsilon: 0.0100 | Loss: 81.9002
Episode 17100 | Reward:  -5.866 | Epsilon: 0.0100 | Loss: 104.6557
Episode 17150 | Reward: -10.646 | Epsilon: 0.0100 | Loss: 67.8549
Episode 17200 | Reward: -10.685 | Epsilon: 0.0100 | Loss: 117.1006
Episode 17250 | Reward: -12.621 | Epsilon: 0.0100 | Loss: 68.9054
Episode 17300 | Reward: -13.216 | Epsilon: 0.0100 | Loss: 76.4001
Episode 17350 | Reward: -16.034 | Epsilon: 0.0100 | Loss: 63.2106
Episode 17400 | Reward:  -9.318 | Epsilon: 0.0100 | Loss: 86.2055
Episode 17450 | Reward:  -6.412 | Epsilon: 0.0100 | Loss: 74.3925
Episode 17500 | Reward:  -7.219 | Epsilon: 0.0100 | Loss: 69.2243
Episode 17550 | Reward:  -4.905 | Epsilon: 0.0100 | Loss: 81.6175
Episode 17600 | Reward:  -9.961 | Epsilon: 0.0100 | Loss: 82.0536
Episode 17650 | Reward: -13.003 | Epsilon: 0.0100 | Loss: 96.4948
Episode 17700 | Reward:  -9.349 | Epsilon: 0.0100 | Loss: 80.4257
Episode 17750 | Reward:  -6.191 | Epsilon: 0.0100 | Loss: 69.8746
Episode 17800 | Reward:  -9.969 | Epsilon: 0.0100 | Loss: 105.0398
Episode 17850 | Reward:  -8.316 | Epsilon: 0.0100 | Loss: 66.6458
Episode 17900 | Reward:  -8.619 | Epsilon: 0.0100 | Loss: 60.3705
Episode 17950 | Reward: -11.766 | Epsilon: 0.0100 | Loss: 79.7041
Episode 18000 | Reward:  -6.006 | Epsilon: 0.0100 | Loss: 82.1410
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:24).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:24)
Episode 18050 | Reward: -10.545 | Epsilon: 0.0100 | Loss: 58.4658
Episode 18100 | Reward:  -8.357 | Epsilon: 0.0100 | Loss: 61.4060
Episode 18150 | Reward:  -8.054 | Epsilon: 0.0100 | Loss: 98.9840
Episode 18200 | Reward:  -9.488 | Epsilon: 0.0100 | Loss: 92.0797
Episode 18250 | Reward: -11.860 | Epsilon: 0.0100 | Loss: 124.1897
Episode 18300 | Reward: -10.609 | Epsilon: 0.0100 | Loss: 89.3586
Episode 18350 | Reward:  -8.871 | Epsilon: 0.0100 | Loss: 74.6688
Episode 18400 | Reward:  -3.795 | Epsilon: 0.0100 | Loss: 87.0903
Episode 18450 | Reward:  -7.383 | Epsilon: 0.0100 | Loss: 83.2764
Episode 18500 | Reward:  -7.584 | Epsilon: 0.0100 | Loss: 89.6314
Episode 18550 | Reward:  -4.518 | Epsilon: 0.0100 | Loss: 106.3624
Episode 18600 | Reward:  -6.147 | Epsilon: 0.0100 | Loss: 68.5675
Episode 18650 | Reward:  -5.874 | Epsilon: 0.0100 | Loss: 64.4669
Episode 18700 | Reward:  -8.093 | Epsilon: 0.0100 | Loss: 73.8418
Episode 18750 | Reward:  -4.324 | Epsilon: 0.0100 | Loss: 51.3839
Episode 18800 | Reward:  -4.953 | Epsilon: 0.0100 | Loss: 104.1025
Episode 18850 | Reward:  -5.747 | Epsilon: 0.0100 | Loss: 83.8645
Episode 18900 | Reward:  -7.359 | Epsilon: 0.0100 | Loss: 78.7539
Episode 18950 | Reward:  -8.117 | Epsilon: 0.0100 | Loss: 75.3167
Episode 19000 | Reward: -12.917 | Epsilon: 0.0100 | Loss: 110.0681
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:26).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:26)
Episode 19050 | Reward:  -7.021 | Epsilon: 0.0100 | Loss: 60.2419
Episode 19100 | Reward: -10.222 | Epsilon: 0.0100 | Loss: 93.4620
Episode 19150 | Reward:  -9.556 | Epsilon: 0.0100 | Loss: 65.8400
Episode 19200 | Reward:  -7.293 | Epsilon: 0.0100 | Loss: 95.2537
Episode 19250 | Reward:  -3.373 | Epsilon: 0.0100 | Loss: 89.5305
Episode 19300 | Reward:  -7.218 | Epsilon: 0.0100 | Loss: 68.6698
Episode 19350 | Reward:  -6.520 | Epsilon: 0.0100 | Loss: 82.7015
Episode 19400 | Reward:  -6.800 | Epsilon: 0.0100 | Loss: 66.8151
Episode 19450 | Reward:  -6.010 | Epsilon: 0.0100 | Loss: 78.9262
Episode 19500 | Reward: -12.143 | Epsilon: 0.0100 | Loss: 80.4869
Episode 19550 | Reward: -10.983 | Epsilon: 0.0100 | Loss: 62.4631
Episode 19600 | Reward:  -9.336 | Epsilon: 0.0100 | Loss: 75.2907
Episode 19650 | Reward:  -7.443 | Epsilon: 0.0100 | Loss: 59.9748
Episode 19700 | Reward:  -7.357 | Epsilon: 0.0100 | Loss: 83.5015
Episode 19750 | Reward:  -7.243 | Epsilon: 0.0100 | Loss: 87.5951
Episode 19800 | Reward:  -8.713 | Epsilon: 0.0100 | Loss: 106.1479
Episode 19850 | Reward:  -7.226 | Epsilon: 0.0100 | Loss: 73.2150
Episode 19900 | Reward:  -7.910 | Epsilon: 0.0100 | Loss: 69.4851
Episode 19950 | Reward:  -9.812 | Epsilon: 0.0100 | Loss: 69.0912
Episode 20000 | Reward:  -9.914 | Epsilon: 0.0100 | Loss: 67.3869
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:27).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:27)
Episode 20050 | Reward:  -7.386 | Epsilon: 0.0100 | Loss: 94.8332
Episode 20100 | Reward:  -8.732 | Epsilon: 0.0100 | Loss: 99.7474
Episode 20150 | Reward: -12.403 | Epsilon: 0.0100 | Loss: 69.8435
Episode 20200 | Reward: -11.033 | Epsilon: 0.0100 | Loss: 74.2018
Episode 20250 | Reward: -10.867 | Epsilon: 0.0100 | Loss: 71.9532
Episode 20300 | Reward: -10.374 | Epsilon: 0.0100 | Loss: 78.4614
Episode 20350 | Reward:  -7.873 | Epsilon: 0.0100 | Loss: 99.9565
Episode 20400 | Reward:  -7.008 | Epsilon: 0.0100 | Loss: 83.8672
Episode 20450 | Reward:  -4.455 | Epsilon: 0.0100 | Loss: 85.8553
Episode 20500 | Reward: -10.884 | Epsilon: 0.0100 | Loss: 79.9407
Episode 20550 | Reward:  -9.377 | Epsilon: 0.0100 | Loss: 95.7011
Episode 20600 | Reward:  -9.367 | Epsilon: 0.0100 | Loss: 94.3465
Episode 20650 | Reward: -10.143 | Epsilon: 0.0100 | Loss: 69.7610
Episode 20700 | Reward: -10.654 | Epsilon: 0.0100 | Loss: 92.1731
Episode 20750 | Reward: -10.764 | Epsilon: 0.0100 | Loss: 106.2423
Episode 20800 | Reward:  -9.925 | Epsilon: 0.0100 | Loss: 85.9498
Episode 20850 | Reward: -10.749 | Epsilon: 0.0100 | Loss: 80.9792
Episode 20900 | Reward: -10.812 | Epsilon: 0.0100 | Loss: 87.7080
Episode 20950 | Reward:  -9.675 | Epsilon: 0.0100 | Loss: 115.4290
Episode 21000 | Reward:  -6.829 | Epsilon: 0.0100 | Loss: 81.5534
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:29).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:29)
Episode 21050 | Reward: -10.984 | Epsilon: 0.0100 | Loss: 74.0813
Episode 21100 | Reward: -11.797 | Epsilon: 0.0100 | Loss: 63.5717
Episode 21150 | Reward:  -7.720 | Epsilon: 0.0100 | Loss: 70.0814
Episode 21200 | Reward: -10.787 | Epsilon: 0.0100 | Loss: 92.1852
Episode 21250 | Reward: -11.032 | Epsilon: 0.0100 | Loss: 73.7820
Episode 21300 | Reward:  -9.976 | Epsilon: 0.0100 | Loss: 70.0199
Episode 21350 | Reward: -10.868 | Epsilon: 0.0100 | Loss: 47.0877
Episode 21400 | Reward:  -8.304 | Epsilon: 0.0100 | Loss: 73.8898
Episode 21450 | Reward:  -4.321 | Epsilon: 0.0100 | Loss: 73.0797
Episode 21500 | Reward:  -7.751 | Epsilon: 0.0100 | Loss: 59.3720
Episode 21550 | Reward:  -7.784 | Epsilon: 0.0100 | Loss: 93.9553
Episode 21600 | Reward:  -1.945 | Epsilon: 0.0100 | Loss: 112.5901
Episode 21650 | Reward:  -5.833 | Epsilon: 0.0100 | Loss: 71.4493
Episode 21700 | Reward:  -5.537 | Epsilon: 0.0100 | Loss: 100.7295
Episode 21750 | Reward:  -4.263 | Epsilon: 0.0100 | Loss: 70.6963
Episode 21800 | Reward:  -8.190 | Epsilon: 0.0100 | Loss: 81.8180
Episode 21850 | Reward:  -8.154 | Epsilon: 0.0100 | Loss: 83.6411
Episode 21900 | Reward:  -7.401 | Epsilon: 0.0100 | Loss: 80.5970
Episode 21950 | Reward:  -9.175 | Epsilon: 0.0100 | Loss: 68.4386
Episode 22000 | Reward:  -6.101 | Epsilon: 0.0100 | Loss: 77.7157
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:30).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:30)
Episode 22050 | Reward:  -9.797 | Epsilon: 0.0100 | Loss: 76.9551
Episode 22100 | Reward:  -8.651 | Epsilon: 0.0100 | Loss: 69.2789
Episode 22150 | Reward:  -8.921 | Epsilon: 0.0100 | Loss: 92.4045
Episode 22200 | Reward:  -7.685 | Epsilon: 0.0100 | Loss: 62.0319
Episode 22250 | Reward:  -7.503 | Epsilon: 0.0100 | Loss: 105.2613
Episode 22300 | Reward:  -9.572 | Epsilon: 0.0100 | Loss: 84.5821
Episode 22350 | Reward: -11.468 | Epsilon: 0.0100 | Loss: 69.7608
Episode 22400 | Reward:  -9.666 | Epsilon: 0.0100 | Loss: 98.7183
Episode 22450 | Reward:  -9.732 | Epsilon: 0.0100 | Loss: 110.6451
Episode 22500 | Reward:  -9.534 | Epsilon: 0.0100 | Loss: 88.0323
Episode 22550 | Reward:  -7.857 | Epsilon: 0.0100 | Loss: 84.5523
Episode 22600 | Reward:  -5.347 | Epsilon: 0.0100 | Loss: 62.2974
Episode 22650 | Reward:  -7.641 | Epsilon: 0.0100 | Loss: 60.0578
Episode 22700 | Reward:  -6.939 | Epsilon: 0.0100 | Loss: 59.1891
Episode 22750 | Reward:  -9.813 | Epsilon: 0.0100 | Loss: 83.4957
Episode 22800 | Reward:  -6.219 | Epsilon: 0.0100 | Loss: 65.9707
Episode 22850 | Reward: -11.723 | Epsilon: 0.0100 | Loss: 98.6871
Episode 22900 | Reward: -10.109 | Epsilon: 0.0100 | Loss: 80.9195
Episode 22950 | Reward:  -5.647 | Epsilon: 0.0100 | Loss: 98.2929
Episode 23000 | Reward:  -6.041 | Epsilon: 0.0100 | Loss: 115.7827
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:32).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:32)
Episode 23050 | Reward:  -7.258 | Epsilon: 0.0100 | Loss: 66.0262
Episode 23100 | Reward:  -5.823 | Epsilon: 0.0100 | Loss: 78.2079
Episode 23150 | Reward:  -2.486 | Epsilon: 0.0100 | Loss: 103.8716
Episode 23200 | Reward:  -7.049 | Epsilon: 0.0100 | Loss: 54.0994
Episode 23250 | Reward:  -7.157 | Epsilon: 0.0100 | Loss: 76.2633
Episode 23300 | Reward:  -6.121 | Epsilon: 0.0100 | Loss: 78.9059
Episode 23350 | Reward:  -6.870 | Epsilon: 0.0100 | Loss: 72.7417
Episode 23400 | Reward:  -9.942 | Epsilon: 0.0100 | Loss: 90.6501
Episode 23450 | Reward:  -8.604 | Epsilon: 0.0100 | Loss: 103.8447
Episode 23500 | Reward:  -9.460 | Epsilon: 0.0100 | Loss: 72.6537
Episode 23550 | Reward:  -7.437 | Epsilon: 0.0100 | Loss: 72.2286
Episode 23600 | Reward: -10.513 | Epsilon: 0.0100 | Loss: 64.0221
Episode 23650 | Reward:  -5.930 | Epsilon: 0.0100 | Loss: 105.8852
Episode 23700 | Reward:  -6.071 | Epsilon: 0.0100 | Loss: 82.1539
Episode 23750 | Reward:  -9.492 | Epsilon: 0.0100 | Loss: 69.2595
Episode 23800 | Reward: -11.586 | Epsilon: 0.0100 | Loss: 106.5381
Episode 23850 | Reward:  -9.934 | Epsilon: 0.0100 | Loss: 74.1248
Episode 23900 | Reward:  -8.685 | Epsilon: 0.0100 | Loss: 70.0292
Episode 23950 | Reward:  -6.289 | Epsilon: 0.0100 | Loss: 119.8676
Episode 24000 | Reward:  -6.528 | Epsilon: 0.0100 | Loss: 89.1297
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:33).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:33)
Episode 24050 | Reward:  -6.435 | Epsilon: 0.0100 | Loss: 67.3728
Episode 24100 | Reward: -12.245 | Epsilon: 0.0100 | Loss: 75.8810
Episode 24150 | Reward: -12.650 | Epsilon: 0.0100 | Loss: 76.5602
Episode 24200 | Reward: -12.426 | Epsilon: 0.0100 | Loss: 74.3334
Episode 24250 | Reward:  -7.048 | Epsilon: 0.0100 | Loss: 77.1389
Episode 24300 | Reward: -11.346 | Epsilon: 0.0100 | Loss: 58.5395
Episode 24350 | Reward:  -9.629 | Epsilon: 0.0100 | Loss: 82.2776
Episode 24400 | Reward: -12.505 | Epsilon: 0.0100 | Loss: 63.1489
Episode 24450 | Reward: -10.050 | Epsilon: 0.0100 | Loss: 98.0023
Episode 24500 | Reward: -13.134 | Epsilon: 0.0100 | Loss: 123.4893
Episode 24550 | Reward: -10.036 | Epsilon: 0.0100 | Loss: 75.4805
Episode 24600 | Reward:  -9.182 | Epsilon: 0.0100 | Loss: 91.6632
Episode 24650 | Reward:  -6.268 | Epsilon: 0.0100 | Loss: 107.0955
Episode 24700 | Reward:  -7.003 | Epsilon: 0.0100 | Loss: 76.7329
Episode 24750 | Reward: -10.926 | Epsilon: 0.0100 | Loss: 63.3851
Episode 24800 | Reward:  -9.058 | Epsilon: 0.0100 | Loss: 93.5513
Episode 24850 | Reward:  -7.754 | Epsilon: 0.0100 | Loss: 67.5327
Episode 24900 | Reward:  -8.363 | Epsilon: 0.0100 | Loss: 99.8538
Episode 24950 | Reward: -11.232 | Epsilon: 0.0100 | Loss: 91.6765
Episode 25000 | Reward:  -5.588 | Epsilon: 0.0100 | Loss: 55.7932
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:34).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:34)
Episode 25050 | Reward:  -6.580 | Epsilon: 0.0100 | Loss: 98.3009
Episode 25100 | Reward:  -9.551 | Epsilon: 0.0100 | Loss: 60.1534
Episode 25150 | Reward:  -4.898 | Epsilon: 0.0100 | Loss: 79.0090
Episode 25200 | Reward:  -5.190 | Epsilon: 0.0100 | Loss: 67.2080
Episode 25250 | Reward:  -6.901 | Epsilon: 0.0100 | Loss: 93.4492
Episode 25300 | Reward:  -5.145 | Epsilon: 0.0100 | Loss: 60.4693
Episode 25350 | Reward:  -6.717 | Epsilon: 0.0100 | Loss: 70.2050
Episode 25400 | Reward:  -5.848 | Epsilon: 0.0100 | Loss: 86.4371
Episode 25450 | Reward:  -6.908 | Epsilon: 0.0100 | Loss: 99.7026
Episode 25500 | Reward:  -6.301 | Epsilon: 0.0100 | Loss: 58.8960
Episode 25550 | Reward:  -5.886 | Epsilon: 0.0100 | Loss: 82.8792
Episode 25600 | Reward:  -7.764 | Epsilon: 0.0100 | Loss: 90.2758
Episode 25650 | Reward:  -4.885 | Epsilon: 0.0100 | Loss: 59.9839
Episode 25700 | Reward:  -8.593 | Epsilon: 0.0100 | Loss: 77.5482
Episode 25750 | Reward:  -6.683 | Epsilon: 0.0100 | Loss: 96.2669
Episode 25800 | Reward: -11.646 | Epsilon: 0.0100 | Loss: 93.0363
Episode 25850 | Reward:  -9.171 | Epsilon: 0.0100 | Loss: 103.2447
Episode 25900 | Reward: -11.760 | Epsilon: 0.0100 | Loss: 102.4385
Episode 25950 | Reward: -11.425 | Epsilon: 0.0100 | Loss: 82.9268
Episode 26000 | Reward:  -5.728 | Epsilon: 0.0100 | Loss: 86.1719
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:36).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:36)
Episode 26050 | Reward:  -9.084 | Epsilon: 0.0100 | Loss: 118.2635
Episode 26100 | Reward:  -9.125 | Epsilon: 0.0100 | Loss: 67.7787
Episode 26150 | Reward:  -7.051 | Epsilon: 0.0100 | Loss: 108.6369
Episode 26200 | Reward:  -7.228 | Epsilon: 0.0100 | Loss: 65.7718
Episode 26250 | Reward:  -5.458 | Epsilon: 0.0100 | Loss: 96.3169
Episode 26300 | Reward:  -6.002 | Epsilon: 0.0100 | Loss: 99.1494
Episode 26350 | Reward:  -5.079 | Epsilon: 0.0100 | Loss: 98.4003
Episode 26400 | Reward:  -8.397 | Epsilon: 0.0100 | Loss: 86.2122
Episode 26450 | Reward:  -7.475 | Epsilon: 0.0100 | Loss: 88.9160
Episode 26500 | Reward:  -6.015 | Epsilon: 0.0100 | Loss: 64.3463
Episode 26550 | Reward:  -5.880 | Epsilon: 0.0100 | Loss: 93.5465
Episode 26600 | Reward:  -4.748 | Epsilon: 0.0100 | Loss: 120.6274
Episode 26650 | Reward:  -8.206 | Epsilon: 0.0100 | Loss: 93.8547
Episode 26700 | Reward:  -3.835 | Epsilon: 0.0100 | Loss: 98.4424
Episode 26750 | Reward:  -6.263 | Epsilon: 0.0100 | Loss: 83.2745
Episode 26800 | Reward:  -6.606 | Epsilon: 0.0100 | Loss: 77.0186
Episode 26850 | Reward:  -6.772 | Epsilon: 0.0100 | Loss: 92.5589
Episode 26900 | Reward: -10.983 | Epsilon: 0.0100 | Loss: 101.3720
Episode 26950 | Reward: -11.312 | Epsilon: 0.0100 | Loss: 67.5065
Episode 27000 | Reward:  -8.827 | Epsilon: 0.0100 | Loss: 79.6498
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:37).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:37)
Episode 27050 | Reward:  -6.925 | Epsilon: 0.0100 | Loss: 92.1043
Episode 27100 | Reward:  -8.092 | Epsilon: 0.0100 | Loss: 76.6978
Episode 27150 | Reward:  -6.463 | Epsilon: 0.0100 | Loss: 89.0167
Episode 27200 | Reward:  -4.833 | Epsilon: 0.0100 | Loss: 74.7638
Episode 27250 | Reward:  -5.436 | Epsilon: 0.0100 | Loss: 77.3943
Episode 27300 | Reward:  -6.378 | Epsilon: 0.0100 | Loss: 116.2138
Episode 27350 | Reward:  -5.347 | Epsilon: 0.0100 | Loss: 97.8258
Episode 27400 | Reward:  -6.693 | Epsilon: 0.0100 | Loss: 71.0320
Episode 27450 | Reward:  -6.188 | Epsilon: 0.0100 | Loss: 63.2285
Episode 27500 | Reward:  -6.417 | Epsilon: 0.0100 | Loss: 83.0521
Episode 27550 | Reward:  -4.479 | Epsilon: 0.0100 | Loss: 99.8148
Episode 27600 | Reward:  -4.979 | Epsilon: 0.0100 | Loss: 65.4940
Episode 27650 | Reward:  -6.383 | Epsilon: 0.0100 | Loss: 85.2882
Episode 27700 | Reward:  -6.870 | Epsilon: 0.0100 | Loss: 81.9109
Episode 27750 | Reward:  -6.281 | Epsilon: 0.0100 | Loss: 64.2045
Episode 27800 | Reward:  -6.592 | Epsilon: 0.0100 | Loss: 82.4741
Episode 27850 | Reward:  -4.062 | Epsilon: 0.0100 | Loss: 78.4167
Episode 27900 | Reward:  -8.838 | Epsilon: 0.0100 | Loss: 80.1694
Episode 27950 | Reward:  -4.724 | Epsilon: 0.0100 | Loss: 64.4657
Episode 28000 | Reward:  -6.193 | Epsilon: 0.0100 | Loss: 51.8958
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:39).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:39)
Episode 28050 | Reward: -10.839 | Epsilon: 0.0100 | Loss: 59.0374
Episode 28100 | Reward: -12.578 | Epsilon: 0.0100 | Loss: 73.3625
Episode 28150 | Reward:  -9.511 | Epsilon: 0.0100 | Loss: 66.9879
Episode 28200 | Reward:  -5.487 | Epsilon: 0.0100 | Loss: 74.9707
Episode 28250 | Reward:  -8.628 | Epsilon: 0.0100 | Loss: 61.2491
Episode 28300 | Reward:  -7.050 | Epsilon: 0.0100 | Loss: 73.4005
Episode 28350 | Reward:  -6.112 | Epsilon: 0.0100 | Loss: 58.2258
Episode 28400 | Reward: -10.196 | Epsilon: 0.0100 | Loss: 78.1709
Episode 28450 | Reward:  -5.898 | Epsilon: 0.0100 | Loss: 77.0682
Episode 28500 | Reward:  -8.628 | Epsilon: 0.0100 | Loss: 56.2760
Episode 28550 | Reward:  -8.876 | Epsilon: 0.0100 | Loss: 46.2056
Episode 28600 | Reward:  -7.500 | Epsilon: 0.0100 | Loss: 67.3283
Episode 28650 | Reward:  -7.674 | Epsilon: 0.0100 | Loss: 76.9273
Episode 28700 | Reward:  -2.871 | Epsilon: 0.0100 | Loss: 54.8213
Episode 28750 | Reward:  -3.379 | Epsilon: 0.0100 | Loss: 59.8846
Episode 28800 | Reward:  -8.332 | Epsilon: 0.0100 | Loss: 65.1874
Episode 28850 | Reward:  -5.023 | Epsilon: 0.0100 | Loss: 99.3642
Episode 28900 | Reward:  -5.125 | Epsilon: 0.0100 | Loss: 62.8822
Episode 28950 | Reward:  -1.953 | Epsilon: 0.0100 | Loss: 77.8081
Episode 29000 | Reward:  -5.155 | Epsilon: 0.0100 | Loss: 81.2969
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:40).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:40)
Episode 29050 | Reward:  -0.872 | Epsilon: 0.0100 | Loss: 64.2103
Episode 29100 | Reward:  -6.307 | Epsilon: 0.0100 | Loss: 108.6051
Episode 29150 | Reward:  -9.322 | Epsilon: 0.0100 | Loss: 52.1758
Episode 29200 | Reward:  -6.748 | Epsilon: 0.0100 | Loss: 65.3464
Episode 29250 | Reward:  -5.267 | Epsilon: 0.0100 | Loss: 69.4021
Episode 29300 | Reward:  -4.661 | Epsilon: 0.0100 | Loss: 86.2671
Episode 29350 | Reward:  -2.033 | Epsilon: 0.0100 | Loss: 47.7674
Episode 29400 | Reward:  -7.339 | Epsilon: 0.0100 | Loss: 69.2582
Episode 29450 | Reward:  -6.775 | Epsilon: 0.0100 | Loss: 58.2717
Episode 29500 | Reward:  -3.418 | Epsilon: 0.0100 | Loss: 78.6806
Episode 29550 | Reward:  -4.088 | Epsilon: 0.0100 | Loss: 90.8367
Episode 29600 | Reward:  -5.234 | Epsilon: 0.0100 | Loss: 39.2937
Episode 29650 | Reward:  -8.834 | Epsilon: 0.0100 | Loss: 80.8628
Episode 29700 | Reward:  -6.184 | Epsilon: 0.0100 | Loss: 52.2015
Episode 29750 | Reward:  -8.322 | Epsilon: 0.0100 | Loss: 91.3268
Episode 29800 | Reward:  -5.614 | Epsilon: 0.0100 | Loss: 63.9695
Episode 29850 | Reward:  -4.463 | Epsilon: 0.0100 | Loss: 58.6693
Episode 29900 | Reward:  -2.135 | Epsilon: 0.0100 | Loss: 106.5230
Episode 29950 | Reward:  -2.389 | Epsilon: 0.0100 | Loss: 80.6230
Episode 30000 | Reward:  -6.773 | Epsilon: 0.0100 | Loss: 85.3999
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:42).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:42)
Episode 30050 | Reward:  -7.593 | Epsilon: 0.0100 | Loss: 82.6398
Episode 30100 | Reward:  -8.202 | Epsilon: 0.0100 | Loss: 54.5662
Episode 30150 | Reward:  -7.297 | Epsilon: 0.0100 | Loss: 38.2598
Episode 30200 | Reward:  -3.097 | Epsilon: 0.0100 | Loss: 77.9091
Episode 30250 | Reward:  -5.974 | Epsilon: 0.0100 | Loss: 56.2393
Episode 30300 | Reward:  -3.516 | Epsilon: 0.0100 | Loss: 84.6132
Episode 30350 | Reward:  -7.088 | Epsilon: 0.0100 | Loss: 61.4584
Episode 30400 | Reward:  -6.162 | Epsilon: 0.0100 | Loss: 74.0719
Episode 30450 | Reward:  -3.041 | Epsilon: 0.0100 | Loss: 64.6900
Episode 30500 | Reward:  -6.999 | Epsilon: 0.0100 | Loss: 75.9313
Episode 30550 | Reward:  -4.510 | Epsilon: 0.0100 | Loss: 57.4325
Episode 30600 | Reward: -11.374 | Epsilon: 0.0100 | Loss: 81.1724
Episode 30650 | Reward:  -6.573 | Epsilon: 0.0100 | Loss: 84.3150
Episode 30700 | Reward:  -6.209 | Epsilon: 0.0100 | Loss: 72.3499
Episode 30750 | Reward:  -5.276 | Epsilon: 0.0100 | Loss: 83.2119
Episode 30800 | Reward:  -4.583 | Epsilon: 0.0100 | Loss: 93.8935
Episode 30850 | Reward:  -4.125 | Epsilon: 0.0100 | Loss: 67.2720
Episode 30900 | Reward:  -5.057 | Epsilon: 0.0100 | Loss: 95.4832
Episode 30950 | Reward:  -5.524 | Epsilon: 0.0100 | Loss: 57.5957
Episode 31000 | Reward:  -3.791 | Epsilon: 0.0100 | Loss: 65.3620
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:43).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:43)
Episode 31050 | Reward:  -3.143 | Epsilon: 0.0100 | Loss: 48.5727
Episode 31100 | Reward:  -5.224 | Epsilon: 0.0100 | Loss: 76.3433
Episode 31150 | Reward:  -6.445 | Epsilon: 0.0100 | Loss: 46.2690
Episode 31200 | Reward:  -2.406 | Epsilon: 0.0100 | Loss: 62.4748
Episode 31250 | Reward:  -7.327 | Epsilon: 0.0100 | Loss: 78.9987
Episode 31300 | Reward:  -5.941 | Epsilon: 0.0100 | Loss: 69.7376
Episode 31350 | Reward:  -2.657 | Epsilon: 0.0100 | Loss: 53.6193
Episode 31400 | Reward:  -3.107 | Epsilon: 0.0100 | Loss: 62.3392
Episode 31450 | Reward:  -8.348 | Epsilon: 0.0100 | Loss: 42.1870
Episode 31500 | Reward:  -7.032 | Epsilon: 0.0100 | Loss: 49.4634
Episode 31550 | Reward:  -2.052 | Epsilon: 0.0100 | Loss: 76.3938
Episode 31600 | Reward:  -5.928 | Epsilon: 0.0100 | Loss: 57.0003
Episode 31650 | Reward:  -7.723 | Epsilon: 0.0100 | Loss: 68.6981
Episode 31700 | Reward:  -8.315 | Epsilon: 0.0100 | Loss: 51.6138
Episode 31750 | Reward:  -7.329 | Epsilon: 0.0100 | Loss: 59.4125
Episode 31800 | Reward:  -7.798 | Epsilon: 0.0100 | Loss: 76.7854
Episode 31850 | Reward:  -5.548 | Epsilon: 0.0100 | Loss: 45.3226
Episode 31900 | Reward:  -3.874 | Epsilon: 0.0100 | Loss: 66.7459
Episode 31950 | Reward:  -3.921 | Epsilon: 0.0100 | Loss: 68.5255
Episode 32000 | Reward:  -2.067 | Epsilon: 0.0100 | Loss: 60.5093
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:45).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:45)
Episode 32050 | Reward:  -3.595 | Epsilon: 0.0100 | Loss: 63.7444
Episode 32100 | Reward:  -5.309 | Epsilon: 0.0100 | Loss: 91.4961
Episode 32150 | Reward:  -7.075 | Epsilon: 0.0100 | Loss: 66.9563
Episode 32200 | Reward:  -4.471 | Epsilon: 0.0100 | Loss: 79.9217
Episode 32250 | Reward:  -2.964 | Epsilon: 0.0100 | Loss: 70.0054
Episode 32300 | Reward:  -2.849 | Epsilon: 0.0100 | Loss: 92.7180
Episode 32350 | Reward:  -2.290 | Epsilon: 0.0100 | Loss: 63.9293
Episode 32400 | Reward:  -1.754 | Epsilon: 0.0100 | Loss: 70.1000
Episode 32450 | Reward:  -2.173 | Epsilon: 0.0100 | Loss: 103.6581
Episode 32500 | Reward:  -2.788 | Epsilon: 0.0100 | Loss: 92.2353
Episode 32550 | Reward:  -2.981 | Epsilon: 0.0100 | Loss: 84.7673
Episode 32600 | Reward:  -2.188 | Epsilon: 0.0100 | Loss: 82.4530
Episode 32650 | Reward:  -0.163 | Epsilon: 0.0100 | Loss: 67.6355
Episode 32700 | Reward:  -1.625 | Epsilon: 0.0100 | Loss: 44.6338
Episode 32750 | Reward:  -3.273 | Epsilon: 0.0100 | Loss: 100.5696
Episode 32800 | Reward:  -2.601 | Epsilon: 0.0100 | Loss: 78.2380
Episode 32850 | Reward:  -0.267 | Epsilon: 0.0100 | Loss: 48.0410
Episode 32900 | Reward:  -0.462 | Epsilon: 0.0100 | Loss: 88.9915
Episode 32950 | Reward:  -2.496 | Epsilon: 0.0100 | Loss: 73.7936
Episode 33000 | Reward:  -0.949 | Epsilon: 0.0100 | Loss: 64.3094
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:46).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:46)
Episode 33050 | Reward:  -2.358 | Epsilon: 0.0100 | Loss: 74.1903
Episode 33100 | Reward:  -3.727 | Epsilon: 0.0100 | Loss: 87.1575
Episode 33150 | Reward:   0.089 | Epsilon: 0.0100 | Loss: 86.0721
Episode 33200 | Reward:  -3.405 | Epsilon: 0.0100 | Loss: 49.4544
Episode 33250 | Reward:  -1.057 | Epsilon: 0.0100 | Loss: 90.9467
Episode 33300 | Reward:  -0.388 | Epsilon: 0.0100 | Loss: 59.3636
Episode 33350 | Reward:  -1.827 | Epsilon: 0.0100 | Loss: 72.7698
Episode 33400 | Reward:  -7.306 | Epsilon: 0.0100 | Loss: 82.1528
Episode 33450 | Reward:  -2.274 | Epsilon: 0.0100 | Loss: 55.3095
Episode 33500 | Reward:  -1.413 | Epsilon: 0.0100 | Loss: 80.3559
Episode 33550 | Reward:  -4.210 | Epsilon: 0.0100 | Loss: 57.7916
Episode 33600 | Reward:  -0.528 | Epsilon: 0.0100 | Loss: 68.4839
Episode 33650 | Reward:  -2.608 | Epsilon: 0.0100 | Loss: 94.4499
Episode 33700 | Reward:  -2.335 | Epsilon: 0.0100 | Loss: 61.1628
Episode 33750 | Reward:  -4.429 | Epsilon: 0.0100 | Loss: 68.4175
Episode 33800 | Reward:  -0.357 | Epsilon: 0.0100 | Loss: 62.8560
Episode 33850 | Reward:  -1.142 | Epsilon: 0.0100 | Loss: 61.4696
Episode 33900 | Reward:  -1.880 | Epsilon: 0.0100 | Loss: 52.4471
Episode 33950 | Reward:  -1.185 | Epsilon: 0.0100 | Loss: 88.7737
Episode 34000 | Reward:  -5.300 | Epsilon: 0.0100 | Loss: 89.4473
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:47).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:47)
Episode 34050 | Reward:  -5.895 | Epsilon: 0.0100 | Loss: 68.8961
Episode 34100 | Reward:  -4.453 | Epsilon: 0.0100 | Loss: 83.5730
Episode 34150 | Reward:  -0.165 | Epsilon: 0.0100 | Loss: 72.0085
Episode 34200 | Reward:  -0.030 | Epsilon: 0.0100 | Loss: 80.9301
Episode 34250 | Reward:  -3.571 | Epsilon: 0.0100 | Loss: 82.4625
Episode 34300 | Reward:  -4.959 | Epsilon: 0.0100 | Loss: 71.0443
Episode 34350 | Reward:  -4.403 | Epsilon: 0.0100 | Loss: 97.0143
Episode 34400 | Reward:  -5.240 | Epsilon: 0.0100 | Loss: 75.8486
Episode 34450 | Reward:  -4.228 | Epsilon: 0.0100 | Loss: 62.4146
Episode 34500 | Reward:  -4.207 | Epsilon: 0.0100 | Loss: 77.9399
Episode 34550 | Reward:  -6.516 | Epsilon: 0.0100 | Loss: 69.0606
Episode 34600 | Reward:  -4.397 | Epsilon: 0.0100 | Loss: 58.1317
Episode 34650 | Reward:  -2.601 | Epsilon: 0.0100 | Loss: 79.5539
Episode 34700 | Reward:  -7.338 | Epsilon: 0.0100 | Loss: 74.2648
Episode 34750 | Reward:  -6.610 | Epsilon: 0.0100 | Loss: 88.3776
Episode 34800 | Reward:  -2.698 | Epsilon: 0.0100 | Loss: 82.3711
Episode 34850 | Reward:  -2.128 | Epsilon: 0.0100 | Loss: 39.3678
Episode 34900 | Reward:  -0.352 | Epsilon: 0.0100 | Loss: 57.7691
Episode 34950 | Reward:  -1.784 | Epsilon: 0.0100 | Loss: 77.1946
Episode 35000 | Reward:  -3.927 | Epsilon: 0.0100 | Loss: 65.5342
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:49).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:49)
Episode 35050 | Reward:  -4.166 | Epsilon: 0.0100 | Loss: 116.0831
Episode 35100 | Reward:  -6.412 | Epsilon: 0.0100 | Loss: 86.5135
Episode 35150 | Reward:   0.007 | Epsilon: 0.0100 | Loss: 69.7567
Episode 35200 | Reward:  -1.922 | Epsilon: 0.0100 | Loss: 72.0866
Episode 35250 | Reward:  -5.275 | Epsilon: 0.0100 | Loss: 67.6823
Episode 35300 | Reward:  -6.210 | Epsilon: 0.0100 | Loss: 102.5328
Episode 35350 | Reward:   0.735 | Epsilon: 0.0100 | Loss: 90.8907
Episode 35400 | Reward:  -3.917 | Epsilon: 0.0100 | Loss: 99.6482
Episode 35450 | Reward:  -9.808 | Epsilon: 0.0100 | Loss: 69.0586
Episode 35500 | Reward:  -5.665 | Epsilon: 0.0100 | Loss: 82.4835
Episode 35550 | Reward:  -7.551 | Epsilon: 0.0100 | Loss: 79.0280
Episode 35600 | Reward: -10.212 | Epsilon: 0.0100 | Loss: 82.0862
Episode 35650 | Reward: -11.250 | Epsilon: 0.0100 | Loss: 88.7663
Episode 35700 | Reward:  -8.903 | Epsilon: 0.0100 | Loss: 77.4743
Episode 35750 | Reward:  -4.184 | Epsilon: 0.0100 | Loss: 68.1093
Episode 35800 | Reward:  -4.474 | Epsilon: 0.0100 | Loss: 90.1926
Episode 35850 | Reward:  -3.281 | Epsilon: 0.0100 | Loss: 109.3667
Episode 35900 | Reward:  -1.707 | Epsilon: 0.0100 | Loss: 78.9843
Episode 35950 | Reward:  -3.459 | Epsilon: 0.0100 | Loss: 67.5846
Episode 36000 | Reward:  -3.302 | Epsilon: 0.0100 | Loss: 64.0560
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:50).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:50)
Episode 36050 | Reward:  -1.091 | Epsilon: 0.0100 | Loss: 97.3120
Episode 36100 | Reward:  -1.332 | Epsilon: 0.0100 | Loss: 99.4594
Episode 36150 | Reward:  -3.399 | Epsilon: 0.0100 | Loss: 69.4097
Episode 36200 | Reward:  -8.785 | Epsilon: 0.0100 | Loss: 103.3204
Episode 36250 | Reward:  -5.709 | Epsilon: 0.0100 | Loss: 116.4393
Episode 36300 | Reward:  -0.430 | Epsilon: 0.0100 | Loss: 92.7537
Episode 36350 | Reward:  -4.042 | Epsilon: 0.0100 | Loss: 96.6846
Episode 36400 | Reward:  -6.190 | Epsilon: 0.0100 | Loss: 83.5967
Episode 36450 | Reward:  -3.113 | Epsilon: 0.0100 | Loss: 82.4054
Episode 36500 | Reward:  -1.508 | Epsilon: 0.0100 | Loss: 62.4318
Episode 36550 | Reward:  -2.756 | Epsilon: 0.0100 | Loss: 118.3280
Episode 36600 | Reward:  -5.468 | Epsilon: 0.0100 | Loss: 84.3991
Episode 36650 | Reward:  -5.056 | Epsilon: 0.0100 | Loss: 99.6166
Episode 36700 | Reward:  -3.622 | Epsilon: 0.0100 | Loss: 81.6704
Episode 36750 | Reward:  -8.439 | Epsilon: 0.0100 | Loss: 102.2665
Episode 36800 | Reward: -10.632 | Epsilon: 0.0100 | Loss: 85.6288
Episode 36850 | Reward:  -7.599 | Epsilon: 0.0100 | Loss: 59.7817
Episode 36900 | Reward:  -5.033 | Epsilon: 0.0100 | Loss: 100.0908
Episode 36950 | Reward:  -3.315 | Epsilon: 0.0100 | Loss: 111.2584
Episode 37000 | Reward:  -1.403 | Epsilon: 0.0100 | Loss: 80.6158
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:52).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:52)
Episode 37050 | Reward:  -3.082 | Epsilon: 0.0100 | Loss: 96.6440
Episode 37100 | Reward:  -7.562 | Epsilon: 0.0100 | Loss: 89.7884
Episode 37150 | Reward:  -4.822 | Epsilon: 0.0100 | Loss: 96.0939
Episode 37200 | Reward:  -4.325 | Epsilon: 0.0100 | Loss: 85.5674
Episode 37250 | Reward:  -9.106 | Epsilon: 0.0100 | Loss: 100.5745
Episode 37300 | Reward: -10.093 | Epsilon: 0.0100 | Loss: 106.7874
Episode 37350 | Reward:  -6.614 | Epsilon: 0.0100 | Loss: 122.8042
Episode 37400 | Reward:  -3.828 | Epsilon: 0.0100 | Loss: 82.7696
Episode 37450 | Reward:  -1.815 | Epsilon: 0.0100 | Loss: 94.5732
Episode 37500 | Reward:  -7.036 | Epsilon: 0.0100 | Loss: 62.4442
Episode 37550 | Reward:  -4.433 | Epsilon: 0.0100 | Loss: 118.9479
Episode 37600 | Reward:  -7.989 | Epsilon: 0.0100 | Loss: 81.2854
Episode 37650 | Reward: -10.478 | Epsilon: 0.0100 | Loss: 99.3529
Episode 37700 | Reward:  -8.470 | Epsilon: 0.0100 | Loss: 109.3349
Episode 37750 | Reward:  -5.624 | Epsilon: 0.0100 | Loss: 60.2209
Episode 37800 | Reward: -10.861 | Epsilon: 0.0100 | Loss: 84.6427
Episode 37850 | Reward:  -8.842 | Epsilon: 0.0100 | Loss: 109.8549
Episode 37900 | Reward:  -4.774 | Epsilon: 0.0100 | Loss: 101.5296
Episode 37950 | Reward:  -9.587 | Epsilon: 0.0100 | Loss: 104.7057
Episode 38000 | Reward: -10.372 | Epsilon: 0.0100 | Loss: 75.3875
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:53).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:53)
Episode 38050 | Reward:  -8.804 | Epsilon: 0.0100 | Loss: 114.0252
Episode 38100 | Reward:  -8.001 | Epsilon: 0.0100 | Loss: 98.3929
Episode 38150 | Reward:  -7.882 | Epsilon: 0.0100 | Loss: 114.5386
Episode 38200 | Reward:  -8.928 | Epsilon: 0.0100 | Loss: 101.3877
Episode 38250 | Reward:  -5.923 | Epsilon: 0.0100 | Loss: 79.4847
Episode 38300 | Reward:  -8.595 | Epsilon: 0.0100 | Loss: 68.9320
Episode 38350 | Reward:  -6.647 | Epsilon: 0.0100 | Loss: 96.0932
Episode 38400 | Reward:  -8.829 | Epsilon: 0.0100 | Loss: 84.6299
Episode 38450 | Reward:  -5.325 | Epsilon: 0.0100 | Loss: 90.5349
Episode 38500 | Reward:  -5.709 | Epsilon: 0.0100 | Loss: 82.0666
Episode 38550 | Reward:  -6.463 | Epsilon: 0.0100 | Loss: 131.4800
Episode 38600 | Reward:  -7.194 | Epsilon: 0.0100 | Loss: 81.4463
Episode 38650 | Reward: -10.044 | Epsilon: 0.0100 | Loss: 106.7221
Episode 38700 | Reward:  -5.238 | Epsilon: 0.0100 | Loss: 86.5785
Episode 38750 | Reward:  -6.640 | Epsilon: 0.0100 | Loss: 83.6170
Episode 38800 | Reward:  -6.785 | Epsilon: 0.0100 | Loss: 95.4519
Episode 38850 | Reward:  -8.077 | Epsilon: 0.0100 | Loss: 104.5534
Episode 38900 | Reward:  -6.097 | Epsilon: 0.0100 | Loss: 111.8674
Episode 38950 | Reward:  -4.401 | Epsilon: 0.0100 | Loss: 69.5133
Episode 39000 | Reward:  -5.981 | Epsilon: 0.0100 | Loss: 86.6859
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:55).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:55)
Episode 39050 | Reward: -10.209 | Epsilon: 0.0100 | Loss: 86.9734
Episode 39100 | Reward:  -5.391 | Epsilon: 0.0100 | Loss: 84.0448
Episode 39150 | Reward:  -8.002 | Epsilon: 0.0100 | Loss: 75.2458
Episode 39200 | Reward:  -9.560 | Epsilon: 0.0100 | Loss: 84.3001
Episode 39250 | Reward:  -7.063 | Epsilon: 0.0100 | Loss: 78.4855
Episode 39300 | Reward:  -4.689 | Epsilon: 0.0100 | Loss: 72.7930
Episode 39350 | Reward:  -5.334 | Epsilon: 0.0100 | Loss: 90.1732
Episode 39400 | Reward:  -4.495 | Epsilon: 0.0100 | Loss: 63.5047
Episode 39450 | Reward:  -6.511 | Epsilon: 0.0100 | Loss: 89.8835
Episode 39500 | Reward:  -8.377 | Epsilon: 0.0100 | Loss: 77.7011
Episode 39550 | Reward:  -5.223 | Epsilon: 0.0100 | Loss: 76.2748
Episode 39600 | Reward:  -4.026 | Epsilon: 0.0100 | Loss: 81.9212
Episode 39650 | Reward:  -7.773 | Epsilon: 0.0100 | Loss: 83.9790
Episode 39700 | Reward:  -6.612 | Epsilon: 0.0100 | Loss: 133.5026
Episode 39750 | Reward:  -9.184 | Epsilon: 0.0100 | Loss: 83.9734
Episode 39800 | Reward:  -5.371 | Epsilon: 0.0100 | Loss: 101.6391
Episode 39850 | Reward:  -5.323 | Epsilon: 0.0100 | Loss: 111.2357
Episode 39900 | Reward:  -6.683 | Epsilon: 0.0100 | Loss: 134.1792
Episode 39950 | Reward:  -9.013 | Epsilon: 0.0100 | Loss: 88.3826
Episode 40000 | Reward:  -4.907 | Epsilon: 0.0100 | Loss: 72.0933
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:56).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:56)
Episode 40050 | Reward:  -6.808 | Epsilon: 0.0100 | Loss: 85.5992
Episode 40100 | Reward:  -6.377 | Epsilon: 0.0100 | Loss: 71.4440
Episode 40150 | Reward:  -5.877 | Epsilon: 0.0100 | Loss: 73.3503
Episode 40200 | Reward:  -5.813 | Epsilon: 0.0100 | Loss: 78.0314
Episode 40250 | Reward: -10.121 | Epsilon: 0.0100 | Loss: 97.5488
Episode 40300 | Reward:  -9.364 | Epsilon: 0.0100 | Loss: 75.3948
Episode 40350 | Reward:  -5.619 | Epsilon: 0.0100 | Loss: 88.0634
Episode 40400 | Reward:  -6.096 | Epsilon: 0.0100 | Loss: 104.1103
Episode 40450 | Reward:  -8.634 | Epsilon: 0.0100 | Loss: 68.0534
Episode 40500 | Reward: -11.147 | Epsilon: 0.0100 | Loss: 84.6000
Episode 40550 | Reward: -10.590 | Epsilon: 0.0100 | Loss: 121.4385
Episode 40600 | Reward:  -9.073 | Epsilon: 0.0100 | Loss: 92.1266
Episode 40650 | Reward:  -7.041 | Epsilon: 0.0100 | Loss: 74.4327
Episode 40700 | Reward:  -4.411 | Epsilon: 0.0100 | Loss: 76.9630
Episode 40750 | Reward:  -1.133 | Epsilon: 0.0100 | Loss: 54.6404
Episode 40800 | Reward:  -4.375 | Epsilon: 0.0100 | Loss: 97.6461
Episode 40850 | Reward:  -4.456 | Epsilon: 0.0100 | Loss: 100.7941
Episode 40900 | Reward:  -6.666 | Epsilon: 0.0100 | Loss: 69.4583
Episode 40950 | Reward:  -7.095 | Epsilon: 0.0100 | Loss: 94.3296
Episode 41000 | Reward:  -8.715 | Epsilon: 0.0100 | Loss: 76.0479
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:58).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:58)
Episode 41050 | Reward:  -6.901 | Epsilon: 0.0100 | Loss: 85.6196
Episode 41100 | Reward:  -6.605 | Epsilon: 0.0100 | Loss: 71.2039
Episode 41150 | Reward: -10.748 | Epsilon: 0.0100 | Loss: 91.6955
Episode 41200 | Reward:  -7.051 | Epsilon: 0.0100 | Loss: 105.8588
Episode 41250 | Reward: -10.745 | Epsilon: 0.0100 | Loss: 56.6895
Episode 41300 | Reward:  -8.696 | Epsilon: 0.0100 | Loss: 109.7625
Episode 41350 | Reward:  -3.939 | Epsilon: 0.0100 | Loss: 81.1604
Episode 41400 | Reward:  -6.874 | Epsilon: 0.0100 | Loss: 90.0228
Episode 41450 | Reward:  -4.764 | Epsilon: 0.0100 | Loss: 92.6405
Episode 41500 | Reward:  -6.018 | Epsilon: 0.0100 | Loss: 104.1395
Episode 41550 | Reward:  -8.375 | Epsilon: 0.0100 | Loss: 100.3294
Episode 41600 | Reward:  -8.409 | Epsilon: 0.0100 | Loss: 105.6363
Episode 41650 | Reward:  -6.555 | Epsilon: 0.0100 | Loss: 82.9056
Episode 41700 | Reward:  -4.295 | Epsilon: 0.0100 | Loss: 115.5965
Episode 41750 | Reward:  -7.440 | Epsilon: 0.0100 | Loss: 99.3219
Episode 41800 | Reward:  -5.320 | Epsilon: 0.0100 | Loss: 101.6506
Episode 41850 | Reward:  -6.776 | Epsilon: 0.0100 | Loss: 141.2775
Episode 41900 | Reward:  -2.286 | Epsilon: 0.0100 | Loss: 79.3513
Episode 41950 | Reward:  -2.929 | Epsilon: 0.0100 | Loss: 90.5769
Episode 42000 | Reward:  -2.199 | Epsilon: 0.0100 | Loss: 80.6082
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:59).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(19:59)
Episode 42050 | Reward:  -4.851 | Epsilon: 0.0100 | Loss: 71.5813
Episode 42100 | Reward:  -7.949 | Epsilon: 0.0100 | Loss: 74.7408
Episode 42150 | Reward:  -6.227 | Epsilon: 0.0100 | Loss: 116.5338
Episode 42200 | Reward:  -5.181 | Epsilon: 0.0100 | Loss: 71.3761
Episode 42250 | Reward:  -0.618 | Epsilon: 0.0100 | Loss: 108.0033
Episode 42300 | Reward:  -5.266 | Epsilon: 0.0100 | Loss: 71.3997
Episode 42350 | Reward:  -5.252 | Epsilon: 0.0100 | Loss: 92.6877
Episode 42400 | Reward:  -2.821 | Epsilon: 0.0100 | Loss: 84.0709
Episode 42450 | Reward:  -3.278 | Epsilon: 0.0100 | Loss: 53.4118
Episode 42500 | Reward:  -4.846 | Epsilon: 0.0100 | Loss: 52.8957
Episode 42550 | Reward:  -6.461 | Epsilon: 0.0100 | Loss: 85.5659
Episode 42600 | Reward:  -5.806 | Epsilon: 0.0100 | Loss: 83.8812
Episode 42650 | Reward:  -5.710 | Epsilon: 0.0100 | Loss: 94.6826
Episode 42700 | Reward: -10.751 | Epsilon: 0.0100 | Loss: 82.3851
Episode 42750 | Reward:  -3.979 | Epsilon: 0.0100 | Loss: 86.8716
Episode 42800 | Reward:  -5.174 | Epsilon: 0.0100 | Loss: 112.8691
Episode 42850 | Reward:  -4.800 | Epsilon: 0.0100 | Loss: 82.9326
Episode 42900 | Reward:  -7.289 | Epsilon: 0.0100 | Loss: 67.4981
Episode 42950 | Reward:  -9.428 | Epsilon: 0.0100 | Loss: 81.1426
Episode 43000 | Reward: -10.458 | Epsilon: 0.0100 | Loss: 75.5632
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:00).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:00)
Episode 43050 | Reward: -10.562 | Epsilon: 0.0100 | Loss: 122.7687
Episode 43100 | Reward: -10.401 | Epsilon: 0.0100 | Loss: 80.4892
Episode 43150 | Reward:  -7.852 | Epsilon: 0.0100 | Loss: 75.6225
Episode 43200 | Reward:  -7.526 | Epsilon: 0.0100 | Loss: 103.7008
Episode 43250 | Reward:  -7.430 | Epsilon: 0.0100 | Loss: 94.9244
Episode 43300 | Reward:  -8.962 | Epsilon: 0.0100 | Loss: 63.1889
Episode 43350 | Reward:  -3.630 | Epsilon: 0.0100 | Loss: 74.1927
Episode 43400 | Reward:  -5.423 | Epsilon: 0.0100 | Loss: 45.5967
Episode 43450 | Reward:  -8.928 | Epsilon: 0.0100 | Loss: 110.1826
Episode 43500 | Reward:  -8.461 | Epsilon: 0.0100 | Loss: 61.8761
Episode 43550 | Reward:  -8.984 | Epsilon: 0.0100 | Loss: 75.1970
Episode 43600 | Reward:  -4.005 | Epsilon: 0.0100 | Loss: 52.9903
Episode 43650 | Reward:  -6.330 | Epsilon: 0.0100 | Loss: 58.3623
Episode 43700 | Reward:  -5.100 | Epsilon: 0.0100 | Loss: 75.3177
Episode 43750 | Reward:  -7.751 | Epsilon: 0.0100 | Loss: 55.8337
Episode 43800 | Reward: -11.135 | Epsilon: 0.0100 | Loss: 90.6535
Episode 43850 | Reward: -12.905 | Epsilon: 0.0100 | Loss: 101.7107
Episode 43900 | Reward:  -9.687 | Epsilon: 0.0100 | Loss: 105.6256
Episode 43950 | Reward:  -7.431 | Epsilon: 0.0100 | Loss: 80.8380
Episode 44000 | Reward:  -7.000 | Epsilon: 0.0100 | Loss: 49.9553
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:02).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:02)
Episode 44050 | Reward:  -7.223 | Epsilon: 0.0100 | Loss: 60.4844
Episode 44100 | Reward:  -4.930 | Epsilon: 0.0100 | Loss: 97.8840
Episode 44150 | Reward:  -8.044 | Epsilon: 0.0100 | Loss: 80.1620
Episode 44200 | Reward:  -6.596 | Epsilon: 0.0100 | Loss: 89.8698
Episode 44250 | Reward:  -6.935 | Epsilon: 0.0100 | Loss: 99.2847
Episode 44300 | Reward:  -5.280 | Epsilon: 0.0100 | Loss: 59.0499
Episode 44350 | Reward:  -7.369 | Epsilon: 0.0100 | Loss: 92.8878
Episode 44400 | Reward:  -8.155 | Epsilon: 0.0100 | Loss: 76.1819
Episode 44450 | Reward:  -6.939 | Epsilon: 0.0100 | Loss: 64.6392
Episode 44500 | Reward:  -9.198 | Epsilon: 0.0100 | Loss: 61.1300
Episode 44550 | Reward:  -6.639 | Epsilon: 0.0100 | Loss: 102.7224
Episode 44600 | Reward:  -6.345 | Epsilon: 0.0100 | Loss: 80.5547
Episode 44650 | Reward:  -7.021 | Epsilon: 0.0100 | Loss: 88.3289
Episode 44700 | Reward:  -6.990 | Epsilon: 0.0100 | Loss: 92.7875
Episode 44750 | Reward:  -8.994 | Epsilon: 0.0100 | Loss: 68.4282
Episode 44800 | Reward:  -8.311 | Epsilon: 0.0100 | Loss: 89.7587
Episode 44850 | Reward:  -9.557 | Epsilon: 0.0100 | Loss: 62.9861
Episode 44900 | Reward:  -9.533 | Epsilon: 0.0100 | Loss: 61.2719
Episode 44950 | Reward: -10.786 | Epsilon: 0.0100 | Loss: 79.1608
Episode 45000 | Reward:  -9.627 | Epsilon: 0.0100 | Loss: 92.0428
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:03).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:03)
Episode 45050 | Reward:  -5.619 | Epsilon: 0.0100 | Loss: 62.8344
Episode 45100 | Reward:  -5.274 | Epsilon: 0.0100 | Loss: 128.5222
Episode 45150 | Reward:  -9.007 | Epsilon: 0.0100 | Loss: 122.1128
Episode 45200 | Reward:  -9.532 | Epsilon: 0.0100 | Loss: 70.3459
Episode 45250 | Reward:  -6.241 | Epsilon: 0.0100 | Loss: 73.7846
Episode 45300 | Reward:  -4.161 | Epsilon: 0.0100 | Loss: 83.5560
Episode 45350 | Reward:  -5.895 | Epsilon: 0.0100 | Loss: 79.8324
Episode 45400 | Reward:  -5.569 | Epsilon: 0.0100 | Loss: 59.1410
Episode 45450 | Reward:  -4.597 | Epsilon: 0.0100 | Loss: 56.3520
Episode 45500 | Reward:  -7.568 | Epsilon: 0.0100 | Loss: 57.9693
Episode 45550 | Reward:  -3.959 | Epsilon: 0.0100 | Loss: 83.9769
Episode 45600 | Reward:  -5.688 | Epsilon: 0.0100 | Loss: 103.6391
Episode 45650 | Reward:  -6.821 | Epsilon: 0.0100 | Loss: 65.7078
Episode 45700 | Reward:  -5.678 | Epsilon: 0.0100 | Loss: 59.5944
Episode 45750 | Reward:  -3.962 | Epsilon: 0.0100 | Loss: 100.0530
Episode 45800 | Reward:  -7.905 | Epsilon: 0.0100 | Loss: 89.1941
Episode 45850 | Reward:  -3.115 | Epsilon: 0.0100 | Loss: 70.8553
Episode 45900 | Reward:  -6.024 | Epsilon: 0.0100 | Loss: 71.3061
Episode 45950 | Reward:  -4.618 | Epsilon: 0.0100 | Loss: 99.8576
Episode 46000 | Reward:  -3.559 | Epsilon: 0.0100 | Loss: 125.1658
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:05).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:05)
Episode 46050 | Reward:  -1.629 | Epsilon: 0.0100 | Loss: 115.1189
Episode 46100 | Reward:  -5.331 | Epsilon: 0.0100 | Loss: 82.9865
Episode 46150 | Reward:  -6.128 | Epsilon: 0.0100 | Loss: 125.2421
Episode 46200 | Reward:  -5.931 | Epsilon: 0.0100 | Loss: 99.2831
Episode 46250 | Reward:  -7.081 | Epsilon: 0.0100 | Loss: 114.3806
Episode 46300 | Reward:  -3.794 | Epsilon: 0.0100 | Loss: 98.0946
Episode 46350 | Reward:  -5.904 | Epsilon: 0.0100 | Loss: 90.0278
Episode 46400 | Reward:  -7.074 | Epsilon: 0.0100 | Loss: 109.6609
Episode 46450 | Reward:  -6.805 | Epsilon: 0.0100 | Loss: 90.6746
Episode 46500 | Reward:  -6.935 | Epsilon: 0.0100 | Loss: 76.9880
Episode 46550 | Reward:  -2.478 | Epsilon: 0.0100 | Loss: 75.1350
Episode 46600 | Reward:  -4.427 | Epsilon: 0.0100 | Loss: 96.7583
Episode 46650 | Reward:  -9.246 | Epsilon: 0.0100 | Loss: 100.7600
Episode 46700 | Reward:  -6.992 | Epsilon: 0.0100 | Loss: 93.1956
Episode 46750 | Reward:  -6.447 | Epsilon: 0.0100 | Loss: 84.7910
Episode 46800 | Reward:  -7.710 | Epsilon: 0.0100 | Loss: 96.0584
Episode 46850 | Reward:  -7.469 | Epsilon: 0.0100 | Loss: 98.0280
Episode 46900 | Reward:  -4.072 | Epsilon: 0.0100 | Loss: 69.7975
Episode 46950 | Reward:  -8.052 | Epsilon: 0.0100 | Loss: 88.8023
Episode 47000 | Reward:  -9.849 | Epsilon: 0.0100 | Loss: 75.7287
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:06).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:06)
Episode 47050 | Reward:  -4.182 | Epsilon: 0.0100 | Loss: 76.6157
Episode 47100 | Reward:  -4.563 | Epsilon: 0.0100 | Loss: 75.0132
Episode 47150 | Reward:  -2.336 | Epsilon: 0.0100 | Loss: 81.4731
Episode 47200 | Reward:   1.948 | Epsilon: 0.0100 | Loss: 90.2985
Episode 47250 | Reward:   2.471 | Epsilon: 0.0100 | Loss: 100.1972
Episode 47300 | Reward:   0.026 | Epsilon: 0.0100 | Loss: 53.8869
Episode 47350 | Reward:  -0.798 | Epsilon: 0.0100 | Loss: 104.4844
Episode 47400 | Reward:  -2.232 | Epsilon: 0.0100 | Loss: 75.5896
Episode 47450 | Reward:  -3.562 | Epsilon: 0.0100 | Loss: 63.5878
Episode 47500 | Reward:  -6.473 | Epsilon: 0.0100 | Loss: 64.8040
Episode 47550 | Reward:  -7.075 | Epsilon: 0.0100 | Loss: 106.6900
Episode 47600 | Reward:  -3.482 | Epsilon: 0.0100 | Loss: 71.6189
Episode 47650 | Reward:  -1.167 | Epsilon: 0.0100 | Loss: 94.2850
Episode 47700 | Reward:   0.667 | Epsilon: 0.0100 | Loss: 75.9694
Episode 47750 | Reward:  -3.666 | Epsilon: 0.0100 | Loss: 88.6845
Episode 47800 | Reward:  -0.865 | Epsilon: 0.0100 | Loss: 84.9299
Episode 47850 | Reward:   1.113 | Epsilon: 0.0100 | Loss: 97.8647
Episode 47900 | Reward:   0.795 | Epsilon: 0.0100 | Loss: 87.3363
Episode 47950 | Reward:  -1.613 | Epsilon: 0.0100 | Loss: 88.7250
Episode 48000 | Reward:  -0.987 | Epsilon: 0.0100 | Loss: 89.7001
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:08).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:08)
Episode 48050 | Reward:  -0.268 | Epsilon: 0.0100 | Loss: 93.8024
Episode 48100 | Reward:  -2.498 | Epsilon: 0.0100 | Loss: 105.0161
Episode 48150 | Reward:  -3.108 | Epsilon: 0.0100 | Loss: 97.6984
Episode 48200 | Reward:  -0.998 | Epsilon: 0.0100 | Loss: 90.8793
Episode 48250 | Reward:  -2.050 | Epsilon: 0.0100 | Loss: 74.1566
Episode 48300 | Reward:  -4.294 | Epsilon: 0.0100 | Loss: 109.9912
Episode 48350 | Reward:  -2.690 | Epsilon: 0.0100 | Loss: 69.0690
Episode 48400 | Reward:  -4.656 | Epsilon: 0.0100 | Loss: 84.3069
Episode 48450 | Reward:  -4.989 | Epsilon: 0.0100 | Loss: 79.3459
Episode 48500 | Reward:  -5.530 | Epsilon: 0.0100 | Loss: 62.6681
Episode 48550 | Reward:  -3.234 | Epsilon: 0.0100 | Loss: 130.6294
Episode 48600 | Reward:  -4.355 | Epsilon: 0.0100 | Loss: 70.9532
Episode 48650 | Reward:  -6.806 | Epsilon: 0.0100 | Loss: 97.2533
Episode 48700 | Reward: -11.930 | Epsilon: 0.0100 | Loss: 104.8608
Episode 48750 | Reward:  -5.890 | Epsilon: 0.0100 | Loss: 64.0638
Episode 48800 | Reward:  -2.847 | Epsilon: 0.0100 | Loss: 118.5630
Episode 48850 | Reward:  -6.903 | Epsilon: 0.0100 | Loss: 97.1254
Episode 48900 | Reward:  -6.060 | Epsilon: 0.0100 | Loss: 105.2588
Episode 48950 | Reward:  -2.218 | Epsilon: 0.0100 | Loss: 75.0157
Episode 49000 | Reward:  -5.641 | Epsilon: 0.0100 | Loss: 121.9174
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:09).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:09)
Episode 49050 | Reward:  -2.415 | Epsilon: 0.0100 | Loss: 78.0894
Episode 49100 | Reward:  -5.414 | Epsilon: 0.0100 | Loss: 112.5241
Episode 49150 | Reward:  -2.793 | Epsilon: 0.0100 | Loss: 77.1294
Episode 49200 | Reward:  -2.165 | Epsilon: 0.0100 | Loss: 103.9969
Episode 49250 | Reward:  -6.852 | Epsilon: 0.0100 | Loss: 125.6540
Episode 49300 | Reward:  -6.605 | Epsilon: 0.0100 | Loss: 104.2556
Episode 49350 | Reward:  -7.626 | Epsilon: 0.0100 | Loss: 111.7885
Episode 49400 | Reward:  -3.548 | Epsilon: 0.0100 | Loss: 76.8597
Episode 49450 | Reward:  -3.253 | Epsilon: 0.0100 | Loss: 96.6824
Episode 49500 | Reward:  -4.937 | Epsilon: 0.0100 | Loss: 98.6183
Episode 49550 | Reward:  -7.771 | Epsilon: 0.0100 | Loss: 91.0562
Episode 49600 | Reward:  -7.005 | Epsilon: 0.0100 | Loss: 93.7694
Episode 49650 | Reward:  -7.198 | Epsilon: 0.0100 | Loss: 92.0629
Episode 49700 | Reward:  -7.123 | Epsilon: 0.0100 | Loss: 67.2038
Episode 49750 | Reward:  -5.245 | Epsilon: 0.0100 | Loss: 100.3143
Episode 49800 | Reward:  -2.721 | Epsilon: 0.0100 | Loss: 69.0081
Episode 49850 | Reward:  -6.312 | Epsilon: 0.0100 | Loss: 82.1344
Episode 49900 | Reward:  -8.540 | Epsilon: 0.0100 | Loss: 77.9500
Episode 49950 | Reward:  -8.832 | Epsilon: 0.0100 | Loss: 98.8699
Episode 50000 | Reward:  -8.785 | Epsilon: 0.0100 | Loss: 93.6771
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:11).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:11)
Episode 50050 | Reward:  -5.102 | Epsilon: 0.0100 | Loss: 75.5326
Episode 50100 | Reward:  -2.854 | Epsilon: 0.0100 | Loss: 105.4912
Episode 50150 | Reward:  -4.507 | Epsilon: 0.0100 | Loss: 87.8812
Episode 50200 | Reward:  -5.991 | Epsilon: 0.0100 | Loss: 67.0145
Episode 50250 | Reward:  -3.857 | Epsilon: 0.0100 | Loss: 107.3721
Episode 50300 | Reward:  -1.376 | Epsilon: 0.0100 | Loss: 81.1484
Episode 50350 | Reward:  -4.352 | Epsilon: 0.0100 | Loss: 58.4239
Episode 50400 | Reward:  -1.371 | Epsilon: 0.0100 | Loss: 99.3958
Episode 50450 | Reward:  -8.912 | Epsilon: 0.0100 | Loss: 60.9528
Episode 50500 | Reward:  -6.705 | Epsilon: 0.0100 | Loss: 66.0241
Episode 50550 | Reward:  -7.148 | Epsilon: 0.0100 | Loss: 101.8827
Episode 50600 | Reward: -10.343 | Epsilon: 0.0100 | Loss: 82.5416
Episode 50650 | Reward:  -5.335 | Epsilon: 0.0100 | Loss: 70.0135
Episode 50700 | Reward:  -4.054 | Epsilon: 0.0100 | Loss: 128.7151
Episode 50750 | Reward:  -8.404 | Epsilon: 0.0100 | Loss: 95.7029
Episode 50800 | Reward:  -3.998 | Epsilon: 0.0100 | Loss: 119.3251
Episode 50850 | Reward:  -4.617 | Epsilon: 0.0100 | Loss: 69.4430
Episode 50900 | Reward:  -7.584 | Epsilon: 0.0100 | Loss: 66.0196
Episode 50950 | Reward:  -6.198 | Epsilon: 0.0100 | Loss: 79.1026
Episode 51000 | Reward:  -5.263 | Epsilon: 0.0100 | Loss: 92.9771
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:12).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:12)
Episode 51050 | Reward:  -5.516 | Epsilon: 0.0100 | Loss: 97.3380
Episode 51100 | Reward:  -7.304 | Epsilon: 0.0100 | Loss: 98.1254
Episode 51150 | Reward:  -6.373 | Epsilon: 0.0100 | Loss: 86.5603
Episode 51200 | Reward:  -2.662 | Epsilon: 0.0100 | Loss: 84.8770
Episode 51250 | Reward:  -8.229 | Epsilon: 0.0100 | Loss: 98.7197
Episode 51300 | Reward:  -7.252 | Epsilon: 0.0100 | Loss: 83.3206
Episode 51350 | Reward:  -3.100 | Epsilon: 0.0100 | Loss: 60.3835
Episode 51400 | Reward:  -6.597 | Epsilon: 0.0100 | Loss: 77.4373
Episode 51450 | Reward:  -6.465 | Epsilon: 0.0100 | Loss: 63.5155
Episode 51500 | Reward:  -6.094 | Epsilon: 0.0100 | Loss: 77.2463
Episode 51550 | Reward: -10.087 | Epsilon: 0.0100 | Loss: 89.1504
Episode 51600 | Reward:  -7.609 | Epsilon: 0.0100 | Loss: 75.5237
Episode 51650 | Reward:  -6.714 | Epsilon: 0.0100 | Loss: 85.3623
Episode 51700 | Reward:  -9.949 | Epsilon: 0.0100 | Loss: 85.9103
Episode 51750 | Reward:  -9.907 | Epsilon: 0.0100 | Loss: 76.0232
Episode 51800 | Reward: -11.019 | Epsilon: 0.0100 | Loss: 99.3899
Episode 51850 | Reward:  -9.998 | Epsilon: 0.0100 | Loss: 110.4402
Episode 51900 | Reward:  -9.291 | Epsilon: 0.0100 | Loss: 65.4034
Episode 51950 | Reward: -10.037 | Epsilon: 0.0100 | Loss: 72.3709
Episode 52000 | Reward: -13.323 | Epsilon: 0.0100 | Loss: 48.6270
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:13).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:13)
Episode 52050 | Reward: -11.355 | Epsilon: 0.0100 | Loss: 73.3636
Episode 52100 | Reward:  -9.553 | Epsilon: 0.0100 | Loss: 79.8186
Episode 52150 | Reward: -13.787 | Epsilon: 0.0100 | Loss: 75.0205
Episode 52200 | Reward: -10.305 | Epsilon: 0.0100 | Loss: 75.2806
Episode 52250 | Reward: -10.331 | Epsilon: 0.0100 | Loss: 61.1892
Episode 52300 | Reward:  -6.199 | Epsilon: 0.0100 | Loss: 75.7244
Episode 52350 | Reward:  -9.501 | Epsilon: 0.0100 | Loss: 73.4397
Episode 52400 | Reward:  -6.894 | Epsilon: 0.0100 | Loss: 103.8193
Episode 52450 | Reward:  -6.625 | Epsilon: 0.0100 | Loss: 89.0071
Episode 52500 | Reward:  -5.491 | Epsilon: 0.0100 | Loss: 72.6806
Episode 52550 | Reward:  -3.304 | Epsilon: 0.0100 | Loss: 84.6842
Episode 52600 | Reward:  -1.152 | Epsilon: 0.0100 | Loss: 88.6497
Episode 52650 | Reward:  -4.923 | Epsilon: 0.0100 | Loss: 89.2909
Episode 52700 | Reward:  -5.812 | Epsilon: 0.0100 | Loss: 82.5703
Episode 52750 | Reward:  -0.480 | Epsilon: 0.0100 | Loss: 82.5939
Episode 52800 | Reward:  -2.560 | Epsilon: 0.0100 | Loss: 99.2489
Episode 52850 | Reward:  -0.140 | Epsilon: 0.0100 | Loss: 65.6903
Episode 52900 | Reward:  -3.737 | Epsilon: 0.0100 | Loss: 94.6979
Episode 52950 | Reward:  -2.716 | Epsilon: 0.0100 | Loss: 64.9841
Episode 53000 | Reward:  -2.142 | Epsilon: 0.0100 | Loss: 49.9528
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:15).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:15)
Episode 53050 | Reward:  -4.097 | Epsilon: 0.0100 | Loss: 76.2955
Episode 53100 | Reward:  -3.645 | Epsilon: 0.0100 | Loss: 74.6348
Episode 53150 | Reward:  -2.308 | Epsilon: 0.0100 | Loss: 65.1204
Episode 53200 | Reward:  -5.501 | Epsilon: 0.0100 | Loss: 65.2679
Episode 53250 | Reward:  -0.447 | Epsilon: 0.0100 | Loss: 77.8853
Episode 53300 | Reward:  -4.396 | Epsilon: 0.0100 | Loss: 90.8862
Episode 53350 | Reward:  -2.630 | Epsilon: 0.0100 | Loss: 85.1798
Episode 53400 | Reward:  -3.627 | Epsilon: 0.0100 | Loss: 39.0118
Episode 53450 | Reward:  -5.690 | Epsilon: 0.0100 | Loss: 64.9469
Episode 53500 | Reward:  -6.341 | Epsilon: 0.0100 | Loss: 97.8329
Episode 53550 | Reward:  -6.153 | Epsilon: 0.0100 | Loss: 89.1159
Episode 53600 | Reward:  -5.206 | Epsilon: 0.0100 | Loss: 87.5282
Episode 53650 | Reward:  -9.844 | Epsilon: 0.0100 | Loss: 106.2582
Episode 53700 | Reward:  -6.836 | Epsilon: 0.0100 | Loss: 90.5747
Episode 53750 | Reward:  -5.895 | Epsilon: 0.0100 | Loss: 108.6690
Episode 53800 | Reward:  -4.342 | Epsilon: 0.0100 | Loss: 94.6216
Episode 53850 | Reward:  -3.807 | Epsilon: 0.0100 | Loss: 70.7521
Episode 53900 | Reward:   1.196 | Epsilon: 0.0100 | Loss: 75.0750
Episode 53950 | Reward:  -1.983 | Epsilon: 0.0100 | Loss: 67.0545
Episode 54000 | Reward:  -2.399 | Epsilon: 0.0100 | Loss: 92.4442
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:16).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:16)
Episode 54050 | Reward:  -2.943 | Epsilon: 0.0100 | Loss: 99.4554
Episode 54100 | Reward:  -2.248 | Epsilon: 0.0100 | Loss: 94.9298
Episode 54150 | Reward:  -3.094 | Epsilon: 0.0100 | Loss: 118.7466
Episode 54200 | Reward:  -2.118 | Epsilon: 0.0100 | Loss: 98.6254
Episode 54250 | Reward:  -4.311 | Epsilon: 0.0100 | Loss: 68.9205
Episode 54300 | Reward:  -4.589 | Epsilon: 0.0100 | Loss: 38.9666
Episode 54350 | Reward:  -5.867 | Epsilon: 0.0100 | Loss: 116.2757
Episode 54400 | Reward:  -2.580 | Epsilon: 0.0100 | Loss: 69.7684
Episode 54450 | Reward:  -3.383 | Epsilon: 0.0100 | Loss: 116.0187
Episode 54500 | Reward:  -4.622 | Epsilon: 0.0100 | Loss: 99.6568
Episode 54550 | Reward:  -2.767 | Epsilon: 0.0100 | Loss: 100.8036
Episode 54600 | Reward:  -4.508 | Epsilon: 0.0100 | Loss: 112.2954
Episode 54650 | Reward:  -3.839 | Epsilon: 0.0100 | Loss: 67.8842
Episode 54700 | Reward:  -2.149 | Epsilon: 0.0100 | Loss: 69.3383
Episode 54750 | Reward:  -4.903 | Epsilon: 0.0100 | Loss: 111.8998
Episode 54800 | Reward:  -9.395 | Epsilon: 0.0100 | Loss: 69.9865
Episode 54850 | Reward:  -3.373 | Epsilon: 0.0100 | Loss: 76.2750
Episode 54900 | Reward:  -2.022 | Epsilon: 0.0100 | Loss: 142.3692
Episode 54950 | Reward:  -2.110 | Epsilon: 0.0100 | Loss: 103.6960
Episode 55000 | Reward:  -1.976 | Epsilon: 0.0100 | Loss: 101.1232
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:18).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:18)
Episode 55050 | Reward:  -6.108 | Epsilon: 0.0100 | Loss: 110.5385
Episode 55100 | Reward:  -6.102 | Epsilon: 0.0100 | Loss: 63.2451
Episode 55150 | Reward:  -3.334 | Epsilon: 0.0100 | Loss: 66.6206
Episode 55200 | Reward:  -4.111 | Epsilon: 0.0100 | Loss: 119.7616
Episode 55250 | Reward:  -2.538 | Epsilon: 0.0100 | Loss: 68.7530
Episode 55300 | Reward:  -4.171 | Epsilon: 0.0100 | Loss: 128.0135
Episode 55350 | Reward:  -1.435 | Epsilon: 0.0100 | Loss: 80.4378
Episode 55400 | Reward:  -7.273 | Epsilon: 0.0100 | Loss: 82.9999
Episode 55450 | Reward:  -4.357 | Epsilon: 0.0100 | Loss: 91.8509
Episode 55500 | Reward:  -4.560 | Epsilon: 0.0100 | Loss: 99.4307
Episode 55550 | Reward:  -8.376 | Epsilon: 0.0100 | Loss: 47.7626
Episode 55600 | Reward:  -7.275 | Epsilon: 0.0100 | Loss: 93.7341
Episode 55650 | Reward:  -6.068 | Epsilon: 0.0100 | Loss: 67.6205
Episode 55700 | Reward:  -6.980 | Epsilon: 0.0100 | Loss: 90.4598
Episode 55750 | Reward:  -6.680 | Epsilon: 0.0100 | Loss: 89.8583
Episode 55800 | Reward:  -8.818 | Epsilon: 0.0100 | Loss: 86.7336
Episode 55850 | Reward:  -7.937 | Epsilon: 0.0100 | Loss: 125.9879
Episode 55900 | Reward:  -6.962 | Epsilon: 0.0100 | Loss: 82.5227
Episode 55950 | Reward:  -6.491 | Epsilon: 0.0100 | Loss: 103.6025
Episode 56000 | Reward:  -2.793 | Epsilon: 0.0100 | Loss: 94.5801
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:19).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:19)
Episode 56050 | Reward:  -1.655 | Epsilon: 0.0100 | Loss: 44.4815
Episode 56100 | Reward:  -1.017 | Epsilon: 0.0100 | Loss: 83.3636
Episode 56150 | Reward:  -4.183 | Epsilon: 0.0100 | Loss: 82.5061
Episode 56200 | Reward:  -4.102 | Epsilon: 0.0100 | Loss: 60.7120
Episode 56250 | Reward:  -2.869 | Epsilon: 0.0100 | Loss: 106.1068
Episode 56300 | Reward:  -4.849 | Epsilon: 0.0100 | Loss: 84.2826
Episode 56350 | Reward:  -2.906 | Epsilon: 0.0100 | Loss: 95.9080
Episode 56400 | Reward:  -4.027 | Epsilon: 0.0100 | Loss: 77.9159
Episode 56450 | Reward:  -2.592 | Epsilon: 0.0100 | Loss: 83.1781
Episode 56500 | Reward:  -5.090 | Epsilon: 0.0100 | Loss: 128.8545
Episode 56550 | Reward:  -5.024 | Epsilon: 0.0100 | Loss: 89.7386
Episode 56600 | Reward:  -3.908 | Epsilon: 0.0100 | Loss: 140.3923
Episode 56650 | Reward:  -2.699 | Epsilon: 0.0100 | Loss: 90.0217
Episode 56700 | Reward:  -5.964 | Epsilon: 0.0100 | Loss: 49.0994
Episode 56750 | Reward:  -4.027 | Epsilon: 0.0100 | Loss: 65.4941
Episode 56800 | Reward:  -4.272 | Epsilon: 0.0100 | Loss: 88.9645
Episode 56850 | Reward:  -4.224 | Epsilon: 0.0100 | Loss: 80.9072
Episode 56900 | Reward:  -3.327 | Epsilon: 0.0100 | Loss: 54.9916
Episode 56950 | Reward:  -4.524 | Epsilon: 0.0100 | Loss: 89.3151
Episode 57000 | Reward:  -7.336 | Epsilon: 0.0100 | Loss: 88.9497
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:21).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:21)
Episode 57050 | Reward:  -2.433 | Epsilon: 0.0100 | Loss: 99.9341
Episode 57100 | Reward:  -8.370 | Epsilon: 0.0100 | Loss: 79.7702
Episode 57150 | Reward:  -8.027 | Epsilon: 0.0100 | Loss: 107.0426
Episode 57200 | Reward:  -2.987 | Epsilon: 0.0100 | Loss: 77.3830
Episode 57250 | Reward:  -2.466 | Epsilon: 0.0100 | Loss: 95.8626
Episode 57300 | Reward:  -6.129 | Epsilon: 0.0100 | Loss: 85.2221
Episode 57350 | Reward:  -2.771 | Epsilon: 0.0100 | Loss: 78.7608
Episode 57400 | Reward:   0.570 | Epsilon: 0.0100 | Loss: 60.1235
Episode 57450 | Reward:  -2.375 | Epsilon: 0.0100 | Loss: 77.3906
Episode 57500 | Reward:  -4.521 | Epsilon: 0.0100 | Loss: 68.9224
Episode 57550 | Reward:  -2.887 | Epsilon: 0.0100 | Loss: 45.0254
Episode 57600 | Reward:  -2.436 | Epsilon: 0.0100 | Loss: 71.0936
Episode 57650 | Reward:  -3.928 | Epsilon: 0.0100 | Loss: 76.4106
Episode 57700 | Reward:  -8.164 | Epsilon: 0.0100 | Loss: 84.2729
Episode 57750 | Reward:  -5.779 | Epsilon: 0.0100 | Loss: 105.1614
Episode 57800 | Reward:  -9.260 | Epsilon: 0.0100 | Loss: 103.3239
Episode 57850 | Reward:  -7.415 | Epsilon: 0.0100 | Loss: 92.0135
Episode 57900 | Reward:  -6.669 | Epsilon: 0.0100 | Loss: 105.7036
Episode 57950 | Reward:  -4.369 | Epsilon: 0.0100 | Loss: 98.5794
Episode 58000 | Reward:  -0.836 | Epsilon: 0.0100 | Loss: 64.4542
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:22).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:22)
Episode 58050 | Reward:  -6.447 | Epsilon: 0.0100 | Loss: 117.5224
Episode 58100 | Reward:  -4.199 | Epsilon: 0.0100 | Loss: 74.6967
Episode 58150 | Reward:  -3.894 | Epsilon: 0.0100 | Loss: 79.1662
Episode 58200 | Reward:  -4.443 | Epsilon: 0.0100 | Loss: 86.5578
Episode 58250 | Reward:  -6.423 | Epsilon: 0.0100 | Loss: 72.4157
Episode 58300 | Reward:  -6.685 | Epsilon: 0.0100 | Loss: 78.4949
Episode 58350 | Reward:  -5.033 | Epsilon: 0.0100 | Loss: 72.4340
Episode 58400 | Reward:  -5.889 | Epsilon: 0.0100 | Loss: 109.7736
Episode 58450 | Reward:  -5.470 | Epsilon: 0.0100 | Loss: 93.5148
Episode 58500 | Reward:  -4.130 | Epsilon: 0.0100 | Loss: 51.7928
Episode 58550 | Reward:  -6.874 | Epsilon: 0.0100 | Loss: 89.2770
Episode 58600 | Reward:  -4.831 | Epsilon: 0.0100 | Loss: 107.7180
Episode 58650 | Reward:  -4.237 | Epsilon: 0.0100 | Loss: 86.6302
Episode 58700 | Reward:  -6.077 | Epsilon: 0.0100 | Loss: 84.9167
Episode 58750 | Reward:  -6.655 | Epsilon: 0.0100 | Loss: 84.2345
Episode 58800 | Reward:  -3.333 | Epsilon: 0.0100 | Loss: 49.3422
Episode 58850 | Reward:  -6.063 | Epsilon: 0.0100 | Loss: 68.6535
Episode 58900 | Reward:  -9.603 | Epsilon: 0.0100 | Loss: 58.0607
Episode 58950 | Reward:  -7.989 | Epsilon: 0.0100 | Loss: 71.4850
Episode 59000 | Reward:  -7.570 | Epsilon: 0.0100 | Loss: 74.7839
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:24).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:24)
Episode 59050 | Reward:  -7.577 | Epsilon: 0.0100 | Loss: 71.3024
Episode 59100 | Reward: -10.237 | Epsilon: 0.0100 | Loss: 61.9012
Episode 59150 | Reward: -13.034 | Epsilon: 0.0100 | Loss: 76.9538
Episode 59200 | Reward: -12.384 | Epsilon: 0.0100 | Loss: 73.6377
Episode 59250 | Reward: -13.030 | Epsilon: 0.0100 | Loss: 51.2468
Episode 59300 | Reward:  -8.968 | Epsilon: 0.0100 | Loss: 84.4782
Episode 59350 | Reward: -13.499 | Epsilon: 0.0100 | Loss: 123.8428
Episode 59400 | Reward:  -7.694 | Epsilon: 0.0100 | Loss: 73.1970
Episode 59450 | Reward:  -7.049 | Epsilon: 0.0100 | Loss: 81.9381
Episode 59500 | Reward:  -6.793 | Epsilon: 0.0100 | Loss: 82.7155
Episode 59550 | Reward:  -7.402 | Epsilon: 0.0100 | Loss: 76.4176
Episode 59600 | Reward: -10.172 | Epsilon: 0.0100 | Loss: 118.6540
Episode 59650 | Reward:  -7.960 | Epsilon: 0.0100 | Loss: 108.1575
Episode 59700 | Reward:  -4.634 | Epsilon: 0.0100 | Loss: 88.7980
Episode 59750 | Reward:  -9.467 | Epsilon: 0.0100 | Loss: 84.8641
Episode 59800 | Reward:  -8.490 | Epsilon: 0.0100 | Loss: 95.3586
Episode 59850 | Reward:  -3.570 | Epsilon: 0.0100 | Loss: 74.4529
Episode 59900 | Reward:  -7.010 | Epsilon: 0.0100 | Loss: 93.8466
Episode 59950 | Reward:  -4.750 | Epsilon: 0.0100 | Loss: 99.7493
Episode 60000 | Reward:  -4.402 | Epsilon: 0.0100 | Loss: 72.2212
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:25).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:25)
Episode 60050 | Reward:  -6.937 | Epsilon: 0.0100 | Loss: 85.6584
Episode 60100 | Reward:  -8.625 | Epsilon: 0.0100 | Loss: 68.9181
Episode 60150 | Reward:  -3.748 | Epsilon: 0.0100 | Loss: 57.0601
Episode 60200 | Reward:  -4.893 | Epsilon: 0.0100 | Loss: 127.0200
Episode 60250 | Reward:  -4.540 | Epsilon: 0.0100 | Loss: 73.6008
Episode 60300 | Reward:  -5.199 | Epsilon: 0.0100 | Loss: 82.1997
Episode 60350 | Reward:  -4.580 | Epsilon: 0.0100 | Loss: 87.9167
Episode 60400 | Reward:  -1.287 | Epsilon: 0.0100 | Loss: 86.8946
Episode 60450 | Reward:  -4.207 | Epsilon: 0.0100 | Loss: 75.9973
Episode 60500 | Reward:  -7.342 | Epsilon: 0.0100 | Loss: 88.7924
Episode 60550 | Reward:  -5.431 | Epsilon: 0.0100 | Loss: 60.3829
Episode 60600 | Reward:  -6.882 | Epsilon: 0.0100 | Loss: 88.8737
Episode 60650 | Reward:  -5.289 | Epsilon: 0.0100 | Loss: 119.0725
Episode 60700 | Reward:  -7.585 | Epsilon: 0.0100 | Loss: 66.4787
Episode 60750 | Reward:  -3.901 | Epsilon: 0.0100 | Loss: 69.1564
Episode 60800 | Reward:  -8.909 | Epsilon: 0.0100 | Loss: 74.4066
Episode 60850 | Reward:  -6.612 | Epsilon: 0.0100 | Loss: 86.5028
Episode 60900 | Reward:  -8.124 | Epsilon: 0.0100 | Loss: 77.1956
Episode 60950 | Reward:  -9.249 | Epsilon: 0.0100 | Loss: 65.4133
Episode 61000 | Reward:  -6.445 | Epsilon: 0.0100 | Loss: 88.6608
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:27).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:27)
Episode 61050 | Reward:  -3.664 | Epsilon: 0.0100 | Loss: 101.8153
Episode 61100 | Reward:  -8.168 | Epsilon: 0.0100 | Loss: 75.1573
Episode 61150 | Reward:  -8.978 | Epsilon: 0.0100 | Loss: 78.1214
Episode 61200 | Reward:  -7.862 | Epsilon: 0.0100 | Loss: 103.2719
Episode 61250 | Reward:  -9.653 | Epsilon: 0.0100 | Loss: 97.6814
Episode 61300 | Reward:  -7.847 | Epsilon: 0.0100 | Loss: 86.4981
Episode 61350 | Reward:  -7.349 | Epsilon: 0.0100 | Loss: 75.7939
Episode 61400 | Reward:  -7.535 | Epsilon: 0.0100 | Loss: 78.6336
Episode 61450 | Reward:  -4.367 | Epsilon: 0.0100 | Loss: 59.5248
Episode 61500 | Reward:  -7.285 | Epsilon: 0.0100 | Loss: 130.3703
Episode 61550 | Reward:  -8.606 | Epsilon: 0.0100 | Loss: 61.6873
Episode 61600 | Reward:  -7.364 | Epsilon: 0.0100 | Loss: 87.5525
Episode 61650 | Reward:  -5.931 | Epsilon: 0.0100 | Loss: 72.3220
Episode 61700 | Reward:  -6.171 | Epsilon: 0.0100 | Loss: 78.7446
Episode 61750 | Reward:  -6.275 | Epsilon: 0.0100 | Loss: 56.0960
Episode 61800 | Reward:  -5.769 | Epsilon: 0.0100 | Loss: 69.0972
Episode 61850 | Reward:  -4.396 | Epsilon: 0.0100 | Loss: 83.0904
Episode 61900 | Reward:  -8.290 | Epsilon: 0.0100 | Loss: 91.2182
Episode 61950 | Reward:  -5.530 | Epsilon: 0.0100 | Loss: 82.1261
Episode 62000 | Reward:  -4.834 | Epsilon: 0.0100 | Loss: 51.3009
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:28).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:28)
Episode 62050 | Reward:  -8.648 | Epsilon: 0.0100 | Loss: 86.4842
Episode 62100 | Reward:  -6.898 | Epsilon: 0.0100 | Loss: 60.9076
Episode 62150 | Reward:  -9.619 | Epsilon: 0.0100 | Loss: 96.2349
Episode 62200 | Reward:  -6.278 | Epsilon: 0.0100 | Loss: 71.1324
Episode 62250 | Reward:  -9.118 | Epsilon: 0.0100 | Loss: 65.6460
Episode 62300 | Reward:  -6.071 | Epsilon: 0.0100 | Loss: 86.8068
Episode 62350 | Reward:  -7.370 | Epsilon: 0.0100 | Loss: 43.3533
Episode 62400 | Reward:  -5.780 | Epsilon: 0.0100 | Loss: 106.4295
Episode 62450 | Reward:  -5.820 | Epsilon: 0.0100 | Loss: 77.5320
Episode 62500 | Reward:  -8.703 | Epsilon: 0.0100 | Loss: 77.0181
Episode 62550 | Reward:  -7.521 | Epsilon: 0.0100 | Loss: 70.7884
Episode 62600 | Reward:  -7.215 | Epsilon: 0.0100 | Loss: 84.0621
Episode 62650 | Reward:  -7.629 | Epsilon: 0.0100 | Loss: 52.1474
Episode 62700 | Reward:  -9.773 | Epsilon: 0.0100 | Loss: 73.6795
Episode 62750 | Reward:  -7.181 | Epsilon: 0.0100 | Loss: 85.0734
Episode 62800 | Reward:  -9.411 | Epsilon: 0.0100 | Loss: 80.6773
Episode 62850 | Reward:  -7.931 | Epsilon: 0.0100 | Loss: 44.5490
Episode 62900 | Reward:  -8.322 | Epsilon: 0.0100 | Loss: 80.2056
Episode 62950 | Reward:  -4.178 | Epsilon: 0.0100 | Loss: 54.5800
Episode 63000 | Reward:  -4.868 | Epsilon: 0.0100 | Loss: 61.6111
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:29).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:29)
Episode 63050 | Reward:  -8.853 | Epsilon: 0.0100 | Loss: 83.0730
Episode 63100 | Reward: -10.469 | Epsilon: 0.0100 | Loss: 55.2151
Episode 63150 | Reward:  -9.056 | Epsilon: 0.0100 | Loss: 78.8358
Episode 63200 | Reward:  -6.283 | Epsilon: 0.0100 | Loss: 102.8156
Episode 63250 | Reward:  -4.237 | Epsilon: 0.0100 | Loss: 66.8903
Episode 63300 | Reward:  -4.815 | Epsilon: 0.0100 | Loss: 51.9166
Episode 63350 | Reward:  -6.985 | Epsilon: 0.0100 | Loss: 100.6685
Episode 63400 | Reward:  -6.208 | Epsilon: 0.0100 | Loss: 74.8442
Episode 63450 | Reward:  -6.690 | Epsilon: 0.0100 | Loss: 90.1562
Episode 63500 | Reward:  -0.740 | Epsilon: 0.0100 | Loss: 104.8892
Episode 63550 | Reward:  -1.077 | Epsilon: 0.0100 | Loss: 70.8830
Episode 63600 | Reward:  -1.328 | Epsilon: 0.0100 | Loss: 72.4690
Episode 63650 | Reward:  -4.884 | Epsilon: 0.0100 | Loss: 79.3946
Episode 63700 | Reward:  -2.484 | Epsilon: 0.0100 | Loss: 101.9677
Episode 63750 | Reward:  -4.497 | Epsilon: 0.0100 | Loss: 73.7241
Episode 63800 | Reward:  -2.312 | Epsilon: 0.0100 | Loss: 85.9693
Episode 63850 | Reward:  -5.842 | Epsilon: 0.0100 | Loss: 101.7097
Episode 63900 | Reward:  -6.802 | Epsilon: 0.0100 | Loss: 64.5407
Episode 63950 | Reward: -10.459 | Epsilon: 0.0100 | Loss: 67.6475
Episode 64000 | Reward:  -6.320 | Epsilon: 0.0100 | Loss: 60.8748
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:31).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:31)
Episode 64050 | Reward:  -5.187 | Epsilon: 0.0100 | Loss: 104.9752
Episode 64100 | Reward:  -7.483 | Epsilon: 0.0100 | Loss: 87.5658
Episode 64150 | Reward:  -1.328 | Epsilon: 0.0100 | Loss: 64.0701
Episode 64200 | Reward:  -8.036 | Epsilon: 0.0100 | Loss: 90.7998
Episode 64250 | Reward:  -4.679 | Epsilon: 0.0100 | Loss: 67.0460
Episode 64300 | Reward:  -1.847 | Epsilon: 0.0100 | Loss: 89.7579
Episode 64350 | Reward:  -3.733 | Epsilon: 0.0100 | Loss: 86.9074
Episode 64400 | Reward:  -2.807 | Epsilon: 0.0100 | Loss: 87.9537
Episode 64450 | Reward:  -4.561 | Epsilon: 0.0100 | Loss: 95.1521
Episode 64500 | Reward:  -5.759 | Epsilon: 0.0100 | Loss: 72.5934
Episode 64550 | Reward:  -3.612 | Epsilon: 0.0100 | Loss: 77.2214
Episode 64600 | Reward:  -4.988 | Epsilon: 0.0100 | Loss: 77.3582
Episode 64650 | Reward:  -5.502 | Epsilon: 0.0100 | Loss: 75.2137
Episode 64700 | Reward:  -3.489 | Epsilon: 0.0100 | Loss: 89.6509
Episode 64750 | Reward:  -0.864 | Epsilon: 0.0100 | Loss: 124.6851
Episode 64800 | Reward:  -2.002 | Epsilon: 0.0100 | Loss: 93.0994
Episode 64850 | Reward:  -4.303 | Epsilon: 0.0100 | Loss: 86.9113
Episode 64900 | Reward:  -6.879 | Epsilon: 0.0100 | Loss: 115.2103
Episode 64950 | Reward:  -8.010 | Epsilon: 0.0100 | Loss: 121.3569
Episode 65000 | Reward:  -0.301 | Epsilon: 0.0100 | Loss: 89.2406
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:32).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:32)
Episode 65050 | Reward: -10.308 | Epsilon: 0.0100 | Loss: 81.5146
Episode 65100 | Reward:  -5.893 | Epsilon: 0.0100 | Loss: 93.8083
Episode 65150 | Reward:  -6.650 | Epsilon: 0.0100 | Loss: 50.6327
Episode 65200 | Reward:  -5.331 | Epsilon: 0.0100 | Loss: 80.3458
Episode 65250 | Reward:  -6.839 | Epsilon: 0.0100 | Loss: 113.8270
Episode 65300 | Reward:  -8.692 | Epsilon: 0.0100 | Loss: 55.5072
Episode 65350 | Reward:  -8.633 | Epsilon: 0.0100 | Loss: 71.6709
Episode 65400 | Reward:  -6.229 | Epsilon: 0.0100 | Loss: 74.6251
Episode 65450 | Reward: -10.421 | Epsilon: 0.0100 | Loss: 79.6145
Episode 65500 | Reward:  -7.752 | Epsilon: 0.0100 | Loss: 82.7203
Episode 65550 | Reward: -13.811 | Epsilon: 0.0100 | Loss: 78.5309
Episode 65600 | Reward: -11.734 | Epsilon: 0.0100 | Loss: 88.7001
Episode 65650 | Reward:  -7.241 | Epsilon: 0.0100 | Loss: 133.4796
Episode 65700 | Reward:  -5.554 | Epsilon: 0.0100 | Loss: 69.4935
Episode 65750 | Reward:  -8.943 | Epsilon: 0.0100 | Loss: 111.9503
Episode 65800 | Reward:  -4.056 | Epsilon: 0.0100 | Loss: 70.5525
Episode 65850 | Reward:  -5.070 | Epsilon: 0.0100 | Loss: 94.2769
Episode 65900 | Reward:  -5.666 | Epsilon: 0.0100 | Loss: 115.8440
Episode 65950 | Reward:  -6.931 | Epsilon: 0.0100 | Loss: 68.5788
Episode 66000 | Reward:  -8.779 | Epsilon: 0.0100 | Loss: 73.5735
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:34).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:34)
Episode 66050 | Reward:  -4.948 | Epsilon: 0.0100 | Loss: 88.1358
Episode 66100 | Reward:  -4.038 | Epsilon: 0.0100 | Loss: 97.6893
Episode 66150 | Reward:   0.191 | Epsilon: 0.0100 | Loss: 59.3967
Episode 66200 | Reward: -10.139 | Epsilon: 0.0100 | Loss: 67.5033
Episode 66250 | Reward:  -7.822 | Epsilon: 0.0100 | Loss: 88.2610
Episode 66300 | Reward:  -7.216 | Epsilon: 0.0100 | Loss: 69.1240
Episode 66350 | Reward: -11.558 | Epsilon: 0.0100 | Loss: 70.3424
Episode 66400 | Reward:  -7.579 | Epsilon: 0.0100 | Loss: 125.4730
Episode 66450 | Reward:  -6.950 | Epsilon: 0.0100 | Loss: 81.9587
Episode 66500 | Reward:  -9.628 | Epsilon: 0.0100 | Loss: 93.6220
Episode 66550 | Reward:  -7.816 | Epsilon: 0.0100 | Loss: 106.8610
Episode 66600 | Reward:  -6.727 | Epsilon: 0.0100 | Loss: 89.8655
Episode 66650 | Reward:  -2.801 | Epsilon: 0.0100 | Loss: 99.5181
Episode 66700 | Reward:  -3.989 | Epsilon: 0.0100 | Loss: 48.9771
Episode 66750 | Reward:  -3.698 | Epsilon: 0.0100 | Loss: 72.4853
Episode 66800 | Reward:  -4.922 | Epsilon: 0.0100 | Loss: 67.8709
Episode 66850 | Reward:  -3.965 | Epsilon: 0.0100 | Loss: 75.7612
Episode 66900 | Reward:  -0.662 | Epsilon: 0.0100 | Loss: 73.6057
Episode 66950 | Reward:  -2.496 | Epsilon: 0.0100 | Loss: 131.9706
Episode 67000 | Reward:  -5.110 | Epsilon: 0.0100 | Loss: 48.7087
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:35).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:35)
Episode 67050 | Reward:  -1.406 | Epsilon: 0.0100 | Loss: 98.9760
Episode 67100 | Reward:  -3.709 | Epsilon: 0.0100 | Loss: 81.0865
Episode 67150 | Reward:  -5.111 | Epsilon: 0.0100 | Loss: 86.2826
Episode 67200 | Reward:  -8.188 | Epsilon: 0.0100 | Loss: 116.4846
Episode 67250 | Reward:  -7.165 | Epsilon: 0.0100 | Loss: 54.4728
Episode 67300 | Reward:  -5.388 | Epsilon: 0.0100 | Loss: 110.7688
Episode 67350 | Reward:  -6.209 | Epsilon: 0.0100 | Loss: 76.1281
Episode 67400 | Reward:  -6.259 | Epsilon: 0.0100 | Loss: 58.4790
Episode 67450 | Reward:  -4.269 | Epsilon: 0.0100 | Loss: 66.5356
Episode 67500 | Reward:  -6.923 | Epsilon: 0.0100 | Loss: 73.2212
Episode 67550 | Reward:  -3.322 | Epsilon: 0.0100 | Loss: 61.5973
Episode 67600 | Reward:  -5.125 | Epsilon: 0.0100 | Loss: 72.1518
Episode 67650 | Reward:  -1.682 | Epsilon: 0.0100 | Loss: 92.5379
Episode 67700 | Reward:  -1.229 | Epsilon: 0.0100 | Loss: 79.4590
Episode 67750 | Reward:  -3.123 | Epsilon: 0.0100 | Loss: 60.0830
Episode 67800 | Reward:  -5.075 | Epsilon: 0.0100 | Loss: 128.3696
Episode 67850 | Reward:  -4.603 | Epsilon: 0.0100 | Loss: 68.9827
Episode 67900 | Reward:  -0.248 | Epsilon: 0.0100 | Loss: 115.7575
Episode 67950 | Reward:  -7.927 | Epsilon: 0.0100 | Loss: 88.6998
Episode 68000 | Reward:  -3.744 | Epsilon: 0.0100 | Loss: 89.9457
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:37).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:37)
Episode 68050 | Reward:  -2.410 | Epsilon: 0.0100 | Loss: 83.9098
Episode 68100 | Reward:  -3.885 | Epsilon: 0.0100 | Loss: 56.1099
Episode 68150 | Reward:  -4.403 | Epsilon: 0.0100 | Loss: 102.4555
Episode 68200 | Reward:  -4.511 | Epsilon: 0.0100 | Loss: 77.6701
Episode 68250 | Reward:  -2.439 | Epsilon: 0.0100 | Loss: 80.1384
Episode 68300 | Reward:  -4.883 | Epsilon: 0.0100 | Loss: 69.0807
Episode 68350 | Reward:  -3.849 | Epsilon: 0.0100 | Loss: 75.4957
Episode 68400 | Reward:  -6.039 | Epsilon: 0.0100 | Loss: 86.8089
Episode 68450 | Reward:  -3.903 | Epsilon: 0.0100 | Loss: 102.0657
Episode 68500 | Reward:  -1.786 | Epsilon: 0.0100 | Loss: 108.5413
Episode 68550 | Reward:  -2.830 | Epsilon: 0.0100 | Loss: 63.5536
Episode 68600 | Reward:  -5.108 | Epsilon: 0.0100 | Loss: 55.2701
Episode 68650 | Reward:  -6.548 | Epsilon: 0.0100 | Loss: 62.1992
Episode 68700 | Reward:  -6.124 | Epsilon: 0.0100 | Loss: 73.6896
Episode 68750 | Reward:  -6.864 | Epsilon: 0.0100 | Loss: 55.5060
Episode 68800 | Reward:  -2.346 | Epsilon: 0.0100 | Loss: 99.0205
Episode 68850 | Reward:  -7.992 | Epsilon: 0.0100 | Loss: 75.3835
Episode 68900 | Reward:  -7.386 | Epsilon: 0.0100 | Loss: 88.9143
Episode 68950 | Reward:  -5.744 | Epsilon: 0.0100 | Loss: 62.6385
Episode 69000 | Reward:  -7.240 | Epsilon: 0.0100 | Loss: 106.6321
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:38).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:38)
Episode 69050 | Reward: -10.212 | Epsilon: 0.0100 | Loss: 77.8879
Episode 69100 | Reward:  -5.746 | Epsilon: 0.0100 | Loss: 125.1892
Episode 69150 | Reward:  -6.593 | Epsilon: 0.0100 | Loss: 54.0834
Episode 69200 | Reward:  -5.106 | Epsilon: 0.0100 | Loss: 76.3942
Episode 69250 | Reward:  -9.587 | Epsilon: 0.0100 | Loss: 124.7104
Episode 69300 | Reward:  -7.626 | Epsilon: 0.0100 | Loss: 76.1759
Episode 69350 | Reward:  -6.614 | Epsilon: 0.0100 | Loss: 64.2077
Episode 69400 | Reward:  -5.741 | Epsilon: 0.0100 | Loss: 98.0442
Episode 69450 | Reward:  -5.141 | Epsilon: 0.0100 | Loss: 67.5133
Episode 69500 | Reward:  -6.867 | Epsilon: 0.0100 | Loss: 73.6303
Episode 69550 | Reward:  -5.891 | Epsilon: 0.0100 | Loss: 70.1052
Episode 69600 | Reward: -12.395 | Epsilon: 0.0100 | Loss: 69.4171
Episode 69650 | Reward:  -7.744 | Epsilon: 0.0100 | Loss: 64.3016
Episode 69700 | Reward: -11.086 | Epsilon: 0.0100 | Loss: 79.6683
Episode 69750 | Reward: -10.708 | Epsilon: 0.0100 | Loss: 62.0493
Episode 69800 | Reward:  -9.604 | Epsilon: 0.0100 | Loss: 54.3589
Episode 69850 | Reward: -10.940 | Epsilon: 0.0100 | Loss: 63.6888
Episode 69900 | Reward: -11.682 | Epsilon: 0.0100 | Loss: 57.7183
Episode 69950 | Reward: -11.428 | Epsilon: 0.0100 | Loss: 81.3587
Episode 70000 | Reward:  -9.658 | Epsilon: 0.0100 | Loss: 62.5937
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:39).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:39)
Episode 70050 | Reward:  -9.398 | Epsilon: 0.0100 | Loss: 34.8625
Episode 70100 | Reward:  -9.798 | Epsilon: 0.0100 | Loss: 70.4852
Episode 70150 | Reward: -13.205 | Epsilon: 0.0100 | Loss: 95.0482
Episode 70200 | Reward: -12.658 | Epsilon: 0.0100 | Loss: 67.8419
Episode 70250 | Reward: -10.953 | Epsilon: 0.0100 | Loss: 52.1128
Episode 70300 | Reward: -10.738 | Epsilon: 0.0100 | Loss: 102.7345
Episode 70350 | Reward: -11.205 | Epsilon: 0.0100 | Loss: 84.6497
Episode 70400 | Reward:  -8.168 | Epsilon: 0.0100 | Loss: 128.8029
Episode 70450 | Reward:  -6.031 | Epsilon: 0.0100 | Loss: 60.1006
Episode 70500 | Reward: -11.800 | Epsilon: 0.0100 | Loss: 56.3817
Episode 70550 | Reward:  -7.694 | Epsilon: 0.0100 | Loss: 70.1068
Episode 70600 | Reward:  -8.348 | Epsilon: 0.0100 | Loss: 78.4059
Episode 70650 | Reward:  -4.601 | Epsilon: 0.0100 | Loss: 101.9000
Episode 70700 | Reward:  -4.093 | Epsilon: 0.0100 | Loss: 67.3042
Episode 70750 | Reward:  -7.014 | Epsilon: 0.0100 | Loss: 81.2326
Episode 70800 | Reward:  -6.670 | Epsilon: 0.0100 | Loss: 93.3076
Episode 70850 | Reward:  -3.966 | Epsilon: 0.0100 | Loss: 73.9695
Episode 70900 | Reward:  -4.150 | Epsilon: 0.0100 | Loss: 65.8458
Episode 70950 | Reward:  -3.808 | Epsilon: 0.0100 | Loss: 92.2772
Episode 71000 | Reward: -10.364 | Epsilon: 0.0100 | Loss: 78.9336
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:41).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:41)
Episode 71050 | Reward:  -4.986 | Epsilon: 0.0100 | Loss: 80.0620
Episode 71100 | Reward:  -2.626 | Epsilon: 0.0100 | Loss: 106.8538
Episode 71150 | Reward:  -1.590 | Epsilon: 0.0100 | Loss: 79.9948
Episode 71200 | Reward:  -4.538 | Epsilon: 0.0100 | Loss: 98.5648
Episode 71250 | Reward:  -6.061 | Epsilon: 0.0100 | Loss: 75.7300
Episode 71300 | Reward:  -6.803 | Epsilon: 0.0100 | Loss: 101.9816
Episode 71350 | Reward: -10.716 | Epsilon: 0.0100 | Loss: 77.1167
Episode 71400 | Reward:  -2.364 | Epsilon: 0.0100 | Loss: 78.8080
Episode 71450 | Reward:  -2.406 | Epsilon: 0.0100 | Loss: 100.7844
Episode 71500 | Reward:  -0.976 | Epsilon: 0.0100 | Loss: 112.1661
Episode 71550 | Reward:  -6.837 | Epsilon: 0.0100 | Loss: 114.2158
Episode 71600 | Reward:  -5.642 | Epsilon: 0.0100 | Loss: 67.8617
Episode 71650 | Reward:  -5.328 | Epsilon: 0.0100 | Loss: 56.7204
Episode 71700 | Reward:  -6.024 | Epsilon: 0.0100 | Loss: 104.4008
Episode 71750 | Reward:  -2.094 | Epsilon: 0.0100 | Loss: 119.8687
Episode 71800 | Reward:  -2.114 | Epsilon: 0.0100 | Loss: 72.4638
Episode 71850 | Reward:  -2.126 | Epsilon: 0.0100 | Loss: 109.8736
Episode 71900 | Reward:  -8.407 | Epsilon: 0.0100 | Loss: 53.3145
Episode 71950 | Reward:  -2.669 | Epsilon: 0.0100 | Loss: 105.8974
Episode 72000 | Reward:  -3.482 | Epsilon: 0.0100 | Loss: 132.8701
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:42).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:42)
Episode 72050 | Reward:  -0.816 | Epsilon: 0.0100 | Loss: 91.6023
Episode 72100 | Reward:  -4.577 | Epsilon: 0.0100 | Loss: 89.7919
Episode 72150 | Reward:  -6.505 | Epsilon: 0.0100 | Loss: 72.5082
Episode 72200 | Reward:  -1.760 | Epsilon: 0.0100 | Loss: 76.3286
Episode 72250 | Reward:  -3.182 | Epsilon: 0.0100 | Loss: 92.7229
Episode 72300 | Reward:  -0.867 | Epsilon: 0.0100 | Loss: 85.4665
Episode 72350 | Reward:  -2.703 | Epsilon: 0.0100 | Loss: 80.5186
Episode 72400 | Reward:  -4.010 | Epsilon: 0.0100 | Loss: 85.4157
Episode 72450 | Reward:  -1.859 | Epsilon: 0.0100 | Loss: 85.2458
Episode 72500 | Reward:  -2.498 | Epsilon: 0.0100 | Loss: 64.2303
Episode 72550 | Reward:  -3.483 | Epsilon: 0.0100 | Loss: 83.3474
Episode 72600 | Reward:  -0.065 | Epsilon: 0.0100 | Loss: 109.9317
Episode 72650 | Reward:  -2.171 | Epsilon: 0.0100 | Loss: 129.5058
Episode 72700 | Reward:  -2.039 | Epsilon: 0.0100 | Loss: 127.3591
Episode 72750 | Reward:  -3.787 | Epsilon: 0.0100 | Loss: 105.0818
Episode 72800 | Reward:  -6.877 | Epsilon: 0.0100 | Loss: 126.2796
Episode 72850 | Reward:  -4.200 | Epsilon: 0.0100 | Loss: 107.8882
Episode 72900 | Reward:  -2.930 | Epsilon: 0.0100 | Loss: 112.4185
Episode 72950 | Reward:  -1.507 | Epsilon: 0.0100 | Loss: 60.1298
Episode 73000 | Reward:  -1.706 | Epsilon: 0.0100 | Loss: 132.3282
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:44).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:44)
Episode 73050 | Reward:  -3.018 | Epsilon: 0.0100 | Loss: 94.2108
Episode 73100 | Reward:  -2.066 | Epsilon: 0.0100 | Loss: 97.8434
Episode 73150 | Reward:  -1.233 | Epsilon: 0.0100 | Loss: 104.4768
Episode 73200 | Reward:  -1.115 | Epsilon: 0.0100 | Loss: 95.5685
Episode 73250 | Reward:  -0.750 | Epsilon: 0.0100 | Loss: 104.8264
Episode 73300 | Reward:  -0.590 | Epsilon: 0.0100 | Loss: 96.0898
Episode 73350 | Reward:  -7.690 | Epsilon: 0.0100 | Loss: 91.4417
Episode 73400 | Reward:  -5.284 | Epsilon: 0.0100 | Loss: 100.8645
Episode 73450 | Reward:  -9.673 | Epsilon: 0.0100 | Loss: 93.1879
Episode 73500 | Reward:  -5.632 | Epsilon: 0.0100 | Loss: 97.3056
Episode 73550 | Reward: -10.604 | Epsilon: 0.0100 | Loss: 73.4415
Episode 73600 | Reward:  -9.922 | Epsilon: 0.0100 | Loss: 77.4903
Episode 73650 | Reward:  -6.205 | Epsilon: 0.0100 | Loss: 95.4955
Episode 73700 | Reward:  -4.965 | Epsilon: 0.0100 | Loss: 115.3971
Episode 73750 | Reward:  -8.068 | Epsilon: 0.0100 | Loss: 73.3496
Episode 73800 | Reward:  -5.980 | Epsilon: 0.0100 | Loss: 52.1675
Episode 73850 | Reward:  -4.863 | Epsilon: 0.0100 | Loss: 104.6283
Episode 73900 | Reward:  -3.407 | Epsilon: 0.0100 | Loss: 84.5799
Episode 73950 | Reward:  -5.380 | Epsilon: 0.0100 | Loss: 78.5872
Episode 74000 | Reward:  -3.795 | Epsilon: 0.0100 | Loss: 59.2104
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:45).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:45)
Episode 74050 | Reward:  -3.680 | Epsilon: 0.0100 | Loss: 67.4549
Episode 74100 | Reward:  -5.360 | Epsilon: 0.0100 | Loss: 80.5453
Episode 74150 | Reward:  -8.379 | Epsilon: 0.0100 | Loss: 116.8956
Episode 74200 | Reward: -11.797 | Epsilon: 0.0100 | Loss: 90.3591
Episode 74250 | Reward:  -9.556 | Epsilon: 0.0100 | Loss: 88.8178
Episode 74300 | Reward: -11.352 | Epsilon: 0.0100 | Loss: 98.3713
Episode 74350 | Reward:  -8.087 | Epsilon: 0.0100 | Loss: 85.3296
Episode 74400 | Reward:  -5.683 | Epsilon: 0.0100 | Loss: 110.0962
Episode 74450 | Reward:  -5.768 | Epsilon: 0.0100 | Loss: 71.8838
Episode 74500 | Reward:  -5.900 | Epsilon: 0.0100 | Loss: 116.8462
Episode 74550 | Reward: -10.335 | Epsilon: 0.0100 | Loss: 81.8081
Episode 74600 | Reward:  -6.293 | Epsilon: 0.0100 | Loss: 81.4883
Episode 74650 | Reward:  -4.867 | Epsilon: 0.0100 | Loss: 90.6463
Episode 74700 | Reward:  -7.868 | Epsilon: 0.0100 | Loss: 83.6135
Episode 74750 | Reward:  -5.318 | Epsilon: 0.0100 | Loss: 78.9659
Episode 74800 | Reward:  -8.570 | Epsilon: 0.0100 | Loss: 67.2499
Episode 74850 | Reward:  -8.976 | Epsilon: 0.0100 | Loss: 69.0240
Episode 74900 | Reward:  -9.573 | Epsilon: 0.0100 | Loss: 76.1674
Episode 74950 | Reward: -10.863 | Epsilon: 0.0100 | Loss: 90.0244
Episode 75000 | Reward:  -7.086 | Epsilon: 0.0100 | Loss: 78.4382
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:47).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:47)
Episode 75050 | Reward:  -8.803 | Epsilon: 0.0100 | Loss: 93.1556
Episode 75100 | Reward:  -7.794 | Epsilon: 0.0100 | Loss: 83.9202
Episode 75150 | Reward:  -7.436 | Epsilon: 0.0100 | Loss: 100.5512
Episode 75200 | Reward: -10.565 | Epsilon: 0.0100 | Loss: 99.6127
Episode 75250 | Reward: -10.581 | Epsilon: 0.0100 | Loss: 80.1251
Episode 75300 | Reward: -12.944 | Epsilon: 0.0100 | Loss: 83.8824
Episode 75350 | Reward:  -8.015 | Epsilon: 0.0100 | Loss: 93.3905
Episode 75400 | Reward:  -5.308 | Epsilon: 0.0100 | Loss: 93.6310
Episode 75450 | Reward:  -9.560 | Epsilon: 0.0100 | Loss: 72.2060
Episode 75500 | Reward:  -7.282 | Epsilon: 0.0100 | Loss: 91.9270
Episode 75550 | Reward:  -8.121 | Epsilon: 0.0100 | Loss: 92.6342
Episode 75600 | Reward:  -9.478 | Epsilon: 0.0100 | Loss: 108.3036
Episode 75650 | Reward: -10.147 | Epsilon: 0.0100 | Loss: 110.0362
Episode 75700 | Reward:  -8.242 | Epsilon: 0.0100 | Loss: 82.8368
Episode 75750 | Reward:  -6.295 | Epsilon: 0.0100 | Loss: 75.4277
Episode 75800 | Reward:  -8.798 | Epsilon: 0.0100 | Loss: 76.1979
Episode 75850 | Reward:  -5.826 | Epsilon: 0.0100 | Loss: 104.3576
Episode 75900 | Reward:  -7.425 | Epsilon: 0.0100 | Loss: 90.8016
Episode 75950 | Reward:  -4.939 | Epsilon: 0.0100 | Loss: 82.0822
Episode 76000 | Reward:  -3.717 | Epsilon: 0.0100 | Loss: 94.0933
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:48).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:48)
Episode 76050 | Reward:  -6.113 | Epsilon: 0.0100 | Loss: 108.0283
Episode 76100 | Reward:  -8.439 | Epsilon: 0.0100 | Loss: 76.4635
Episode 76150 | Reward:  -8.524 | Epsilon: 0.0100 | Loss: 98.4450
Episode 76200 | Reward:  -6.111 | Epsilon: 0.0100 | Loss: 95.5981
Episode 76250 | Reward:  -4.637 | Epsilon: 0.0100 | Loss: 86.7683
Episode 76300 | Reward:  -5.322 | Epsilon: 0.0100 | Loss: 47.2414
Episode 76350 | Reward:  -6.678 | Epsilon: 0.0100 | Loss: 89.7899
Episode 76400 | Reward:  -7.760 | Epsilon: 0.0100 | Loss: 61.9532
Episode 76450 | Reward:  -7.702 | Epsilon: 0.0100 | Loss: 86.9054
Episode 76500 | Reward:  -5.843 | Epsilon: 0.0100 | Loss: 90.3568
Episode 76550 | Reward:  -5.270 | Epsilon: 0.0100 | Loss: 70.5551
Episode 76600 | Reward:  -6.997 | Epsilon: 0.0100 | Loss: 85.0130
Episode 76650 | Reward:  -6.799 | Epsilon: 0.0100 | Loss: 114.7367
Episode 76700 | Reward:  -4.287 | Epsilon: 0.0100 | Loss: 94.8920
Episode 76750 | Reward:  -4.708 | Epsilon: 0.0100 | Loss: 49.7092
Episode 76800 | Reward:  -6.016 | Epsilon: 0.0100 | Loss: 77.4620
Episode 76850 | Reward:  -7.413 | Epsilon: 0.0100 | Loss: 66.8207
Episode 76900 | Reward:  -3.748 | Epsilon: 0.0100 | Loss: 70.5756
Episode 76950 | Reward:  -8.361 | Epsilon: 0.0100 | Loss: 85.2186
Episode 77000 | Reward:  -8.441 | Epsilon: 0.0100 | Loss: 45.9450
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:50).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:50)
Episode 77050 | Reward:  -6.487 | Epsilon: 0.0100 | Loss: 103.1955
Episode 77100 | Reward:  -4.329 | Epsilon: 0.0100 | Loss: 98.7929
Episode 77150 | Reward:  -7.657 | Epsilon: 0.0100 | Loss: 80.4716
Episode 77200 | Reward:  -6.469 | Epsilon: 0.0100 | Loss: 90.1576
Episode 77250 | Reward:  -7.624 | Epsilon: 0.0100 | Loss: 70.4207
Episode 77300 | Reward:  -4.953 | Epsilon: 0.0100 | Loss: 111.2794
Episode 77350 | Reward:  -3.667 | Epsilon: 0.0100 | Loss: 65.2953
Episode 77400 | Reward:  -6.680 | Epsilon: 0.0100 | Loss: 90.1107
Episode 77450 | Reward:  -8.173 | Epsilon: 0.0100 | Loss: 65.7477
Episode 77500 | Reward:  -5.727 | Epsilon: 0.0100 | Loss: 58.5559
Episode 77550 | Reward:  -4.264 | Epsilon: 0.0100 | Loss: 64.2794
Episode 77600 | Reward:  -4.537 | Epsilon: 0.0100 | Loss: 79.6824
Episode 77650 | Reward:  -8.946 | Epsilon: 0.0100 | Loss: 50.4346
Episode 77700 | Reward: -11.110 | Epsilon: 0.0100 | Loss: 68.1323
Episode 77750 | Reward:  -6.972 | Epsilon: 0.0100 | Loss: 94.7346
Episode 77800 | Reward:  -7.949 | Epsilon: 0.0100 | Loss: 89.9393
Episode 77850 | Reward:  -6.228 | Epsilon: 0.0100 | Loss: 81.9767
Episode 77900 | Reward:  -7.053 | Epsilon: 0.0100 | Loss: 79.2950
Episode 77950 | Reward:  -7.957 | Epsilon: 0.0100 | Loss: 43.3650
Episode 78000 | Reward:  -7.707 | Epsilon: 0.0100 | Loss: 79.0655
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:51).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:51)
Episode 78050 | Reward:  -6.121 | Epsilon: 0.0100 | Loss: 87.0784
Episode 78100 | Reward:  -8.886 | Epsilon: 0.0100 | Loss: 95.3705
Episode 78150 | Reward:  -7.431 | Epsilon: 0.0100 | Loss: 77.3131
Episode 78200 | Reward:  -5.626 | Epsilon: 0.0100 | Loss: 83.0386
Episode 78250 | Reward:  -8.636 | Epsilon: 0.0100 | Loss: 74.3452
Episode 78300 | Reward:  -7.886 | Epsilon: 0.0100 | Loss: 83.2704
Episode 78350 | Reward:  -7.245 | Epsilon: 0.0100 | Loss: 77.2373
Episode 78400 | Reward: -11.506 | Epsilon: 0.0100 | Loss: 39.2469
Episode 78450 | Reward: -11.039 | Epsilon: 0.0100 | Loss: 69.1694
Episode 78500 | Reward: -11.771 | Epsilon: 0.0100 | Loss: 63.3649
Episode 78550 | Reward: -11.197 | Epsilon: 0.0100 | Loss: 77.7595
Episode 78600 | Reward:  -8.548 | Epsilon: 0.0100 | Loss: 98.2193
Episode 78650 | Reward:  -8.995 | Epsilon: 0.0100 | Loss: 59.7947
Episode 78700 | Reward:  -8.372 | Epsilon: 0.0100 | Loss: 86.6152
Episode 78750 | Reward:  -6.520 | Epsilon: 0.0100 | Loss: 93.3456
Episode 78800 | Reward:  -7.491 | Epsilon: 0.0100 | Loss: 89.9024
Episode 78850 | Reward:  -6.639 | Epsilon: 0.0100 | Loss: 89.9038
Episode 78900 | Reward: -10.392 | Epsilon: 0.0100 | Loss: 83.7861
Episode 78950 | Reward:  -8.467 | Epsilon: 0.0100 | Loss: 77.9831
Episode 79000 | Reward:  -9.046 | Epsilon: 0.0100 | Loss: 61.4449
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:52).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:52)
Episode 79050 | Reward:  -8.047 | Epsilon: 0.0100 | Loss: 71.4038
Episode 79100 | Reward: -10.768 | Epsilon: 0.0100 | Loss: 84.1445
Episode 79150 | Reward:  -8.176 | Epsilon: 0.0100 | Loss: 93.1227
Episode 79200 | Reward:  -4.772 | Epsilon: 0.0100 | Loss: 90.9489
Episode 79250 | Reward:  -6.401 | Epsilon: 0.0100 | Loss: 95.1201
Episode 79300 | Reward:  -6.387 | Epsilon: 0.0100 | Loss: 86.2221
Episode 79350 | Reward:  -6.314 | Epsilon: 0.0100 | Loss: 63.0874
Episode 79400 | Reward:  -4.419 | Epsilon: 0.0100 | Loss: 65.1075
Episode 79450 | Reward:  -5.282 | Epsilon: 0.0100 | Loss: 79.7307
Episode 79500 | Reward:  -7.671 | Epsilon: 0.0100 | Loss: 93.4393
Episode 79550 | Reward:  -4.705 | Epsilon: 0.0100 | Loss: 74.2286
Episode 79600 | Reward:  -7.153 | Epsilon: 0.0100 | Loss: 95.6952
Episode 79650 | Reward:  -6.133 | Epsilon: 0.0100 | Loss: 49.6519
Episode 79700 | Reward:  -9.422 | Epsilon: 0.0100 | Loss: 67.7315
Episode 79750 | Reward:  -7.158 | Epsilon: 0.0100 | Loss: 79.2700
Episode 79800 | Reward:  -5.405 | Epsilon: 0.0100 | Loss: 77.1972
Episode 79850 | Reward:  -2.675 | Epsilon: 0.0100 | Loss: 81.4337
Episode 79900 | Reward:  -5.350 | Epsilon: 0.0100 | Loss: 80.2236
Episode 79950 | Reward:  -7.869 | Epsilon: 0.0100 | Loss: 85.3391
Episode 80000 | Reward:  -5.084 | Epsilon: 0.0100 | Loss: 95.2310
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:54).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:54)
Episode 80050 | Reward:  -7.967 | Epsilon: 0.0100 | Loss: 63.6987
Episode 80100 | Reward:  -8.129 | Epsilon: 0.0100 | Loss: 63.3607
Episode 80150 | Reward:  -8.344 | Epsilon: 0.0100 | Loss: 82.9470
Episode 80200 | Reward:  -4.938 | Epsilon: 0.0100 | Loss: 82.9516
Episode 80250 | Reward:  -7.356 | Epsilon: 0.0100 | Loss: 75.2220
Episode 80300 | Reward:  -5.716 | Epsilon: 0.0100 | Loss: 50.6850
Episode 80350 | Reward:  -5.246 | Epsilon: 0.0100 | Loss: 89.5042
Episode 80400 | Reward:  -5.886 | Epsilon: 0.0100 | Loss: 68.1239
Episode 80450 | Reward:  -6.916 | Epsilon: 0.0100 | Loss: 48.7185
Episode 80500 | Reward:  -6.651 | Epsilon: 0.0100 | Loss: 114.8980
Episode 80550 | Reward:  -4.882 | Epsilon: 0.0100 | Loss: 76.1861
Episode 80600 | Reward:  -7.133 | Epsilon: 0.0100 | Loss: 97.8961
Episode 80650 | Reward:  -7.874 | Epsilon: 0.0100 | Loss: 69.0030
Episode 80700 | Reward:  -6.344 | Epsilon: 0.0100 | Loss: 95.5308
Episode 80750 | Reward:  -5.501 | Epsilon: 0.0100 | Loss: 98.6868
Episode 80800 | Reward:  -4.033 | Epsilon: 0.0100 | Loss: 45.4104
Episode 80850 | Reward:  -5.768 | Epsilon: 0.0100 | Loss: 65.3192
Episode 80900 | Reward:  -4.662 | Epsilon: 0.0100 | Loss: 65.7370
Episode 80950 | Reward:  -6.008 | Epsilon: 0.0100 | Loss: 80.4864
Episode 81000 | Reward:  -9.972 | Epsilon: 0.0100 | Loss: 69.1486
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:55).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:55)
Episode 81050 | Reward:  -7.076 | Epsilon: 0.0100 | Loss: 66.9031
Episode 81100 | Reward:  -7.787 | Epsilon: 0.0100 | Loss: 113.0457
Episode 81150 | Reward:  -5.607 | Epsilon: 0.0100 | Loss: 54.5011
Episode 81200 | Reward:  -7.088 | Epsilon: 0.0100 | Loss: 99.0248
Episode 81250 | Reward:  -5.118 | Epsilon: 0.0100 | Loss: 54.6555
Episode 81300 | Reward:  -6.000 | Epsilon: 0.0100 | Loss: 72.7007
Episode 81350 | Reward:  -7.577 | Epsilon: 0.0100 | Loss: 79.6081
Episode 81400 | Reward:  -5.498 | Epsilon: 0.0100 | Loss: 82.9584
Episode 81450 | Reward:  -4.541 | Epsilon: 0.0100 | Loss: 83.9314
Episode 81500 | Reward:  -2.205 | Epsilon: 0.0100 | Loss: 95.5529
Episode 81550 | Reward:  -5.042 | Epsilon: 0.0100 | Loss: 71.1611
Episode 81600 | Reward:  -2.143 | Epsilon: 0.0100 | Loss: 67.3687
Episode 81650 | Reward:  -3.488 | Epsilon: 0.0100 | Loss: 73.3801
Episode 81700 | Reward:  -4.714 | Epsilon: 0.0100 | Loss: 79.1283
Episode 81750 | Reward:  -5.335 | Epsilon: 0.0100 | Loss: 64.7323
Episode 81800 | Reward:  -5.341 | Epsilon: 0.0100 | Loss: 49.4091
Episode 81850 | Reward:  -3.872 | Epsilon: 0.0100 | Loss: 103.2691
Episode 81900 | Reward:  -9.212 | Epsilon: 0.0100 | Loss: 71.1877
Episode 81950 | Reward:  -7.394 | Epsilon: 0.0100 | Loss: 80.3208
Episode 82000 | Reward:  -5.423 | Epsilon: 0.0100 | Loss: 66.3428
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:57).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:57)
Episode 82050 | Reward:  -2.374 | Epsilon: 0.0100 | Loss: 129.1887
Episode 82100 | Reward:  -6.109 | Epsilon: 0.0100 | Loss: 56.0909
Episode 82150 | Reward:  -6.244 | Epsilon: 0.0100 | Loss: 72.8935
Episode 82200 | Reward:  -6.259 | Epsilon: 0.0100 | Loss: 106.2357
Episode 82250 | Reward: -12.915 | Epsilon: 0.0100 | Loss: 85.4727
Episode 82300 | Reward:  -7.322 | Epsilon: 0.0100 | Loss: 76.8195
Episode 82350 | Reward:  -7.132 | Epsilon: 0.0100 | Loss: 83.7663
Episode 82400 | Reward:  -7.141 | Epsilon: 0.0100 | Loss: 79.9196
Episode 82450 | Reward:  -6.737 | Epsilon: 0.0100 | Loss: 81.7927
Episode 82500 | Reward:  -9.504 | Epsilon: 0.0100 | Loss: 112.9298
Episode 82550 | Reward:  -7.281 | Epsilon: 0.0100 | Loss: 80.7189
Episode 82600 | Reward:  -7.002 | Epsilon: 0.0100 | Loss: 63.5091
Episode 82650 | Reward:  -3.613 | Epsilon: 0.0100 | Loss: 112.6477
Episode 82700 | Reward:  -6.049 | Epsilon: 0.0100 | Loss: 101.8819
Episode 82750 | Reward:  -6.533 | Epsilon: 0.0100 | Loss: 81.7004
Episode 82800 | Reward:  -4.189 | Epsilon: 0.0100 | Loss: 69.4563
Episode 82850 | Reward:  -2.091 | Epsilon: 0.0100 | Loss: 91.2824
Episode 82900 | Reward:  -3.786 | Epsilon: 0.0100 | Loss: 95.4098
Episode 82950 | Reward:  -2.716 | Epsilon: 0.0100 | Loss: 81.8489
Episode 83000 | Reward:  -2.257 | Epsilon: 0.0100 | Loss: 74.0414
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:58).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(20:58)
Episode 83050 | Reward:  -1.890 | Epsilon: 0.0100 | Loss: 73.4186
Episode 83100 | Reward:  -4.362 | Epsilon: 0.0100 | Loss: 91.2015
Episode 83150 | Reward:  -3.795 | Epsilon: 0.0100 | Loss: 76.4010
Episode 83200 | Reward:  -6.986 | Epsilon: 0.0100 | Loss: 95.3761
Episode 83250 | Reward:  -3.527 | Epsilon: 0.0100 | Loss: 56.4135
Episode 83300 | Reward:  -3.387 | Epsilon: 0.0100 | Loss: 56.9047
Episode 83350 | Reward:  -4.119 | Epsilon: 0.0100 | Loss: 66.3587
Episode 83400 | Reward:  -4.472 | Epsilon: 0.0100 | Loss: 115.6413
Episode 83450 | Reward:  -3.955 | Epsilon: 0.0100 | Loss: 83.8184
Episode 83500 | Reward:  -2.659 | Epsilon: 0.0100 | Loss: 64.7475
Episode 83550 | Reward:  -3.329 | Epsilon: 0.0100 | Loss: 86.3567
Episode 83600 | Reward:  -6.708 | Epsilon: 0.0100 | Loss: 71.4589
Episode 83650 | Reward:  -3.341 | Epsilon: 0.0100 | Loss: 66.4308
Episode 83700 | Reward:  -1.239 | Epsilon: 0.0100 | Loss: 67.6500
Episode 83750 | Reward:   0.302 | Epsilon: 0.0100 | Loss: 56.2205
Episode 83800 | Reward:  -4.874 | Epsilon: 0.0100 | Loss: 101.4028
Episode 83850 | Reward:  -4.253 | Epsilon: 0.0100 | Loss: 87.3145
Episode 83900 | Reward:  -3.674 | Epsilon: 0.0100 | Loss: 110.5919
Episode 83950 | Reward:  -5.028 | Epsilon: 0.0100 | Loss: 34.0965
Episode 84000 | Reward:  -4.457 | Epsilon: 0.0100 | Loss: 67.2632
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(21:00).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(21:00)
Episode 84050 | Reward:  -3.457 | Epsilon: 0.0100 | Loss: 103.2849
Episode 84100 | Reward:  -3.893 | Epsilon: 0.0100 | Loss: 84.7152
Episode 84150 | Reward:  -5.313 | Epsilon: 0.0100 | Loss: 72.8878
Episode 84200 | Reward:  -6.699 | Epsilon: 0.0100 | Loss: 57.2175
Episode 84250 | Reward:  -5.898 | Epsilon: 0.0100 | Loss: 85.4820
Episode 84300 | Reward:  -7.387 | Epsilon: 0.0100 | Loss: 68.5577
Episode 84350 | Reward:  -1.978 | Epsilon: 0.0100 | Loss: 41.7841
Episode 84400 | Reward:  -4.402 | Epsilon: 0.0100 | Loss: 77.1127
Episode 84450 | Reward:   0.116 | Epsilon: 0.0100 | Loss: 79.2109
Episode 84500 | Reward:  -5.481 | Epsilon: 0.0100 | Loss: 56.7802
Episode 84550 | Reward:  -6.362 | Epsilon: 0.0100 | Loss: 105.3822
Episode 84600 | Reward:  -5.099 | Epsilon: 0.0100 | Loss: 93.0681
Episode 84650 | Reward:  -2.388 | Epsilon: 0.0100 | Loss: 84.2268
Episode 84700 | Reward:  -3.838 | Epsilon: 0.0100 | Loss: 111.0446
Episode 84750 | Reward:  -4.721 | Epsilon: 0.0100 | Loss: 119.3161
Episode 84800 | Reward:  -3.768 | Epsilon: 0.0100 | Loss: 94.0843
Episode 84850 | Reward:  -5.761 | Epsilon: 0.0100 | Loss: 84.0467
Episode 84900 | Reward:  -1.954 | Epsilon: 0.0100 | Loss: 88.6020
Episode 84950 | Reward:  -3.403 | Epsilon: 0.0100 | Loss: 68.4322
Episode 85000 | Reward:  -1.479 | Epsilon: 0.0100 | Loss: 68.3933
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(21:01).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(21:01)
Episode 85050 | Reward:  -3.474 | Epsilon: 0.0100 | Loss: 68.9945
Episode 85100 | Reward:  -5.654 | Epsilon: 0.0100 | Loss: 63.0061
Episode 85150 | Reward:  -5.643 | Epsilon: 0.0100 | Loss: 93.5288
Episode 85200 | Reward:  -4.701 | Epsilon: 0.0100 | Loss: 76.1897
Episode 85250 | Reward:  -4.154 | Epsilon: 0.0100 | Loss: 90.9929
Episode 85300 | Reward:  -3.778 | Epsilon: 0.0100 | Loss: 77.6530
Episode 85350 | Reward:  -4.783 | Epsilon: 0.0100 | Loss: 88.1060
Episode 85400 | Reward:  -2.974 | Epsilon: 0.0100 | Loss: 101.8679
Episode 85450 | Reward:  -6.814 | Epsilon: 0.0100 | Loss: 83.1990
Episode 85500 | Reward:  -7.070 | Epsilon: 0.0100 | Loss: 57.2947
Episode 85550 | Reward:  -4.916 | Epsilon: 0.0100 | Loss: 62.0639
Episode 85600 | Reward:  -4.562 | Epsilon: 0.0100 | Loss: 108.7551
Episode 85650 | Reward:  -4.826 | Epsilon: 0.0100 | Loss: 66.9200
Episode 85700 | Reward:  -3.250 | Epsilon: 0.0100 | Loss: 82.2820
Episode 85750 | Reward:  -9.502 | Epsilon: 0.0100 | Loss: 82.8214
Episode 85800 | Reward:  -9.790 | Epsilon: 0.0100 | Loss: 91.0594
Episode 85850 | Reward: -10.366 | Epsilon: 0.0100 | Loss: 55.7553
Episode 85900 | Reward:  -9.855 | Epsilon: 0.0100 | Loss: 96.0436
Episode 85950 | Reward: -10.178 | Epsilon: 0.0100 | Loss: 95.0116
Episode 86000 | Reward:  -6.035 | Epsilon: 0.0100 | Loss: 49.1909
Model saved to PyTorch_models/model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(21:03).dict
✓ Model saved: model.DQN.hierarchical.Hierarchical.M1=8,M2=4.30-11-2025(21:03)
Episode 86050 | Reward:  -3.352 | Epsilon: 0.0100 | Loss: 63.1161
Episode 86100 | Reward:  -6.358 | Epsilon: 0.0100 | Loss: 108.6309
Episode 86150 | Reward:  -9.657 | Epsilon: 0.0100 | Loss: 91.2396
Episode 86200 | Reward: -11.299 | Epsilon: 0.0100 | Loss: 90.3997
Episode 86250 | Reward: -12.821 | Epsilon: 0.0100 | Loss: 95.9384
Episode 86300 | Reward:  -8.649 | Epsilon: 0.0100 | Loss: 93.9020
Episode 86350 | Reward: -10.211 | Epsilon: 0.0100 | Loss: 73.7017
Episode 86400 | Reward: -10.860 | Epsilon: 0.0100 | Loss: 97.7415
Episode 86450 | Reward:  -6.313 | Epsilon: 0.0100 | Loss: 82.7235
Episode 86500 | Reward:  -9.105 | Epsilon: 0.0100 | Loss: 89.0735
Episode 86550 | Reward:  -7.469 | Epsilon: 0.0100 | Loss: 101.4473
Episode 86600 | Reward:  -5.996 | Epsilon: 0.0100 | Loss: 83.5298
Episode 86650 | Reward:  -3.140 | Epsilon: 0.0100 | Loss: 104.5400
Episode 86700 | Reward:  -4.377 | Epsilon: 0.0100 | Loss: 97.7376
Episode 86750 | Reward:  -3.474 | Epsilon: 0.0100 | Loss: 89.4761
Episode 86800 | Reward:  -4.029 | Epsilon: 0.0100 | Loss: 96.5767
Episode 86850 | Reward:  -1.404 | Epsilon: 0.0100 | Loss: 88.3381
Episode 86900 | Reward:  -3.678 | Epsilon: 0.0100 | Loss: 61.6564
