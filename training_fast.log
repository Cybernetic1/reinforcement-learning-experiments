nohup: ignoring input
Using device: cpu (CUDA not available)
======================================================================
FAST TRAINING MODE - Optimizations:
- M=8 rules (doubled capacity for learning strategies)
- Learning rate: 0.003 (3x normal)
- Batch size: 128 (smaller for faster updates)
- Update every game
- Target network sync every 50 episodes
- No rendering/visualization
======================================================================
Episode    50 | Reward:  -9.794 | Epsilon: 0.7783
Episode   100 | Reward: -14.036 | Epsilon: 0.6058 | Loss: 168.9323
Episode   150 | Reward: -14.595 | Epsilon: 0.4715 | Loss: 134.7429
Episode   200 | Reward: -14.927 | Epsilon: 0.3670 | Loss: 125.5004
Episode   250 | Reward: -15.093 | Epsilon: 0.2856 | Loss: 125.3129
Episode   300 | Reward: -17.371 | Epsilon: 0.2223 | Loss: 145.0423
Episode   350 | Reward: -14.393 | Epsilon: 0.1730 | Loss: 157.5722
Episode   400 | Reward: -12.974 | Epsilon: 0.1347 | Loss: 137.3930
Episode   450 | Reward: -13.254 | Epsilon: 0.1048 | Loss: 165.6779
Episode   500 | Reward: -15.547 | Epsilon: 0.0816 | Loss: 196.5649
Episode   550 | Reward: -11.592 | Epsilon: 0.0635 | Loss: 157.9968
Episode   600 | Reward: -11.740 | Epsilon: 0.0494 | Loss: 149.4623
Episode   650 | Reward:  -8.868 | Epsilon: 0.0385 | Loss: 197.6252
Episode   700 | Reward: -10.471 | Epsilon: 0.0299 | Loss: 217.7977
Episode   750 | Reward:  -8.613 | Epsilon: 0.0233 | Loss: 235.1001
Episode   800 | Reward:  -3.680 | Epsilon: 0.0181 | Loss: 184.4224
Episode   850 | Reward: -12.640 | Epsilon: 0.0141 | Loss: 210.4557
Episode   900 | Reward: -12.704 | Epsilon: 0.0110 | Loss: 188.6836
Episode   950 | Reward:  -7.951 | Epsilon: 0.0100 | Loss: 219.6819
Episode  1000 | Reward:  -7.014 | Epsilon: 0.0100 | Loss: 259.8365
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:07).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:07).dict
Episode  1050 | Reward:  -8.935 | Epsilon: 0.0100 | Loss: 220.1659
Episode  1100 | Reward:  -6.520 | Epsilon: 0.0100 | Loss: 221.7290
Episode  1150 | Reward: -12.185 | Epsilon: 0.0100 | Loss: 224.2964
Episode  1200 | Reward:  -7.243 | Epsilon: 0.0100 | Loss: 246.4423
Episode  1250 | Reward:  -9.248 | Epsilon: 0.0100 | Loss: 254.4575
Episode  1300 | Reward: -11.539 | Epsilon: 0.0100 | Loss: 213.9631
Episode  1350 | Reward:  -7.199 | Epsilon: 0.0100 | Loss: 290.3609
Episode  1400 | Reward:  -4.891 | Epsilon: 0.0100 | Loss: 210.5294
Episode  1450 | Reward:  -6.158 | Epsilon: 0.0100 | Loss: 233.0381
Episode  1500 | Reward:  -9.840 | Epsilon: 0.0100 | Loss: 271.1498
Episode  1550 | Reward: -10.590 | Epsilon: 0.0100 | Loss: 306.5050
Episode  1600 | Reward:  -4.715 | Epsilon: 0.0100 | Loss: 235.8869
Episode  1650 | Reward:  -6.252 | Epsilon: 0.0100 | Loss: 237.3643
Episode  1700 | Reward:  -6.501 | Epsilon: 0.0100 | Loss: 221.7454
Episode  1750 | Reward:  -6.245 | Epsilon: 0.0100 | Loss: 244.9742
Episode  1800 | Reward:  -9.068 | Epsilon: 0.0100 | Loss: 299.0086
Episode  1850 | Reward:  -8.526 | Epsilon: 0.0100 | Loss: 308.6432
Episode  1900 | Reward:  -9.752 | Epsilon: 0.0100 | Loss: 250.3983
Episode  1950 | Reward:  -7.074 | Epsilon: 0.0100 | Loss: 292.7786
Episode  2000 | Reward:  -8.955 | Epsilon: 0.0100 | Loss: 277.6908
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:11).dict
Episode  2050 | Reward: -10.308 | Epsilon: 0.0100 | Loss: 242.1243
Episode  2100 | Reward:  -9.805 | Epsilon: 0.0100 | Loss: 311.2138
Episode  2150 | Reward:  -8.890 | Epsilon: 0.0100 | Loss: 245.0133
Episode  2200 | Reward:  -4.048 | Epsilon: 0.0100 | Loss: 293.2262
Episode  2250 | Reward:  -3.521 | Epsilon: 0.0100 | Loss: 254.2869
Episode  2300 | Reward:  -3.559 | Epsilon: 0.0100 | Loss: 333.6530
Episode  2350 | Reward:  -3.331 | Epsilon: 0.0100 | Loss: 266.1555
Episode  2400 | Reward: -10.858 | Epsilon: 0.0100 | Loss: 356.9975
Episode  2450 | Reward:  -7.944 | Epsilon: 0.0100 | Loss: 254.3834
Episode  2500 | Reward:  -3.349 | Epsilon: 0.0100 | Loss: 265.8495
Episode  2550 | Reward:  -6.167 | Epsilon: 0.0100 | Loss: 310.0538
Episode  2600 | Reward:  -5.881 | Epsilon: 0.0100 | Loss: 287.0134
Episode  2650 | Reward:  -7.121 | Epsilon: 0.0100 | Loss: 298.6323
Episode  2700 | Reward:  -7.449 | Epsilon: 0.0100 | Loss: 298.4295
Episode  2750 | Reward:  -9.094 | Epsilon: 0.0100 | Loss: 334.6619
Episode  2800 | Reward:  -0.928 | Epsilon: 0.0100 | Loss: 293.2818
Episode  2850 | Reward:  -3.793 | Epsilon: 0.0100 | Loss: 328.6668
Episode  2900 | Reward:  -4.401 | Epsilon: 0.0100 | Loss: 314.2172
Episode  2950 | Reward:  -7.343 | Epsilon: 0.0100 | Loss: 296.3185
Episode  3000 | Reward:  -4.989 | Epsilon: 0.0100 | Loss: 343.6557
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:15).dict
Episode  3050 | Reward:  -3.420 | Epsilon: 0.0100 | Loss: 351.4048
Episode  3100 | Reward:  -6.190 | Epsilon: 0.0100 | Loss: 258.6961
Episode  3150 | Reward:  -5.546 | Epsilon: 0.0100 | Loss: 364.4614
Episode  3200 | Reward:  -6.978 | Epsilon: 0.0100 | Loss: 227.0124
Episode  3250 | Reward:  -9.149 | Epsilon: 0.0100 | Loss: 271.3748
Episode  3300 | Reward:  -5.384 | Epsilon: 0.0100 | Loss: 277.7891
Episode  3350 | Reward:  -4.946 | Epsilon: 0.0100 | Loss: 271.6643
Episode  3400 | Reward:  -2.205 | Epsilon: 0.0100 | Loss: 312.8954
Episode  3450 | Reward:  -5.228 | Epsilon: 0.0100 | Loss: 263.4374
Episode  3500 | Reward:  -6.081 | Epsilon: 0.0100 | Loss: 287.4793
Episode  3550 | Reward:  -6.719 | Epsilon: 0.0100 | Loss: 244.3526
Episode  3600 | Reward:  -5.458 | Epsilon: 0.0100 | Loss: 360.4090
Episode  3650 | Reward:  -9.862 | Epsilon: 0.0100 | Loss: 269.7737
Episode  3700 | Reward:  -4.733 | Epsilon: 0.0100 | Loss: 250.1100
Episode  3750 | Reward:  -6.769 | Epsilon: 0.0100 | Loss: 338.5780
Episode  3800 | Reward:  -6.697 | Epsilon: 0.0100 | Loss: 305.3136
Episode  3850 | Reward:  -8.659 | Epsilon: 0.0100 | Loss: 316.1570
Episode  3900 | Reward:  -5.859 | Epsilon: 0.0100 | Loss: 341.2029
Episode  3950 | Reward:  -5.121 | Epsilon: 0.0100 | Loss: 240.0228
Episode  4000 | Reward:  -7.633 | Epsilon: 0.0100 | Loss: 320.2288
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:19).dict
Episode  4050 | Reward:  -3.679 | Epsilon: 0.0100 | Loss: 324.0897
Episode  4100 | Reward:  -3.186 | Epsilon: 0.0100 | Loss: 282.3937
Episode  4150 | Reward:  -3.905 | Epsilon: 0.0100 | Loss: 284.5053
Episode  4200 | Reward:  -4.339 | Epsilon: 0.0100 | Loss: 308.7262
Episode  4250 | Reward:  -3.050 | Epsilon: 0.0100 | Loss: 280.2762
Episode  4300 | Reward:  -1.584 | Epsilon: 0.0100 | Loss: 268.3507
Episode  4350 | Reward:  -3.890 | Epsilon: 0.0100 | Loss: 242.3276
Episode  4400 | Reward:  -6.544 | Epsilon: 0.0100 | Loss: 346.0942
Episode  4450 | Reward:  -8.535 | Epsilon: 0.0100 | Loss: 195.1305
Episode  4500 | Reward:  -7.575 | Epsilon: 0.0100 | Loss: 322.1723
Episode  4550 | Reward:  -5.118 | Epsilon: 0.0100 | Loss: 285.7951
Episode  4600 | Reward:  -6.268 | Epsilon: 0.0100 | Loss: 310.4099
Episode  4650 | Reward:  -0.355 | Epsilon: 0.0100 | Loss: 342.6944
Episode  4700 | Reward:  -2.800 | Epsilon: 0.0100 | Loss: 326.2209
Episode  4750 | Reward:  -4.261 | Epsilon: 0.0100 | Loss: 386.3354
Episode  4800 | Reward:  -3.077 | Epsilon: 0.0100 | Loss: 270.2320
Episode  4850 | Reward:  -3.920 | Epsilon: 0.0100 | Loss: 305.0900
Episode  4900 | Reward:  -3.371 | Epsilon: 0.0100 | Loss: 409.8623
Episode  4950 | Reward:  -7.387 | Epsilon: 0.0100 | Loss: 352.6458
Episode  5000 | Reward:  -6.457 | Epsilon: 0.0100 | Loss: 254.6013
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:23).dict
Episode  5050 | Reward:  -1.377 | Epsilon: 0.0100 | Loss: 341.2880
Episode  5100 | Reward:  -2.809 | Epsilon: 0.0100 | Loss: 315.4394
Episode  5150 | Reward:  -6.478 | Epsilon: 0.0100 | Loss: 290.3045
Episode  5200 | Reward:  -2.753 | Epsilon: 0.0100 | Loss: 342.4021
Episode  5250 | Reward:  -1.003 | Epsilon: 0.0100 | Loss: 292.4580
Episode  5300 | Reward:  -1.640 | Epsilon: 0.0100 | Loss: 387.9058
Episode  5350 | Reward:  -3.089 | Epsilon: 0.0100 | Loss: 316.2260
Episode  5400 | Reward:   1.140 | Epsilon: 0.0100 | Loss: 240.2615
Episode  5450 | Reward:  -4.441 | Epsilon: 0.0100 | Loss: 351.2535
Episode  5500 | Reward:  -3.381 | Epsilon: 0.0100 | Loss: 305.0460
Episode  5550 | Reward:  -6.555 | Epsilon: 0.0100 | Loss: 360.0563
Episode  5600 | Reward:  -3.567 | Epsilon: 0.0100 | Loss: 307.3590
Episode  5650 | Reward:  -6.310 | Epsilon: 0.0100 | Loss: 336.5711
Episode  5700 | Reward:  -8.304 | Epsilon: 0.0100 | Loss: 365.3198
Episode  5750 | Reward:  -4.324 | Epsilon: 0.0100 | Loss: 274.0853
Episode  5800 | Reward:  -4.928 | Epsilon: 0.0100 | Loss: 334.7840
Episode  5850 | Reward:  -4.896 | Epsilon: 0.0100 | Loss: 250.4067
Episode  5900 | Reward:  -6.111 | Epsilon: 0.0100 | Loss: 364.9890
Episode  5950 | Reward:   1.265 | Epsilon: 0.0100 | Loss: 353.5979
Episode  6000 | Reward:  -0.368 | Epsilon: 0.0100 | Loss: 298.3632
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:27).dict
Episode  6050 | Reward:  -3.320 | Epsilon: 0.0100 | Loss: 255.8552
Episode  6100 | Reward:  -5.995 | Epsilon: 0.0100 | Loss: 206.6287
Episode  6150 | Reward:  -6.119 | Epsilon: 0.0100 | Loss: 390.9024
Episode  6200 | Reward:  -3.716 | Epsilon: 0.0100 | Loss: 273.5657
Episode  6250 | Reward:  -3.735 | Epsilon: 0.0100 | Loss: 281.0341
Episode  6300 | Reward:  -4.845 | Epsilon: 0.0100 | Loss: 242.2547
Episode  6350 | Reward:  -0.774 | Epsilon: 0.0100 | Loss: 305.3502
Episode  6400 | Reward:  -8.390 | Epsilon: 0.0100 | Loss: 359.5810
Episode  6450 | Reward:  -5.224 | Epsilon: 0.0100 | Loss: 293.2729
Episode  6500 | Reward:  -7.681 | Epsilon: 0.0100 | Loss: 266.9776
Episode  6550 | Reward:  -3.321 | Epsilon: 0.0100 | Loss: 380.0767
Episode  6600 | Reward:  -7.471 | Epsilon: 0.0100 | Loss: 351.8943
Episode  6650 | Reward:  -5.256 | Epsilon: 0.0100 | Loss: 267.2741
Episode  6700 | Reward:  -9.358 | Epsilon: 0.0100 | Loss: 352.4360
Episode  6750 | Reward:  -5.934 | Epsilon: 0.0100 | Loss: 292.9062
Episode  6800 | Reward:  -1.349 | Epsilon: 0.0100 | Loss: 300.6693
Episode  6850 | Reward:  -0.635 | Epsilon: 0.0100 | Loss: 316.1520
Episode  6900 | Reward:  -1.586 | Epsilon: 0.0100 | Loss: 400.0742
Episode  6950 | Reward:  -2.370 | Epsilon: 0.0100 | Loss: 326.3937
Episode  7000 | Reward:  -2.075 | Epsilon: 0.0100 | Loss: 313.4004
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:31).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:31).dict
Episode  7050 | Reward:  -4.037 | Epsilon: 0.0100 | Loss: 312.9584
Episode  7100 | Reward:  -1.875 | Epsilon: 0.0100 | Loss: 352.0840
Episode  7150 | Reward:  -4.455 | Epsilon: 0.0100 | Loss: 217.4478
Episode  7200 | Reward:  -2.218 | Epsilon: 0.0100 | Loss: 333.0567
Episode  7250 | Reward:  -6.847 | Epsilon: 0.0100 | Loss: 273.3566
Episode  7300 | Reward:  -7.253 | Epsilon: 0.0100 | Loss: 383.0188
Episode  7350 | Reward:  -6.552 | Epsilon: 0.0100 | Loss: 382.0359
Episode  7400 | Reward:  -3.959 | Epsilon: 0.0100 | Loss: 397.6829
Episode  7450 | Reward:  -3.821 | Epsilon: 0.0100 | Loss: 387.4198
Episode  7500 | Reward:  -4.834 | Epsilon: 0.0100 | Loss: 330.4619
Episode  7550 | Reward:  -9.681 | Epsilon: 0.0100 | Loss: 337.1889
Episode  7600 | Reward:  -5.953 | Epsilon: 0.0100 | Loss: 386.6297
Episode  7650 | Reward:  -3.523 | Epsilon: 0.0100 | Loss: 339.1820
Episode  7700 | Reward:  -7.132 | Epsilon: 0.0100 | Loss: 317.1823
Episode  7750 | Reward:  -7.236 | Epsilon: 0.0100 | Loss: 350.6108
Episode  7800 | Reward:  -8.502 | Epsilon: 0.0100 | Loss: 331.9010
Episode  7850 | Reward: -13.464 | Epsilon: 0.0100 | Loss: 267.8882
Episode  7900 | Reward:  -9.096 | Epsilon: 0.0100 | Loss: 255.4489
Episode  7950 | Reward:  -6.186 | Epsilon: 0.0100 | Loss: 408.4542
Episode  8000 | Reward:  -3.635 | Epsilon: 0.0100 | Loss: 315.8721
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:35).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:35).dict
Episode  8050 | Reward:  -2.572 | Epsilon: 0.0100 | Loss: 390.0157
Episode  8100 | Reward:  -5.338 | Epsilon: 0.0100 | Loss: 292.8403
Episode  8150 | Reward:  -6.235 | Epsilon: 0.0100 | Loss: 512.5615
Episode  8200 | Reward:  -6.135 | Epsilon: 0.0100 | Loss: 358.3991
Episode  8250 | Reward:  -6.062 | Epsilon: 0.0100 | Loss: 308.9561
Episode  8300 | Reward:  -2.421 | Epsilon: 0.0100 | Loss: 361.1167
Episode  8350 | Reward:  -3.776 | Epsilon: 0.0100 | Loss: 300.5286
Episode  8400 | Reward:  -2.404 | Epsilon: 0.0100 | Loss: 357.3381
Episode  8450 | Reward:  -3.197 | Epsilon: 0.0100 | Loss: 348.4893
Episode  8500 | Reward:  -2.682 | Epsilon: 0.0100 | Loss: 304.7883
Episode  8550 | Reward:  -1.374 | Epsilon: 0.0100 | Loss: 338.8085
Episode  8600 | Reward:  -6.824 | Epsilon: 0.0100 | Loss: 370.6172
Episode  8650 | Reward:  -5.866 | Epsilon: 0.0100 | Loss: 403.2705
Episode  8700 | Reward:  -4.531 | Epsilon: 0.0100 | Loss: 434.8113
Episode  8750 | Reward:  -7.769 | Epsilon: 0.0100 | Loss: 356.5875
Episode  8800 | Reward:  -4.456 | Epsilon: 0.0100 | Loss: 207.2579
Episode  8850 | Reward:  -5.757 | Epsilon: 0.0100 | Loss: 397.5918
Episode  8900 | Reward:  -6.752 | Epsilon: 0.0100 | Loss: 390.7084
Episode  8950 | Reward:  -5.923 | Epsilon: 0.0100 | Loss: 357.1490
Episode  9000 | Reward:  -2.316 | Epsilon: 0.0100 | Loss: 374.4799
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:39).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:39).dict
Episode  9050 | Reward:  -5.295 | Epsilon: 0.0100 | Loss: 315.5856
Episode  9100 | Reward:  -9.280 | Epsilon: 0.0100 | Loss: 373.7147
Episode  9150 | Reward:  -5.485 | Epsilon: 0.0100 | Loss: 306.9443
Episode  9200 | Reward:  -8.796 | Epsilon: 0.0100 | Loss: 364.1805
Episode  9250 | Reward:  -6.103 | Epsilon: 0.0100 | Loss: 368.3338
Episode  9300 | Reward:  -5.086 | Epsilon: 0.0100 | Loss: 395.7409
Episode  9350 | Reward:  -7.212 | Epsilon: 0.0100 | Loss: 396.7062
Episode  9400 | Reward:  -6.959 | Epsilon: 0.0100 | Loss: 404.8238
Episode  9450 | Reward:  -6.390 | Epsilon: 0.0100 | Loss: 311.6382
Episode  9500 | Reward:  -1.818 | Epsilon: 0.0100 | Loss: 349.3392
Episode  9550 | Reward:  -3.111 | Epsilon: 0.0100 | Loss: 353.8939
Episode  9600 | Reward:  -7.405 | Epsilon: 0.0100 | Loss: 354.0074
Episode  9650 | Reward:  -4.311 | Epsilon: 0.0100 | Loss: 364.9801
Episode  9700 | Reward:  -3.200 | Epsilon: 0.0100 | Loss: 351.4666
Episode  9750 | Reward:  -8.581 | Epsilon: 0.0100 | Loss: 394.8224
Episode  9800 | Reward:  -3.575 | Epsilon: 0.0100 | Loss: 332.4576
Episode  9850 | Reward:  -6.533 | Epsilon: 0.0100 | Loss: 361.2695
Episode  9900 | Reward:  -6.649 | Epsilon: 0.0100 | Loss: 358.1016
Episode  9950 | Reward:  -7.731 | Epsilon: 0.0100 | Loss: 231.0884
Episode 10000 | Reward:  -6.617 | Epsilon: 0.0100 | Loss: 421.0938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:43).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:43).dict
Episode 10050 | Reward:  -9.194 | Epsilon: 0.0100 | Loss: 440.7867
Episode 10100 | Reward:  -9.882 | Epsilon: 0.0100 | Loss: 409.7072
Episode 10150 | Reward:  -6.825 | Epsilon: 0.0100 | Loss: 285.7183
Episode 10200 | Reward:  -8.281 | Epsilon: 0.0100 | Loss: 307.0660
Episode 10250 | Reward:  -5.226 | Epsilon: 0.0100 | Loss: 370.2766
Episode 10300 | Reward:  -5.447 | Epsilon: 0.0100 | Loss: 234.4301
Episode 10350 | Reward:  -8.176 | Epsilon: 0.0100 | Loss: 358.6227
Episode 10400 | Reward: -10.237 | Epsilon: 0.0100 | Loss: 286.4575
Episode 10450 | Reward:  -9.797 | Epsilon: 0.0100 | Loss: 312.0504
Episode 10500 | Reward: -10.511 | Epsilon: 0.0100 | Loss: 339.9561
Episode 10550 | Reward:  -9.944 | Epsilon: 0.0100 | Loss: 399.0337
Episode 10600 | Reward:  -2.742 | Epsilon: 0.0100 | Loss: 425.9214
Episode 10650 | Reward:  -5.279 | Epsilon: 0.0100 | Loss: 393.4025
Episode 10700 | Reward:  -6.054 | Epsilon: 0.0100 | Loss: 303.1968
Episode 10750 | Reward: -11.139 | Epsilon: 0.0100 | Loss: 323.4059
Episode 10800 | Reward: -12.360 | Epsilon: 0.0100 | Loss: 304.3079
Episode 10850 | Reward:  -9.876 | Epsilon: 0.0100 | Loss: 316.2768
Episode 10900 | Reward:  -7.931 | Epsilon: 0.0100 | Loss: 277.6008
Episode 10950 | Reward:  -6.911 | Epsilon: 0.0100 | Loss: 362.7436
Episode 11000 | Reward:  -2.963 | Epsilon: 0.0100 | Loss: 279.9217
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:47).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:47).dict
Episode 11050 | Reward:  -6.921 | Epsilon: 0.0100 | Loss: 425.6168
Episode 11100 | Reward:  -4.046 | Epsilon: 0.0100 | Loss: 354.5161
Episode 11150 | Reward:  -5.040 | Epsilon: 0.0100 | Loss: 413.7012
Episode 11200 | Reward:  -5.168 | Epsilon: 0.0100 | Loss: 394.2428
Episode 11250 | Reward:  -8.286 | Epsilon: 0.0100 | Loss: 392.6112
Episode 11300 | Reward:  -6.966 | Epsilon: 0.0100 | Loss: 402.6342
Episode 11350 | Reward:  -8.892 | Epsilon: 0.0100 | Loss: 391.2658
Episode 11400 | Reward:  -4.216 | Epsilon: 0.0100 | Loss: 373.1984
Episode 11450 | Reward:  -9.033 | Epsilon: 0.0100 | Loss: 375.8400
Episode 11500 | Reward: -10.468 | Epsilon: 0.0100 | Loss: 351.1786
Episode 11550 | Reward:  -9.875 | Epsilon: 0.0100 | Loss: 356.0105
Episode 11600 | Reward: -11.483 | Epsilon: 0.0100 | Loss: 471.6036
Episode 11650 | Reward: -11.374 | Epsilon: 0.0100 | Loss: 429.5354
Episode 11700 | Reward:  -3.503 | Epsilon: 0.0100 | Loss: 483.2887
Episode 11750 | Reward:  -8.689 | Epsilon: 0.0100 | Loss: 445.8614
Episode 11800 | Reward: -10.310 | Epsilon: 0.0100 | Loss: 271.5497
Episode 11850 | Reward:  -4.787 | Epsilon: 0.0100 | Loss: 342.9770
Episode 11900 | Reward:  -5.710 | Epsilon: 0.0100 | Loss: 344.4077
Episode 11950 | Reward:  -6.128 | Epsilon: 0.0100 | Loss: 505.1266
Episode 12000 | Reward:  -8.122 | Epsilon: 0.0100 | Loss: 448.4852
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:51).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:51).dict
Episode 12050 | Reward:  -4.750 | Epsilon: 0.0100 | Loss: 586.7662
Episode 12100 | Reward:  -4.943 | Epsilon: 0.0100 | Loss: 520.0784
Episode 12150 | Reward:  -4.302 | Epsilon: 0.0100 | Loss: 408.4809
Episode 12200 | Reward:  -5.017 | Epsilon: 0.0100 | Loss: 404.4241
Episode 12250 | Reward:  -9.224 | Epsilon: 0.0100 | Loss: 347.1594
Episode 12300 | Reward:  -8.762 | Epsilon: 0.0100 | Loss: 370.1365
Episode 12350 | Reward:  -6.725 | Epsilon: 0.0100 | Loss: 375.6532
Episode 12400 | Reward:  -8.134 | Epsilon: 0.0100 | Loss: 484.3892
Episode 12450 | Reward:  -8.395 | Epsilon: 0.0100 | Loss: 436.3488
Episode 12500 | Reward:  -5.059 | Epsilon: 0.0100 | Loss: 464.3962
Episode 12550 | Reward:  -5.933 | Epsilon: 0.0100 | Loss: 479.1015
Episode 12600 | Reward:  -7.378 | Epsilon: 0.0100 | Loss: 458.9956
Episode 12650 | Reward:  -6.359 | Epsilon: 0.0100 | Loss: 594.9951
Episode 12700 | Reward: -10.005 | Epsilon: 0.0100 | Loss: 632.0894
Episode 12750 | Reward: -12.797 | Epsilon: 0.0100 | Loss: 436.9865
Episode 12800 | Reward:  -8.096 | Epsilon: 0.0100 | Loss: 526.6245
Episode 12850 | Reward:  -3.620 | Epsilon: 0.0100 | Loss: 531.9869
Episode 12900 | Reward:  -3.013 | Epsilon: 0.0100 | Loss: 602.2859
Episode 12950 | Reward:  -8.928 | Epsilon: 0.0100 | Loss: 519.4984
Episode 13000 | Reward:  -7.947 | Epsilon: 0.0100 | Loss: 504.0713
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:55).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:55).dict
Episode 13050 | Reward: -10.293 | Epsilon: 0.0100 | Loss: 486.3450
Episode 13100 | Reward:  -5.196 | Epsilon: 0.0100 | Loss: 689.5452
Episode 13150 | Reward:  -5.573 | Epsilon: 0.0100 | Loss: 555.1044
Episode 13200 | Reward:  -2.081 | Epsilon: 0.0100 | Loss: 633.2874
Episode 13250 | Reward:  -6.975 | Epsilon: 0.0100 | Loss: 558.5043
Episode 13300 | Reward:  -9.168 | Epsilon: 0.0100 | Loss: 556.1238
Episode 13350 | Reward:  -8.415 | Epsilon: 0.0100 | Loss: 566.4802
Episode 13400 | Reward:  -4.987 | Epsilon: 0.0100 | Loss: 577.6959
Episode 13450 | Reward:  -5.964 | Epsilon: 0.0100 | Loss: 578.1879
Episode 13500 | Reward:  -5.186 | Epsilon: 0.0100 | Loss: 282.7482
Episode 13550 | Reward:  -4.291 | Epsilon: 0.0100 | Loss: 648.7049
Episode 13600 | Reward:  -3.330 | Epsilon: 0.0100 | Loss: 521.4188
Episode 13650 | Reward:  -2.298 | Epsilon: 0.0100 | Loss: 550.7197
Episode 13700 | Reward:  -3.336 | Epsilon: 0.0100 | Loss: 534.5420
Episode 13750 | Reward:  -7.642 | Epsilon: 0.0100 | Loss: 703.8216
Episode 13800 | Reward:  -8.132 | Epsilon: 0.0100 | Loss: 634.9241
Episode 13850 | Reward:  -6.685 | Epsilon: 0.0100 | Loss: 525.5409
Episode 13900 | Reward:  -2.513 | Epsilon: 0.0100 | Loss: 608.6684
Episode 13950 | Reward:  -4.842 | Epsilon: 0.0100 | Loss: 690.0179
Episode 14000 | Reward:  -4.477 | Epsilon: 0.0100 | Loss: 527.2338
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:59).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:59).dict
Episode 14050 | Reward:  -5.823 | Epsilon: 0.0100 | Loss: 609.9561
Episode 14100 | Reward:  -7.339 | Epsilon: 0.0100 | Loss: 599.8611
Episode 14150 | Reward: -10.404 | Epsilon: 0.0100 | Loss: 497.6542
Episode 14200 | Reward: -11.802 | Epsilon: 0.0100 | Loss: 528.6818
Episode 14250 | Reward:  -8.682 | Epsilon: 0.0100 | Loss: 568.0593
Episode 14300 | Reward:  -8.212 | Epsilon: 0.0100 | Loss: 570.9252
Episode 14350 | Reward:  -3.669 | Epsilon: 0.0100 | Loss: 520.3203
Episode 14400 | Reward:  -5.487 | Epsilon: 0.0100 | Loss: 458.8148
Episode 14450 | Reward:  -4.339 | Epsilon: 0.0100 | Loss: 565.2724
Episode 14500 | Reward:  -6.114 | Epsilon: 0.0100 | Loss: 548.6002
Episode 14550 | Reward: -11.231 | Epsilon: 0.0100 | Loss: 427.4100
Episode 14600 | Reward:  -7.247 | Epsilon: 0.0100 | Loss: 467.8864
Episode 14650 | Reward:  -4.879 | Epsilon: 0.0100 | Loss: 422.7119
Episode 14700 | Reward:  -4.561 | Epsilon: 0.0100 | Loss: 485.3140
Episode 14750 | Reward:  -1.922 | Epsilon: 0.0100 | Loss: 390.3515
Episode 14800 | Reward: -11.386 | Epsilon: 0.0100 | Loss: 507.2319
Episode 14850 | Reward:  -7.393 | Epsilon: 0.0100 | Loss: 595.6957
Episode 14900 | Reward:  -8.966 | Epsilon: 0.0100 | Loss: 540.6078
Episode 14950 | Reward:  -4.097 | Epsilon: 0.0100 | Loss: 499.8517
Episode 15000 | Reward:  -7.644 | Epsilon: 0.0100 | Loss: 523.3839
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:03).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:03).dict
Episode 15050 | Reward: -11.453 | Epsilon: 0.0100 | Loss: 426.1686
Episode 15100 | Reward:  -6.750 | Epsilon: 0.0100 | Loss: 609.7834
Episode 15150 | Reward:  -7.358 | Epsilon: 0.0100 | Loss: 357.6180
Episode 15200 | Reward:  -8.949 | Epsilon: 0.0100 | Loss: 543.1511
Episode 15250 | Reward:  -8.210 | Epsilon: 0.0100 | Loss: 641.0079
Episode 15300 | Reward:  -9.692 | Epsilon: 0.0100 | Loss: 629.6071
Episode 15350 | Reward: -10.112 | Epsilon: 0.0100 | Loss: 692.5609
Episode 15400 | Reward: -11.229 | Epsilon: 0.0100 | Loss: 570.0730
Episode 15450 | Reward: -10.000 | Epsilon: 0.0100 | Loss: 498.9732
Episode 15500 | Reward:  -6.198 | Epsilon: 0.0100 | Loss: 522.8079
Episode 15550 | Reward:  -6.805 | Epsilon: 0.0100 | Loss: 521.5084
Episode 15600 | Reward: -13.487 | Epsilon: 0.0100 | Loss: 796.9832
Episode 15650 | Reward: -15.103 | Epsilon: 0.0100 | Loss: 566.7864
Episode 15700 | Reward:  -9.310 | Epsilon: 0.0100 | Loss: 733.5717
Episode 15750 | Reward:  -7.573 | Epsilon: 0.0100 | Loss: 372.6942
Episode 15800 | Reward:  -6.330 | Epsilon: 0.0100 | Loss: 628.4660
Episode 15850 | Reward:  -6.961 | Epsilon: 0.0100 | Loss: 379.1384
Episode 15900 | Reward:  -4.967 | Epsilon: 0.0100 | Loss: 582.2410
Episode 15950 | Reward:  -7.302 | Epsilon: 0.0100 | Loss: 439.8287
Episode 16000 | Reward:  -8.586 | Epsilon: 0.0100 | Loss: 573.6304
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:07).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:07).dict
Episode 16050 | Reward:  -7.845 | Epsilon: 0.0100 | Loss: 647.4645
Episode 16100 | Reward:  -9.547 | Epsilon: 0.0100 | Loss: 636.3641
Episode 16150 | Reward:  -7.642 | Epsilon: 0.0100 | Loss: 533.0068
Episode 16200 | Reward:  -5.583 | Epsilon: 0.0100 | Loss: 573.1762
Episode 16250 | Reward:  -2.207 | Epsilon: 0.0100 | Loss: 561.1449
Episode 16300 | Reward:  -7.434 | Epsilon: 0.0100 | Loss: 521.3799
Episode 16350 | Reward:  -5.260 | Epsilon: 0.0100 | Loss: 467.7144
Episode 16400 | Reward: -11.977 | Epsilon: 0.0100 | Loss: 497.8287
Episode 16450 | Reward:  -3.938 | Epsilon: 0.0100 | Loss: 487.1426
Episode 16500 | Reward:  -3.687 | Epsilon: 0.0100 | Loss: 559.5478
Episode 16550 | Reward:  -2.964 | Epsilon: 0.0100 | Loss: 536.9007
Episode 16600 | Reward:  -4.764 | Epsilon: 0.0100 | Loss: 504.7383
Episode 16650 | Reward:  -6.976 | Epsilon: 0.0100 | Loss: 494.8686
Episode 16700 | Reward:  -4.710 | Epsilon: 0.0100 | Loss: 581.2158
Episode 16750 | Reward:  -2.920 | Epsilon: 0.0100 | Loss: 627.8469
Episode 16800 | Reward:  -3.817 | Epsilon: 0.0100 | Loss: 504.6410
Episode 16850 | Reward:  -5.010 | Epsilon: 0.0100 | Loss: 635.9022
Episode 16900 | Reward:  -7.348 | Epsilon: 0.0100 | Loss: 468.6729
Episode 16950 | Reward:  -5.692 | Epsilon: 0.0100 | Loss: 707.8201
Episode 17000 | Reward:  -9.704 | Epsilon: 0.0100 | Loss: 457.9349
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:11).dict
Episode 17050 | Reward:  -7.263 | Epsilon: 0.0100 | Loss: 731.8945
Episode 17100 | Reward:  -6.265 | Epsilon: 0.0100 | Loss: 726.0003
Episode 17150 | Reward:  -3.880 | Epsilon: 0.0100 | Loss: 677.1733
Episode 17200 | Reward:  -7.561 | Epsilon: 0.0100 | Loss: 681.5648
Episode 17250 | Reward:  -5.428 | Epsilon: 0.0100 | Loss: 622.4689
Episode 17300 | Reward:  -7.527 | Epsilon: 0.0100 | Loss: 656.5275
Episode 17350 | Reward:  -8.199 | Epsilon: 0.0100 | Loss: 574.4487
Episode 17400 | Reward:  -9.435 | Epsilon: 0.0100 | Loss: 593.4701
Episode 17450 | Reward: -10.386 | Epsilon: 0.0100 | Loss: 636.1678
Episode 17500 | Reward: -11.222 | Epsilon: 0.0100 | Loss: 453.1348
Episode 17550 | Reward: -10.813 | Epsilon: 0.0100 | Loss: 562.7097
Episode 17600 | Reward:  -9.825 | Epsilon: 0.0100 | Loss: 605.9893
Episode 17650 | Reward:  -2.426 | Epsilon: 0.0100 | Loss: 516.0023
Episode 17700 | Reward:  -7.180 | Epsilon: 0.0100 | Loss: 524.5940
Episode 17750 | Reward:  -8.853 | Epsilon: 0.0100 | Loss: 521.0340
Episode 17800 | Reward:  -5.773 | Epsilon: 0.0100 | Loss: 575.6946
Episode 17850 | Reward:  -3.859 | Epsilon: 0.0100 | Loss: 575.0355
Episode 17900 | Reward:  -5.430 | Epsilon: 0.0100 | Loss: 498.3717
Episode 17950 | Reward:  -7.052 | Epsilon: 0.0100 | Loss: 411.3793
Episode 18000 | Reward:  -6.711 | Epsilon: 0.0100 | Loss: 541.3459
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:15).dict
Episode 18050 | Reward:  -5.567 | Epsilon: 0.0100 | Loss: 680.8770
Episode 18100 | Reward:   0.228 | Epsilon: 0.0100 | Loss: 656.8277
Episode 18150 | Reward:  -3.378 | Epsilon: 0.0100 | Loss: 434.0187
Episode 18200 | Reward:  -3.733 | Epsilon: 0.0100 | Loss: 528.4227
Episode 18250 | Reward:  -4.734 | Epsilon: 0.0100 | Loss: 482.7637
Episode 18300 | Reward:  -4.956 | Epsilon: 0.0100 | Loss: 516.6314
Episode 18350 | Reward:  -4.125 | Epsilon: 0.0100 | Loss: 508.5850
Episode 18400 | Reward:  -6.633 | Epsilon: 0.0100 | Loss: 471.3449
Episode 18450 | Reward:  -8.148 | Epsilon: 0.0100 | Loss: 510.1443
Episode 18500 | Reward:  -6.713 | Epsilon: 0.0100 | Loss: 527.7671
Episode 18550 | Reward:  -6.459 | Epsilon: 0.0100 | Loss: 547.1879
Episode 18600 | Reward:  -2.574 | Epsilon: 0.0100 | Loss: 446.9273
Episode 18650 | Reward:  -4.837 | Epsilon: 0.0100 | Loss: 507.2714
Episode 18700 | Reward:  -3.785 | Epsilon: 0.0100 | Loss: 553.8550
Episode 18750 | Reward:  -7.842 | Epsilon: 0.0100 | Loss: 658.5917
Episode 18800 | Reward:  -5.943 | Epsilon: 0.0100 | Loss: 556.6152
Episode 18850 | Reward:  -8.622 | Epsilon: 0.0100 | Loss: 372.1400
Episode 18900 | Reward:  -8.704 | Epsilon: 0.0100 | Loss: 571.2936
Episode 18950 | Reward:  -7.359 | Epsilon: 0.0100 | Loss: 427.1776
Episode 19000 | Reward:  -6.767 | Epsilon: 0.0100 | Loss: 393.9003
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:19).dict
Episode 19050 | Reward:  -5.512 | Epsilon: 0.0100 | Loss: 493.1027
Episode 19100 | Reward:  -6.632 | Epsilon: 0.0100 | Loss: 531.7175
Episode 19150 | Reward:  -8.493 | Epsilon: 0.0100 | Loss: 433.2559
Episode 19200 | Reward:  -9.219 | Epsilon: 0.0100 | Loss: 477.2155
Episode 19250 | Reward:  -5.308 | Epsilon: 0.0100 | Loss: 523.4648
Episode 19300 | Reward:  -7.357 | Epsilon: 0.0100 | Loss: 533.5153
Episode 19350 | Reward:  -7.899 | Epsilon: 0.0100 | Loss: 430.9903
Episode 19400 | Reward: -10.498 | Epsilon: 0.0100 | Loss: 525.2471
Episode 19450 | Reward:  -7.339 | Epsilon: 0.0100 | Loss: 508.0274
Episode 19500 | Reward:  -2.982 | Epsilon: 0.0100 | Loss: 593.5460
Episode 19550 | Reward:  -8.890 | Epsilon: 0.0100 | Loss: 320.9682
Episode 19600 | Reward: -11.236 | Epsilon: 0.0100 | Loss: 524.4878
Episode 19650 | Reward:  -8.594 | Epsilon: 0.0100 | Loss: 492.9721
Episode 19700 | Reward:  -7.830 | Epsilon: 0.0100 | Loss: 395.6765
Episode 19750 | Reward:  -6.543 | Epsilon: 0.0100 | Loss: 379.2006
Episode 19800 | Reward:  -8.575 | Epsilon: 0.0100 | Loss: 581.8560
Episode 19850 | Reward:  -4.497 | Epsilon: 0.0100 | Loss: 464.5403
Episode 19900 | Reward:  -9.154 | Epsilon: 0.0100 | Loss: 497.3504
Episode 19950 | Reward: -11.495 | Epsilon: 0.0100 | Loss: 493.7328
Episode 20000 | Reward:  -8.844 | Epsilon: 0.0100 | Loss: 490.9796
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:23).dict
Episode 20050 | Reward:  -6.222 | Epsilon: 0.0100 | Loss: 508.7732
Episode 20100 | Reward:  -6.218 | Epsilon: 0.0100 | Loss: 478.3805
Episode 20150 | Reward:  -5.655 | Epsilon: 0.0100 | Loss: 488.2120
Episode 20200 | Reward:  -4.200 | Epsilon: 0.0100 | Loss: 462.9913
Episode 20250 | Reward:  -7.965 | Epsilon: 0.0100 | Loss: 338.5023
Episode 20300 | Reward:  -6.499 | Epsilon: 0.0100 | Loss: 555.0377
Episode 20350 | Reward:  -4.207 | Epsilon: 0.0100 | Loss: 480.4344
Episode 20400 | Reward:  -6.494 | Epsilon: 0.0100 | Loss: 580.1677
Episode 20450 | Reward:  -5.728 | Epsilon: 0.0100 | Loss: 575.4919
Episode 20500 | Reward:  -5.651 | Epsilon: 0.0100 | Loss: 554.4167
Episode 20550 | Reward:  -4.547 | Epsilon: 0.0100 | Loss: 593.1636
Episode 20600 | Reward:  -6.239 | Epsilon: 0.0100 | Loss: 614.8160
Episode 20650 | Reward:  -4.857 | Epsilon: 0.0100 | Loss: 555.3944
Episode 20700 | Reward:  -4.846 | Epsilon: 0.0100 | Loss: 719.1940
Episode 20750 | Reward:  -8.470 | Epsilon: 0.0100 | Loss: 559.8193
Episode 20800 | Reward:  -7.231 | Epsilon: 0.0100 | Loss: 511.3970
Episode 20850 | Reward:  -4.760 | Epsilon: 0.0100 | Loss: 545.7463
Episode 20900 | Reward:  -8.344 | Epsilon: 0.0100 | Loss: 645.0160
Episode 20950 | Reward:  -3.206 | Epsilon: 0.0100 | Loss: 770.4101
Episode 21000 | Reward:  -7.114 | Epsilon: 0.0100 | Loss: 662.7615
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:27).dict
Episode 21050 | Reward:  -4.423 | Epsilon: 0.0100 | Loss: 688.1955
Episode 21100 | Reward:  -4.508 | Epsilon: 0.0100 | Loss: 553.8780
Episode 21150 | Reward:  -6.646 | Epsilon: 0.0100 | Loss: 721.3814
Episode 21200 | Reward:  -8.443 | Epsilon: 0.0100 | Loss: 808.5131
Episode 21250 | Reward:  -7.117 | Epsilon: 0.0100 | Loss: 746.7266
Episode 21300 | Reward:  -3.144 | Epsilon: 0.0100 | Loss: 579.4944
Episode 21350 | Reward:  -1.555 | Epsilon: 0.0100 | Loss: 766.7521
Episode 21400 | Reward:  -3.687 | Epsilon: 0.0100 | Loss: 672.7001
Episode 21450 | Reward:  -5.131 | Epsilon: 0.0100 | Loss: 907.4791
Episode 21500 | Reward:  -1.141 | Epsilon: 0.0100 | Loss: 972.6287
Episode 21550 | Reward:  -3.866 | Epsilon: 0.0100 | Loss: 997.0081
Episode 21600 | Reward:  -3.608 | Epsilon: 0.0100 | Loss: 763.0565
Episode 21650 | Reward:  -9.006 | Epsilon: 0.0100 | Loss: 834.5942
Episode 21700 | Reward:  -1.280 | Epsilon: 0.0100 | Loss: 936.4106
Episode 21750 | Reward:  -5.601 | Epsilon: 0.0100 | Loss: 963.1552
Episode 21800 | Reward:  -2.977 | Epsilon: 0.0100 | Loss: 732.7397
Episode 21850 | Reward:  -5.785 | Epsilon: 0.0100 | Loss: 811.9314
Episode 21900 | Reward:  -1.926 | Epsilon: 0.0100 | Loss: 1069.2422
Episode 21950 | Reward:  -5.734 | Epsilon: 0.0100 | Loss: 874.6390
Episode 22000 | Reward:  -8.487 | Epsilon: 0.0100 | Loss: 904.2197
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:31).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:31).dict
Episode 22050 | Reward:  -4.085 | Epsilon: 0.0100 | Loss: 810.4187
Episode 22100 | Reward:  -7.321 | Epsilon: 0.0100 | Loss: 991.7050
Episode 22150 | Reward:  -4.352 | Epsilon: 0.0100 | Loss: 1080.5330
Episode 22200 | Reward:  -2.748 | Epsilon: 0.0100 | Loss: 721.4049
Episode 22250 | Reward:  -5.697 | Epsilon: 0.0100 | Loss: 1013.0134
Episode 22300 | Reward:  -5.442 | Epsilon: 0.0100 | Loss: 876.1938
Episode 22350 | Reward:  -4.638 | Epsilon: 0.0100 | Loss: 973.0903
Episode 22400 | Reward:  -4.407 | Epsilon: 0.0100 | Loss: 1026.2577
Episode 22450 | Reward:  -7.413 | Epsilon: 0.0100 | Loss: 1041.0940
Episode 22500 | Reward:   0.060 | Epsilon: 0.0100 | Loss: 963.5442
Episode 22550 | Reward:  -0.955 | Epsilon: 0.0100 | Loss: 902.0478
Episode 22600 | Reward:  -2.667 | Epsilon: 0.0100 | Loss: 1063.0903
Episode 22650 | Reward:  -4.666 | Epsilon: 0.0100 | Loss: 1148.3007
Episode 22700 | Reward:  -2.176 | Epsilon: 0.0100 | Loss: 664.6765
Episode 22750 | Reward:  -5.934 | Epsilon: 0.0100 | Loss: 1185.1360
Episode 22800 | Reward:  -5.501 | Epsilon: 0.0100 | Loss: 1138.6733
Episode 22850 | Reward:  -7.479 | Epsilon: 0.0100 | Loss: 1209.8817
Episode 22900 | Reward:  -5.957 | Epsilon: 0.0100 | Loss: 1223.3656
Episode 22950 | Reward:  -4.001 | Epsilon: 0.0100 | Loss: 1319.0787
Episode 23000 | Reward:  -6.821 | Epsilon: 0.0100 | Loss: 1165.5972
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:35).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:35).dict
Episode 23050 | Reward:  -2.609 | Epsilon: 0.0100 | Loss: 1395.7908
Episode 23100 | Reward:  -5.396 | Epsilon: 0.0100 | Loss: 1177.9775
Episode 23150 | Reward:  -1.406 | Epsilon: 0.0100 | Loss: 1131.1118
Episode 23200 | Reward:   0.616 | Epsilon: 0.0100 | Loss: 772.8470
Episode 23250 | Reward:  -4.895 | Epsilon: 0.0100 | Loss: 1214.8789
Episode 23300 | Reward:  -3.803 | Epsilon: 0.0100 | Loss: 1244.7719
Episode 23350 | Reward:  -0.046 | Epsilon: 0.0100 | Loss: 956.9385
Episode 23400 | Reward:   0.845 | Epsilon: 0.0100 | Loss: 649.5473
Episode 23450 | Reward:  -0.834 | Epsilon: 0.0100 | Loss: 927.1549
Episode 23500 | Reward:  -5.901 | Epsilon: 0.0100 | Loss: 809.1049
Episode 23550 | Reward:  -7.745 | Epsilon: 0.0100 | Loss: 764.5334
Episode 23600 | Reward:  -2.893 | Epsilon: 0.0100 | Loss: 1090.0332
Episode 23650 | Reward:  -5.612 | Epsilon: 0.0100 | Loss: 816.1044
Episode 23700 | Reward:  -3.599 | Epsilon: 0.0100 | Loss: 1048.6687
Episode 23750 | Reward:  -3.278 | Epsilon: 0.0100 | Loss: 931.2760
Episode 23800 | Reward:  -6.106 | Epsilon: 0.0100 | Loss: 968.0642
Episode 23850 | Reward:  -6.900 | Epsilon: 0.0100 | Loss: 881.0052
Episode 23900 | Reward:  -4.330 | Epsilon: 0.0100 | Loss: 1092.0690
Episode 23950 | Reward:  -6.710 | Epsilon: 0.0100 | Loss: 1124.3345
Episode 24000 | Reward:  -8.740 | Epsilon: 0.0100 | Loss: 896.2775
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:39).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:39).dict
Episode 24050 | Reward:  -6.078 | Epsilon: 0.0100 | Loss: 862.7134
Episode 24100 | Reward:  -8.569 | Epsilon: 0.0100 | Loss: 958.2376
Episode 24150 | Reward:  -6.846 | Epsilon: 0.0100 | Loss: 1066.8704
Episode 24200 | Reward:  -5.790 | Epsilon: 0.0100 | Loss: 860.3399
Episode 24250 | Reward:  -9.387 | Epsilon: 0.0100 | Loss: 957.2382
Episode 24300 | Reward:  -6.297 | Epsilon: 0.0100 | Loss: 925.8608
Episode 24350 | Reward:  -2.616 | Epsilon: 0.0100 | Loss: 1091.7686
Episode 24400 | Reward:  -6.628 | Epsilon: 0.0100 | Loss: 958.3806
Episode 24450 | Reward:  -4.229 | Epsilon: 0.0100 | Loss: 743.2314
Episode 24500 | Reward:   0.082 | Epsilon: 0.0100 | Loss: 906.7540
Episode 24550 | Reward:  -2.518 | Epsilon: 0.0100 | Loss: 968.7439
Episode 24600 | Reward:  -4.062 | Epsilon: 0.0100 | Loss: 951.7085
Episode 24650 | Reward:  -6.133 | Epsilon: 0.0100 | Loss: 635.4844
Episode 24700 | Reward:  -4.802 | Epsilon: 0.0100 | Loss: 920.2160
Episode 24750 | Reward:  -5.562 | Epsilon: 0.0100 | Loss: 945.6402
Episode 24800 | Reward:  -5.256 | Epsilon: 0.0100 | Loss: 910.7773
Episode 24850 | Reward:  -6.531 | Epsilon: 0.0100 | Loss: 872.9873
Episode 24900 | Reward:  -8.452 | Epsilon: 0.0100 | Loss: 657.5724
Episode 24950 | Reward:  -6.888 | Epsilon: 0.0100 | Loss: 780.3875
Episode 25000 | Reward:  -8.638 | Epsilon: 0.0100 | Loss: 1133.6544
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:43).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:43).dict
Episode 25050 | Reward: -13.440 | Epsilon: 0.0100 | Loss: 1049.9753
Episode 25100 | Reward: -11.177 | Epsilon: 0.0100 | Loss: 1075.5055
Episode 25150 | Reward: -11.477 | Epsilon: 0.0100 | Loss: 954.6226
Episode 25200 | Reward:  -9.978 | Epsilon: 0.0100 | Loss: 883.4669
Episode 25250 | Reward: -11.811 | Epsilon: 0.0100 | Loss: 1048.7711
Episode 25300 | Reward: -11.698 | Epsilon: 0.0100 | Loss: 918.2342
Episode 25350 | Reward: -11.654 | Epsilon: 0.0100 | Loss: 894.0679
Episode 25400 | Reward:  -6.911 | Epsilon: 0.0100 | Loss: 908.4521
Episode 25450 | Reward: -10.465 | Epsilon: 0.0100 | Loss: 750.7166
Episode 25500 | Reward:  -8.261 | Epsilon: 0.0100 | Loss: 1081.4508
Episode 25550 | Reward:  -8.515 | Epsilon: 0.0100 | Loss: 978.5529
Episode 25600 | Reward:  -8.344 | Epsilon: 0.0100 | Loss: 835.1334
Episode 25650 | Reward: -11.143 | Epsilon: 0.0100 | Loss: 998.4712
Episode 25700 | Reward:  -9.757 | Epsilon: 0.0100 | Loss: 745.3810
Episode 25750 | Reward:  -8.617 | Epsilon: 0.0100 | Loss: 985.6836
Episode 25800 | Reward:  -9.519 | Epsilon: 0.0100 | Loss: 806.7087
Episode 25850 | Reward: -12.619 | Epsilon: 0.0100 | Loss: 909.1178
Episode 25900 | Reward: -11.292 | Epsilon: 0.0100 | Loss: 1280.5706
Episode 25950 | Reward:  -5.465 | Epsilon: 0.0100 | Loss: 1070.0232
Episode 26000 | Reward:  -4.121 | Epsilon: 0.0100 | Loss: 1273.4036
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:47).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:47).dict
Episode 26050 | Reward:  -4.328 | Epsilon: 0.0100 | Loss: 1151.9675
Episode 26100 | Reward:  -6.849 | Epsilon: 0.0100 | Loss: 1025.7722
Episode 26150 | Reward:  -3.512 | Epsilon: 0.0100 | Loss: 1073.8960
Episode 26200 | Reward:  -4.981 | Epsilon: 0.0100 | Loss: 1191.2648
Episode 26250 | Reward:  -6.675 | Epsilon: 0.0100 | Loss: 1124.9110
Episode 26300 | Reward:  -4.095 | Epsilon: 0.0100 | Loss: 1223.9803
Episode 26350 | Reward:  -6.118 | Epsilon: 0.0100 | Loss: 885.8792
Episode 26400 | Reward:  -4.178 | Epsilon: 0.0100 | Loss: 1107.9879
Episode 26450 | Reward:  -3.703 | Epsilon: 0.0100 | Loss: 1122.2136
Episode 26500 | Reward:  -2.821 | Epsilon: 0.0100 | Loss: 1051.3513
Episode 26550 | Reward:  -7.087 | Epsilon: 0.0100 | Loss: 1017.5996
Episode 26600 | Reward: -11.022 | Epsilon: 0.0100 | Loss: 858.2413
Episode 26650 | Reward:  -7.821 | Epsilon: 0.0100 | Loss: 1126.8820
Episode 26700 | Reward:  -9.503 | Epsilon: 0.0100 | Loss: 948.5587
Episode 26750 | Reward:  -6.938 | Epsilon: 0.0100 | Loss: 1299.9871
Episode 26800 | Reward:  -5.741 | Epsilon: 0.0100 | Loss: 1028.7638
Episode 26850 | Reward:  -2.302 | Epsilon: 0.0100 | Loss: 1019.2161
Episode 26900 | Reward:  -5.903 | Epsilon: 0.0100 | Loss: 1105.9886
Episode 26950 | Reward:  -8.622 | Epsilon: 0.0100 | Loss: 1451.7021
Episode 27000 | Reward:  -3.316 | Epsilon: 0.0100 | Loss: 1229.6249
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:51).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:51).dict
Episode 27050 | Reward:  -1.735 | Epsilon: 0.0100 | Loss: 1119.1428
Episode 27100 | Reward:  -5.383 | Epsilon: 0.0100 | Loss: 1029.9398
Episode 27150 | Reward:  -0.602 | Epsilon: 0.0100 | Loss: 1053.7577
Episode 27200 | Reward:  -2.973 | Epsilon: 0.0100 | Loss: 838.3926
Episode 27250 | Reward:  -5.618 | Epsilon: 0.0100 | Loss: 1291.5529
Episode 27300 | Reward:  -6.442 | Epsilon: 0.0100 | Loss: 855.2108
Episode 27350 | Reward:  -8.597 | Epsilon: 0.0100 | Loss: 1138.7461
Episode 27400 | Reward:  -5.540 | Epsilon: 0.0100 | Loss: 1203.6521
Episode 27450 | Reward:  -5.014 | Epsilon: 0.0100 | Loss: 1221.0956
Episode 27500 | Reward:  -3.800 | Epsilon: 0.0100 | Loss: 1180.8894
Episode 27550 | Reward:  -4.823 | Epsilon: 0.0100 | Loss: 1270.5134
Episode 27600 | Reward: -13.008 | Epsilon: 0.0100 | Loss: 1191.5239
Episode 27650 | Reward:  -9.208 | Epsilon: 0.0100 | Loss: 957.3134
Episode 27700 | Reward:  -4.690 | Epsilon: 0.0100 | Loss: 1086.5803
Episode 27750 | Reward:  -6.952 | Epsilon: 0.0100 | Loss: 1195.0753
Episode 27800 | Reward:  -5.566 | Epsilon: 0.0100 | Loss: 947.6342
Episode 27850 | Reward:  -4.683 | Epsilon: 0.0100 | Loss: 1180.4039
Episode 27900 | Reward:  -7.377 | Epsilon: 0.0100 | Loss: 1104.9520
Episode 27950 | Reward:  -6.080 | Epsilon: 0.0100 | Loss: 1276.5001
Episode 28000 | Reward:  -5.672 | Epsilon: 0.0100 | Loss: 1094.6851
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:55).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:55).dict
Episode 28050 | Reward:  -6.195 | Epsilon: 0.0100 | Loss: 1197.4236
Episode 28100 | Reward:  -9.492 | Epsilon: 0.0100 | Loss: 951.5021
Episode 28150 | Reward:  -5.060 | Epsilon: 0.0100 | Loss: 1122.4686
Episode 28200 | Reward:  -5.869 | Epsilon: 0.0100 | Loss: 1089.0026
Episode 28250 | Reward:  -3.182 | Epsilon: 0.0100 | Loss: 1257.2286
Episode 28300 | Reward:  -4.064 | Epsilon: 0.0100 | Loss: 1085.1459
Episode 28350 | Reward:  -2.812 | Epsilon: 0.0100 | Loss: 1211.3356
Episode 28400 | Reward:  -6.066 | Epsilon: 0.0100 | Loss: 901.0864
Episode 28450 | Reward:  -6.228 | Epsilon: 0.0100 | Loss: 1276.3378
Episode 28500 | Reward:  -7.601 | Epsilon: 0.0100 | Loss: 1250.5701
Episode 28550 | Reward:  -6.216 | Epsilon: 0.0100 | Loss: 925.9893
Episode 28600 | Reward:  -5.939 | Epsilon: 0.0100 | Loss: 1227.2695
Episode 28650 | Reward:  -6.928 | Epsilon: 0.0100 | Loss: 815.7454
Episode 28700 | Reward:  -9.272 | Epsilon: 0.0100 | Loss: 995.1695
Episode 28750 | Reward:  -6.650 | Epsilon: 0.0100 | Loss: 1142.3635
Episode 28800 | Reward:  -9.497 | Epsilon: 0.0100 | Loss: 1193.9810
Episode 28850 | Reward:  -6.450 | Epsilon: 0.0100 | Loss: 1104.3232
Episode 28900 | Reward:  -9.708 | Epsilon: 0.0100 | Loss: 901.2446
Episode 28950 | Reward:  -6.989 | Epsilon: 0.0100 | Loss: 1152.5868
Episode 29000 | Reward:  -6.513 | Epsilon: 0.0100 | Loss: 835.2638
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:59).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:59).dict
Episode 29050 | Reward: -13.880 | Epsilon: 0.0100 | Loss: 1148.7209
Episode 29100 | Reward:  -6.520 | Epsilon: 0.0100 | Loss: 792.1266
Episode 29150 | Reward:  -5.452 | Epsilon: 0.0100 | Loss: 888.4022
Episode 29200 | Reward:  -4.439 | Epsilon: 0.0100 | Loss: 967.9067
Episode 29250 | Reward:  -6.599 | Epsilon: 0.0100 | Loss: 981.7548
Episode 29300 | Reward:  -3.381 | Epsilon: 0.0100 | Loss: 1150.5337
Episode 29350 | Reward:  -4.959 | Epsilon: 0.0100 | Loss: 925.6444
Episode 29400 | Reward:  -7.187 | Epsilon: 0.0100 | Loss: 1109.5828
Episode 29450 | Reward:  -6.153 | Epsilon: 0.0100 | Loss: 885.4008
Episode 29500 | Reward:  -8.292 | Epsilon: 0.0100 | Loss: 881.7413
Episode 29550 | Reward:  -9.719 | Epsilon: 0.0100 | Loss: 1003.2634
Episode 29600 | Reward:  -7.492 | Epsilon: 0.0100 | Loss: 957.8946
Episode 29650 | Reward:  -7.707 | Epsilon: 0.0100 | Loss: 1138.5859
Episode 29700 | Reward:  -6.770 | Epsilon: 0.0100 | Loss: 1151.0275
Episode 29750 | Reward:  -7.351 | Epsilon: 0.0100 | Loss: 1186.8215
Episode 29800 | Reward:  -8.062 | Epsilon: 0.0100 | Loss: 892.6574
Episode 29850 | Reward:  -8.646 | Epsilon: 0.0100 | Loss: 794.0525
Episode 29900 | Reward:  -5.674 | Epsilon: 0.0100 | Loss: 1060.6974
Episode 29950 | Reward:  -6.512 | Epsilon: 0.0100 | Loss: 1196.2568
Episode 30000 | Reward:  -3.026 | Epsilon: 0.0100 | Loss: 1049.6072
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:03).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:03).dict
Episode 30050 | Reward:  -5.227 | Epsilon: 0.0100 | Loss: 1137.5127
Episode 30100 | Reward:  -6.171 | Epsilon: 0.0100 | Loss: 1109.3489
Episode 30150 | Reward:  -6.499 | Epsilon: 0.0100 | Loss: 902.7052
Episode 30200 | Reward:  -6.157 | Epsilon: 0.0100 | Loss: 1265.0880
Episode 30250 | Reward:  -3.765 | Epsilon: 0.0100 | Loss: 1330.5979
Episode 30300 | Reward:  -5.157 | Epsilon: 0.0100 | Loss: 1573.5898
Episode 30350 | Reward:  -8.763 | Epsilon: 0.0100 | Loss: 868.1934
Episode 30400 | Reward:  -9.361 | Epsilon: 0.0100 | Loss: 1447.9669
Episode 30450 | Reward:  -8.984 | Epsilon: 0.0100 | Loss: 1530.6285
Episode 30500 | Reward:  -8.292 | Epsilon: 0.0100 | Loss: 1362.5587
Episode 30550 | Reward:  -9.981 | Epsilon: 0.0100 | Loss: 1201.0193
Episode 30600 | Reward:  -7.964 | Epsilon: 0.0100 | Loss: 1230.5380
Episode 30650 | Reward:  -7.431 | Epsilon: 0.0100 | Loss: 1019.9131
Episode 30700 | Reward:  -7.495 | Epsilon: 0.0100 | Loss: 1319.1536
Episode 30750 | Reward:  -6.624 | Epsilon: 0.0100 | Loss: 1647.1924
Episode 30800 | Reward:  -5.078 | Epsilon: 0.0100 | Loss: 1414.6964
Episode 30850 | Reward:  -8.119 | Epsilon: 0.0100 | Loss: 1477.8661
Episode 30900 | Reward:  -7.774 | Epsilon: 0.0100 | Loss: 1059.5977
Episode 30950 | Reward:  -3.769 | Epsilon: 0.0100 | Loss: 1707.5632
Episode 31000 | Reward:  -5.121 | Epsilon: 0.0100 | Loss: 1215.6276
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:07).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:07).dict
Episode 31050 | Reward:  -6.974 | Epsilon: 0.0100 | Loss: 1255.8600
Episode 31100 | Reward:  -7.089 | Epsilon: 0.0100 | Loss: 1147.1716
Episode 31150 | Reward:  -9.870 | Epsilon: 0.0100 | Loss: 1062.9949
Episode 31200 | Reward:  -9.783 | Epsilon: 0.0100 | Loss: 1215.2916
Episode 31250 | Reward:  -9.612 | Epsilon: 0.0100 | Loss: 1499.0232
Episode 31300 | Reward:  -7.262 | Epsilon: 0.0100 | Loss: 1500.1201
Episode 31350 | Reward:  -4.412 | Epsilon: 0.0100 | Loss: 1255.3511
Episode 31400 | Reward:  -7.375 | Epsilon: 0.0100 | Loss: 1169.1760
Episode 31450 | Reward:  -4.953 | Epsilon: 0.0100 | Loss: 1519.4917
Episode 31500 | Reward:  -6.585 | Epsilon: 0.0100 | Loss: 1976.8743
Episode 31550 | Reward:  -7.158 | Epsilon: 0.0100 | Loss: 1549.1267
Episode 31600 | Reward:  -4.290 | Epsilon: 0.0100 | Loss: 1302.9540
Episode 31650 | Reward:  -6.419 | Epsilon: 0.0100 | Loss: 1520.5503
Episode 31700 | Reward:  -6.612 | Epsilon: 0.0100 | Loss: 1680.0428
Episode 31750 | Reward:  -3.048 | Epsilon: 0.0100 | Loss: 1215.3721
Episode 31800 | Reward:  -6.405 | Epsilon: 0.0100 | Loss: 1478.4097
Episode 31850 | Reward:  -5.602 | Epsilon: 0.0100 | Loss: 1463.0703
Episode 31900 | Reward:  -9.211 | Epsilon: 0.0100 | Loss: 1314.6035
Episode 31950 | Reward:  -4.788 | Epsilon: 0.0100 | Loss: 1824.0708
Episode 32000 | Reward:  -4.357 | Epsilon: 0.0100 | Loss: 883.0880
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:11).dict
Episode 32050 | Reward:  -4.799 | Epsilon: 0.0100 | Loss: 1532.0288
Episode 32100 | Reward:  -5.704 | Epsilon: 0.0100 | Loss: 1390.2494
Episode 32150 | Reward:  -6.481 | Epsilon: 0.0100 | Loss: 1682.3308
Episode 32200 | Reward:  -5.357 | Epsilon: 0.0100 | Loss: 1325.9747
Episode 32250 | Reward:  -3.335 | Epsilon: 0.0100 | Loss: 1533.9604
Episode 32300 | Reward:  -5.227 | Epsilon: 0.0100 | Loss: 1580.4923
Episode 32350 | Reward:  -6.777 | Epsilon: 0.0100 | Loss: 1567.9414
Episode 32400 | Reward:  -6.586 | Epsilon: 0.0100 | Loss: 2158.2817
Episode 32450 | Reward:  -6.413 | Epsilon: 0.0100 | Loss: 2095.2334
Episode 32500 | Reward:  -3.312 | Epsilon: 0.0100 | Loss: 2235.6414
Episode 32550 | Reward:  -5.270 | Epsilon: 0.0100 | Loss: 2156.6306
Episode 32600 | Reward:  -5.651 | Epsilon: 0.0100 | Loss: 2020.0879
Episode 32650 | Reward:  -6.130 | Epsilon: 0.0100 | Loss: 1840.8168
Episode 32700 | Reward:  -3.162 | Epsilon: 0.0100 | Loss: 1695.4421
Episode 32750 | Reward:  -5.957 | Epsilon: 0.0100 | Loss: 1463.8779
Episode 32800 | Reward:  -6.199 | Epsilon: 0.0100 | Loss: 2534.6160
Episode 32850 | Reward:  -6.720 | Epsilon: 0.0100 | Loss: 1854.0479
Episode 32900 | Reward:  -9.298 | Epsilon: 0.0100 | Loss: 1890.8634
Episode 32950 | Reward:  -4.052 | Epsilon: 0.0100 | Loss: 1625.9816
Episode 33000 | Reward:  -2.429 | Epsilon: 0.0100 | Loss: 2070.5398
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:15).dict
Episode 33050 | Reward:  -3.657 | Epsilon: 0.0100 | Loss: 1855.7773
Episode 33100 | Reward:  -5.320 | Epsilon: 0.0100 | Loss: 1581.3059
Episode 33150 | Reward:  -6.369 | Epsilon: 0.0100 | Loss: 2214.1926
Episode 33200 | Reward:  -5.548 | Epsilon: 0.0100 | Loss: 2142.5701
Episode 33250 | Reward:   0.430 | Epsilon: 0.0100 | Loss: 1933.1803
Episode 33300 | Reward:  -4.729 | Epsilon: 0.0100 | Loss: 2071.8013
Episode 33350 | Reward:  -6.473 | Epsilon: 0.0100 | Loss: 2285.4326
Episode 33400 | Reward:  -7.259 | Epsilon: 0.0100 | Loss: 1648.8756
Episode 33450 | Reward:  -6.886 | Epsilon: 0.0100 | Loss: 2148.2617
Episode 33500 | Reward:  -6.952 | Epsilon: 0.0100 | Loss: 2488.4832
Episode 33550 | Reward:  -6.938 | Epsilon: 0.0100 | Loss: 2094.0066
Episode 33600 | Reward:  -4.427 | Epsilon: 0.0100 | Loss: 2264.7307
Episode 33650 | Reward:  -9.045 | Epsilon: 0.0100 | Loss: 2989.5322
Episode 33700 | Reward:  -5.977 | Epsilon: 0.0100 | Loss: 2645.5481
Episode 33750 | Reward:  -7.721 | Epsilon: 0.0100 | Loss: 2767.8848
Episode 33800 | Reward:  -7.488 | Epsilon: 0.0100 | Loss: 2301.1973
Episode 33850 | Reward:  -5.976 | Epsilon: 0.0100 | Loss: 1918.1543
Episode 33900 | Reward:  -7.694 | Epsilon: 0.0100 | Loss: 2806.8044
Episode 33950 | Reward:  -7.785 | Epsilon: 0.0100 | Loss: 2555.9199
Episode 34000 | Reward:  -3.837 | Epsilon: 0.0100 | Loss: 2637.6099
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:19).dict
Episode 34050 | Reward:  -4.428 | Epsilon: 0.0100 | Loss: 2862.5735
Episode 34100 | Reward:  -6.186 | Epsilon: 0.0100 | Loss: 3404.7661
Episode 34150 | Reward:  -8.520 | Epsilon: 0.0100 | Loss: 2668.0781
Episode 34200 | Reward:  -5.415 | Epsilon: 0.0100 | Loss: 2644.1782
Episode 34250 | Reward:  -4.567 | Epsilon: 0.0100 | Loss: 3417.2776
Episode 34300 | Reward:  -7.694 | Epsilon: 0.0100 | Loss: 2649.0146
Episode 34350 | Reward:  -5.545 | Epsilon: 0.0100 | Loss: 3236.7432
Episode 34400 | Reward:  -6.245 | Epsilon: 0.0100 | Loss: 3394.6091
Episode 34450 | Reward:  -8.005 | Epsilon: 0.0100 | Loss: 2628.3928
Episode 34500 | Reward:  -5.748 | Epsilon: 0.0100 | Loss: 2629.7778
Episode 34550 | Reward:  -5.505 | Epsilon: 0.0100 | Loss: 3005.6699
Episode 34600 | Reward:  -2.647 | Epsilon: 0.0100 | Loss: 3077.4407
Episode 34650 | Reward:  -6.412 | Epsilon: 0.0100 | Loss: 3338.9629
Episode 34700 | Reward:  -5.853 | Epsilon: 0.0100 | Loss: 2930.3513
Episode 34750 | Reward:  -7.799 | Epsilon: 0.0100 | Loss: 3306.0298
Episode 34800 | Reward:  -5.811 | Epsilon: 0.0100 | Loss: 3754.6548
Episode 34850 | Reward:  -6.489 | Epsilon: 0.0100 | Loss: 2879.6125
Episode 34900 | Reward:  -3.519 | Epsilon: 0.0100 | Loss: 3179.4136
Episode 34950 | Reward:  -5.725 | Epsilon: 0.0100 | Loss: 3894.1106
Episode 35000 | Reward:  -5.312 | Epsilon: 0.0100 | Loss: 3394.5398
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:23).dict
Episode 35050 | Reward:  -6.289 | Epsilon: 0.0100 | Loss: 4226.5542
Episode 35100 | Reward:  -2.622 | Epsilon: 0.0100 | Loss: 3946.9001
Episode 35150 | Reward:  -1.814 | Epsilon: 0.0100 | Loss: 3609.4768
Episode 35200 | Reward:  -4.422 | Epsilon: 0.0100 | Loss: 3224.4019
Episode 35250 | Reward:  -4.939 | Epsilon: 0.0100 | Loss: 4026.5032
Episode 35300 | Reward:  -4.580 | Epsilon: 0.0100 | Loss: 3803.9036
Episode 35350 | Reward:  -2.338 | Epsilon: 0.0100 | Loss: 2852.6001
Episode 35400 | Reward:  -4.780 | Epsilon: 0.0100 | Loss: 4232.7251
Episode 35450 | Reward:  -4.486 | Epsilon: 0.0100 | Loss: 3974.7915
Episode 35500 | Reward:  -3.127 | Epsilon: 0.0100 | Loss: 3404.4316
Episode 35550 | Reward:  -3.263 | Epsilon: 0.0100 | Loss: 3576.2710
Episode 35600 | Reward:  -5.497 | Epsilon: 0.0100 | Loss: 4434.9614
Episode 35650 | Reward:  -6.163 | Epsilon: 0.0100 | Loss: 4364.1270
Episode 35700 | Reward:  -5.685 | Epsilon: 0.0100 | Loss: 4470.0708
Episode 35750 | Reward:  -5.920 | Epsilon: 0.0100 | Loss: 4581.7349
Episode 35800 | Reward:  -4.540 | Epsilon: 0.0100 | Loss: 5216.8677
Episode 35850 | Reward:  -4.889 | Epsilon: 0.0100 | Loss: 4656.9575
Episode 35900 | Reward:  -5.349 | Epsilon: 0.0100 | Loss: 3791.1487
Episode 35950 | Reward:  -4.139 | Epsilon: 0.0100 | Loss: 3705.4331
Episode 36000 | Reward:  -7.292 | Epsilon: 0.0100 | Loss: 4738.3569
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:27).dict
Episode 36050 | Reward:  -1.198 | Epsilon: 0.0100 | Loss: 4928.9775
Episode 36100 | Reward:  -5.073 | Epsilon: 0.0100 | Loss: 4151.9302
Episode 36150 | Reward:  -7.261 | Epsilon: 0.0100 | Loss: 4844.2930
Episode 36200 | Reward:  -9.687 | Epsilon: 0.0100 | Loss: 3976.4453
Episode 36250 | Reward:  -6.142 | Epsilon: 0.0100 | Loss: 4819.1382
Episode 36300 | Reward:  -4.144 | Epsilon: 0.0100 | Loss: 5037.4312
Episode 36350 | Reward:  -4.524 | Epsilon: 0.0100 | Loss: 5219.8062
Episode 36400 | Reward:  -5.200 | Epsilon: 0.0100 | Loss: 5293.0435
Episode 36450 | Reward:  -6.921 | Epsilon: 0.0100 | Loss: 4111.7324
Episode 36500 | Reward:  -7.311 | Epsilon: 0.0100 | Loss: 3807.1470
Episode 36550 | Reward:  -6.272 | Epsilon: 0.0100 | Loss: 3753.8828
Episode 36600 | Reward:  -8.626 | Epsilon: 0.0100 | Loss: 5505.6230
Episode 36650 | Reward: -11.038 | Epsilon: 0.0100 | Loss: 3903.8044
Episode 36700 | Reward:  -9.577 | Epsilon: 0.0100 | Loss: 4713.3101
Episode 36750 | Reward:  -9.700 | Epsilon: 0.0100 | Loss: 4136.0347
Episode 36800 | Reward:  -8.129 | Epsilon: 0.0100 | Loss: 4463.0464
Episode 36850 | Reward:  -6.332 | Epsilon: 0.0100 | Loss: 5168.9111
Episode 36900 | Reward:  -5.165 | Epsilon: 0.0100 | Loss: 5698.0483
Episode 36950 | Reward:  -2.818 | Epsilon: 0.0100 | Loss: 4444.4141
Episode 37000 | Reward:  -4.910 | Epsilon: 0.0100 | Loss: 5187.4209
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:32).dict
Episode 37050 | Reward:  -4.962 | Epsilon: 0.0100 | Loss: 4910.3896
Episode 37100 | Reward:  -6.755 | Epsilon: 0.0100 | Loss: 5252.2808
Episode 37150 | Reward:  -5.763 | Epsilon: 0.0100 | Loss: 4712.2456
Episode 37200 | Reward:  -3.614 | Epsilon: 0.0100 | Loss: 5422.3706
Episode 37250 | Reward:  -7.391 | Epsilon: 0.0100 | Loss: 5012.5552
Episode 37300 | Reward:  -8.175 | Epsilon: 0.0100 | Loss: 4242.0669
Episode 37350 | Reward: -12.746 | Epsilon: 0.0100 | Loss: 4306.3716
Episode 37400 | Reward:  -9.353 | Epsilon: 0.0100 | Loss: 5313.5854
Episode 37450 | Reward:  -5.261 | Epsilon: 0.0100 | Loss: 6072.4297
Episode 37500 | Reward:  -2.988 | Epsilon: 0.0100 | Loss: 5787.5986
Episode 37550 | Reward:  -4.558 | Epsilon: 0.0100 | Loss: 5862.0010
Episode 37600 | Reward:  -8.781 | Epsilon: 0.0100 | Loss: 4524.1768
Episode 37650 | Reward:  -6.913 | Epsilon: 0.0100 | Loss: 5741.9541
Episode 37700 | Reward:  -5.266 | Epsilon: 0.0100 | Loss: 6345.5366
Episode 37750 | Reward:  -4.296 | Epsilon: 0.0100 | Loss: 6898.4712
Episode 37800 | Reward:  -1.191 | Epsilon: 0.0100 | Loss: 6108.6230
Episode 37850 | Reward:  -3.074 | Epsilon: 0.0100 | Loss: 5792.1826
Episode 37900 | Reward:  -3.971 | Epsilon: 0.0100 | Loss: 8816.5889
Episode 37950 | Reward:  -3.161 | Epsilon: 0.0100 | Loss: 6600.4458
Episode 38000 | Reward:  -8.767 | Epsilon: 0.0100 | Loss: 6213.2212
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:36).dict
Episode 38050 | Reward: -11.216 | Epsilon: 0.0100 | Loss: 5480.6724
Episode 38100 | Reward: -11.286 | Epsilon: 0.0100 | Loss: 7476.2227
Episode 38150 | Reward:  -9.900 | Epsilon: 0.0100 | Loss: 7300.3281
Episode 38200 | Reward:  -8.797 | Epsilon: 0.0100 | Loss: 7409.0996
Episode 38250 | Reward: -10.053 | Epsilon: 0.0100 | Loss: 6193.0522
Episode 38300 | Reward:  -7.980 | Epsilon: 0.0100 | Loss: 5268.0088
Episode 38350 | Reward:  -6.080 | Epsilon: 0.0100 | Loss: 7268.5161
Episode 38400 | Reward:  -5.749 | Epsilon: 0.0100 | Loss: 8095.7480
Episode 38450 | Reward:  -6.460 | Epsilon: 0.0100 | Loss: 9116.1660
Episode 38500 | Reward:  -7.477 | Epsilon: 0.0100 | Loss: 9598.4795
Episode 38550 | Reward:  -5.047 | Epsilon: 0.0100 | Loss: 8569.4160
Episode 38600 | Reward:  -7.999 | Epsilon: 0.0100 | Loss: 9749.5469
Episode 38650 | Reward:  -7.374 | Epsilon: 0.0100 | Loss: 9439.0078
Episode 38700 | Reward: -10.643 | Epsilon: 0.0100 | Loss: 9935.3379
Episode 38750 | Reward:  -7.439 | Epsilon: 0.0100 | Loss: 9592.2109
Episode 38800 | Reward:  -6.589 | Epsilon: 0.0100 | Loss: 11208.2793
Episode 38850 | Reward:  -8.952 | Epsilon: 0.0100 | Loss: 8293.6982
Episode 38900 | Reward:  -4.266 | Epsilon: 0.0100 | Loss: 10839.6396
Episode 38950 | Reward:  -6.117 | Epsilon: 0.0100 | Loss: 10737.9824
Episode 39000 | Reward:  -7.781 | Epsilon: 0.0100 | Loss: 13280.2139
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:40).dict
Episode 39050 | Reward:  -3.847 | Epsilon: 0.0100 | Loss: 11238.6533
Episode 39100 | Reward:  -7.824 | Epsilon: 0.0100 | Loss: 12440.7197
Episode 39150 | Reward:  -6.968 | Epsilon: 0.0100 | Loss: 12846.8809
Episode 39200 | Reward:  -4.346 | Epsilon: 0.0100 | Loss: 12414.8359
Episode 39250 | Reward:  -7.038 | Epsilon: 0.0100 | Loss: 11014.6660
Episode 39300 | Reward: -11.467 | Epsilon: 0.0100 | Loss: 9837.7754
Episode 39350 | Reward:  -9.541 | Epsilon: 0.0100 | Loss: 9771.1123
Episode 39400 | Reward:  -8.263 | Epsilon: 0.0100 | Loss: 11755.3975
Episode 39450 | Reward: -11.129 | Epsilon: 0.0100 | Loss: 15049.7207
Episode 39500 | Reward: -11.990 | Epsilon: 0.0100 | Loss: 11283.4404
Episode 39550 | Reward: -12.646 | Epsilon: 0.0100 | Loss: 15181.5400
Episode 39600 | Reward: -11.045 | Epsilon: 0.0100 | Loss: 11600.2607
Episode 39650 | Reward: -12.281 | Epsilon: 0.0100 | Loss: 16558.8105
Episode 39700 | Reward: -14.907 | Epsilon: 0.0100 | Loss: 18693.6328
Episode 39750 | Reward: -11.347 | Epsilon: 0.0100 | Loss: 19493.7422
Episode 39800 | Reward: -10.146 | Epsilon: 0.0100 | Loss: 17292.5098
Episode 39850 | Reward: -10.916 | Epsilon: 0.0100 | Loss: 20257.0508
Episode 39900 | Reward: -12.274 | Epsilon: 0.0100 | Loss: 18942.1719
Episode 39950 | Reward: -15.258 | Epsilon: 0.0100 | Loss: 16245.4395
Episode 40000 | Reward: -13.483 | Epsilon: 0.0100 | Loss: 24205.5195
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:44).dict
Episode 40050 | Reward: -14.127 | Epsilon: 0.0100 | Loss: 24120.5078
Episode 40100 | Reward:  -9.929 | Epsilon: 0.0100 | Loss: 15558.3096
Episode 40150 | Reward: -10.762 | Epsilon: 0.0100 | Loss: 25380.0781
Episode 40200 | Reward: -13.438 | Epsilon: 0.0100 | Loss: 21046.0918
Episode 40250 | Reward: -15.840 | Epsilon: 0.0100 | Loss: 24624.5410
Episode 40300 | Reward: -14.511 | Epsilon: 0.0100 | Loss: 32327.9727
Episode 40350 | Reward: -13.337 | Epsilon: 0.0100 | Loss: 22682.9531
Episode 40400 | Reward: -12.793 | Epsilon: 0.0100 | Loss: 26598.7988
Episode 40450 | Reward: -13.623 | Epsilon: 0.0100 | Loss: 30995.3750
Episode 40500 | Reward: -11.506 | Epsilon: 0.0100 | Loss: 30246.4219
Episode 40550 | Reward:  -9.798 | Epsilon: 0.0100 | Loss: 23840.7949
Episode 40600 | Reward: -13.053 | Epsilon: 0.0100 | Loss: 30179.7285
Episode 40650 | Reward: -10.767 | Epsilon: 0.0100 | Loss: 30811.2402
Episode 40700 | Reward: -13.900 | Epsilon: 0.0100 | Loss: 31205.8672
Episode 40750 | Reward: -13.194 | Epsilon: 0.0100 | Loss: 34830.4648
Episode 40800 | Reward: -15.465 | Epsilon: 0.0100 | Loss: 32120.2578
Episode 40850 | Reward: -10.270 | Epsilon: 0.0100 | Loss: 29083.7734
Episode 40900 | Reward: -11.802 | Epsilon: 0.0100 | Loss: 30309.8359
Episode 40950 | Reward: -15.277 | Epsilon: 0.0100 | Loss: 35579.2070
Episode 41000 | Reward: -11.173 | Epsilon: 0.0100 | Loss: 35242.9961
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:48).dict
Episode 41050 | Reward: -11.825 | Epsilon: 0.0100 | Loss: 40610.4492
Episode 41100 | Reward: -11.088 | Epsilon: 0.0100 | Loss: 40677.1328
Episode 41150 | Reward: -10.022 | Epsilon: 0.0100 | Loss: 38737.1680
Episode 41200 | Reward: -10.278 | Epsilon: 0.0100 | Loss: 47110.0000
Episode 41250 | Reward:  -8.304 | Epsilon: 0.0100 | Loss: 30085.4180
Episode 41300 | Reward: -10.610 | Epsilon: 0.0100 | Loss: 43543.2773
Episode 41350 | Reward:  -8.064 | Epsilon: 0.0100 | Loss: 38220.8047
Episode 41400 | Reward: -10.306 | Epsilon: 0.0100 | Loss: 35747.1875
Episode 41450 | Reward: -10.391 | Epsilon: 0.0100 | Loss: 44851.9648
Episode 41500 | Reward:  -9.193 | Epsilon: 0.0100 | Loss: 57954.8203
Episode 41550 | Reward:  -8.013 | Epsilon: 0.0100 | Loss: 45683.9922
Episode 41600 | Reward:  -6.066 | Epsilon: 0.0100 | Loss: 49007.1250
Episode 41650 | Reward: -10.335 | Epsilon: 0.0100 | Loss: 42657.1016
Episode 41700 | Reward:  -7.457 | Epsilon: 0.0100 | Loss: 35995.5000
Episode 41750 | Reward:  -9.467 | Epsilon: 0.0100 | Loss: 45938.8867
Episode 41800 | Reward:  -8.778 | Epsilon: 0.0100 | Loss: 51637.4844
Episode 41850 | Reward: -10.531 | Epsilon: 0.0100 | Loss: 50845.7969
Episode 41900 | Reward: -11.272 | Epsilon: 0.0100 | Loss: 63614.2227
Episode 41950 | Reward:  -6.151 | Epsilon: 0.0100 | Loss: 44922.7031
Episode 42000 | Reward:  -8.244 | Epsilon: 0.0100 | Loss: 54618.2422
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:52).dict
Episode 42050 | Reward:  -8.176 | Epsilon: 0.0100 | Loss: 53037.0430
Episode 42100 | Reward:  -7.418 | Epsilon: 0.0100 | Loss: 64218.1094
Episode 42150 | Reward:  -8.480 | Epsilon: 0.0100 | Loss: 52674.6953
Episode 42200 | Reward: -13.280 | Epsilon: 0.0100 | Loss: 49123.3750
Episode 42250 | Reward:  -6.683 | Epsilon: 0.0100 | Loss: 60284.7734
Episode 42300 | Reward:  -6.737 | Epsilon: 0.0100 | Loss: 62450.8281
Episode 42350 | Reward:  -4.121 | Epsilon: 0.0100 | Loss: 49531.7656
Episode 42400 | Reward:  -5.368 | Epsilon: 0.0100 | Loss: 66982.4844
Episode 42450 | Reward: -10.027 | Epsilon: 0.0100 | Loss: 67820.2109
Episode 42500 | Reward:  -8.985 | Epsilon: 0.0100 | Loss: 56570.3594
Episode 42550 | Reward: -10.334 | Epsilon: 0.0100 | Loss: 56630.4922
Episode 42600 | Reward:  -9.630 | Epsilon: 0.0100 | Loss: 72539.6719
Episode 42650 | Reward:  -4.004 | Epsilon: 0.0100 | Loss: 66514.6797
Episode 42700 | Reward:  -5.117 | Epsilon: 0.0100 | Loss: 61014.9922
Episode 42750 | Reward:  -5.767 | Epsilon: 0.0100 | Loss: 74055.8203
Episode 42800 | Reward:  -8.857 | Epsilon: 0.0100 | Loss: 71528.8828
Episode 42850 | Reward:  -9.671 | Epsilon: 0.0100 | Loss: 59550.3242
Episode 42900 | Reward:  -6.375 | Epsilon: 0.0100 | Loss: 57841.8945
Episode 42950 | Reward:  -6.564 | Epsilon: 0.0100 | Loss: 69269.3594
Episode 43000 | Reward:  -2.603 | Epsilon: 0.0100 | Loss: 85912.6172
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:56).dict
Episode 43050 | Reward:  -7.498 | Epsilon: 0.0100 | Loss: 73366.0469
Episode 43100 | Reward:  -2.036 | Epsilon: 0.0100 | Loss: 85229.6719
Episode 43150 | Reward:  -3.990 | Epsilon: 0.0100 | Loss: 80896.2578
Episode 43200 | Reward: -11.014 | Epsilon: 0.0100 | Loss: 68883.3984
Episode 43250 | Reward:  -8.838 | Epsilon: 0.0100 | Loss: 59699.8125
Episode 43300 | Reward:  -9.411 | Epsilon: 0.0100 | Loss: 68582.7891
Episode 43350 | Reward: -11.223 | Epsilon: 0.0100 | Loss: 74251.2578
Episode 43400 | Reward:  -9.702 | Epsilon: 0.0100 | Loss: 90038.8438
Episode 43450 | Reward:  -6.619 | Epsilon: 0.0100 | Loss: 84801.6016
Episode 43500 | Reward:  -6.829 | Epsilon: 0.0100 | Loss: 72038.4688
Episode 43550 | Reward:  -8.051 | Epsilon: 0.0100 | Loss: 76921.5312
Episode 43600 | Reward:  -7.639 | Epsilon: 0.0100 | Loss: 79391.4844
Episode 43650 | Reward: -10.233 | Epsilon: 0.0100 | Loss: 90764.2578
Episode 43700 | Reward: -12.210 | Epsilon: 0.0100 | Loss: 59564.9180
Episode 43750 | Reward: -11.187 | Epsilon: 0.0100 | Loss: 77021.1328
Episode 43800 | Reward:  -9.026 | Epsilon: 0.0100 | Loss: 80202.9453
Episode 43850 | Reward:  -8.077 | Epsilon: 0.0100 | Loss: 78293.2734
Episode 43900 | Reward:  -5.905 | Epsilon: 0.0100 | Loss: 105424.5938
Episode 43950 | Reward:  -4.926 | Epsilon: 0.0100 | Loss: 82251.8516
Episode 44000 | Reward:  -7.397 | Epsilon: 0.0100 | Loss: 91084.4062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:00).dict
Episode 44050 | Reward: -12.690 | Epsilon: 0.0100 | Loss: 74913.5312
Episode 44100 | Reward: -13.202 | Epsilon: 0.0100 | Loss: 91892.1016
Episode 44150 | Reward:  -9.843 | Epsilon: 0.0100 | Loss: 88971.6797
Episode 44200 | Reward:  -5.128 | Epsilon: 0.0100 | Loss: 92554.9609
Episode 44250 | Reward:  -4.509 | Epsilon: 0.0100 | Loss: 97177.0938
Episode 44300 | Reward:  -9.172 | Epsilon: 0.0100 | Loss: 127236.8125
Episode 44350 | Reward:  -9.791 | Epsilon: 0.0100 | Loss: 109630.7656
Episode 44400 | Reward: -10.643 | Epsilon: 0.0100 | Loss: 93485.5078
Episode 44450 | Reward:  -9.362 | Epsilon: 0.0100 | Loss: 113868.8828
Episode 44500 | Reward:  -9.588 | Epsilon: 0.0100 | Loss: 114808.2656
Episode 44550 | Reward: -12.108 | Epsilon: 0.0100 | Loss: 105608.8281
Episode 44600 | Reward: -12.170 | Epsilon: 0.0100 | Loss: 97346.3125
Episode 44650 | Reward:  -9.682 | Epsilon: 0.0100 | Loss: 125019.1250
Episode 44700 | Reward: -10.545 | Epsilon: 0.0100 | Loss: 102400.1094
Episode 44750 | Reward: -10.364 | Epsilon: 0.0100 | Loss: 126824.9531
Episode 44800 | Reward:  -9.380 | Epsilon: 0.0100 | Loss: 115664.9375
Episode 44850 | Reward:  -9.138 | Epsilon: 0.0100 | Loss: 94136.6250
Episode 44900 | Reward:  -7.620 | Epsilon: 0.0100 | Loss: 128798.5312
Episode 44950 | Reward: -11.827 | Epsilon: 0.0100 | Loss: 123622.9531
Episode 45000 | Reward: -11.645 | Epsilon: 0.0100 | Loss: 122679.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:04).dict
Episode 45050 | Reward:  -9.400 | Epsilon: 0.0100 | Loss: 94264.7812
Episode 45100 | Reward:  -7.267 | Epsilon: 0.0100 | Loss: 126956.2656
Episode 45150 | Reward:  -6.645 | Epsilon: 0.0100 | Loss: 116308.2891
Episode 45200 | Reward:  -8.108 | Epsilon: 0.0100 | Loss: 110204.9062
Episode 45250 | Reward:  -9.605 | Epsilon: 0.0100 | Loss: 129098.4531
Episode 45300 | Reward:  -6.744 | Epsilon: 0.0100 | Loss: 116592.5781
Episode 45350 | Reward:  -5.826 | Epsilon: 0.0100 | Loss: 117258.6406
Episode 45400 | Reward:  -7.016 | Epsilon: 0.0100 | Loss: 168124.9375
Episode 45450 | Reward: -11.670 | Epsilon: 0.0100 | Loss: 119660.2656
Episode 45500 | Reward: -12.881 | Epsilon: 0.0100 | Loss: 108581.7422
Episode 45550 | Reward: -10.279 | Epsilon: 0.0100 | Loss: 137802.6562
Episode 45600 | Reward: -13.484 | Epsilon: 0.0100 | Loss: 133524.7188
Episode 45650 | Reward: -11.298 | Epsilon: 0.0100 | Loss: 162596.4688
Episode 45700 | Reward: -10.478 | Epsilon: 0.0100 | Loss: 99370.0703
Episode 45750 | Reward: -12.640 | Epsilon: 0.0100 | Loss: 129430.0547
Episode 45800 | Reward: -13.527 | Epsilon: 0.0100 | Loss: 199784.1094
Episode 45850 | Reward: -14.426 | Epsilon: 0.0100 | Loss: 147078.4219
Episode 45900 | Reward:  -9.991 | Epsilon: 0.0100 | Loss: 126736.2188
Episode 45950 | Reward:  -8.311 | Epsilon: 0.0100 | Loss: 135037.9062
Episode 46000 | Reward:  -7.867 | Epsilon: 0.0100 | Loss: 107897.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:08).dict
Episode 46050 | Reward:  -8.344 | Epsilon: 0.0100 | Loss: 166496.7344
Episode 46100 | Reward:  -9.091 | Epsilon: 0.0100 | Loss: 141770.1719
Episode 46150 | Reward: -11.704 | Epsilon: 0.0100 | Loss: 166747.9219
Episode 46200 | Reward: -11.174 | Epsilon: 0.0100 | Loss: 159384.6562
Episode 46250 | Reward: -10.402 | Epsilon: 0.0100 | Loss: 164080.0469
Episode 46300 | Reward: -11.847 | Epsilon: 0.0100 | Loss: 166410.6562
Episode 46350 | Reward:  -8.227 | Epsilon: 0.0100 | Loss: 131164.3281
Episode 46400 | Reward: -11.992 | Epsilon: 0.0100 | Loss: 146919.5312
Episode 46450 | Reward: -13.328 | Epsilon: 0.0100 | Loss: 136137.5000
Episode 46500 | Reward: -13.186 | Epsilon: 0.0100 | Loss: 131850.4688
Episode 46550 | Reward:  -8.782 | Epsilon: 0.0100 | Loss: 133894.7656
Episode 46600 | Reward: -10.017 | Epsilon: 0.0100 | Loss: 127072.6797
Episode 46650 | Reward: -10.693 | Epsilon: 0.0100 | Loss: 181242.7656
Episode 46700 | Reward:  -9.402 | Epsilon: 0.0100 | Loss: 101980.4531
Episode 46750 | Reward: -12.308 | Epsilon: 0.0100 | Loss: 106999.6953
Episode 46800 | Reward:  -9.866 | Epsilon: 0.0100 | Loss: 132804.0625
Episode 46850 | Reward:  -9.086 | Epsilon: 0.0100 | Loss: 181126.4062
Episode 46900 | Reward: -12.746 | Epsilon: 0.0100 | Loss: 185026.2656
Episode 46950 | Reward: -13.622 | Epsilon: 0.0100 | Loss: 171342.2969
Episode 47000 | Reward: -13.469 | Epsilon: 0.0100 | Loss: 193862.7812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:12).dict
Episode 47050 | Reward:  -9.001 | Epsilon: 0.0100 | Loss: 198836.3438
Episode 47100 | Reward: -13.772 | Epsilon: 0.0100 | Loss: 118432.3047
Episode 47150 | Reward:  -9.394 | Epsilon: 0.0100 | Loss: 174619.5156
Episode 47200 | Reward:  -8.689 | Epsilon: 0.0100 | Loss: 144175.3281
Episode 47250 | Reward: -10.019 | Epsilon: 0.0100 | Loss: 140168.6875
Episode 47300 | Reward:  -7.308 | Epsilon: 0.0100 | Loss: 144469.2031
Episode 47350 | Reward:  -6.944 | Epsilon: 0.0100 | Loss: 164140.2812
Episode 47400 | Reward:  -7.229 | Epsilon: 0.0100 | Loss: 199684.9219
Episode 47450 | Reward: -11.692 | Epsilon: 0.0100 | Loss: 152761.0156
Episode 47500 | Reward:  -9.502 | Epsilon: 0.0100 | Loss: 145375.8438
Episode 47550 | Reward: -13.901 | Epsilon: 0.0100 | Loss: 163995.1719
Episode 47600 | Reward:  -4.944 | Epsilon: 0.0100 | Loss: 185076.7188
Episode 47650 | Reward:  -4.058 | Epsilon: 0.0100 | Loss: 173994.3906
Episode 47700 | Reward:  -7.378 | Epsilon: 0.0100 | Loss: 162172.3438
Episode 47750 | Reward:  -8.906 | Epsilon: 0.0100 | Loss: 207810.4062
Episode 47800 | Reward: -11.154 | Epsilon: 0.0100 | Loss: 166892.1250
Episode 47850 | Reward:  -7.446 | Epsilon: 0.0100 | Loss: 211776.9219
Episode 47900 | Reward:  -7.436 | Epsilon: 0.0100 | Loss: 210901.3750
Episode 47950 | Reward:  -5.190 | Epsilon: 0.0100 | Loss: 148256.2969
Episode 48000 | Reward:  -5.869 | Epsilon: 0.0100 | Loss: 224332.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:16).dict
Episode 48050 | Reward:  -5.592 | Epsilon: 0.0100 | Loss: 212460.8594
Episode 48100 | Reward:  -6.975 | Epsilon: 0.0100 | Loss: 194902.5625
Episode 48150 | Reward:  -7.421 | Epsilon: 0.0100 | Loss: 199228.7188
Episode 48200 | Reward:  -7.966 | Epsilon: 0.0100 | Loss: 168296.1875
Episode 48250 | Reward:  -8.205 | Epsilon: 0.0100 | Loss: 163151.0781
Episode 48300 | Reward:  -7.126 | Epsilon: 0.0100 | Loss: 202944.6562
Episode 48350 | Reward:  -8.214 | Epsilon: 0.0100 | Loss: 172642.9375
Episode 48400 | Reward: -12.822 | Epsilon: 0.0100 | Loss: 200423.0625
Episode 48450 | Reward: -10.625 | Epsilon: 0.0100 | Loss: 174560.6562
Episode 48500 | Reward:  -8.523 | Epsilon: 0.0100 | Loss: 167490.6562
Episode 48550 | Reward:  -9.396 | Epsilon: 0.0100 | Loss: 211862.4844
Episode 48600 | Reward:  -6.113 | Epsilon: 0.0100 | Loss: 208419.9062
Episode 48650 | Reward:  -7.904 | Epsilon: 0.0100 | Loss: 219395.7812
Episode 48700 | Reward: -12.729 | Epsilon: 0.0100 | Loss: 206713.8906
Episode 48750 | Reward:  -9.894 | Epsilon: 0.0100 | Loss: 228283.2656
Episode 48800 | Reward: -10.600 | Epsilon: 0.0100 | Loss: 170072.7812
Episode 48850 | Reward: -10.513 | Epsilon: 0.0100 | Loss: 193271.8594
Episode 48900 | Reward: -10.141 | Epsilon: 0.0100 | Loss: 202517.2188
Episode 48950 | Reward:  -9.262 | Epsilon: 0.0100 | Loss: 222227.2969
Episode 49000 | Reward:  -8.893 | Epsilon: 0.0100 | Loss: 211463.9531
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:20).dict
Episode 49050 | Reward:  -9.721 | Epsilon: 0.0100 | Loss: 153268.6719
Episode 49100 | Reward: -10.621 | Epsilon: 0.0100 | Loss: 183639.8750
Episode 49150 | Reward:  -7.344 | Epsilon: 0.0100 | Loss: 167270.0312
Episode 49200 | Reward:  -7.523 | Epsilon: 0.0100 | Loss: 204614.5938
Episode 49250 | Reward: -10.334 | Epsilon: 0.0100 | Loss: 223456.0781
Episode 49300 | Reward: -10.045 | Epsilon: 0.0100 | Loss: 120248.8828
Episode 49350 | Reward:  -9.017 | Epsilon: 0.0100 | Loss: 146413.0625
Episode 49400 | Reward:  -9.600 | Epsilon: 0.0100 | Loss: 152336.9062
Episode 49450 | Reward:  -9.066 | Epsilon: 0.0100 | Loss: 176169.1094
Episode 49500 | Reward:  -7.996 | Epsilon: 0.0100 | Loss: 178612.2188
Episode 49550 | Reward:  -3.588 | Epsilon: 0.0100 | Loss: 198203.5938
Episode 49600 | Reward:  -6.955 | Epsilon: 0.0100 | Loss: 212933.1094
Episode 49650 | Reward:  -6.437 | Epsilon: 0.0100 | Loss: 140256.6250
Episode 49700 | Reward:  -7.871 | Epsilon: 0.0100 | Loss: 179730.4844
Episode 49750 | Reward:  -8.635 | Epsilon: 0.0100 | Loss: 134381.9375
Episode 49800 | Reward:  -8.037 | Epsilon: 0.0100 | Loss: 220094.0000
Episode 49850 | Reward: -13.245 | Epsilon: 0.0100 | Loss: 190226.6250
Episode 49900 | Reward: -10.351 | Epsilon: 0.0100 | Loss: 160123.1875
Episode 49950 | Reward:  -8.950 | Epsilon: 0.0100 | Loss: 203787.6406
Episode 50000 | Reward:  -9.530 | Epsilon: 0.0100 | Loss: 146050.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:24).dict
Episode 50050 | Reward:  -9.314 | Epsilon: 0.0100 | Loss: 138554.8906
Episode 50100 | Reward:  -6.401 | Epsilon: 0.0100 | Loss: 142453.9062
Episode 50150 | Reward: -10.045 | Epsilon: 0.0100 | Loss: 156993.6875
Episode 50200 | Reward:  -9.632 | Epsilon: 0.0100 | Loss: 151140.3125
Episode 50250 | Reward:  -7.571 | Epsilon: 0.0100 | Loss: 125278.4688
Episode 50300 | Reward:  -8.289 | Epsilon: 0.0100 | Loss: 162505.7188
Episode 50350 | Reward:  -9.615 | Epsilon: 0.0100 | Loss: 140309.4375
Episode 50400 | Reward: -11.602 | Epsilon: 0.0100 | Loss: 163554.9531
Episode 50450 | Reward:  -9.310 | Epsilon: 0.0100 | Loss: 162504.4062
Episode 50500 | Reward:  -5.596 | Epsilon: 0.0100 | Loss: 116435.6094
Episode 50550 | Reward:  -8.724 | Epsilon: 0.0100 | Loss: 135100.5781
Episode 50600 | Reward:  -7.800 | Epsilon: 0.0100 | Loss: 144062.7812
Episode 50650 | Reward:  -8.569 | Epsilon: 0.0100 | Loss: 138117.0625
Episode 50700 | Reward:  -5.282 | Epsilon: 0.0100 | Loss: 113519.8750
Episode 50750 | Reward:  -8.381 | Epsilon: 0.0100 | Loss: 172752.7031
Episode 50800 | Reward:  -9.060 | Epsilon: 0.0100 | Loss: 105211.5938
Episode 50850 | Reward:  -5.365 | Epsilon: 0.0100 | Loss: 115746.3359
Episode 50900 | Reward:  -3.352 | Epsilon: 0.0100 | Loss: 126664.7812
Episode 50950 | Reward:  -5.610 | Epsilon: 0.0100 | Loss: 142508.8750
Episode 51000 | Reward:  -5.639 | Epsilon: 0.0100 | Loss: 90437.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:28).dict
Episode 51050 | Reward:  -6.400 | Epsilon: 0.0100 | Loss: 144850.4219
Episode 51100 | Reward:  -6.574 | Epsilon: 0.0100 | Loss: 141208.3594
Episode 51150 | Reward:  -8.452 | Epsilon: 0.0100 | Loss: 124819.2031
Episode 51200 | Reward:  -7.347 | Epsilon: 0.0100 | Loss: 155190.6250
Episode 51250 | Reward:  -5.712 | Epsilon: 0.0100 | Loss: 145164.4375
Episode 51300 | Reward:  -6.417 | Epsilon: 0.0100 | Loss: 133747.3594
Episode 51350 | Reward:  -4.763 | Epsilon: 0.0100 | Loss: 140694.7812
Episode 51400 | Reward:  -3.454 | Epsilon: 0.0100 | Loss: 125184.8359
Episode 51450 | Reward:  -6.114 | Epsilon: 0.0100 | Loss: 124761.5000
Episode 51500 | Reward:  -4.404 | Epsilon: 0.0100 | Loss: 130097.4844
Episode 51550 | Reward:  -6.737 | Epsilon: 0.0100 | Loss: 126413.0234
Episode 51600 | Reward:  -4.158 | Epsilon: 0.0100 | Loss: 137110.2500
Episode 51650 | Reward:  -5.326 | Epsilon: 0.0100 | Loss: 139354.1406
Episode 51700 | Reward:  -6.525 | Epsilon: 0.0100 | Loss: 143527.9219
Episode 51750 | Reward:  -7.412 | Epsilon: 0.0100 | Loss: 135180.1562
Episode 51800 | Reward: -10.326 | Epsilon: 0.0100 | Loss: 156952.8594
Episode 51850 | Reward:  -9.473 | Epsilon: 0.0100 | Loss: 110876.2422
Episode 51900 | Reward:  -8.262 | Epsilon: 0.0100 | Loss: 117443.8359
Episode 51950 | Reward:  -6.023 | Epsilon: 0.0100 | Loss: 131885.1562
Episode 52000 | Reward:  -7.283 | Epsilon: 0.0100 | Loss: 111539.4141
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:32).dict
Episode 52050 | Reward:  -6.971 | Epsilon: 0.0100 | Loss: 120579.1875
Episode 52100 | Reward:  -8.328 | Epsilon: 0.0100 | Loss: 114642.0391
Episode 52150 | Reward: -11.152 | Epsilon: 0.0100 | Loss: 151595.8281
Episode 52200 | Reward:  -6.489 | Epsilon: 0.0100 | Loss: 142495.4375
Episode 52250 | Reward:  -8.121 | Epsilon: 0.0100 | Loss: 154035.9375
Episode 52300 | Reward:  -7.858 | Epsilon: 0.0100 | Loss: 140980.2344
Episode 52350 | Reward:  -5.633 | Epsilon: 0.0100 | Loss: 157770.2969
Episode 52400 | Reward:  -5.885 | Epsilon: 0.0100 | Loss: 100741.9297
Episode 52450 | Reward:  -9.961 | Epsilon: 0.0100 | Loss: 123873.1953
Episode 52500 | Reward:  -8.623 | Epsilon: 0.0100 | Loss: 116782.1719
Episode 52550 | Reward:  -8.398 | Epsilon: 0.0100 | Loss: 119985.3672
Episode 52600 | Reward:  -9.221 | Epsilon: 0.0100 | Loss: 140869.4062
Episode 52650 | Reward:  -6.311 | Epsilon: 0.0100 | Loss: 144430.1250
Episode 52700 | Reward:  -8.270 | Epsilon: 0.0100 | Loss: 128223.8906
Episode 52750 | Reward:  -8.497 | Epsilon: 0.0100 | Loss: 153209.4844
Episode 52800 | Reward:  -5.062 | Epsilon: 0.0100 | Loss: 133919.0312
Episode 52850 | Reward:  -7.032 | Epsilon: 0.0100 | Loss: 115608.1172
Episode 52900 | Reward:  -6.809 | Epsilon: 0.0100 | Loss: 119303.8984
Episode 52950 | Reward:  -3.679 | Epsilon: 0.0100 | Loss: 144939.5000
Episode 53000 | Reward:  -3.606 | Epsilon: 0.0100 | Loss: 111353.7422
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:36).dict
Episode 53050 | Reward:  -8.682 | Epsilon: 0.0100 | Loss: 153676.1875
Episode 53100 | Reward:  -6.787 | Epsilon: 0.0100 | Loss: 122665.9922
Episode 53150 | Reward:  -5.713 | Epsilon: 0.0100 | Loss: 118683.7969
Episode 53200 | Reward:  -4.808 | Epsilon: 0.0100 | Loss: 153703.8438
Episode 53250 | Reward:  -6.661 | Epsilon: 0.0100 | Loss: 136501.5469
Episode 53300 | Reward:  -4.215 | Epsilon: 0.0100 | Loss: 134440.2656
Episode 53350 | Reward:  -5.241 | Epsilon: 0.0100 | Loss: 126069.9922
Episode 53400 | Reward:  -5.672 | Epsilon: 0.0100 | Loss: 128286.2812
Episode 53450 | Reward:  -7.129 | Epsilon: 0.0100 | Loss: 160294.9062
Episode 53500 | Reward:  -6.772 | Epsilon: 0.0100 | Loss: 156441.0000
Episode 53550 | Reward:  -6.189 | Epsilon: 0.0100 | Loss: 168007.7500
Episode 53600 | Reward:  -6.145 | Epsilon: 0.0100 | Loss: 135771.5469
Episode 53650 | Reward:  -8.960 | Epsilon: 0.0100 | Loss: 113440.0234
Episode 53700 | Reward:  -9.068 | Epsilon: 0.0100 | Loss: 156311.8438
Episode 53750 | Reward:  -8.248 | Epsilon: 0.0100 | Loss: 149925.9375
Episode 53800 | Reward:  -7.472 | Epsilon: 0.0100 | Loss: 146534.1094
Episode 53850 | Reward:  -6.807 | Epsilon: 0.0100 | Loss: 114945.6094
Episode 53900 | Reward:  -9.119 | Epsilon: 0.0100 | Loss: 146358.6250
Episode 53950 | Reward:  -9.680 | Epsilon: 0.0100 | Loss: 167952.6562
Episode 54000 | Reward:  -7.190 | Epsilon: 0.0100 | Loss: 119742.0312
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:40).dict
Episode 54050 | Reward:  -7.781 | Epsilon: 0.0100 | Loss: 182616.5312
Episode 54100 | Reward:  -7.659 | Epsilon: 0.0100 | Loss: 112582.7344
Episode 54150 | Reward: -10.864 | Epsilon: 0.0100 | Loss: 106289.3906
Episode 54200 | Reward:  -9.596 | Epsilon: 0.0100 | Loss: 105020.6172
Episode 54250 | Reward:  -6.049 | Epsilon: 0.0100 | Loss: 121535.7109
Episode 54300 | Reward:  -8.301 | Epsilon: 0.0100 | Loss: 128059.1797
Episode 54350 | Reward:  -7.294 | Epsilon: 0.0100 | Loss: 147741.8438
Episode 54400 | Reward:  -4.426 | Epsilon: 0.0100 | Loss: 113883.6875
Episode 54450 | Reward:  -8.453 | Epsilon: 0.0100 | Loss: 139471.4531
Episode 54500 | Reward:  -6.377 | Epsilon: 0.0100 | Loss: 130083.6406
Episode 54550 | Reward:  -8.592 | Epsilon: 0.0100 | Loss: 101478.8438
Episode 54600 | Reward:  -6.557 | Epsilon: 0.0100 | Loss: 93383.6328
Episode 54650 | Reward:  -5.444 | Epsilon: 0.0100 | Loss: 122506.4688
Episode 54700 | Reward:  -7.740 | Epsilon: 0.0100 | Loss: 127409.7031
Episode 54750 | Reward:  -6.386 | Epsilon: 0.0100 | Loss: 147054.7812
Episode 54800 | Reward:  -5.527 | Epsilon: 0.0100 | Loss: 105885.0156
Episode 54850 | Reward:  -5.661 | Epsilon: 0.0100 | Loss: 134736.1562
Episode 54900 | Reward:  -6.117 | Epsilon: 0.0100 | Loss: 101545.2344
Episode 54950 | Reward:  -7.482 | Epsilon: 0.0100 | Loss: 128275.1562
Episode 55000 | Reward: -10.269 | Epsilon: 0.0100 | Loss: 145147.6094
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:44).dict
Episode 55050 | Reward:  -7.445 | Epsilon: 0.0100 | Loss: 141502.1562
Episode 55100 | Reward:  -5.614 | Epsilon: 0.0100 | Loss: 109196.0703
Episode 55150 | Reward:  -7.845 | Epsilon: 0.0100 | Loss: 126513.7578
Episode 55200 | Reward:  -7.400 | Epsilon: 0.0100 | Loss: 181398.6719
Episode 55250 | Reward:  -4.857 | Epsilon: 0.0100 | Loss: 134074.3750
Episode 55300 | Reward:  -6.552 | Epsilon: 0.0100 | Loss: 139681.0938
Episode 55350 | Reward:  -5.689 | Epsilon: 0.0100 | Loss: 137048.3125
Episode 55400 | Reward:  -4.722 | Epsilon: 0.0100 | Loss: 127722.7266
Episode 55450 | Reward:  -5.285 | Epsilon: 0.0100 | Loss: 99599.7188
Episode 55500 | Reward:  -5.176 | Epsilon: 0.0100 | Loss: 117438.5234
Episode 55550 | Reward:  -7.698 | Epsilon: 0.0100 | Loss: 104732.4297
Episode 55600 | Reward:  -5.041 | Epsilon: 0.0100 | Loss: 123906.6562
Episode 55650 | Reward:  -4.800 | Epsilon: 0.0100 | Loss: 113317.1875
Episode 55700 | Reward:  -5.093 | Epsilon: 0.0100 | Loss: 102794.5078
Episode 55750 | Reward:  -4.365 | Epsilon: 0.0100 | Loss: 136642.5625
Episode 55800 | Reward:  -4.507 | Epsilon: 0.0100 | Loss: 143058.0000
Episode 55850 | Reward:  -7.983 | Epsilon: 0.0100 | Loss: 110851.9531
Episode 55900 | Reward:  -9.217 | Epsilon: 0.0100 | Loss: 120400.7891
Episode 55950 | Reward:  -6.727 | Epsilon: 0.0100 | Loss: 99980.1094
Episode 56000 | Reward:  -8.006 | Epsilon: 0.0100 | Loss: 111900.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:48).dict
Episode 56050 | Reward:  -9.697 | Epsilon: 0.0100 | Loss: 115565.9844
Episode 56100 | Reward:  -8.937 | Epsilon: 0.0100 | Loss: 107366.8281
Episode 56150 | Reward:  -7.662 | Epsilon: 0.0100 | Loss: 115476.0234
Episode 56200 | Reward: -11.811 | Epsilon: 0.0100 | Loss: 117369.5938
Episode 56250 | Reward: -11.856 | Epsilon: 0.0100 | Loss: 96239.5625
Episode 56300 | Reward:  -8.049 | Epsilon: 0.0100 | Loss: 116489.7422
Episode 56350 | Reward:  -9.685 | Epsilon: 0.0100 | Loss: 112678.1406
Episode 56400 | Reward: -10.694 | Epsilon: 0.0100 | Loss: 131955.5938
Episode 56450 | Reward:  -9.616 | Epsilon: 0.0100 | Loss: 127300.4062
Episode 56500 | Reward:  -5.833 | Epsilon: 0.0100 | Loss: 116728.0859
Episode 56550 | Reward:  -5.710 | Epsilon: 0.0100 | Loss: 130390.6484
Episode 56600 | Reward:  -7.077 | Epsilon: 0.0100 | Loss: 123391.7969
Episode 56650 | Reward:  -5.300 | Epsilon: 0.0100 | Loss: 94874.0156
Episode 56700 | Reward:  -5.653 | Epsilon: 0.0100 | Loss: 104171.6875
Episode 56750 | Reward:  -5.183 | Epsilon: 0.0100 | Loss: 133061.9375
Episode 56800 | Reward:  -8.362 | Epsilon: 0.0100 | Loss: 108388.0625
Episode 56850 | Reward:  -8.076 | Epsilon: 0.0100 | Loss: 109066.4141
Episode 56900 | Reward:  -5.839 | Epsilon: 0.0100 | Loss: 87976.8125
Episode 56950 | Reward:  -7.186 | Epsilon: 0.0100 | Loss: 106378.2969
Episode 57000 | Reward:  -7.744 | Epsilon: 0.0100 | Loss: 106833.8984
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:52).dict
Episode 57050 | Reward:  -8.449 | Epsilon: 0.0100 | Loss: 112275.9375
Episode 57100 | Reward:  -4.297 | Epsilon: 0.0100 | Loss: 97756.4219
Episode 57150 | Reward:  -4.768 | Epsilon: 0.0100 | Loss: 127480.9688
Episode 57200 | Reward:  -6.802 | Epsilon: 0.0100 | Loss: 138352.0938
Episode 57250 | Reward:  -6.023 | Epsilon: 0.0100 | Loss: 105327.9844
Episode 57300 | Reward:  -9.272 | Epsilon: 0.0100 | Loss: 104341.8359
Episode 57350 | Reward:  -6.899 | Epsilon: 0.0100 | Loss: 104728.5859
Episode 57400 | Reward:  -7.246 | Epsilon: 0.0100 | Loss: 121762.4297
Episode 57450 | Reward:  -8.310 | Epsilon: 0.0100 | Loss: 118644.4688
Episode 57500 | Reward:  -3.541 | Epsilon: 0.0100 | Loss: 100989.6406
Episode 57550 | Reward:  -6.713 | Epsilon: 0.0100 | Loss: 94650.1562
Episode 57600 | Reward:  -5.352 | Epsilon: 0.0100 | Loss: 114916.2969
Episode 57650 | Reward:  -9.093 | Epsilon: 0.0100 | Loss: 115326.5781
Episode 57700 | Reward:  -8.800 | Epsilon: 0.0100 | Loss: 108685.2656
Episode 57750 | Reward:  -8.390 | Epsilon: 0.0100 | Loss: 122648.5469
Episode 57800 | Reward:  -7.031 | Epsilon: 0.0100 | Loss: 120943.9609
Episode 57850 | Reward:  -8.288 | Epsilon: 0.0100 | Loss: 99457.0781
Episode 57900 | Reward:  -6.439 | Epsilon: 0.0100 | Loss: 137346.4844
Episode 57950 | Reward:  -7.004 | Epsilon: 0.0100 | Loss: 116719.6484
Episode 58000 | Reward:  -7.851 | Epsilon: 0.0100 | Loss: 117145.1406
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:56).dict
Episode 58050 | Reward:  -7.855 | Epsilon: 0.0100 | Loss: 125424.7656
Episode 58100 | Reward:  -6.928 | Epsilon: 0.0100 | Loss: 147713.1250
Episode 58150 | Reward:  -6.417 | Epsilon: 0.0100 | Loss: 111854.0859
Episode 58200 | Reward:  -8.701 | Epsilon: 0.0100 | Loss: 127328.2031
Episode 58250 | Reward:  -5.102 | Epsilon: 0.0100 | Loss: 151751.5625
Episode 58300 | Reward:  -7.218 | Epsilon: 0.0100 | Loss: 104410.6641
Episode 58350 | Reward:  -8.880 | Epsilon: 0.0100 | Loss: 105364.8281
Episode 58400 | Reward:  -7.593 | Epsilon: 0.0100 | Loss: 135394.7500
Episode 58450 | Reward:  -9.609 | Epsilon: 0.0100 | Loss: 107591.5938
Episode 58500 | Reward: -10.453 | Epsilon: 0.0100 | Loss: 126930.6562
Episode 58550 | Reward:  -8.469 | Epsilon: 0.0100 | Loss: 104350.2188
Episode 58600 | Reward:  -7.051 | Epsilon: 0.0100 | Loss: 114047.7734
Episode 58650 | Reward:  -9.052 | Epsilon: 0.0100 | Loss: 117807.1641
Episode 58700 | Reward:  -5.083 | Epsilon: 0.0100 | Loss: 114946.5625
Episode 58750 | Reward:  -7.763 | Epsilon: 0.0100 | Loss: 84275.2734
Episode 58800 | Reward:  -6.904 | Epsilon: 0.0100 | Loss: 129426.2969
Episode 58850 | Reward:  -7.060 | Epsilon: 0.0100 | Loss: 100879.2500
Episode 58900 | Reward:  -9.717 | Epsilon: 0.0100 | Loss: 119743.5312
Episode 58950 | Reward: -10.819 | Epsilon: 0.0100 | Loss: 119557.9844
Episode 59000 | Reward:  -5.694 | Epsilon: 0.0100 | Loss: 137706.4531
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:00).dict
Episode 59050 | Reward:  -7.369 | Epsilon: 0.0100 | Loss: 101177.5625
Episode 59100 | Reward: -12.349 | Epsilon: 0.0100 | Loss: 151299.6094
Episode 59150 | Reward:  -5.657 | Epsilon: 0.0100 | Loss: 138654.0000
Episode 59200 | Reward:  -8.893 | Epsilon: 0.0100 | Loss: 153810.9062
Episode 59250 | Reward: -11.273 | Epsilon: 0.0100 | Loss: 165828.5312
Episode 59300 | Reward: -10.365 | Epsilon: 0.0100 | Loss: 112469.7734
Episode 59350 | Reward:  -7.110 | Epsilon: 0.0100 | Loss: 154132.7969
Episode 59400 | Reward:  -5.899 | Epsilon: 0.0100 | Loss: 143065.1406
Episode 59450 | Reward:  -8.642 | Epsilon: 0.0100 | Loss: 167206.0781
Episode 59500 | Reward:  -8.473 | Epsilon: 0.0100 | Loss: 156479.7188
Episode 59550 | Reward:  -9.551 | Epsilon: 0.0100 | Loss: 177921.2969
Episode 59600 | Reward: -10.314 | Epsilon: 0.0100 | Loss: 194794.5000
Episode 59650 | Reward:  -8.373 | Epsilon: 0.0100 | Loss: 218594.0938
Episode 59700 | Reward: -13.261 | Epsilon: 0.0100 | Loss: 220845.5469
Episode 59750 | Reward: -13.823 | Epsilon: 0.0100 | Loss: 178449.5938
Episode 59800 | Reward:  -8.404 | Epsilon: 0.0100 | Loss: 201334.4531
Episode 59850 | Reward: -10.578 | Epsilon: 0.0100 | Loss: 252600.9375
Episode 59900 | Reward: -13.976 | Epsilon: 0.0100 | Loss: 234505.7969
Episode 59950 | Reward: -13.774 | Epsilon: 0.0100 | Loss: 228932.9375
Episode 60000 | Reward: -11.435 | Epsilon: 0.0100 | Loss: 238275.7344
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:04).dict
Episode 60050 | Reward: -10.828 | Epsilon: 0.0100 | Loss: 255993.0000
Episode 60100 | Reward:  -8.775 | Epsilon: 0.0100 | Loss: 297778.5938
Episode 60150 | Reward: -12.404 | Epsilon: 0.0100 | Loss: 263247.4375
Episode 60200 | Reward:  -9.438 | Epsilon: 0.0100 | Loss: 240910.0469
Episode 60250 | Reward: -12.675 | Epsilon: 0.0100 | Loss: 295441.3750
Episode 60300 | Reward:  -8.425 | Epsilon: 0.0100 | Loss: 279790.5625
Episode 60350 | Reward: -10.430 | Epsilon: 0.0100 | Loss: 337665.2500
Episode 60400 | Reward: -12.130 | Epsilon: 0.0100 | Loss: 331688.6250
Episode 60450 | Reward: -11.679 | Epsilon: 0.0100 | Loss: 377330.3750
Episode 60500 | Reward:  -7.595 | Epsilon: 0.0100 | Loss: 245541.3594
Episode 60550 | Reward:  -8.957 | Epsilon: 0.0100 | Loss: 258101.0312
Episode 60600 | Reward:  -7.197 | Epsilon: 0.0100 | Loss: 323444.3125
Episode 60650 | Reward:  -9.959 | Epsilon: 0.0100 | Loss: 258488.0312
Episode 60700 | Reward: -10.542 | Epsilon: 0.0100 | Loss: 256894.6094
Episode 60750 | Reward:  -9.588 | Epsilon: 0.0100 | Loss: 369316.2812
Episode 60800 | Reward: -16.447 | Epsilon: 0.0100 | Loss: 343720.1250
Episode 60850 | Reward: -11.251 | Epsilon: 0.0100 | Loss: 305338.6562
Episode 60900 | Reward:  -7.056 | Epsilon: 0.0100 | Loss: 381487.5938
Episode 60950 | Reward:  -3.678 | Epsilon: 0.0100 | Loss: 409716.4375
Episode 61000 | Reward: -10.612 | Epsilon: 0.0100 | Loss: 298149.5938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:08).dict
Episode 61050 | Reward:  -8.470 | Epsilon: 0.0100 | Loss: 399314.6250
Episode 61100 | Reward:  -7.142 | Epsilon: 0.0100 | Loss: 373569.3750
Episode 61150 | Reward:  -8.771 | Epsilon: 0.0100 | Loss: 381191.0312
Episode 61200 | Reward:  -8.813 | Epsilon: 0.0100 | Loss: 258514.2344
Episode 61250 | Reward:  -5.744 | Epsilon: 0.0100 | Loss: 396472.1875
Episode 61300 | Reward:  -7.551 | Epsilon: 0.0100 | Loss: 330104.0000
Episode 61350 | Reward:  -6.992 | Epsilon: 0.0100 | Loss: 359344.0938
Episode 61400 | Reward:  -5.042 | Epsilon: 0.0100 | Loss: 479762.3438
Episode 61450 | Reward:  -8.019 | Epsilon: 0.0100 | Loss: 373330.4062
Episode 61500 | Reward:  -8.302 | Epsilon: 0.0100 | Loss: 310255.3125
Episode 61550 | Reward:  -7.749 | Epsilon: 0.0100 | Loss: 415103.3125
Episode 61600 | Reward:  -5.969 | Epsilon: 0.0100 | Loss: 449127.6250
Episode 61650 | Reward:  -5.623 | Epsilon: 0.0100 | Loss: 374815.1875
Episode 61700 | Reward:  -5.265 | Epsilon: 0.0100 | Loss: 420863.1875
Episode 61750 | Reward:  -3.240 | Epsilon: 0.0100 | Loss: 392661.3125
Episode 61800 | Reward:  -6.810 | Epsilon: 0.0100 | Loss: 455368.5938
Episode 61850 | Reward:  -9.246 | Epsilon: 0.0100 | Loss: 371551.5000
Episode 61900 | Reward: -11.130 | Epsilon: 0.0100 | Loss: 473401.0625
Episode 61950 | Reward:  -8.074 | Epsilon: 0.0100 | Loss: 445737.6250
Episode 62000 | Reward: -12.678 | Epsilon: 0.0100 | Loss: 406376.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:12).dict
Episode 62050 | Reward:  -7.127 | Epsilon: 0.0100 | Loss: 423888.5938
Episode 62100 | Reward: -10.226 | Epsilon: 0.0100 | Loss: 613341.3750
Episode 62150 | Reward:  -9.885 | Epsilon: 0.0100 | Loss: 345165.3125
Episode 62200 | Reward: -10.251 | Epsilon: 0.0100 | Loss: 547945.5000
Episode 62250 | Reward: -13.156 | Epsilon: 0.0100 | Loss: 497049.9688
Episode 62300 | Reward: -13.851 | Epsilon: 0.0100 | Loss: 515359.1875
Episode 62350 | Reward: -10.897 | Epsilon: 0.0100 | Loss: 422619.4375
Episode 62400 | Reward: -12.436 | Epsilon: 0.0100 | Loss: 605542.3750
Episode 62450 | Reward: -13.088 | Epsilon: 0.0100 | Loss: 510199.3750
Episode 62500 | Reward:  -9.995 | Epsilon: 0.0100 | Loss: 556896.7500
Episode 62550 | Reward:  -6.403 | Epsilon: 0.0100 | Loss: 604348.5000
Episode 62600 | Reward:  -4.953 | Epsilon: 0.0100 | Loss: 569695.8750
Episode 62650 | Reward:  -7.301 | Epsilon: 0.0100 | Loss: 504432.5312
Episode 62700 | Reward:  -8.171 | Epsilon: 0.0100 | Loss: 544126.5000
Episode 62750 | Reward:  -9.435 | Epsilon: 0.0100 | Loss: 623932.6875
Episode 62800 | Reward:  -9.794 | Epsilon: 0.0100 | Loss: 617128.0000
Episode 62850 | Reward: -10.732 | Epsilon: 0.0100 | Loss: 444972.9375
Episode 62900 | Reward:  -9.522 | Epsilon: 0.0100 | Loss: 839598.0000
Episode 62950 | Reward:  -9.616 | Epsilon: 0.0100 | Loss: 743834.3750
Episode 63000 | Reward:  -7.455 | Epsilon: 0.0100 | Loss: 638733.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:16).dict
Episode 63050 | Reward:  -8.160 | Epsilon: 0.0100 | Loss: 722254.0000
Episode 63100 | Reward:  -9.791 | Epsilon: 0.0100 | Loss: 704146.2500
Episode 63150 | Reward: -11.001 | Epsilon: 0.0100 | Loss: 712833.3125
Episode 63200 | Reward: -14.048 | Epsilon: 0.0100 | Loss: 699980.5625
Episode 63250 | Reward: -13.008 | Epsilon: 0.0100 | Loss: 715013.0625
Episode 63300 | Reward:  -9.082 | Epsilon: 0.0100 | Loss: 756820.3750
Episode 63350 | Reward: -11.960 | Epsilon: 0.0100 | Loss: 751139.5625
Episode 63400 | Reward:  -8.184 | Epsilon: 0.0100 | Loss: 898103.7500
Episode 63450 | Reward: -13.824 | Epsilon: 0.0100 | Loss: 627046.4375
Episode 63500 | Reward: -14.496 | Epsilon: 0.0100 | Loss: 816863.1875
Episode 63550 | Reward: -12.640 | Epsilon: 0.0100 | Loss: 1081163.2500
Episode 63600 | Reward: -11.782 | Epsilon: 0.0100 | Loss: 1056168.3750
Episode 63650 | Reward: -10.425 | Epsilon: 0.0100 | Loss: 1111844.7500
Episode 63700 | Reward: -12.588 | Epsilon: 0.0100 | Loss: 895853.3750
Episode 63750 | Reward: -13.123 | Epsilon: 0.0100 | Loss: 755430.0625
Episode 63800 | Reward: -10.446 | Epsilon: 0.0100 | Loss: 915566.8125
Episode 63850 | Reward: -14.397 | Epsilon: 0.0100 | Loss: 882173.8125
Episode 63900 | Reward: -16.792 | Epsilon: 0.0100 | Loss: 865460.8125
Episode 63950 | Reward: -10.945 | Epsilon: 0.0100 | Loss: 906738.1875
Episode 64000 | Reward: -11.644 | Epsilon: 0.0100 | Loss: 888096.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:20).dict
Episode 64050 | Reward:  -9.399 | Epsilon: 0.0100 | Loss: 793422.3125
Episode 64100 | Reward: -11.332 | Epsilon: 0.0100 | Loss: 951187.1875
Episode 64150 | Reward: -12.355 | Epsilon: 0.0100 | Loss: 727029.8750
Episode 64200 | Reward:  -9.942 | Epsilon: 0.0100 | Loss: 920303.6250
Episode 64250 | Reward: -11.350 | Epsilon: 0.0100 | Loss: 801573.6250
Episode 64300 | Reward: -11.952 | Epsilon: 0.0100 | Loss: 1046671.7500
Episode 64350 | Reward:  -8.286 | Epsilon: 0.0100 | Loss: 1105708.6250
Episode 64400 | Reward:  -9.730 | Epsilon: 0.0100 | Loss: 1023851.9375
Episode 64450 | Reward: -10.112 | Epsilon: 0.0100 | Loss: 1080370.2500
Episode 64500 | Reward:  -9.215 | Epsilon: 0.0100 | Loss: 1186449.6250
Episode 64550 | Reward: -13.395 | Epsilon: 0.0100 | Loss: 1234176.1250
Episode 64600 | Reward: -10.964 | Epsilon: 0.0100 | Loss: 1053632.5000
Episode 64650 | Reward: -10.838 | Epsilon: 0.0100 | Loss: 938506.0625
Episode 64700 | Reward: -11.036 | Epsilon: 0.0100 | Loss: 1219236.7500
Episode 64750 | Reward: -10.164 | Epsilon: 0.0100 | Loss: 1101042.1250
Episode 64800 | Reward: -14.416 | Epsilon: 0.0100 | Loss: 1198463.2500
Episode 64850 | Reward: -14.253 | Epsilon: 0.0100 | Loss: 1338801.3750
Episode 64900 | Reward: -15.137 | Epsilon: 0.0100 | Loss: 1644822.2500
Episode 64950 | Reward: -12.729 | Epsilon: 0.0100 | Loss: 1077651.5000
Episode 65000 | Reward: -12.777 | Epsilon: 0.0100 | Loss: 1073489.8750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:24).dict
Episode 65050 | Reward: -14.110 | Epsilon: 0.0100 | Loss: 1160138.0000
Episode 65100 | Reward: -13.750 | Epsilon: 0.0100 | Loss: 1614953.1250
Episode 65150 | Reward: -13.331 | Epsilon: 0.0100 | Loss: 1328082.8750
Episode 65200 | Reward: -14.163 | Epsilon: 0.0100 | Loss: 1223697.3750
Episode 65250 | Reward: -14.772 | Epsilon: 0.0100 | Loss: 1184348.0000
Episode 65300 | Reward: -10.576 | Epsilon: 0.0100 | Loss: 1377697.7500
Episode 65350 | Reward: -13.040 | Epsilon: 0.0100 | Loss: 1197293.1250
Episode 65400 | Reward: -16.753 | Epsilon: 0.0100 | Loss: 1431197.1250
Episode 65450 | Reward: -16.478 | Epsilon: 0.0100 | Loss: 1439911.5000
Episode 65500 | Reward: -18.372 | Epsilon: 0.0100 | Loss: 1263166.0000
Episode 65550 | Reward: -10.628 | Epsilon: 0.0100 | Loss: 1652417.7500
Episode 65600 | Reward:  -8.875 | Epsilon: 0.0100 | Loss: 1203614.5000
Episode 65650 | Reward: -12.650 | Epsilon: 0.0100 | Loss: 1606597.1250
Episode 65700 | Reward:  -9.218 | Epsilon: 0.0100 | Loss: 1025740.6250
Episode 65750 | Reward:  -7.106 | Epsilon: 0.0100 | Loss: 1340396.6250
Episode 65800 | Reward:  -5.958 | Epsilon: 0.0100 | Loss: 1536619.5000
Episode 65850 | Reward:  -8.318 | Epsilon: 0.0100 | Loss: 1408167.7500
Episode 65900 | Reward:  -6.601 | Epsilon: 0.0100 | Loss: 932679.3125
Episode 65950 | Reward: -11.080 | Epsilon: 0.0100 | Loss: 1525058.8750
Episode 66000 | Reward: -10.503 | Epsilon: 0.0100 | Loss: 1648264.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:28).dict
Episode 66050 | Reward: -11.545 | Epsilon: 0.0100 | Loss: 1498014.0000
Episode 66100 | Reward: -11.323 | Epsilon: 0.0100 | Loss: 1270686.5000
Episode 66150 | Reward: -12.682 | Epsilon: 0.0100 | Loss: 1046476.6875
Episode 66200 | Reward:  -9.715 | Epsilon: 0.0100 | Loss: 1369944.6250
Episode 66250 | Reward: -12.598 | Epsilon: 0.0100 | Loss: 1845370.5000
Episode 66300 | Reward: -12.210 | Epsilon: 0.0100 | Loss: 1790594.1250
Episode 66350 | Reward: -13.268 | Epsilon: 0.0100 | Loss: 1245712.6250
Episode 66400 | Reward: -11.150 | Epsilon: 0.0100 | Loss: 1206564.0000
Episode 66450 | Reward:  -9.932 | Epsilon: 0.0100 | Loss: 1321998.7500
Episode 66500 | Reward: -12.887 | Epsilon: 0.0100 | Loss: 1920188.6250
Episode 66550 | Reward: -10.785 | Epsilon: 0.0100 | Loss: 1353097.8750
Episode 66600 | Reward: -16.655 | Epsilon: 0.0100 | Loss: 1726721.2500
Episode 66650 | Reward:  -9.117 | Epsilon: 0.0100 | Loss: 1256700.2500
Episode 66700 | Reward: -13.665 | Epsilon: 0.0100 | Loss: 1305710.1250
Episode 66750 | Reward: -11.424 | Epsilon: 0.0100 | Loss: 1169802.7500
Episode 66800 | Reward: -11.485 | Epsilon: 0.0100 | Loss: 1287774.2500
Episode 66850 | Reward: -13.780 | Epsilon: 0.0100 | Loss: 1406587.0000
Episode 66900 | Reward: -12.319 | Epsilon: 0.0100 | Loss: 1407967.7500
Episode 66950 | Reward: -15.215 | Epsilon: 0.0100 | Loss: 1146576.6250
Episode 67000 | Reward: -15.545 | Epsilon: 0.0100 | Loss: 1215551.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:32).dict
Episode 67050 | Reward: -16.599 | Epsilon: 0.0100 | Loss: 1235151.5000
Episode 67100 | Reward: -13.537 | Epsilon: 0.0100 | Loss: 1426277.8750
Episode 67150 | Reward: -10.324 | Epsilon: 0.0100 | Loss: 1241535.7500
Episode 67200 | Reward: -13.866 | Epsilon: 0.0100 | Loss: 1671907.0000
Episode 67250 | Reward: -13.412 | Epsilon: 0.0100 | Loss: 1716569.2500
Episode 67300 | Reward:  -9.008 | Epsilon: 0.0100 | Loss: 1142247.0000
Episode 67350 | Reward: -13.491 | Epsilon: 0.0100 | Loss: 1067158.1250
Episode 67400 | Reward: -11.857 | Epsilon: 0.0100 | Loss: 1674020.8750
Episode 67450 | Reward: -11.245 | Epsilon: 0.0100 | Loss: 1457279.1250
Episode 67500 | Reward: -10.444 | Epsilon: 0.0100 | Loss: 1411896.0000
Episode 67550 | Reward: -12.706 | Epsilon: 0.0100 | Loss: 1056967.2500
Episode 67600 | Reward: -13.512 | Epsilon: 0.0100 | Loss: 1205226.5000
Episode 67650 | Reward:  -7.925 | Epsilon: 0.0100 | Loss: 1414054.7500
Episode 67700 | Reward: -12.062 | Epsilon: 0.0100 | Loss: 1305762.5000
Episode 67750 | Reward: -13.185 | Epsilon: 0.0100 | Loss: 1330844.7500
Episode 67800 | Reward: -14.078 | Epsilon: 0.0100 | Loss: 982504.8750
Episode 67850 | Reward: -13.876 | Epsilon: 0.0100 | Loss: 1003535.8125
Episode 67900 | Reward:  -9.815 | Epsilon: 0.0100 | Loss: 1135144.7500
Episode 67950 | Reward: -13.571 | Epsilon: 0.0100 | Loss: 999230.1250
Episode 68000 | Reward: -11.663 | Epsilon: 0.0100 | Loss: 1153484.6250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:36).dict
Episode 68050 | Reward: -13.037 | Epsilon: 0.0100 | Loss: 992882.3125
Episode 68100 | Reward:  -9.822 | Epsilon: 0.0100 | Loss: 1193637.6250
Episode 68150 | Reward: -14.127 | Epsilon: 0.0100 | Loss: 926877.3125
Episode 68200 | Reward: -16.902 | Epsilon: 0.0100 | Loss: 1428711.3750
Episode 68250 | Reward: -14.486 | Epsilon: 0.0100 | Loss: 911775.9375
Episode 68300 | Reward: -14.728 | Epsilon: 0.0100 | Loss: 1184674.1250
Episode 68350 | Reward: -16.896 | Epsilon: 0.0100 | Loss: 1042177.6250
Episode 68400 | Reward: -17.392 | Epsilon: 0.0100 | Loss: 757442.7500
Episode 68450 | Reward: -13.750 | Epsilon: 0.0100 | Loss: 1122684.7500
Episode 68500 | Reward:  -8.616 | Epsilon: 0.0100 | Loss: 1190554.7500
Episode 68550 | Reward:  -8.928 | Epsilon: 0.0100 | Loss: 1117072.6250
Episode 68600 | Reward: -11.548 | Epsilon: 0.0100 | Loss: 1191316.0000
Episode 68650 | Reward: -11.092 | Epsilon: 0.0100 | Loss: 1271688.0000
Episode 68700 | Reward:  -9.623 | Epsilon: 0.0100 | Loss: 829480.3750
Episode 68750 | Reward: -11.869 | Epsilon: 0.0100 | Loss: 1130239.5000
Episode 68800 | Reward: -11.893 | Epsilon: 0.0100 | Loss: 783767.8750
Episode 68850 | Reward:  -9.678 | Epsilon: 0.0100 | Loss: 713747.7500
Episode 68900 | Reward: -14.349 | Epsilon: 0.0100 | Loss: 1429833.7500
Episode 68950 | Reward: -18.293 | Epsilon: 0.0100 | Loss: 1177482.6250
Episode 69000 | Reward: -15.424 | Epsilon: 0.0100 | Loss: 922917.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:40).dict
Episode 69050 | Reward: -15.225 | Epsilon: 0.0100 | Loss: 1093720.3750
Episode 69100 | Reward: -13.648 | Epsilon: 0.0100 | Loss: 914488.0000
Episode 69150 | Reward: -13.049 | Epsilon: 0.0100 | Loss: 826196.2500
Episode 69200 | Reward: -12.322 | Epsilon: 0.0100 | Loss: 825246.5625
Episode 69250 | Reward: -12.873 | Epsilon: 0.0100 | Loss: 972523.1875
Episode 69300 | Reward:  -8.975 | Epsilon: 0.0100 | Loss: 1039708.0625
Episode 69350 | Reward: -14.114 | Epsilon: 0.0100 | Loss: 996237.1875
Episode 69400 | Reward: -13.750 | Epsilon: 0.0100 | Loss: 765385.4375
Episode 69450 | Reward: -12.349 | Epsilon: 0.0100 | Loss: 1008104.7500
Episode 69500 | Reward:  -9.830 | Epsilon: 0.0100 | Loss: 926967.3125
Episode 69550 | Reward:  -9.928 | Epsilon: 0.0100 | Loss: 1140301.1250
Episode 69600 | Reward: -11.263 | Epsilon: 0.0100 | Loss: 894302.0000
Episode 69650 | Reward:  -9.211 | Epsilon: 0.0100 | Loss: 1218306.8750
Episode 69700 | Reward: -11.947 | Epsilon: 0.0100 | Loss: 855799.0000
Episode 69750 | Reward: -13.746 | Epsilon: 0.0100 | Loss: 947769.3750
Episode 69800 | Reward: -11.418 | Epsilon: 0.0100 | Loss: 962223.3125
Episode 69850 | Reward: -11.147 | Epsilon: 0.0100 | Loss: 880151.7500
Episode 69900 | Reward: -13.248 | Epsilon: 0.0100 | Loss: 814450.5000
Episode 69950 | Reward: -13.889 | Epsilon: 0.0100 | Loss: 820783.7500
Episode 70000 | Reward: -11.985 | Epsilon: 0.0100 | Loss: 1119446.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:44).dict
Episode 70050 | Reward: -11.696 | Epsilon: 0.0100 | Loss: 972667.5625
Episode 70100 | Reward: -11.217 | Epsilon: 0.0100 | Loss: 918446.5000
Episode 70150 | Reward: -13.099 | Epsilon: 0.0100 | Loss: 1183638.2500
Episode 70200 | Reward: -14.949 | Epsilon: 0.0100 | Loss: 1068325.2500
Episode 70250 | Reward: -12.414 | Epsilon: 0.0100 | Loss: 1345435.8750
Episode 70300 | Reward:  -9.363 | Epsilon: 0.0100 | Loss: 1061845.1250
Episode 70350 | Reward: -12.785 | Epsilon: 0.0100 | Loss: 1040614.8750
Episode 70400 | Reward: -12.728 | Epsilon: 0.0100 | Loss: 1351929.7500
Episode 70450 | Reward: -10.538 | Epsilon: 0.0100 | Loss: 1043561.8750
Episode 70500 | Reward: -10.228 | Epsilon: 0.0100 | Loss: 987601.0000
Episode 70550 | Reward: -11.270 | Epsilon: 0.0100 | Loss: 1045651.3125
Episode 70600 | Reward:  -8.068 | Epsilon: 0.0100 | Loss: 847647.4375
Episode 70650 | Reward: -11.027 | Epsilon: 0.0100 | Loss: 999579.4375
Episode 70700 | Reward:  -7.662 | Epsilon: 0.0100 | Loss: 1047725.0000
Episode 70750 | Reward: -14.318 | Epsilon: 0.0100 | Loss: 1127777.7500
Episode 70800 | Reward: -11.932 | Epsilon: 0.0100 | Loss: 1097774.0000
Episode 70850 | Reward:  -7.586 | Epsilon: 0.0100 | Loss: 1156390.1250
Episode 70900 | Reward: -10.120 | Epsilon: 0.0100 | Loss: 787807.5000
Episode 70950 | Reward: -10.544 | Epsilon: 0.0100 | Loss: 1088124.2500
Episode 71000 | Reward:  -7.131 | Epsilon: 0.0100 | Loss: 1266917.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:48).dict
Episode 71050 | Reward:  -8.110 | Epsilon: 0.0100 | Loss: 981386.5625
Episode 71100 | Reward: -10.924 | Epsilon: 0.0100 | Loss: 1087775.2500
Episode 71150 | Reward: -13.762 | Epsilon: 0.0100 | Loss: 815371.5000
Episode 71200 | Reward: -10.107 | Epsilon: 0.0100 | Loss: 1284143.1250
Episode 71250 | Reward: -14.662 | Epsilon: 0.0100 | Loss: 1077385.0000
Episode 71300 | Reward: -10.511 | Epsilon: 0.0100 | Loss: 877078.5000
Episode 71350 | Reward:  -7.548 | Epsilon: 0.0100 | Loss: 1526164.2500
Episode 71400 | Reward: -11.774 | Epsilon: 0.0100 | Loss: 1003380.6250
Episode 71450 | Reward: -13.004 | Epsilon: 0.0100 | Loss: 1418505.0000
Episode 71500 | Reward: -12.247 | Epsilon: 0.0100 | Loss: 917914.4375
Episode 71550 | Reward: -15.472 | Epsilon: 0.0100 | Loss: 1198955.3750
Episode 71600 | Reward:  -9.690 | Epsilon: 0.0100 | Loss: 1259562.1250
Episode 71650 | Reward: -14.236 | Epsilon: 0.0100 | Loss: 1174153.2500
Episode 71700 | Reward: -13.684 | Epsilon: 0.0100 | Loss: 1432162.2500
Episode 71750 | Reward: -13.416 | Epsilon: 0.0100 | Loss: 1184927.2500
Episode 71800 | Reward: -12.663 | Epsilon: 0.0100 | Loss: 926470.6250
Episode 71850 | Reward: -13.187 | Epsilon: 0.0100 | Loss: 1150219.2500
Episode 71900 | Reward: -12.286 | Epsilon: 0.0100 | Loss: 1267416.1250
Episode 71950 | Reward: -11.480 | Epsilon: 0.0100 | Loss: 960393.6250
Episode 72000 | Reward: -13.269 | Epsilon: 0.0100 | Loss: 1279880.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:52).dict
Episode 72050 | Reward: -13.251 | Epsilon: 0.0100 | Loss: 939434.3750
Episode 72100 | Reward:  -8.433 | Epsilon: 0.0100 | Loss: 858712.2500
Episode 72150 | Reward: -14.100 | Epsilon: 0.0100 | Loss: 1260376.5000
Episode 72200 | Reward: -11.798 | Epsilon: 0.0100 | Loss: 921632.1250
Episode 72250 | Reward: -13.092 | Epsilon: 0.0100 | Loss: 977822.2500
Episode 72300 | Reward: -11.269 | Epsilon: 0.0100 | Loss: 1025844.9375
Episode 72350 | Reward: -11.297 | Epsilon: 0.0100 | Loss: 842023.0000
Episode 72400 | Reward:  -7.582 | Epsilon: 0.0100 | Loss: 933372.9375
Episode 72450 | Reward: -12.434 | Epsilon: 0.0100 | Loss: 555092.8125
Episode 72500 | Reward: -14.241 | Epsilon: 0.0100 | Loss: 849346.8750
Episode 72550 | Reward: -17.016 | Epsilon: 0.0100 | Loss: 564579.0625
Episode 72600 | Reward: -14.552 | Epsilon: 0.0100 | Loss: 812752.3750
Episode 72650 | Reward:  -9.689 | Epsilon: 0.0100 | Loss: 778096.1250
Episode 72700 | Reward: -13.003 | Epsilon: 0.0100 | Loss: 941457.3125
Episode 72750 | Reward: -13.184 | Epsilon: 0.0100 | Loss: 694128.9375
Episode 72800 | Reward: -13.963 | Epsilon: 0.0100 | Loss: 971374.5000
Episode 72850 | Reward: -11.202 | Epsilon: 0.0100 | Loss: 863201.1250
Episode 72900 | Reward: -10.798 | Epsilon: 0.0100 | Loss: 677541.6250
Episode 72950 | Reward: -14.792 | Epsilon: 0.0100 | Loss: 713254.6250
Episode 73000 | Reward: -15.422 | Epsilon: 0.0100 | Loss: 894679.3125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:56).dict
Episode 73050 | Reward: -16.963 | Epsilon: 0.0100 | Loss: 812232.1250
Episode 73100 | Reward: -12.741 | Epsilon: 0.0100 | Loss: 727125.4375
Episode 73150 | Reward: -10.404 | Epsilon: 0.0100 | Loss: 489809.7188
Episode 73200 | Reward: -12.043 | Epsilon: 0.0100 | Loss: 713892.5000
Episode 73250 | Reward: -13.300 | Epsilon: 0.0100 | Loss: 669080.1875
Episode 73300 | Reward: -10.613 | Epsilon: 0.0100 | Loss: 539689.9375
Episode 73350 | Reward:  -9.600 | Epsilon: 0.0100 | Loss: 673401.8750
Episode 73400 | Reward: -15.039 | Epsilon: 0.0100 | Loss: 508598.6250
Episode 73450 | Reward: -12.722 | Epsilon: 0.0100 | Loss: 795940.5000
Episode 73500 | Reward:  -8.954 | Epsilon: 0.0100 | Loss: 656043.1875
Episode 73550 | Reward: -12.269 | Epsilon: 0.0100 | Loss: 708988.5000
Episode 73600 | Reward: -12.521 | Epsilon: 0.0100 | Loss: 670982.3750
Episode 73650 | Reward: -12.038 | Epsilon: 0.0100 | Loss: 666247.6250
Episode 73700 | Reward: -13.663 | Epsilon: 0.0100 | Loss: 598932.5000
Episode 73750 | Reward: -10.220 | Epsilon: 0.0100 | Loss: 529180.6250
Episode 73800 | Reward: -13.457 | Epsilon: 0.0100 | Loss: 648413.8125
Episode 73850 | Reward: -13.249 | Epsilon: 0.0100 | Loss: 637920.3125
Episode 73900 | Reward: -11.727 | Epsilon: 0.0100 | Loss: 542909.5000
Episode 73950 | Reward:  -8.266 | Epsilon: 0.0100 | Loss: 416607.8438
Episode 74000 | Reward: -11.009 | Epsilon: 0.0100 | Loss: 656465.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:00).dict
Episode 74050 | Reward: -15.000 | Epsilon: 0.0100 | Loss: 567606.3750
Episode 74100 | Reward: -12.700 | Epsilon: 0.0100 | Loss: 518345.6875
Episode 74150 | Reward: -12.315 | Epsilon: 0.0100 | Loss: 644262.8125
Episode 74200 | Reward: -12.030 | Epsilon: 0.0100 | Loss: 693002.6250
Episode 74250 | Reward: -11.215 | Epsilon: 0.0100 | Loss: 626209.1250
Episode 74300 | Reward: -12.511 | Epsilon: 0.0100 | Loss: 588252.0000
Episode 74350 | Reward: -10.474 | Epsilon: 0.0100 | Loss: 456599.5938
Episode 74400 | Reward: -10.119 | Epsilon: 0.0100 | Loss: 414878.2188
Episode 74450 | Reward: -12.679 | Epsilon: 0.0100 | Loss: 495165.7812
Episode 74500 | Reward: -10.930 | Epsilon: 0.0100 | Loss: 437275.0938
Episode 74550 | Reward: -11.500 | Epsilon: 0.0100 | Loss: 590608.6250
Episode 74600 | Reward:  -9.420 | Epsilon: 0.0100 | Loss: 596574.0000
Episode 74650 | Reward: -12.460 | Epsilon: 0.0100 | Loss: 622419.0625
Episode 74700 | Reward:  -8.578 | Epsilon: 0.0100 | Loss: 589614.8750
Episode 74750 | Reward: -17.279 | Epsilon: 0.0100 | Loss: 473354.9375
Episode 74800 | Reward: -10.861 | Epsilon: 0.0100 | Loss: 533559.0000
Episode 74850 | Reward:  -7.788 | Epsilon: 0.0100 | Loss: 462807.0938
Episode 74900 | Reward: -12.535 | Epsilon: 0.0100 | Loss: 439719.1562
Episode 74950 | Reward: -11.420 | Epsilon: 0.0100 | Loss: 538983.7500
Episode 75000 | Reward: -11.621 | Epsilon: 0.0100 | Loss: 484495.7812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:04).dict
Episode 75050 | Reward:  -8.850 | Epsilon: 0.0100 | Loss: 534598.0000
Episode 75100 | Reward: -12.987 | Epsilon: 0.0100 | Loss: 494165.6250
Episode 75150 | Reward: -10.438 | Epsilon: 0.0100 | Loss: 398742.9375
Episode 75200 | Reward: -10.614 | Epsilon: 0.0100 | Loss: 466026.2812
Episode 75250 | Reward: -10.742 | Epsilon: 0.0100 | Loss: 513974.4688
Episode 75300 | Reward: -13.072 | Epsilon: 0.0100 | Loss: 646055.8750
Episode 75350 | Reward: -12.020 | Epsilon: 0.0100 | Loss: 494025.8750
Episode 75400 | Reward: -12.653 | Epsilon: 0.0100 | Loss: 561141.9375
Episode 75450 | Reward:  -7.999 | Epsilon: 0.0100 | Loss: 413326.5000
Episode 75500 | Reward:  -6.867 | Epsilon: 0.0100 | Loss: 517532.2812
Episode 75550 | Reward: -13.753 | Epsilon: 0.0100 | Loss: 499761.8125
Episode 75600 | Reward:  -7.383 | Epsilon: 0.0100 | Loss: 441456.5938
Episode 75650 | Reward: -15.137 | Epsilon: 0.0100 | Loss: 495075.9688
Episode 75700 | Reward: -15.466 | Epsilon: 0.0100 | Loss: 552917.6250
Episode 75750 | Reward: -14.989 | Epsilon: 0.0100 | Loss: 409345.5312
Episode 75800 | Reward: -12.915 | Epsilon: 0.0100 | Loss: 451897.5625
Episode 75850 | Reward:  -9.366 | Epsilon: 0.0100 | Loss: 413242.9062
Episode 75900 | Reward: -13.305 | Epsilon: 0.0100 | Loss: 476104.5312
Episode 75950 | Reward:  -9.359 | Epsilon: 0.0100 | Loss: 686990.0000
Episode 76000 | Reward: -13.551 | Epsilon: 0.0100 | Loss: 461353.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:08).dict
Episode 76050 | Reward: -13.933 | Epsilon: 0.0100 | Loss: 550879.0625
Episode 76100 | Reward: -14.400 | Epsilon: 0.0100 | Loss: 496490.3438
Episode 76150 | Reward: -14.927 | Epsilon: 0.0100 | Loss: 435120.3750
Episode 76200 | Reward: -12.784 | Epsilon: 0.0100 | Loss: 412621.3125
Episode 76250 | Reward: -10.346 | Epsilon: 0.0100 | Loss: 508171.3125
Episode 76300 | Reward: -10.144 | Epsilon: 0.0100 | Loss: 470726.4375
Episode 76350 | Reward: -10.242 | Epsilon: 0.0100 | Loss: 530311.0625
Episode 76400 | Reward: -13.394 | Epsilon: 0.0100 | Loss: 545991.3125
Episode 76450 | Reward: -16.361 | Epsilon: 0.0100 | Loss: 413182.8438
Episode 76500 | Reward: -14.869 | Epsilon: 0.0100 | Loss: 297426.9062
Episode 76550 | Reward: -13.247 | Epsilon: 0.0100 | Loss: 453944.8438
Episode 76600 | Reward: -13.692 | Epsilon: 0.0100 | Loss: 591870.2500
Episode 76650 | Reward: -12.754 | Epsilon: 0.0100 | Loss: 540661.3750
Episode 76700 | Reward: -14.027 | Epsilon: 0.0100 | Loss: 441743.6875
Episode 76750 | Reward: -12.741 | Epsilon: 0.0100 | Loss: 499096.7188
Episode 76800 | Reward: -11.652 | Epsilon: 0.0100 | Loss: 456650.7188
Episode 76850 | Reward:  -8.168 | Epsilon: 0.0100 | Loss: 487656.7500
Episode 76900 | Reward:  -9.685 | Epsilon: 0.0100 | Loss: 387745.0938
Episode 76950 | Reward: -10.347 | Epsilon: 0.0100 | Loss: 450520.2500
Episode 77000 | Reward: -12.484 | Epsilon: 0.0100 | Loss: 550428.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:12).dict
Episode 77050 | Reward: -15.067 | Epsilon: 0.0100 | Loss: 437296.6250
Episode 77100 | Reward:  -9.150 | Epsilon: 0.0100 | Loss: 408457.9375
Episode 77150 | Reward: -16.832 | Epsilon: 0.0100 | Loss: 511802.6562
Episode 77200 | Reward: -17.010 | Epsilon: 0.0100 | Loss: 492255.2188
Episode 77250 | Reward: -13.822 | Epsilon: 0.0100 | Loss: 498127.8750
Episode 77300 | Reward: -10.758 | Epsilon: 0.0100 | Loss: 429136.6875
Episode 77350 | Reward: -17.021 | Epsilon: 0.0100 | Loss: 578866.6250
Episode 77400 | Reward: -17.003 | Epsilon: 0.0100 | Loss: 424854.6250
Episode 77450 | Reward: -16.307 | Epsilon: 0.0100 | Loss: 445049.0938
Episode 77500 | Reward: -15.467 | Epsilon: 0.0100 | Loss: 652386.5000
Episode 77550 | Reward: -18.918 | Epsilon: 0.0100 | Loss: 531931.6875
Episode 77600 | Reward: -13.941 | Epsilon: 0.0100 | Loss: 442418.8438
Episode 77650 | Reward: -11.036 | Epsilon: 0.0100 | Loss: 421371.8750
Episode 77700 | Reward: -14.276 | Epsilon: 0.0100 | Loss: 383052.0625
Episode 77750 | Reward: -12.524 | Epsilon: 0.0100 | Loss: 454407.2500
Episode 77800 | Reward: -12.111 | Epsilon: 0.0100 | Loss: 537446.3750
Episode 77850 | Reward: -17.554 | Epsilon: 0.0100 | Loss: 508083.0000
Episode 77900 | Reward: -11.300 | Epsilon: 0.0100 | Loss: 524956.4375
Episode 77950 | Reward: -14.276 | Epsilon: 0.0100 | Loss: 589889.6875
Episode 78000 | Reward: -10.487 | Epsilon: 0.0100 | Loss: 620391.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:16).dict
Episode 78050 | Reward: -11.768 | Epsilon: 0.0100 | Loss: 557882.3750
Episode 78100 | Reward: -15.821 | Epsilon: 0.0100 | Loss: 465573.1875
Episode 78150 | Reward: -16.667 | Epsilon: 0.0100 | Loss: 622402.4375
Episode 78200 | Reward: -18.152 | Epsilon: 0.0100 | Loss: 732571.1250
Episode 78250 | Reward: -14.430 | Epsilon: 0.0100 | Loss: 483125.3125
Episode 78300 | Reward: -11.856 | Epsilon: 0.0100 | Loss: 579184.3125
Episode 78350 | Reward: -13.637 | Epsilon: 0.0100 | Loss: 543749.1250
Episode 78400 | Reward: -12.787 | Epsilon: 0.0100 | Loss: 538198.5000
Episode 78450 | Reward: -12.219 | Epsilon: 0.0100 | Loss: 506398.0000
Episode 78500 | Reward: -11.111 | Epsilon: 0.0100 | Loss: 555494.5625
Episode 78550 | Reward: -12.587 | Epsilon: 0.0100 | Loss: 622215.3125
Episode 78600 | Reward: -12.335 | Epsilon: 0.0100 | Loss: 563624.6250
Episode 78650 | Reward: -10.094 | Epsilon: 0.0100 | Loss: 615519.8750
Episode 78700 | Reward: -13.270 | Epsilon: 0.0100 | Loss: 598603.0000
Episode 78750 | Reward:  -6.428 | Epsilon: 0.0100 | Loss: 393374.4375
Episode 78800 | Reward: -11.230 | Epsilon: 0.0100 | Loss: 655085.5625
Episode 78850 | Reward: -13.126 | Epsilon: 0.0100 | Loss: 508317.4375
Episode 78900 | Reward: -16.248 | Epsilon: 0.0100 | Loss: 532058.0000
Episode 78950 | Reward: -15.382 | Epsilon: 0.0100 | Loss: 672846.8750
Episode 79000 | Reward: -12.150 | Epsilon: 0.0100 | Loss: 631264.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:20).dict
Episode 79050 | Reward: -14.316 | Epsilon: 0.0100 | Loss: 526347.1250
Episode 79100 | Reward: -12.886 | Epsilon: 0.0100 | Loss: 560735.5625
Episode 79150 | Reward: -10.941 | Epsilon: 0.0100 | Loss: 487056.2500
Episode 79200 | Reward: -10.721 | Epsilon: 0.0100 | Loss: 636771.3750
Episode 79250 | Reward: -13.243 | Epsilon: 0.0100 | Loss: 481106.2500
Episode 79300 | Reward: -11.683 | Epsilon: 0.0100 | Loss: 723306.6875
Episode 79350 | Reward:  -9.950 | Epsilon: 0.0100 | Loss: 530081.2500
Episode 79400 | Reward: -13.475 | Epsilon: 0.0100 | Loss: 515843.8125
Episode 79450 | Reward: -11.076 | Epsilon: 0.0100 | Loss: 591796.3750
Episode 79500 | Reward: -12.259 | Epsilon: 0.0100 | Loss: 423872.5000
Episode 79550 | Reward: -15.870 | Epsilon: 0.0100 | Loss: 539156.6250
Episode 79600 | Reward: -14.335 | Epsilon: 0.0100 | Loss: 607082.5000
Episode 79650 | Reward: -14.996 | Epsilon: 0.0100 | Loss: 472635.9062
Episode 79700 | Reward: -14.339 | Epsilon: 0.0100 | Loss: 645790.3125
Episode 79750 | Reward: -13.383 | Epsilon: 0.0100 | Loss: 625512.9375
Episode 79800 | Reward: -13.233 | Epsilon: 0.0100 | Loss: 532962.6875
Episode 79850 | Reward: -13.863 | Epsilon: 0.0100 | Loss: 531051.6875
Episode 79900 | Reward: -13.772 | Epsilon: 0.0100 | Loss: 770301.3125
Episode 79950 | Reward:  -8.621 | Epsilon: 0.0100 | Loss: 619064.0625
Episode 80000 | Reward: -12.507 | Epsilon: 0.0100 | Loss: 542839.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:24).dict
Episode 80050 | Reward: -15.375 | Epsilon: 0.0100 | Loss: 539225.3750
Episode 80100 | Reward: -15.339 | Epsilon: 0.0100 | Loss: 571970.4375
Episode 80150 | Reward:  -9.033 | Epsilon: 0.0100 | Loss: 700243.8125
Episode 80200 | Reward: -13.353 | Epsilon: 0.0100 | Loss: 672367.9375
Episode 80250 | Reward: -11.905 | Epsilon: 0.0100 | Loss: 553606.3750
Episode 80300 | Reward: -10.529 | Epsilon: 0.0100 | Loss: 613216.8750
Episode 80350 | Reward: -13.646 | Epsilon: 0.0100 | Loss: 419432.6562
Episode 80400 | Reward: -12.295 | Epsilon: 0.0100 | Loss: 632326.8750
Episode 80450 | Reward: -16.049 | Epsilon: 0.0100 | Loss: 615538.3750
Episode 80500 | Reward: -14.350 | Epsilon: 0.0100 | Loss: 504523.1250
Episode 80550 | Reward: -13.337 | Epsilon: 0.0100 | Loss: 624838.0000
Episode 80600 | Reward: -11.806 | Epsilon: 0.0100 | Loss: 651573.4375
Episode 80650 | Reward: -13.544 | Epsilon: 0.0100 | Loss: 522107.3750
Episode 80700 | Reward: -11.803 | Epsilon: 0.0100 | Loss: 657906.9375
Episode 80750 | Reward:  -9.902 | Epsilon: 0.0100 | Loss: 756075.1875
Episode 80800 | Reward: -12.843 | Epsilon: 0.0100 | Loss: 575236.4375
Episode 80850 | Reward: -13.845 | Epsilon: 0.0100 | Loss: 521954.2188
Episode 80900 | Reward: -10.246 | Epsilon: 0.0100 | Loss: 552651.1250
Episode 80950 | Reward: -10.375 | Epsilon: 0.0100 | Loss: 619705.3750
Episode 81000 | Reward: -11.068 | Epsilon: 0.0100 | Loss: 540519.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:28).dict
Episode 81050 | Reward:  -7.300 | Epsilon: 0.0100 | Loss: 617326.1875
Episode 81100 | Reward: -10.611 | Epsilon: 0.0100 | Loss: 619296.0625
Episode 81150 | Reward: -13.771 | Epsilon: 0.0100 | Loss: 588432.3125
Episode 81200 | Reward: -10.392 | Epsilon: 0.0100 | Loss: 520632.8125
Episode 81250 | Reward: -11.120 | Epsilon: 0.0100 | Loss: 486850.0000
Episode 81300 | Reward:  -7.027 | Epsilon: 0.0100 | Loss: 537261.9375
Episode 81350 | Reward:  -9.855 | Epsilon: 0.0100 | Loss: 714355.8750
Episode 81400 | Reward: -12.354 | Epsilon: 0.0100 | Loss: 703640.8125
Episode 81450 | Reward: -12.430 | Epsilon: 0.0100 | Loss: 600657.6875
Episode 81500 | Reward: -10.850 | Epsilon: 0.0100 | Loss: 514961.8125
Episode 81550 | Reward: -10.075 | Epsilon: 0.0100 | Loss: 609180.2500
Episode 81600 | Reward:  -8.158 | Epsilon: 0.0100 | Loss: 537468.6250
Episode 81650 | Reward:  -9.318 | Epsilon: 0.0100 | Loss: 540978.4375
Episode 81700 | Reward: -12.533 | Epsilon: 0.0100 | Loss: 409194.8750
Episode 81750 | Reward: -14.440 | Epsilon: 0.0100 | Loss: 457904.4062
Episode 81800 | Reward: -11.690 | Epsilon: 0.0100 | Loss: 472694.3125
Episode 81850 | Reward: -10.980 | Epsilon: 0.0100 | Loss: 394143.3750
Episode 81900 | Reward:  -9.998 | Epsilon: 0.0100 | Loss: 588921.3750
Episode 81950 | Reward: -12.611 | Epsilon: 0.0100 | Loss: 427046.3125
Episode 82000 | Reward:  -9.350 | Epsilon: 0.0100 | Loss: 477462.1562
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:32).dict
Episode 82050 | Reward: -10.187 | Epsilon: 0.0100 | Loss: 484322.5000
Episode 82100 | Reward:  -9.827 | Epsilon: 0.0100 | Loss: 539484.1250
Episode 82150 | Reward: -12.478 | Epsilon: 0.0100 | Loss: 748265.5625
Episode 82200 | Reward:  -9.872 | Epsilon: 0.0100 | Loss: 388296.4688
Episode 82250 | Reward: -13.917 | Epsilon: 0.0100 | Loss: 432058.5938
Episode 82300 | Reward: -17.096 | Epsilon: 0.0100 | Loss: 448971.9375
Episode 82350 | Reward: -12.046 | Epsilon: 0.0100 | Loss: 468694.3125
Episode 82400 | Reward: -12.835 | Epsilon: 0.0100 | Loss: 508554.3125
Episode 82450 | Reward: -10.982 | Epsilon: 0.0100 | Loss: 477604.4062
Episode 82500 | Reward: -17.676 | Epsilon: 0.0100 | Loss: 485653.4375
Episode 82550 | Reward: -15.922 | Epsilon: 0.0100 | Loss: 503554.6250
Episode 82600 | Reward: -14.212 | Epsilon: 0.0100 | Loss: 531009.5000
Episode 82650 | Reward: -12.394 | Epsilon: 0.0100 | Loss: 530395.3125
Episode 82700 | Reward:  -9.904 | Epsilon: 0.0100 | Loss: 482477.2188
Episode 82750 | Reward: -14.879 | Epsilon: 0.0100 | Loss: 412194.2812
Episode 82800 | Reward: -12.983 | Epsilon: 0.0100 | Loss: 457097.4375
Episode 82850 | Reward: -11.380 | Epsilon: 0.0100 | Loss: 541823.1250
Episode 82900 | Reward: -13.505 | Epsilon: 0.0100 | Loss: 576116.0000
Episode 82950 | Reward: -11.528 | Epsilon: 0.0100 | Loss: 500523.7500
Episode 83000 | Reward: -15.578 | Epsilon: 0.0100 | Loss: 448647.7188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:36).dict
Episode 83050 | Reward: -12.403 | Epsilon: 0.0100 | Loss: 383409.0625
Episode 83100 | Reward: -13.854 | Epsilon: 0.0100 | Loss: 580869.5000
Episode 83150 | Reward: -10.404 | Epsilon: 0.0100 | Loss: 432419.8125
Episode 83200 | Reward: -12.546 | Epsilon: 0.0100 | Loss: 437355.9062
Episode 83250 | Reward:  -8.327 | Epsilon: 0.0100 | Loss: 525909.0625
Episode 83300 | Reward: -13.184 | Epsilon: 0.0100 | Loss: 441860.0312
Episode 83350 | Reward:  -9.575 | Epsilon: 0.0100 | Loss: 333057.8750
Episode 83400 | Reward: -14.729 | Epsilon: 0.0100 | Loss: 398398.2500
Episode 83450 | Reward: -16.642 | Epsilon: 0.0100 | Loss: 540032.8125
Episode 83500 | Reward: -16.867 | Epsilon: 0.0100 | Loss: 404646.7812
Episode 83550 | Reward: -14.539 | Epsilon: 0.0100 | Loss: 420861.9688
Episode 83600 | Reward: -15.134 | Epsilon: 0.0100 | Loss: 574364.9375
Episode 83650 | Reward: -15.248 | Epsilon: 0.0100 | Loss: 399749.6875
Episode 83700 | Reward: -10.533 | Epsilon: 0.0100 | Loss: 459322.0625
Episode 83750 | Reward:  -9.526 | Epsilon: 0.0100 | Loss: 500486.8750
Episode 83800 | Reward: -13.079 | Epsilon: 0.0100 | Loss: 479104.7188
Episode 83850 | Reward: -13.382 | Epsilon: 0.0100 | Loss: 399185.8125
Episode 83900 | Reward: -13.233 | Epsilon: 0.0100 | Loss: 554943.2500
Episode 83950 | Reward: -10.869 | Epsilon: 0.0100 | Loss: 443262.9375
Episode 84000 | Reward: -10.108 | Epsilon: 0.0100 | Loss: 406800.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:40).dict
Episode 84050 | Reward: -10.754 | Epsilon: 0.0100 | Loss: 540095.9375
Episode 84100 | Reward: -14.466 | Epsilon: 0.0100 | Loss: 399120.3125
Episode 84150 | Reward: -17.492 | Epsilon: 0.0100 | Loss: 489406.1250
Episode 84200 | Reward: -14.728 | Epsilon: 0.0100 | Loss: 445886.1250
Episode 84250 | Reward: -11.179 | Epsilon: 0.0100 | Loss: 408636.0312
Episode 84300 | Reward: -15.475 | Epsilon: 0.0100 | Loss: 455686.5312
Episode 84350 | Reward: -14.483 | Epsilon: 0.0100 | Loss: 623616.8750
Episode 84400 | Reward: -13.941 | Epsilon: 0.0100 | Loss: 501736.8125
Episode 84450 | Reward: -16.957 | Epsilon: 0.0100 | Loss: 525334.5000
Episode 84500 | Reward: -12.883 | Epsilon: 0.0100 | Loss: 578317.7500
Episode 84550 | Reward: -10.829 | Epsilon: 0.0100 | Loss: 349582.8750
Episode 84600 | Reward: -13.963 | Epsilon: 0.0100 | Loss: 448471.6250
Episode 84650 | Reward: -11.833 | Epsilon: 0.0100 | Loss: 489889.6250
Episode 84700 | Reward: -10.565 | Epsilon: 0.0100 | Loss: 487628.0000
Episode 84750 | Reward:  -8.373 | Epsilon: 0.0100 | Loss: 614753.5000
Episode 84800 | Reward:  -9.545 | Epsilon: 0.0100 | Loss: 537052.9375
Episode 84850 | Reward: -12.436 | Epsilon: 0.0100 | Loss: 488470.9062
Episode 84900 | Reward: -13.827 | Epsilon: 0.0100 | Loss: 485524.8438
Episode 84950 | Reward: -13.574 | Epsilon: 0.0100 | Loss: 559686.3750
Episode 85000 | Reward: -13.273 | Epsilon: 0.0100 | Loss: 604940.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:44).dict
Episode 85050 | Reward: -14.153 | Epsilon: 0.0100 | Loss: 508731.2188
Episode 85100 | Reward: -10.714 | Epsilon: 0.0100 | Loss: 493416.6875
Episode 85150 | Reward:  -7.472 | Epsilon: 0.0100 | Loss: 465809.2812
Episode 85200 | Reward: -12.501 | Epsilon: 0.0100 | Loss: 391641.6875
Episode 85250 | Reward: -12.837 | Epsilon: 0.0100 | Loss: 371414.1250
Episode 85300 | Reward: -12.416 | Epsilon: 0.0100 | Loss: 499847.0312
Episode 85350 | Reward: -14.166 | Epsilon: 0.0100 | Loss: 491671.1250
Episode 85400 | Reward: -17.882 | Epsilon: 0.0100 | Loss: 392837.8125
Episode 85450 | Reward: -12.959 | Epsilon: 0.0100 | Loss: 440104.0938
Episode 85500 | Reward: -16.861 | Epsilon: 0.0100 | Loss: 660599.0625
Episode 85550 | Reward: -10.137 | Epsilon: 0.0100 | Loss: 618501.9375
Episode 85600 | Reward: -15.472 | Epsilon: 0.0100 | Loss: 463428.1875
Episode 85650 | Reward: -17.065 | Epsilon: 0.0100 | Loss: 574857.0000
Episode 85700 | Reward: -16.064 | Epsilon: 0.0100 | Loss: 605577.2500
Episode 85750 | Reward: -11.340 | Epsilon: 0.0100 | Loss: 566345.8125
Episode 85800 | Reward: -14.358 | Epsilon: 0.0100 | Loss: 535545.0000
Episode 85850 | Reward: -15.129 | Epsilon: 0.0100 | Loss: 579840.0625
Episode 85900 | Reward: -14.069 | Epsilon: 0.0100 | Loss: 605761.5625
Episode 85950 | Reward: -15.012 | Epsilon: 0.0100 | Loss: 592708.2500
Episode 86000 | Reward: -12.444 | Epsilon: 0.0100 | Loss: 461075.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:48).dict
Episode 86050 | Reward: -13.239 | Epsilon: 0.0100 | Loss: 578341.8125
Episode 86100 | Reward: -14.759 | Epsilon: 0.0100 | Loss: 492543.3125
Episode 86150 | Reward: -14.215 | Epsilon: 0.0100 | Loss: 523019.3125
Episode 86200 | Reward: -12.990 | Epsilon: 0.0100 | Loss: 441165.5625
Episode 86250 | Reward: -10.220 | Epsilon: 0.0100 | Loss: 538294.7500
Episode 86300 | Reward: -10.618 | Epsilon: 0.0100 | Loss: 497564.3125
Episode 86350 | Reward: -10.997 | Epsilon: 0.0100 | Loss: 539075.2500
Episode 86400 | Reward: -16.173 | Epsilon: 0.0100 | Loss: 549652.7500
Episode 86450 | Reward: -14.956 | Epsilon: 0.0100 | Loss: 356293.6875
Episode 86500 | Reward: -16.213 | Epsilon: 0.0100 | Loss: 492703.3125
Episode 86550 | Reward: -15.594 | Epsilon: 0.0100 | Loss: 449517.7812
Episode 86600 | Reward: -12.466 | Epsilon: 0.0100 | Loss: 510523.2188
Episode 86650 | Reward: -13.371 | Epsilon: 0.0100 | Loss: 375863.2500
Episode 86700 | Reward: -14.003 | Epsilon: 0.0100 | Loss: 534165.1250
Episode 86750 | Reward: -13.973 | Epsilon: 0.0100 | Loss: 404034.0625
Episode 86800 | Reward: -11.995 | Epsilon: 0.0100 | Loss: 502576.1562
Episode 86850 | Reward: -14.426 | Epsilon: 0.0100 | Loss: 504276.1250
Episode 86900 | Reward: -14.144 | Epsilon: 0.0100 | Loss: 424101.8438
Episode 86950 | Reward: -12.400 | Epsilon: 0.0100 | Loss: 603909.6250
Episode 87000 | Reward: -13.236 | Epsilon: 0.0100 | Loss: 493630.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:52).dict
Episode 87050 | Reward: -14.893 | Epsilon: 0.0100 | Loss: 672963.7500
Episode 87100 | Reward: -14.706 | Epsilon: 0.0100 | Loss: 414510.8125
Episode 87150 | Reward: -15.234 | Epsilon: 0.0100 | Loss: 486531.9375
Episode 87200 | Reward:  -7.579 | Epsilon: 0.0100 | Loss: 418448.3125
Episode 87250 | Reward: -10.305 | Epsilon: 0.0100 | Loss: 605369.3125
Episode 87300 | Reward: -12.204 | Epsilon: 0.0100 | Loss: 633913.1250
Episode 87350 | Reward: -12.014 | Epsilon: 0.0100 | Loss: 394129.7812
Episode 87400 | Reward: -12.319 | Epsilon: 0.0100 | Loss: 386045.6875
Episode 87450 | Reward: -15.484 | Epsilon: 0.0100 | Loss: 552837.8750
Episode 87500 | Reward: -11.649 | Epsilon: 0.0100 | Loss: 604487.7500
Episode 87550 | Reward: -13.610 | Epsilon: 0.0100 | Loss: 635843.2500
Episode 87600 | Reward: -13.728 | Epsilon: 0.0100 | Loss: 361627.4688
Episode 87650 | Reward: -12.374 | Epsilon: 0.0100 | Loss: 503405.9375
Episode 87700 | Reward: -10.097 | Epsilon: 0.0100 | Loss: 475495.6562
Episode 87750 | Reward: -14.260 | Epsilon: 0.0100 | Loss: 397420.1875
Episode 87800 | Reward: -13.520 | Epsilon: 0.0100 | Loss: 503141.6562
Episode 87850 | Reward: -12.782 | Epsilon: 0.0100 | Loss: 554734.5625
Episode 87900 | Reward: -12.274 | Epsilon: 0.0100 | Loss: 472270.4688
Episode 87950 | Reward: -13.306 | Epsilon: 0.0100 | Loss: 526001.5625
Episode 88000 | Reward: -13.295 | Epsilon: 0.0100 | Loss: 510639.2812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:56).dict
Episode 88050 | Reward:  -9.056 | Epsilon: 0.0100 | Loss: 585809.0000
Episode 88100 | Reward: -10.631 | Epsilon: 0.0100 | Loss: 518388.7812
Episode 88150 | Reward: -13.756 | Epsilon: 0.0100 | Loss: 623583.1875
Episode 88200 | Reward: -12.248 | Epsilon: 0.0100 | Loss: 410156.8125
Episode 88250 | Reward:  -8.446 | Epsilon: 0.0100 | Loss: 607139.5625
Episode 88300 | Reward: -11.033 | Epsilon: 0.0100 | Loss: 513561.8125
Episode 88350 | Reward: -10.434 | Epsilon: 0.0100 | Loss: 454243.3750
Episode 88400 | Reward: -11.408 | Epsilon: 0.0100 | Loss: 412435.2812
Episode 88450 | Reward:  -9.527 | Epsilon: 0.0100 | Loss: 600372.9375
Episode 88500 | Reward:  -9.287 | Epsilon: 0.0100 | Loss: 594233.4375
Episode 88550 | Reward: -11.013 | Epsilon: 0.0100 | Loss: 374787.6250
Episode 88600 | Reward: -12.449 | Epsilon: 0.0100 | Loss: 526477.4375
Episode 88650 | Reward:  -9.899 | Epsilon: 0.0100 | Loss: 508768.6875
Episode 88700 | Reward: -10.954 | Epsilon: 0.0100 | Loss: 452946.7188
Episode 88750 | Reward: -12.029 | Epsilon: 0.0100 | Loss: 606137.7500
Episode 88800 | Reward: -11.057 | Epsilon: 0.0100 | Loss: 437217.0625
Episode 88850 | Reward: -13.269 | Epsilon: 0.0100 | Loss: 565994.0000
Episode 88900 | Reward: -11.180 | Epsilon: 0.0100 | Loss: 369906.7812
Episode 88950 | Reward:  -9.819 | Epsilon: 0.0100 | Loss: 459856.3125
Episode 89000 | Reward: -10.624 | Epsilon: 0.0100 | Loss: 411050.4688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:00).dict
Episode 89050 | Reward: -12.813 | Epsilon: 0.0100 | Loss: 575245.3750
Episode 89100 | Reward: -13.927 | Epsilon: 0.0100 | Loss: 462397.7188
Episode 89150 | Reward:  -8.602 | Epsilon: 0.0100 | Loss: 503792.5625
Episode 89200 | Reward: -14.974 | Epsilon: 0.0100 | Loss: 537365.2500
Episode 89250 | Reward: -15.029 | Epsilon: 0.0100 | Loss: 463760.1250
Episode 89300 | Reward: -14.574 | Epsilon: 0.0100 | Loss: 396843.0625
Episode 89350 | Reward: -17.506 | Epsilon: 0.0100 | Loss: 426338.5312
Episode 89400 | Reward: -17.134 | Epsilon: 0.0100 | Loss: 409404.8750
Episode 89450 | Reward: -17.027 | Epsilon: 0.0100 | Loss: 343881.3125
Episode 89500 | Reward: -14.905 | Epsilon: 0.0100 | Loss: 431778.7812
Episode 89550 | Reward: -12.919 | Epsilon: 0.0100 | Loss: 397673.4062
Episode 89600 | Reward: -14.440 | Epsilon: 0.0100 | Loss: 509534.2812
Episode 89650 | Reward: -13.687 | Epsilon: 0.0100 | Loss: 403943.9375
Episode 89700 | Reward:  -9.478 | Epsilon: 0.0100 | Loss: 355606.3750
Episode 89750 | Reward: -14.462 | Epsilon: 0.0100 | Loss: 507983.1562
Episode 89800 | Reward: -12.922 | Epsilon: 0.0100 | Loss: 446897.4688
Episode 89850 | Reward: -12.298 | Epsilon: 0.0100 | Loss: 349800.5000
Episode 89900 | Reward: -11.827 | Epsilon: 0.0100 | Loss: 397530.0312
Episode 89950 | Reward: -14.152 | Epsilon: 0.0100 | Loss: 409946.4375
Episode 90000 | Reward: -11.648 | Epsilon: 0.0100 | Loss: 405351.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:04).dict
Episode 90050 | Reward: -11.420 | Epsilon: 0.0100 | Loss: 357248.4375
Episode 90100 | Reward: -10.830 | Epsilon: 0.0100 | Loss: 391171.5000
Episode 90150 | Reward: -11.446 | Epsilon: 0.0100 | Loss: 390526.3125
Episode 90200 | Reward: -11.426 | Epsilon: 0.0100 | Loss: 487759.1875
Episode 90250 | Reward: -13.254 | Epsilon: 0.0100 | Loss: 456900.4062
Episode 90300 | Reward: -14.460 | Epsilon: 0.0100 | Loss: 424449.9062
Episode 90350 | Reward:  -9.813 | Epsilon: 0.0100 | Loss: 455851.2500
Episode 90400 | Reward: -12.604 | Epsilon: 0.0100 | Loss: 434206.2500
Episode 90450 | Reward: -15.596 | Epsilon: 0.0100 | Loss: 433215.9062
Episode 90500 | Reward:  -8.367 | Epsilon: 0.0100 | Loss: 445144.1875
Episode 90550 | Reward:  -8.277 | Epsilon: 0.0100 | Loss: 429990.8750
Episode 90600 | Reward:  -7.984 | Epsilon: 0.0100 | Loss: 509192.8750
Episode 90650 | Reward: -14.016 | Epsilon: 0.0100 | Loss: 462090.3125
Episode 90700 | Reward: -11.126 | Epsilon: 0.0100 | Loss: 398107.8125
Episode 90750 | Reward:  -8.369 | Epsilon: 0.0100 | Loss: 380089.1250
Episode 90800 | Reward: -14.980 | Epsilon: 0.0100 | Loss: 477197.6562
Episode 90850 | Reward: -11.352 | Epsilon: 0.0100 | Loss: 471372.2500
Episode 90900 | Reward: -14.056 | Epsilon: 0.0100 | Loss: 414989.1250
Episode 90950 | Reward: -13.820 | Epsilon: 0.0100 | Loss: 474505.4062
Episode 91000 | Reward:  -9.151 | Epsilon: 0.0100 | Loss: 390118.5312
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:08).dict
Episode 91050 | Reward: -12.520 | Epsilon: 0.0100 | Loss: 454950.2500
Episode 91100 | Reward: -12.741 | Epsilon: 0.0100 | Loss: 506063.0000
Episode 91150 | Reward: -16.320 | Epsilon: 0.0100 | Loss: 447362.3438
Episode 91200 | Reward: -16.724 | Epsilon: 0.0100 | Loss: 479922.2500
Episode 91250 | Reward: -13.734 | Epsilon: 0.0100 | Loss: 548345.6875
Episode 91300 | Reward: -15.321 | Epsilon: 0.0100 | Loss: 379692.3125
Episode 91350 | Reward: -12.733 | Epsilon: 0.0100 | Loss: 515671.2812
Episode 91400 | Reward:  -8.992 | Epsilon: 0.0100 | Loss: 427510.6562
Episode 91450 | Reward:  -8.245 | Epsilon: 0.0100 | Loss: 390393.0000
Episode 91500 | Reward:  -8.685 | Epsilon: 0.0100 | Loss: 366555.0625
Episode 91550 | Reward: -12.163 | Epsilon: 0.0100 | Loss: 429958.0625
Episode 91600 | Reward: -11.855 | Epsilon: 0.0100 | Loss: 393516.6250
Episode 91650 | Reward:  -9.909 | Epsilon: 0.0100 | Loss: 463713.0938
Episode 91700 | Reward:  -9.884 | Epsilon: 0.0100 | Loss: 498683.1562
Episode 91750 | Reward: -14.998 | Epsilon: 0.0100 | Loss: 417280.1562
Episode 91800 | Reward: -10.834 | Epsilon: 0.0100 | Loss: 332121.0625
Episode 91850 | Reward:  -8.754 | Epsilon: 0.0100 | Loss: 390616.4688
Episode 91900 | Reward:  -9.538 | Epsilon: 0.0100 | Loss: 327746.2188
Episode 91950 | Reward: -11.737 | Epsilon: 0.0100 | Loss: 410735.5312
Episode 92000 | Reward: -10.388 | Epsilon: 0.0100 | Loss: 295051.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:12).dict
Episode 92050 | Reward: -11.226 | Epsilon: 0.0100 | Loss: 459986.3750
Episode 92100 | Reward: -12.855 | Epsilon: 0.0100 | Loss: 383446.1250
Episode 92150 | Reward: -10.051 | Epsilon: 0.0100 | Loss: 476094.0000
Episode 92200 | Reward: -10.531 | Epsilon: 0.0100 | Loss: 382137.9688
Episode 92250 | Reward: -10.713 | Epsilon: 0.0100 | Loss: 333000.3125
Episode 92300 | Reward: -12.173 | Epsilon: 0.0100 | Loss: 372958.4375
Episode 92350 | Reward: -14.341 | Epsilon: 0.0100 | Loss: 466321.2812
Episode 92400 | Reward: -11.535 | Epsilon: 0.0100 | Loss: 230770.4219
Episode 92450 | Reward: -15.629 | Epsilon: 0.0100 | Loss: 466854.5000
Episode 92500 | Reward: -15.986 | Epsilon: 0.0100 | Loss: 371974.6562
Episode 92550 | Reward: -12.970 | Epsilon: 0.0100 | Loss: 423603.1875
Episode 92600 | Reward: -13.099 | Epsilon: 0.0100 | Loss: 358512.9375
Episode 92650 | Reward: -12.692 | Epsilon: 0.0100 | Loss: 464491.5312
Episode 92700 | Reward: -14.322 | Epsilon: 0.0100 | Loss: 368032.9375
Episode 92750 | Reward: -13.032 | Epsilon: 0.0100 | Loss: 417824.0938
Episode 92800 | Reward: -12.545 | Epsilon: 0.0100 | Loss: 472928.3750
Episode 92850 | Reward: -11.712 | Epsilon: 0.0100 | Loss: 334970.4375
Episode 92900 | Reward: -11.415 | Epsilon: 0.0100 | Loss: 392256.3750
Episode 92950 | Reward: -10.734 | Epsilon: 0.0100 | Loss: 453267.7500
Episode 93000 | Reward: -11.124 | Epsilon: 0.0100 | Loss: 446627.9062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:16).dict
Episode 93050 | Reward: -13.267 | Epsilon: 0.0100 | Loss: 499876.0625
Episode 93100 | Reward:  -9.235 | Epsilon: 0.0100 | Loss: 387816.6875
Episode 93150 | Reward: -12.024 | Epsilon: 0.0100 | Loss: 417608.7812
Episode 93200 | Reward: -10.458 | Epsilon: 0.0100 | Loss: 483887.3438
Episode 93250 | Reward:  -8.709 | Epsilon: 0.0100 | Loss: 460116.9688
Episode 93300 | Reward:  -8.749 | Epsilon: 0.0100 | Loss: 517454.6875
Episode 93350 | Reward: -10.339 | Epsilon: 0.0100 | Loss: 400054.7188
Episode 93400 | Reward: -18.464 | Epsilon: 0.0100 | Loss: 614014.2500
Episode 93450 | Reward: -14.503 | Epsilon: 0.0100 | Loss: 462315.1875
Episode 93500 | Reward: -11.964 | Epsilon: 0.0100 | Loss: 464035.2500
Episode 93550 | Reward:  -9.075 | Epsilon: 0.0100 | Loss: 433985.7812
Episode 93600 | Reward: -12.819 | Epsilon: 0.0100 | Loss: 471097.9688
Episode 93650 | Reward: -10.934 | Epsilon: 0.0100 | Loss: 502841.5938
Episode 93700 | Reward:  -8.199 | Epsilon: 0.0100 | Loss: 411426.2188
Episode 93750 | Reward:  -8.723 | Epsilon: 0.0100 | Loss: 341710.3125
Episode 93800 | Reward: -12.288 | Epsilon: 0.0100 | Loss: 423475.3125
Episode 93850 | Reward: -14.048 | Epsilon: 0.0100 | Loss: 286723.4062
Episode 93900 | Reward: -15.551 | Epsilon: 0.0100 | Loss: 318465.5625
Episode 93950 | Reward: -14.778 | Epsilon: 0.0100 | Loss: 453737.0938
Episode 94000 | Reward: -11.358 | Epsilon: 0.0100 | Loss: 458205.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:20).dict
Episode 94050 | Reward: -12.867 | Epsilon: 0.0100 | Loss: 336876.5938
Episode 94100 | Reward: -12.161 | Epsilon: 0.0100 | Loss: 359335.4688
Episode 94150 | Reward: -16.761 | Epsilon: 0.0100 | Loss: 493211.9062
Episode 94200 | Reward: -11.783 | Epsilon: 0.0100 | Loss: 381463.9688
Episode 94250 | Reward: -14.664 | Epsilon: 0.0100 | Loss: 378087.8125
Episode 94300 | Reward: -15.525 | Epsilon: 0.0100 | Loss: 435900.9062
Episode 94350 | Reward: -10.559 | Epsilon: 0.0100 | Loss: 472273.3750
Episode 94400 | Reward: -13.288 | Epsilon: 0.0100 | Loss: 470636.9375
Episode 94450 | Reward: -16.461 | Epsilon: 0.0100 | Loss: 450026.5938
Episode 94500 | Reward: -14.423 | Epsilon: 0.0100 | Loss: 411887.8125
Episode 94550 | Reward: -12.476 | Epsilon: 0.0100 | Loss: 369010.5000
Episode 94600 | Reward:  -8.789 | Epsilon: 0.0100 | Loss: 333390.8125
Episode 94650 | Reward: -10.564 | Epsilon: 0.0100 | Loss: 372831.0000
Episode 94700 | Reward: -12.754 | Epsilon: 0.0100 | Loss: 429812.4688
Episode 94750 | Reward: -13.388 | Epsilon: 0.0100 | Loss: 421430.6562
Episode 94800 | Reward: -14.237 | Epsilon: 0.0100 | Loss: 461271.5938
Episode 94850 | Reward: -12.584 | Epsilon: 0.0100 | Loss: 406046.7500
Episode 94900 | Reward: -11.984 | Epsilon: 0.0100 | Loss: 474866.1875
Episode 94950 | Reward:  -7.887 | Epsilon: 0.0100 | Loss: 443907.4688
Episode 95000 | Reward: -11.156 | Epsilon: 0.0100 | Loss: 536109.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:24).dict
Episode 95050 | Reward: -12.677 | Epsilon: 0.0100 | Loss: 364866.0938
Episode 95100 | Reward: -12.681 | Epsilon: 0.0100 | Loss: 371350.6875
Episode 95150 | Reward: -14.609 | Epsilon: 0.0100 | Loss: 449965.5625
Episode 95200 | Reward: -13.738 | Epsilon: 0.0100 | Loss: 311924.1875
Episode 95250 | Reward: -13.892 | Epsilon: 0.0100 | Loss: 450139.5625
Episode 95300 | Reward: -11.517 | Epsilon: 0.0100 | Loss: 330615.3438
Episode 95350 | Reward: -11.174 | Epsilon: 0.0100 | Loss: 344139.0000
Episode 95400 | Reward: -13.356 | Epsilon: 0.0100 | Loss: 358722.3750
Episode 95450 | Reward: -12.282 | Epsilon: 0.0100 | Loss: 420346.9375
Episode 95500 | Reward: -12.829 | Epsilon: 0.0100 | Loss: 354322.6875
Episode 95550 | Reward: -10.210 | Epsilon: 0.0100 | Loss: 448609.7188
Episode 95600 | Reward: -12.578 | Epsilon: 0.0100 | Loss: 411327.3438
Episode 95650 | Reward: -14.880 | Epsilon: 0.0100 | Loss: 370283.4062
Episode 95700 | Reward: -12.325 | Epsilon: 0.0100 | Loss: 375769.3438
Episode 95750 | Reward:  -6.358 | Epsilon: 0.0100 | Loss: 388321.5625
Episode 95800 | Reward:  -9.442 | Epsilon: 0.0100 | Loss: 350115.4375
Episode 95850 | Reward: -14.659 | Epsilon: 0.0100 | Loss: 501456.8750
Episode 95900 | Reward: -14.349 | Epsilon: 0.0100 | Loss: 359620.4688
Episode 95950 | Reward:  -9.139 | Epsilon: 0.0100 | Loss: 408196.7188
Episode 96000 | Reward: -15.942 | Epsilon: 0.0100 | Loss: 352303.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:28).dict
Episode 96050 | Reward: -13.288 | Epsilon: 0.0100 | Loss: 416401.2500
Episode 96100 | Reward: -17.524 | Epsilon: 0.0100 | Loss: 299913.2500
Episode 96150 | Reward:  -9.959 | Epsilon: 0.0100 | Loss: 292551.9375
Episode 96200 | Reward: -12.563 | Epsilon: 0.0100 | Loss: 432148.0000
Episode 96250 | Reward: -14.232 | Epsilon: 0.0100 | Loss: 313960.2188
Episode 96300 | Reward: -14.454 | Epsilon: 0.0100 | Loss: 366136.9375
Episode 96350 | Reward: -13.849 | Epsilon: 0.0100 | Loss: 395525.2500
Episode 96400 | Reward: -11.142 | Epsilon: 0.0100 | Loss: 417906.8750
Episode 96450 | Reward:  -9.569 | Epsilon: 0.0100 | Loss: 343236.6250
Episode 96500 | Reward: -14.461 | Epsilon: 0.0100 | Loss: 357126.5938
Episode 96550 | Reward: -12.453 | Epsilon: 0.0100 | Loss: 369008.4062
Episode 96600 | Reward: -14.871 | Epsilon: 0.0100 | Loss: 454324.1875
Episode 96650 | Reward: -10.711 | Epsilon: 0.0100 | Loss: 387896.7500
Episode 96700 | Reward: -12.087 | Epsilon: 0.0100 | Loss: 359882.4062
Episode 96750 | Reward: -11.407 | Epsilon: 0.0100 | Loss: 388027.6875
Episode 96800 | Reward: -12.753 | Epsilon: 0.0100 | Loss: 334313.2812
Episode 96850 | Reward: -14.513 | Epsilon: 0.0100 | Loss: 318921.6875
Episode 96900 | Reward: -14.553 | Epsilon: 0.0100 | Loss: 438542.8438
Episode 96950 | Reward: -11.708 | Epsilon: 0.0100 | Loss: 313467.5938
Episode 97000 | Reward: -12.198 | Epsilon: 0.0100 | Loss: 379642.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:32).dict
Episode 97050 | Reward: -15.497 | Epsilon: 0.0100 | Loss: 358612.2500
Episode 97100 | Reward: -13.296 | Epsilon: 0.0100 | Loss: 378229.1250
Episode 97150 | Reward: -15.607 | Epsilon: 0.0100 | Loss: 472812.4375
Episode 97200 | Reward: -12.340 | Epsilon: 0.0100 | Loss: 406071.0000
Episode 97250 | Reward: -11.862 | Epsilon: 0.0100 | Loss: 340079.4375
Episode 97300 | Reward: -13.279 | Epsilon: 0.0100 | Loss: 397241.5938
Episode 97350 | Reward: -10.482 | Epsilon: 0.0100 | Loss: 302162.3750
Episode 97400 | Reward: -14.196 | Epsilon: 0.0100 | Loss: 372489.9688
Episode 97450 | Reward: -15.424 | Epsilon: 0.0100 | Loss: 393592.7500
Episode 97500 | Reward: -11.141 | Epsilon: 0.0100 | Loss: 365049.4375
Episode 97550 | Reward:  -8.152 | Epsilon: 0.0100 | Loss: 387302.3125
Episode 97600 | Reward: -12.652 | Epsilon: 0.0100 | Loss: 270255.5625
Episode 97650 | Reward: -14.849 | Epsilon: 0.0100 | Loss: 321879.1562
Episode 97700 | Reward: -11.598 | Epsilon: 0.0100 | Loss: 308952.3438
Episode 97750 | Reward: -13.310 | Epsilon: 0.0100 | Loss: 446750.2188
Episode 97800 | Reward: -11.356 | Epsilon: 0.0100 | Loss: 394488.6250
Episode 97850 | Reward:  -8.453 | Epsilon: 0.0100 | Loss: 334902.9062
Episode 97900 | Reward: -10.710 | Epsilon: 0.0100 | Loss: 295240.0312
Episode 97950 | Reward: -12.658 | Epsilon: 0.0100 | Loss: 360066.2188
Episode 98000 | Reward:  -7.531 | Epsilon: 0.0100 | Loss: 314999.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:36).dict
Episode 98050 | Reward: -13.904 | Epsilon: 0.0100 | Loss: 339086.1562
Episode 98100 | Reward: -14.248 | Epsilon: 0.0100 | Loss: 259850.5000
Episode 98150 | Reward:  -9.476 | Epsilon: 0.0100 | Loss: 347144.8750
Episode 98200 | Reward:  -9.362 | Epsilon: 0.0100 | Loss: 390979.0312
Episode 98250 | Reward: -14.127 | Epsilon: 0.0100 | Loss: 267407.4375
Episode 98300 | Reward: -11.384 | Epsilon: 0.0100 | Loss: 376736.7812
Episode 98350 | Reward: -14.055 | Epsilon: 0.0100 | Loss: 312125.9688
Episode 98400 | Reward: -12.377 | Epsilon: 0.0100 | Loss: 256210.5000
Episode 98450 | Reward: -12.251 | Epsilon: 0.0100 | Loss: 291188.8438
Episode 98500 | Reward: -15.206 | Epsilon: 0.0100 | Loss: 391010.2500
Episode 98550 | Reward: -14.778 | Epsilon: 0.0100 | Loss: 307890.2812
Episode 98600 | Reward: -13.280 | Epsilon: 0.0100 | Loss: 279907.6562
Episode 98650 | Reward: -11.361 | Epsilon: 0.0100 | Loss: 236286.0312
Episode 98700 | Reward: -11.993 | Epsilon: 0.0100 | Loss: 321415.6250
Episode 98750 | Reward:  -9.657 | Epsilon: 0.0100 | Loss: 248531.5781
Episode 98800 | Reward: -15.159 | Epsilon: 0.0100 | Loss: 259945.3594
Episode 98850 | Reward: -13.296 | Epsilon: 0.0100 | Loss: 316438.7812
Episode 98900 | Reward:  -5.898 | Epsilon: 0.0100 | Loss: 414001.9688
Episode 98950 | Reward:  -9.280 | Epsilon: 0.0100 | Loss: 347372.2188
Episode 99000 | Reward:  -9.436 | Epsilon: 0.0100 | Loss: 389570.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:40).dict
Episode 99050 | Reward: -11.860 | Epsilon: 0.0100 | Loss: 394505.0938
Episode 99100 | Reward: -11.668 | Epsilon: 0.0100 | Loss: 337816.3125
Episode 99150 | Reward: -11.258 | Epsilon: 0.0100 | Loss: 255902.3438
Episode 99200 | Reward:  -8.003 | Epsilon: 0.0100 | Loss: 337594.3438
Episode 99250 | Reward: -12.552 | Epsilon: 0.0100 | Loss: 466724.9062
Episode 99300 | Reward: -10.487 | Epsilon: 0.0100 | Loss: 316438.8750
Episode 99350 | Reward:  -7.431 | Epsilon: 0.0100 | Loss: 273495.6250
Episode 99400 | Reward: -10.220 | Epsilon: 0.0100 | Loss: 319167.0000
Episode 99450 | Reward:  -8.192 | Epsilon: 0.0100 | Loss: 360979.5000
Episode 99500 | Reward: -13.385 | Epsilon: 0.0100 | Loss: 351991.6250
Episode 99550 | Reward: -11.408 | Epsilon: 0.0100 | Loss: 342553.6562
Episode 99600 | Reward: -12.993 | Epsilon: 0.0100 | Loss: 384437.9375
Episode 99650 | Reward:  -7.426 | Epsilon: 0.0100 | Loss: 406034.1875
Episode 99700 | Reward: -13.034 | Epsilon: 0.0100 | Loss: 318125.5312
Episode 99750 | Reward: -10.318 | Epsilon: 0.0100 | Loss: 414336.8125
Episode 99800 | Reward:  -9.297 | Epsilon: 0.0100 | Loss: 254730.3438
Episode 99850 | Reward: -10.119 | Epsilon: 0.0100 | Loss: 393407.8750
Episode 99900 | Reward: -10.754 | Epsilon: 0.0100 | Loss: 236511.6406
Episode 99950 | Reward: -14.431 | Epsilon: 0.0100 | Loss: 303374.3125
Episode 100000 | Reward: -16.629 | Epsilon: 0.0100 | Loss: 419563.5938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:44).dict
Episode 100050 | Reward: -12.887 | Epsilon: 0.0100 | Loss: 320332.3750
Episode 100100 | Reward: -10.289 | Epsilon: 0.0100 | Loss: 365834.7500
Episode 100150 | Reward: -12.191 | Epsilon: 0.0100 | Loss: 377510.3750
Episode 100200 | Reward: -13.201 | Epsilon: 0.0100 | Loss: 259644.1094
Episode 100250 | Reward: -13.921 | Epsilon: 0.0100 | Loss: 292999.5625
Episode 100300 | Reward: -13.234 | Epsilon: 0.0100 | Loss: 304193.0000
Episode 100350 | Reward: -11.791 | Epsilon: 0.0100 | Loss: 387316.0938
Episode 100400 | Reward: -13.789 | Epsilon: 0.0100 | Loss: 445741.5312
Episode 100450 | Reward: -13.966 | Epsilon: 0.0100 | Loss: 315831.8750
Episode 100500 | Reward: -14.350 | Epsilon: 0.0100 | Loss: 383051.5312
Episode 100550 | Reward:  -9.176 | Epsilon: 0.0100 | Loss: 385351.5312
Episode 100600 | Reward: -15.953 | Epsilon: 0.0100 | Loss: 332170.2500
Episode 100650 | Reward: -10.465 | Epsilon: 0.0100 | Loss: 450910.3750
Episode 100700 | Reward: -12.497 | Epsilon: 0.0100 | Loss: 365862.9375
Episode 100750 | Reward: -14.880 | Epsilon: 0.0100 | Loss: 358247.3125
Episode 100800 | Reward: -15.414 | Epsilon: 0.0100 | Loss: 510754.4688
Episode 100850 | Reward: -16.393 | Epsilon: 0.0100 | Loss: 287265.0625
Episode 100900 | Reward: -15.043 | Epsilon: 0.0100 | Loss: 512906.7188
Episode 100950 | Reward: -16.143 | Epsilon: 0.0100 | Loss: 387140.8750
Episode 101000 | Reward: -11.393 | Epsilon: 0.0100 | Loss: 399587.2812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:48).dict
Episode 101050 | Reward: -11.653 | Epsilon: 0.0100 | Loss: 370873.9375
Episode 101100 | Reward: -11.599 | Epsilon: 0.0100 | Loss: 403476.4375
Episode 101150 | Reward: -12.820 | Epsilon: 0.0100 | Loss: 350466.4688
Episode 101200 | Reward: -13.043 | Epsilon: 0.0100 | Loss: 445486.4688
Episode 101250 | Reward: -13.261 | Epsilon: 0.0100 | Loss: 432563.5625
Episode 101300 | Reward: -14.979 | Epsilon: 0.0100 | Loss: 448136.5000
Episode 101350 | Reward: -14.720 | Epsilon: 0.0100 | Loss: 563577.5625
Episode 101400 | Reward: -14.111 | Epsilon: 0.0100 | Loss: 435080.0000
Episode 101450 | Reward: -14.240 | Epsilon: 0.0100 | Loss: 454172.4375
Episode 101500 | Reward: -11.753 | Epsilon: 0.0100 | Loss: 387630.9375
Episode 101550 | Reward: -16.525 | Epsilon: 0.0100 | Loss: 477057.4375
Episode 101600 | Reward: -12.902 | Epsilon: 0.0100 | Loss: 527751.5000
Episode 101650 | Reward: -11.208 | Epsilon: 0.0100 | Loss: 410683.5000
Episode 101700 | Reward: -11.503 | Epsilon: 0.0100 | Loss: 474056.5625
Episode 101750 | Reward: -13.712 | Epsilon: 0.0100 | Loss: 432437.8125
Episode 101800 | Reward:  -8.829 | Epsilon: 0.0100 | Loss: 352059.1250
Episode 101850 | Reward: -15.155 | Epsilon: 0.0100 | Loss: 503975.3125
Episode 101900 | Reward: -11.818 | Epsilon: 0.0100 | Loss: 636151.3750
Episode 101950 | Reward: -15.978 | Epsilon: 0.0100 | Loss: 562292.8750
Episode 102000 | Reward: -16.853 | Epsilon: 0.0100 | Loss: 543402.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:52).dict
Episode 102050 | Reward: -14.356 | Epsilon: 0.0100 | Loss: 557271.2500
Episode 102100 | Reward: -13.230 | Epsilon: 0.0100 | Loss: 476858.6250
Episode 102150 | Reward: -10.965 | Epsilon: 0.0100 | Loss: 441753.4062
Episode 102200 | Reward: -13.981 | Epsilon: 0.0100 | Loss: 464901.3125
Episode 102250 | Reward: -12.177 | Epsilon: 0.0100 | Loss: 594222.8125
Episode 102300 | Reward: -10.245 | Epsilon: 0.0100 | Loss: 624763.1875
Episode 102350 | Reward: -10.086 | Epsilon: 0.0100 | Loss: 611889.4375
Episode 102400 | Reward: -10.954 | Epsilon: 0.0100 | Loss: 560124.6875
Episode 102450 | Reward: -12.116 | Epsilon: 0.0100 | Loss: 526236.6250
Episode 102500 | Reward:  -9.532 | Epsilon: 0.0100 | Loss: 575252.8750
Episode 102550 | Reward: -11.937 | Epsilon: 0.0100 | Loss: 483563.6562
Episode 102600 | Reward: -10.129 | Epsilon: 0.0100 | Loss: 441107.1875
Episode 102650 | Reward: -12.148 | Epsilon: 0.0100 | Loss: 522018.3750
Episode 102700 | Reward: -12.883 | Epsilon: 0.0100 | Loss: 581461.3125
Episode 102750 | Reward: -12.857 | Epsilon: 0.0100 | Loss: 625926.7500
Episode 102800 | Reward: -14.427 | Epsilon: 0.0100 | Loss: 554940.8750
Episode 102850 | Reward: -10.096 | Epsilon: 0.0100 | Loss: 434366.3125
Episode 102900 | Reward:  -9.538 | Epsilon: 0.0100 | Loss: 530428.3125
Episode 102950 | Reward: -14.834 | Epsilon: 0.0100 | Loss: 427333.5000
Episode 103000 | Reward: -17.122 | Epsilon: 0.0100 | Loss: 699762.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:57).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:57).dict
Episode 103050 | Reward: -14.393 | Epsilon: 0.0100 | Loss: 640756.6250
Episode 103100 | Reward: -11.569 | Epsilon: 0.0100 | Loss: 518677.6250
Episode 103150 | Reward: -13.384 | Epsilon: 0.0100 | Loss: 628205.6250
Episode 103200 | Reward:  -9.025 | Epsilon: 0.0100 | Loss: 561463.2500
Episode 103250 | Reward: -12.862 | Epsilon: 0.0100 | Loss: 525601.5625
Episode 103300 | Reward: -12.358 | Epsilon: 0.0100 | Loss: 570597.5625
Episode 103350 | Reward: -11.938 | Epsilon: 0.0100 | Loss: 530803.4375
Episode 103400 | Reward: -15.019 | Epsilon: 0.0100 | Loss: 525035.1250
Episode 103450 | Reward: -15.416 | Epsilon: 0.0100 | Loss: 614328.3750
Episode 103500 | Reward: -10.804 | Epsilon: 0.0100 | Loss: 423066.8750
Episode 103550 | Reward: -12.404 | Epsilon: 0.0100 | Loss: 551168.4375
Episode 103600 | Reward: -12.667 | Epsilon: 0.0100 | Loss: 514156.9062
Episode 103650 | Reward: -15.656 | Epsilon: 0.0100 | Loss: 476290.9375
Episode 103700 | Reward: -10.483 | Epsilon: 0.0100 | Loss: 485591.0312
Episode 103750 | Reward: -12.561 | Epsilon: 0.0100 | Loss: 638493.8125
Episode 103800 | Reward: -11.441 | Epsilon: 0.0100 | Loss: 576876.0625
Episode 103850 | Reward: -16.821 | Epsilon: 0.0100 | Loss: 578499.3750
Episode 103900 | Reward:  -9.741 | Epsilon: 0.0100 | Loss: 678725.1875
Episode 103950 | Reward:  -9.977 | Epsilon: 0.0100 | Loss: 517517.5312
Episode 104000 | Reward: -10.868 | Epsilon: 0.0100 | Loss: 326473.8750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:01).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:01).dict
Episode 104050 | Reward: -11.923 | Epsilon: 0.0100 | Loss: 564594.4375
Episode 104100 | Reward: -12.480 | Epsilon: 0.0100 | Loss: 693793.8750
Episode 104150 | Reward:  -7.292 | Epsilon: 0.0100 | Loss: 633672.3125
Episode 104200 | Reward:  -7.662 | Epsilon: 0.0100 | Loss: 476221.3750
Episode 104250 | Reward: -10.024 | Epsilon: 0.0100 | Loss: 496470.5938
Episode 104300 | Reward:  -9.615 | Epsilon: 0.0100 | Loss: 716216.3750
Episode 104350 | Reward: -10.393 | Epsilon: 0.0100 | Loss: 385049.6875
Episode 104400 | Reward: -10.482 | Epsilon: 0.0100 | Loss: 618401.5000
Episode 104450 | Reward: -12.592 | Epsilon: 0.0100 | Loss: 577399.5000
Episode 104500 | Reward: -10.301 | Epsilon: 0.0100 | Loss: 469447.7188
Episode 104550 | Reward: -13.914 | Epsilon: 0.0100 | Loss: 470489.0000
Episode 104600 | Reward: -11.017 | Epsilon: 0.0100 | Loss: 532974.3125
Episode 104650 | Reward: -12.970 | Epsilon: 0.0100 | Loss: 521380.7500
Episode 104700 | Reward:  -8.952 | Epsilon: 0.0100 | Loss: 729014.9375
Episode 104750 | Reward: -13.357 | Epsilon: 0.0100 | Loss: 529705.0000
Episode 104800 | Reward: -10.665 | Epsilon: 0.0100 | Loss: 646121.3125
Episode 104850 | Reward: -11.934 | Epsilon: 0.0100 | Loss: 629191.8125
Episode 104900 | Reward: -13.279 | Epsilon: 0.0100 | Loss: 545020.5000
Episode 104950 | Reward: -12.004 | Epsilon: 0.0100 | Loss: 680965.6875
Episode 105000 | Reward: -11.083 | Epsilon: 0.0100 | Loss: 459815.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:05).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:05).dict
Episode 105050 | Reward: -12.731 | Epsilon: 0.0100 | Loss: 509184.3750
Episode 105100 | Reward: -10.274 | Epsilon: 0.0100 | Loss: 609432.3750
Episode 105150 | Reward: -10.264 | Epsilon: 0.0100 | Loss: 522502.5625
Episode 105200 | Reward:  -8.795 | Epsilon: 0.0100 | Loss: 374209.0938
Episode 105250 | Reward: -10.670 | Epsilon: 0.0100 | Loss: 548427.0000
Episode 105300 | Reward: -12.035 | Epsilon: 0.0100 | Loss: 438158.6875
Episode 105350 | Reward: -11.584 | Epsilon: 0.0100 | Loss: 577973.7500
Episode 105400 | Reward: -13.312 | Epsilon: 0.0100 | Loss: 636896.5625
Episode 105450 | Reward: -10.987 | Epsilon: 0.0100 | Loss: 615156.0625
Episode 105500 | Reward: -12.973 | Epsilon: 0.0100 | Loss: 416905.2188
Episode 105550 | Reward: -11.777 | Epsilon: 0.0100 | Loss: 386716.9688
Episode 105600 | Reward: -13.096 | Epsilon: 0.0100 | Loss: 364770.0625
Episode 105650 | Reward: -11.988 | Epsilon: 0.0100 | Loss: 302461.9062
Episode 105700 | Reward:  -9.060 | Epsilon: 0.0100 | Loss: 475893.6875
Episode 105750 | Reward: -11.149 | Epsilon: 0.0100 | Loss: 403203.6562
Episode 105800 | Reward:  -9.632 | Epsilon: 0.0100 | Loss: 489958.1250
Episode 105850 | Reward:  -8.919 | Epsilon: 0.0100 | Loss: 410463.7500
Episode 105900 | Reward: -10.108 | Epsilon: 0.0100 | Loss: 475718.3125
Episode 105950 | Reward: -11.472 | Epsilon: 0.0100 | Loss: 379149.5625
Episode 106000 | Reward: -11.695 | Epsilon: 0.0100 | Loss: 439768.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:09).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:09).dict
Episode 106050 | Reward: -11.284 | Epsilon: 0.0100 | Loss: 475910.4062
Episode 106100 | Reward: -10.526 | Epsilon: 0.0100 | Loss: 461737.4688
Episode 106150 | Reward: -13.136 | Epsilon: 0.0100 | Loss: 288121.3125
Episode 106200 | Reward: -15.476 | Epsilon: 0.0100 | Loss: 416111.5938
Episode 106250 | Reward:  -7.920 | Epsilon: 0.0100 | Loss: 351985.4375
Episode 106300 | Reward: -10.797 | Epsilon: 0.0100 | Loss: 419699.0625
Episode 106350 | Reward: -16.622 | Epsilon: 0.0100 | Loss: 281227.5000
Episode 106400 | Reward: -17.512 | Epsilon: 0.0100 | Loss: 511750.8750
Episode 106450 | Reward: -14.857 | Epsilon: 0.0100 | Loss: 379138.3750
Episode 106500 | Reward: -11.719 | Epsilon: 0.0100 | Loss: 342593.6562
Episode 106550 | Reward: -11.649 | Epsilon: 0.0100 | Loss: 295301.3750
Episode 106600 | Reward: -13.409 | Epsilon: 0.0100 | Loss: 388746.5000
Episode 106650 | Reward: -12.126 | Epsilon: 0.0100 | Loss: 360811.6875
Episode 106700 | Reward:  -8.849 | Epsilon: 0.0100 | Loss: 414983.0312
Episode 106750 | Reward:  -8.699 | Epsilon: 0.0100 | Loss: 407247.2812
Episode 106800 | Reward:  -6.744 | Epsilon: 0.0100 | Loss: 369466.2812
Episode 106850 | Reward: -15.173 | Epsilon: 0.0100 | Loss: 403429.4375
Episode 106900 | Reward: -11.869 | Epsilon: 0.0100 | Loss: 376925.5625
Episode 106950 | Reward:  -8.887 | Epsilon: 0.0100 | Loss: 329070.7500
Episode 107000 | Reward:  -8.298 | Epsilon: 0.0100 | Loss: 332593.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:13).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:13).dict
Episode 107050 | Reward: -10.679 | Epsilon: 0.0100 | Loss: 360906.1875
Episode 107100 | Reward: -12.415 | Epsilon: 0.0100 | Loss: 376392.5625
Episode 107150 | Reward: -10.655 | Epsilon: 0.0100 | Loss: 438398.9688
Episode 107200 | Reward: -10.362 | Epsilon: 0.0100 | Loss: 349529.2812
Episode 107250 | Reward:  -5.432 | Epsilon: 0.0100 | Loss: 483585.9375
Episode 107300 | Reward:  -4.640 | Epsilon: 0.0100 | Loss: 480183.5000
Episode 107350 | Reward: -10.975 | Epsilon: 0.0100 | Loss: 319538.4062
Episode 107400 | Reward: -12.101 | Epsilon: 0.0100 | Loss: 483451.3438
Episode 107450 | Reward: -11.112 | Epsilon: 0.0100 | Loss: 240655.8594
Episode 107500 | Reward: -11.786 | Epsilon: 0.0100 | Loss: 426578.0000
Episode 107550 | Reward: -11.279 | Epsilon: 0.0100 | Loss: 276994.2500
Episode 107600 | Reward: -11.987 | Epsilon: 0.0100 | Loss: 486761.8125
Episode 107650 | Reward: -12.623 | Epsilon: 0.0100 | Loss: 337807.6250
Episode 107700 | Reward:  -8.830 | Epsilon: 0.0100 | Loss: 298737.2188
Episode 107750 | Reward: -11.604 | Epsilon: 0.0100 | Loss: 429703.7188
Episode 107800 | Reward: -12.431 | Epsilon: 0.0100 | Loss: 430678.8750
Episode 107850 | Reward: -13.665 | Epsilon: 0.0100 | Loss: 464842.2812
Episode 107900 | Reward: -14.634 | Epsilon: 0.0100 | Loss: 399980.5625
Episode 107950 | Reward: -14.285 | Epsilon: 0.0100 | Loss: 486429.4688
Episode 108000 | Reward: -13.592 | Epsilon: 0.0100 | Loss: 467886.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:17).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:17).dict
Episode 108050 | Reward: -12.435 | Epsilon: 0.0100 | Loss: 396431.4062
Episode 108100 | Reward: -15.759 | Epsilon: 0.0100 | Loss: 411620.2812
Episode 108150 | Reward: -12.664 | Epsilon: 0.0100 | Loss: 343959.9688
Episode 108200 | Reward: -10.885 | Epsilon: 0.0100 | Loss: 458808.2812
Episode 108250 | Reward: -12.093 | Epsilon: 0.0100 | Loss: 420603.4688
Episode 108300 | Reward: -10.834 | Epsilon: 0.0100 | Loss: 386683.5000
Episode 108350 | Reward: -10.596 | Epsilon: 0.0100 | Loss: 433236.6562
Episode 108400 | Reward: -11.846 | Epsilon: 0.0100 | Loss: 357505.7188
Episode 108450 | Reward: -12.402 | Epsilon: 0.0100 | Loss: 432148.6875
Episode 108500 | Reward: -11.528 | Epsilon: 0.0100 | Loss: 385950.8750
Episode 108550 | Reward: -11.821 | Epsilon: 0.0100 | Loss: 450751.1250
Episode 108600 | Reward: -11.318 | Epsilon: 0.0100 | Loss: 491056.0312
Episode 108650 | Reward: -12.781 | Epsilon: 0.0100 | Loss: 396137.0312
Episode 108700 | Reward:  -7.573 | Epsilon: 0.0100 | Loss: 351269.1562
Episode 108750 | Reward: -11.950 | Epsilon: 0.0100 | Loss: 459647.7812
Episode 108800 | Reward: -14.230 | Epsilon: 0.0100 | Loss: 500211.1875
Episode 108850 | Reward: -11.478 | Epsilon: 0.0100 | Loss: 466737.3438
Episode 108900 | Reward: -11.683 | Epsilon: 0.0100 | Loss: 354217.2812
Episode 108950 | Reward:  -9.118 | Epsilon: 0.0100 | Loss: 396119.1250
Episode 109000 | Reward: -10.822 | Epsilon: 0.0100 | Loss: 440454.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:21).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:21).dict
Episode 109050 | Reward: -10.827 | Epsilon: 0.0100 | Loss: 403061.9062
Episode 109100 | Reward: -13.147 | Epsilon: 0.0100 | Loss: 351861.8438
Episode 109150 | Reward:  -9.029 | Epsilon: 0.0100 | Loss: 455147.7188
Episode 109200 | Reward:  -9.859 | Epsilon: 0.0100 | Loss: 489397.0938
Episode 109250 | Reward: -10.103 | Epsilon: 0.0100 | Loss: 468843.0000
Episode 109300 | Reward: -12.180 | Epsilon: 0.0100 | Loss: 415592.8750
Episode 109350 | Reward:  -7.788 | Epsilon: 0.0100 | Loss: 469930.3750
Episode 109400 | Reward: -10.678 | Epsilon: 0.0100 | Loss: 311414.6250
Episode 109450 | Reward: -10.208 | Epsilon: 0.0100 | Loss: 364101.5625
Episode 109500 | Reward: -10.729 | Epsilon: 0.0100 | Loss: 418943.7188
Episode 109550 | Reward:  -9.171 | Epsilon: 0.0100 | Loss: 458696.1875
Episode 109600 | Reward:  -8.793 | Epsilon: 0.0100 | Loss: 420056.4062
Episode 109650 | Reward:  -9.689 | Epsilon: 0.0100 | Loss: 442750.8750
Episode 109700 | Reward: -13.297 | Epsilon: 0.0100 | Loss: 503884.6250
Episode 109750 | Reward: -10.483 | Epsilon: 0.0100 | Loss: 450133.2812
Episode 109800 | Reward: -12.181 | Epsilon: 0.0100 | Loss: 432434.8750
Episode 109850 | Reward: -12.336 | Epsilon: 0.0100 | Loss: 397144.4062
Episode 109900 | Reward: -13.298 | Epsilon: 0.0100 | Loss: 405475.0938
Episode 109950 | Reward: -11.628 | Epsilon: 0.0100 | Loss: 420986.1875
Episode 110000 | Reward:  -9.346 | Epsilon: 0.0100 | Loss: 465197.7812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:26).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:26).dict
Episode 110050 | Reward: -12.690 | Epsilon: 0.0100 | Loss: 415394.7812
Episode 110100 | Reward: -10.422 | Epsilon: 0.0100 | Loss: 379596.7188
Episode 110150 | Reward: -13.737 | Epsilon: 0.0100 | Loss: 409653.3750
Episode 110200 | Reward:  -8.836 | Epsilon: 0.0100 | Loss: 328276.3750
Episode 110250 | Reward: -11.727 | Epsilon: 0.0100 | Loss: 395511.2500
Episode 110300 | Reward: -10.049 | Epsilon: 0.0100 | Loss: 361559.6875
Episode 110350 | Reward:  -9.979 | Epsilon: 0.0100 | Loss: 427300.5625
Episode 110400 | Reward: -10.220 | Epsilon: 0.0100 | Loss: 375692.5312
Episode 110450 | Reward:  -8.817 | Epsilon: 0.0100 | Loss: 509144.6562
Episode 110500 | Reward:  -7.971 | Epsilon: 0.0100 | Loss: 387760.7188
Episode 110550 | Reward: -11.609 | Epsilon: 0.0100 | Loss: 267879.6562
Episode 110600 | Reward:  -9.342 | Epsilon: 0.0100 | Loss: 329902.2188
Episode 110650 | Reward:  -9.146 | Epsilon: 0.0100 | Loss: 358484.2500
Episode 110700 | Reward: -12.000 | Epsilon: 0.0100 | Loss: 376354.8750
Episode 110750 | Reward: -11.057 | Epsilon: 0.0100 | Loss: 381953.3125
Episode 110800 | Reward: -12.713 | Epsilon: 0.0100 | Loss: 261451.3438
Episode 110850 | Reward: -15.928 | Epsilon: 0.0100 | Loss: 315555.2812
Episode 110900 | Reward:  -9.567 | Epsilon: 0.0100 | Loss: 319303.6562
Episode 110950 | Reward: -15.802 | Epsilon: 0.0100 | Loss: 313697.8750
Episode 111000 | Reward:  -8.655 | Epsilon: 0.0100 | Loss: 368348.7188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:30).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:30).dict
Episode 111050 | Reward:  -7.423 | Epsilon: 0.0100 | Loss: 313529.4375
Episode 111100 | Reward: -10.976 | Epsilon: 0.0100 | Loss: 382747.0625
Episode 111150 | Reward:  -8.767 | Epsilon: 0.0100 | Loss: 327365.7812
Episode 111200 | Reward: -10.998 | Epsilon: 0.0100 | Loss: 398865.0000
Episode 111250 | Reward:  -8.341 | Epsilon: 0.0100 | Loss: 389632.5000
Episode 111300 | Reward:  -9.437 | Epsilon: 0.0100 | Loss: 309791.6562
Episode 111350 | Reward:  -7.894 | Epsilon: 0.0100 | Loss: 412153.9375
Episode 111400 | Reward: -10.183 | Epsilon: 0.0100 | Loss: 495852.5312
Episode 111450 | Reward:  -8.788 | Epsilon: 0.0100 | Loss: 374131.0938
Episode 111500 | Reward: -13.839 | Epsilon: 0.0100 | Loss: 412555.7812
Episode 111550 | Reward: -10.986 | Epsilon: 0.0100 | Loss: 401057.7500
Episode 111600 | Reward:  -8.530 | Epsilon: 0.0100 | Loss: 325644.9375
Episode 111650 | Reward: -10.282 | Epsilon: 0.0100 | Loss: 484909.6875
Episode 111700 | Reward:  -9.137 | Epsilon: 0.0100 | Loss: 351963.1250
Episode 111750 | Reward: -10.745 | Epsilon: 0.0100 | Loss: 373067.3125
Episode 111800 | Reward:  -9.558 | Epsilon: 0.0100 | Loss: 430354.1562
Episode 111850 | Reward: -11.125 | Epsilon: 0.0100 | Loss: 296899.4375
Episode 111900 | Reward: -11.518 | Epsilon: 0.0100 | Loss: 413991.6250
Episode 111950 | Reward: -15.053 | Epsilon: 0.0100 | Loss: 308135.7812
Episode 112000 | Reward: -10.409 | Epsilon: 0.0100 | Loss: 425837.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:34).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:34).dict
Episode 112050 | Reward: -10.720 | Epsilon: 0.0100 | Loss: 457008.8750
Episode 112100 | Reward: -13.860 | Epsilon: 0.0100 | Loss: 594934.8750
Episode 112150 | Reward:  -9.832 | Epsilon: 0.0100 | Loss: 495633.0938
Episode 112200 | Reward: -11.014 | Epsilon: 0.0100 | Loss: 433716.2812
Episode 112250 | Reward:  -9.845 | Epsilon: 0.0100 | Loss: 346725.8125
Episode 112300 | Reward: -13.152 | Epsilon: 0.0100 | Loss: 443483.9375
Episode 112350 | Reward: -11.594 | Epsilon: 0.0100 | Loss: 354796.3438
Episode 112400 | Reward: -10.443 | Epsilon: 0.0100 | Loss: 400566.4375
Episode 112450 | Reward:  -9.380 | Epsilon: 0.0100 | Loss: 439323.2500
Episode 112500 | Reward:  -9.481 | Epsilon: 0.0100 | Loss: 411013.3750
Episode 112550 | Reward: -13.629 | Epsilon: 0.0100 | Loss: 395858.0625
Episode 112600 | Reward: -11.028 | Epsilon: 0.0100 | Loss: 461812.4375
Episode 112650 | Reward: -13.285 | Epsilon: 0.0100 | Loss: 341564.1875
Episode 112700 | Reward:  -7.170 | Epsilon: 0.0100 | Loss: 482189.8750
Episode 112750 | Reward:  -9.870 | Epsilon: 0.0100 | Loss: 492799.2188
Episode 112800 | Reward: -10.258 | Epsilon: 0.0100 | Loss: 437787.9688
Episode 112850 | Reward: -12.812 | Epsilon: 0.0100 | Loss: 381770.1875
Episode 112900 | Reward: -10.520 | Epsilon: 0.0100 | Loss: 363217.9375
Episode 112950 | Reward:  -7.933 | Epsilon: 0.0100 | Loss: 377345.6562
Episode 113000 | Reward:  -9.384 | Epsilon: 0.0100 | Loss: 428138.3438
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:38).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:38).dict
Episode 113050 | Reward: -10.687 | Epsilon: 0.0100 | Loss: 465318.4375
Episode 113100 | Reward: -13.124 | Epsilon: 0.0100 | Loss: 362457.9375
Episode 113150 | Reward: -14.569 | Epsilon: 0.0100 | Loss: 336367.0625
Episode 113200 | Reward: -13.704 | Epsilon: 0.0100 | Loss: 452884.3125
Episode 113250 | Reward:  -8.779 | Epsilon: 0.0100 | Loss: 416909.9375
Episode 113300 | Reward: -11.924 | Epsilon: 0.0100 | Loss: 448509.6250
Episode 113350 | Reward:  -9.964 | Epsilon: 0.0100 | Loss: 429196.0312
Episode 113400 | Reward: -14.537 | Epsilon: 0.0100 | Loss: 426444.4375
Episode 113450 | Reward: -12.246 | Epsilon: 0.0100 | Loss: 495455.0625
Episode 113500 | Reward: -10.358 | Epsilon: 0.0100 | Loss: 480383.1875
Episode 113550 | Reward: -14.743 | Epsilon: 0.0100 | Loss: 577539.1250
Episode 113600 | Reward: -11.309 | Epsilon: 0.0100 | Loss: 450823.1875
Episode 113650 | Reward:  -9.634 | Epsilon: 0.0100 | Loss: 455714.7188
Episode 113700 | Reward: -11.014 | Epsilon: 0.0100 | Loss: 398913.3750
Episode 113750 | Reward:  -8.724 | Epsilon: 0.0100 | Loss: 492528.3438
Episode 113800 | Reward: -13.031 | Epsilon: 0.0100 | Loss: 400218.5938
Episode 113850 | Reward: -10.268 | Epsilon: 0.0100 | Loss: 374020.6250
Episode 113900 | Reward: -11.638 | Epsilon: 0.0100 | Loss: 525219.4375
Episode 113950 | Reward: -10.466 | Epsilon: 0.0100 | Loss: 508721.1875
Episode 114000 | Reward: -13.063 | Epsilon: 0.0100 | Loss: 483580.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:42).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:42).dict
Episode 114050 | Reward: -13.930 | Epsilon: 0.0100 | Loss: 484680.4375
Episode 114100 | Reward: -13.811 | Epsilon: 0.0100 | Loss: 410598.8438
Episode 114150 | Reward:  -9.334 | Epsilon: 0.0100 | Loss: 476504.8750
Episode 114200 | Reward: -12.456 | Epsilon: 0.0100 | Loss: 458113.1562
Episode 114250 | Reward: -15.784 | Epsilon: 0.0100 | Loss: 506363.6250
Episode 114300 | Reward: -13.779 | Epsilon: 0.0100 | Loss: 592691.3750
Episode 114350 | Reward:  -9.928 | Epsilon: 0.0100 | Loss: 472422.9375
Episode 114400 | Reward: -13.699 | Epsilon: 0.0100 | Loss: 516964.0000
Episode 114450 | Reward: -11.960 | Epsilon: 0.0100 | Loss: 410465.6250
Episode 114500 | Reward: -11.968 | Epsilon: 0.0100 | Loss: 543988.1250
Episode 114550 | Reward: -12.299 | Epsilon: 0.0100 | Loss: 393318.5625
Episode 114600 | Reward: -10.912 | Epsilon: 0.0100 | Loss: 481384.4688
Episode 114650 | Reward: -10.689 | Epsilon: 0.0100 | Loss: 413206.0000
Episode 114700 | Reward: -12.097 | Epsilon: 0.0100 | Loss: 566766.3750
Episode 114750 | Reward: -10.750 | Epsilon: 0.0100 | Loss: 507109.4062
Episode 114800 | Reward: -10.874 | Epsilon: 0.0100 | Loss: 536866.8125
Episode 114850 | Reward: -14.123 | Epsilon: 0.0100 | Loss: 466491.9375
Episode 114900 | Reward: -10.110 | Epsilon: 0.0100 | Loss: 406429.5000
Episode 114950 | Reward:  -4.143 | Epsilon: 0.0100 | Loss: 397849.7500
Episode 115000 | Reward: -12.204 | Epsilon: 0.0100 | Loss: 498225.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:46).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:46).dict
Episode 115050 | Reward:  -8.449 | Epsilon: 0.0100 | Loss: 575641.6250
Episode 115100 | Reward:  -8.286 | Epsilon: 0.0100 | Loss: 589666.1875
Episode 115150 | Reward:  -9.478 | Epsilon: 0.0100 | Loss: 586020.5000
Episode 115200 | Reward: -11.853 | Epsilon: 0.0100 | Loss: 547943.1250
Episode 115250 | Reward: -15.017 | Epsilon: 0.0100 | Loss: 513696.5938
Episode 115300 | Reward: -13.898 | Epsilon: 0.0100 | Loss: 608244.3750
Episode 115350 | Reward: -15.096 | Epsilon: 0.0100 | Loss: 427990.0000
Episode 115400 | Reward: -12.807 | Epsilon: 0.0100 | Loss: 367088.3438
Episode 115450 | Reward: -12.967 | Epsilon: 0.0100 | Loss: 453859.4375
Episode 115500 | Reward: -12.958 | Epsilon: 0.0100 | Loss: 528078.3750
Episode 115550 | Reward: -11.028 | Epsilon: 0.0100 | Loss: 508915.5312
Episode 115600 | Reward:  -9.802 | Epsilon: 0.0100 | Loss: 626164.1875
Episode 115650 | Reward: -12.876 | Epsilon: 0.0100 | Loss: 575354.8750
Episode 115700 | Reward:  -9.976 | Epsilon: 0.0100 | Loss: 482538.3750
Episode 115750 | Reward:  -8.365 | Epsilon: 0.0100 | Loss: 574500.6250
Episode 115800 | Reward:  -8.461 | Epsilon: 0.0100 | Loss: 427760.9688
Episode 115850 | Reward:  -7.420 | Epsilon: 0.0100 | Loss: 500558.2812
Episode 115900 | Reward:  -7.603 | Epsilon: 0.0100 | Loss: 545124.5625
Episode 115950 | Reward: -11.043 | Epsilon: 0.0100 | Loss: 512421.6250
Episode 116000 | Reward:  -9.723 | Epsilon: 0.0100 | Loss: 460836.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:50).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:50).dict
Episode 116050 | Reward: -11.581 | Epsilon: 0.0100 | Loss: 559045.4375
Episode 116100 | Reward:  -9.879 | Epsilon: 0.0100 | Loss: 517337.1250
Episode 116150 | Reward:  -9.936 | Epsilon: 0.0100 | Loss: 499804.6250
Episode 116200 | Reward:  -9.382 | Epsilon: 0.0100 | Loss: 586658.2500
Episode 116250 | Reward: -12.527 | Epsilon: 0.0100 | Loss: 563526.7500
Episode 116300 | Reward: -11.726 | Epsilon: 0.0100 | Loss: 549209.9375
Episode 116350 | Reward: -11.747 | Epsilon: 0.0100 | Loss: 545310.9375
Episode 116400 | Reward: -11.167 | Epsilon: 0.0100 | Loss: 577763.3750
Episode 116450 | Reward:  -9.002 | Epsilon: 0.0100 | Loss: 620547.7500
Episode 116500 | Reward:  -9.731 | Epsilon: 0.0100 | Loss: 453336.1250
Episode 116550 | Reward:  -9.766 | Epsilon: 0.0100 | Loss: 697865.2500
Episode 116600 | Reward:  -8.561 | Epsilon: 0.0100 | Loss: 580804.2500
Episode 116650 | Reward:  -9.682 | Epsilon: 0.0100 | Loss: 397441.4688
Episode 116700 | Reward: -12.260 | Epsilon: 0.0100 | Loss: 477330.1875
Episode 116750 | Reward: -11.366 | Epsilon: 0.0100 | Loss: 446563.6250
Episode 116800 | Reward: -13.265 | Epsilon: 0.0100 | Loss: 497001.4375
Episode 116850 | Reward: -13.135 | Epsilon: 0.0100 | Loss: 555024.5625
Episode 116900 | Reward: -12.685 | Epsilon: 0.0100 | Loss: 438492.5000
Episode 116950 | Reward: -12.291 | Epsilon: 0.0100 | Loss: 585583.2500
Episode 117000 | Reward:  -7.927 | Epsilon: 0.0100 | Loss: 629074.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:54).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:54).dict
Episode 117050 | Reward:  -5.805 | Epsilon: 0.0100 | Loss: 498241.8125
Episode 117100 | Reward:  -7.058 | Epsilon: 0.0100 | Loss: 414965.5000
Episode 117150 | Reward:  -3.916 | Epsilon: 0.0100 | Loss: 532742.5625
Episode 117200 | Reward: -11.214 | Epsilon: 0.0100 | Loss: 492607.9375
Episode 117250 | Reward: -11.739 | Epsilon: 0.0100 | Loss: 467942.5938
Episode 117300 | Reward: -14.647 | Epsilon: 0.0100 | Loss: 524320.9375
Episode 117350 | Reward: -16.424 | Epsilon: 0.0100 | Loss: 523037.0312
Episode 117400 | Reward: -13.850 | Epsilon: 0.0100 | Loss: 458441.3125
Episode 117450 | Reward: -16.371 | Epsilon: 0.0100 | Loss: 518407.1250
Episode 117500 | Reward: -13.163 | Epsilon: 0.0100 | Loss: 472541.3438
Episode 117550 | Reward: -12.953 | Epsilon: 0.0100 | Loss: 457339.2812
Episode 117600 | Reward: -14.784 | Epsilon: 0.0100 | Loss: 436647.3125
Episode 117650 | Reward: -17.245 | Epsilon: 0.0100 | Loss: 591489.6250
Episode 117700 | Reward: -17.738 | Epsilon: 0.0100 | Loss: 496733.5938
Episode 117750 | Reward: -16.840 | Epsilon: 0.0100 | Loss: 439806.5625
Episode 117800 | Reward: -11.033 | Epsilon: 0.0100 | Loss: 483468.6875
Episode 117850 | Reward: -12.483 | Epsilon: 0.0100 | Loss: 492610.5000
Episode 117900 | Reward: -13.765 | Epsilon: 0.0100 | Loss: 481442.9375
Episode 117950 | Reward: -12.922 | Epsilon: 0.0100 | Loss: 457094.5625
Episode 118000 | Reward: -11.703 | Epsilon: 0.0100 | Loss: 556579.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:58).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:58).dict
Episode 118050 | Reward:  -9.192 | Epsilon: 0.0100 | Loss: 463840.4688
Episode 118100 | Reward: -12.254 | Epsilon: 0.0100 | Loss: 465390.2812
Episode 118150 | Reward: -11.398 | Epsilon: 0.0100 | Loss: 576280.8750
Episode 118200 | Reward:  -8.916 | Epsilon: 0.0100 | Loss: 529436.9375
Episode 118250 | Reward:  -9.885 | Epsilon: 0.0100 | Loss: 506416.3438
Episode 118300 | Reward: -10.783 | Epsilon: 0.0100 | Loss: 526425.1875
Episode 118350 | Reward: -14.512 | Epsilon: 0.0100 | Loss: 581406.0625
Episode 118400 | Reward: -14.426 | Epsilon: 0.0100 | Loss: 589219.9375
Episode 118450 | Reward: -13.082 | Epsilon: 0.0100 | Loss: 441605.6562
Episode 118500 | Reward: -10.886 | Epsilon: 0.0100 | Loss: 495417.3438
Episode 118550 | Reward:  -9.782 | Epsilon: 0.0100 | Loss: 440759.4688
Episode 118600 | Reward:  -9.519 | Epsilon: 0.0100 | Loss: 604737.1250
Episode 118650 | Reward: -13.465 | Epsilon: 0.0100 | Loss: 511602.7812
Episode 118700 | Reward: -13.480 | Epsilon: 0.0100 | Loss: 406441.3750
Episode 118750 | Reward: -13.003 | Epsilon: 0.0100 | Loss: 482353.2812
Episode 118800 | Reward: -10.484 | Epsilon: 0.0100 | Loss: 514816.8750
Episode 118850 | Reward: -13.405 | Epsilon: 0.0100 | Loss: 491330.2188
Episode 118900 | Reward:  -5.212 | Epsilon: 0.0100 | Loss: 514566.1250
Episode 118950 | Reward: -11.244 | Epsilon: 0.0100 | Loss: 611767.9375
Episode 119000 | Reward:  -8.958 | Epsilon: 0.0100 | Loss: 425791.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:02).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:02).dict
Episode 119050 | Reward:  -7.161 | Epsilon: 0.0100 | Loss: 498862.5938
Episode 119100 | Reward: -11.004 | Epsilon: 0.0100 | Loss: 521184.6250
Episode 119150 | Reward:  -6.683 | Epsilon: 0.0100 | Loss: 533652.3125
Episode 119200 | Reward:  -7.211 | Epsilon: 0.0100 | Loss: 472284.6875
Episode 119250 | Reward: -12.905 | Epsilon: 0.0100 | Loss: 503448.5000
Episode 119300 | Reward: -10.498 | Epsilon: 0.0100 | Loss: 477421.9375
Episode 119350 | Reward: -11.069 | Epsilon: 0.0100 | Loss: 365816.3750
Episode 119400 | Reward: -12.391 | Epsilon: 0.0100 | Loss: 468928.8750
Episode 119450 | Reward:  -9.847 | Epsilon: 0.0100 | Loss: 518006.3125
Episode 119500 | Reward: -10.912 | Epsilon: 0.0100 | Loss: 540221.6875
Episode 119550 | Reward: -10.399 | Epsilon: 0.0100 | Loss: 487387.5000
Episode 119600 | Reward: -14.003 | Epsilon: 0.0100 | Loss: 392954.6875
Episode 119650 | Reward: -13.288 | Epsilon: 0.0100 | Loss: 493922.3125
Episode 119700 | Reward: -11.500 | Epsilon: 0.0100 | Loss: 457669.1562
Episode 119750 | Reward: -13.140 | Epsilon: 0.0100 | Loss: 533350.1250
Episode 119800 | Reward: -11.348 | Epsilon: 0.0100 | Loss: 492590.8750
Episode 119850 | Reward:  -8.089 | Epsilon: 0.0100 | Loss: 465785.8438
Episode 119900 | Reward: -11.274 | Epsilon: 0.0100 | Loss: 568663.7500
Episode 119950 | Reward:  -8.686 | Epsilon: 0.0100 | Loss: 454604.3438
Episode 120000 | Reward: -10.372 | Epsilon: 0.0100 | Loss: 493599.4062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:06).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:06).dict
Episode 120050 | Reward: -11.027 | Epsilon: 0.0100 | Loss: 495322.2812
Episode 120100 | Reward: -10.549 | Epsilon: 0.0100 | Loss: 386467.4375
Episode 120150 | Reward: -10.774 | Epsilon: 0.0100 | Loss: 537713.1250
Episode 120200 | Reward: -11.206 | Epsilon: 0.0100 | Loss: 520792.1562
Episode 120250 | Reward:  -4.988 | Epsilon: 0.0100 | Loss: 539214.7500
Episode 120300 | Reward: -11.068 | Epsilon: 0.0100 | Loss: 414565.2188
Episode 120350 | Reward: -10.830 | Epsilon: 0.0100 | Loss: 482420.4375
Episode 120400 | Reward:  -9.526 | Epsilon: 0.0100 | Loss: 636807.4375
Episode 120450 | Reward:  -8.855 | Epsilon: 0.0100 | Loss: 517005.8438
Episode 120500 | Reward: -10.438 | Epsilon: 0.0100 | Loss: 624538.8125
Episode 120550 | Reward:  -8.877 | Epsilon: 0.0100 | Loss: 621170.2500
Episode 120600 | Reward:  -3.127 | Epsilon: 0.0100 | Loss: 533436.8125
Episode 120650 | Reward: -10.667 | Epsilon: 0.0100 | Loss: 503555.6250
Episode 120700 | Reward: -11.120 | Epsilon: 0.0100 | Loss: 520597.0000
Episode 120750 | Reward:  -9.755 | Epsilon: 0.0100 | Loss: 461997.5625
Episode 120800 | Reward:  -7.466 | Epsilon: 0.0100 | Loss: 486200.1250
Episode 120850 | Reward: -10.465 | Epsilon: 0.0100 | Loss: 536591.6250
Episode 120900 | Reward: -10.920 | Epsilon: 0.0100 | Loss: 633954.6875
Episode 120950 | Reward: -16.474 | Epsilon: 0.0100 | Loss: 602974.0625
Episode 121000 | Reward: -10.157 | Epsilon: 0.0100 | Loss: 558482.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:10).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:10).dict
Episode 121050 | Reward:  -9.617 | Epsilon: 0.0100 | Loss: 562808.7500
Episode 121100 | Reward:  -6.779 | Epsilon: 0.0100 | Loss: 513986.8125
Episode 121150 | Reward:  -6.238 | Epsilon: 0.0100 | Loss: 473665.5625
Episode 121200 | Reward:  -8.451 | Epsilon: 0.0100 | Loss: 452952.0312
Episode 121250 | Reward:  -8.035 | Epsilon: 0.0100 | Loss: 699478.6250
Episode 121300 | Reward: -11.585 | Epsilon: 0.0100 | Loss: 633706.3750
Episode 121350 | Reward: -11.399 | Epsilon: 0.0100 | Loss: 460322.3125
Episode 121400 | Reward: -14.888 | Epsilon: 0.0100 | Loss: 499733.7500
Episode 121450 | Reward: -14.346 | Epsilon: 0.0100 | Loss: 538298.6250
Episode 121500 | Reward: -11.830 | Epsilon: 0.0100 | Loss: 674735.6875
Episode 121550 | Reward:  -8.968 | Epsilon: 0.0100 | Loss: 619478.3125
Episode 121600 | Reward:  -9.634 | Epsilon: 0.0100 | Loss: 517743.1250
Episode 121650 | Reward: -10.944 | Epsilon: 0.0100 | Loss: 723021.5000
Episode 121700 | Reward: -11.435 | Epsilon: 0.0100 | Loss: 576556.1250
Episode 121750 | Reward: -10.520 | Epsilon: 0.0100 | Loss: 458818.7812
Episode 121800 | Reward: -10.709 | Epsilon: 0.0100 | Loss: 596677.1250
Episode 121850 | Reward: -10.071 | Epsilon: 0.0100 | Loss: 466570.5312
Episode 121900 | Reward: -12.581 | Epsilon: 0.0100 | Loss: 554392.8125
Episode 121950 | Reward: -10.582 | Epsilon: 0.0100 | Loss: 600340.9375
Episode 122000 | Reward: -10.904 | Epsilon: 0.0100 | Loss: 517157.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:14).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:14).dict
Episode 122050 | Reward: -10.837 | Epsilon: 0.0100 | Loss: 461031.5938
Episode 122100 | Reward: -12.229 | Epsilon: 0.0100 | Loss: 601376.5000
Episode 122150 | Reward: -10.496 | Epsilon: 0.0100 | Loss: 484680.4688
Episode 122200 | Reward:  -6.831 | Epsilon: 0.0100 | Loss: 477342.6875
Episode 122250 | Reward:  -5.582 | Epsilon: 0.0100 | Loss: 498639.5000
Episode 122300 | Reward: -11.841 | Epsilon: 0.0100 | Loss: 415363.2500
Episode 122350 | Reward:  -8.492 | Epsilon: 0.0100 | Loss: 386700.5000
Episode 122400 | Reward:  -9.008 | Epsilon: 0.0100 | Loss: 446484.2500
Episode 122450 | Reward: -10.305 | Epsilon: 0.0100 | Loss: 469698.9375
Episode 122500 | Reward:  -9.277 | Epsilon: 0.0100 | Loss: 456485.2812
Episode 122550 | Reward: -10.157 | Epsilon: 0.0100 | Loss: 469835.3750
Episode 122600 | Reward:  -8.653 | Epsilon: 0.0100 | Loss: 452384.6562
Episode 122650 | Reward: -10.432 | Epsilon: 0.0100 | Loss: 510629.0312
Episode 122700 | Reward:  -7.192 | Epsilon: 0.0100 | Loss: 562827.8750
Episode 122750 | Reward: -10.200 | Epsilon: 0.0100 | Loss: 515820.0938
Episode 122800 | Reward:  -9.018 | Epsilon: 0.0100 | Loss: 555513.2500
Episode 122850 | Reward:  -9.863 | Epsilon: 0.0100 | Loss: 563759.1250
Episode 122900 | Reward: -13.548 | Epsilon: 0.0100 | Loss: 439331.5625
Episode 122950 | Reward: -13.933 | Epsilon: 0.0100 | Loss: 585583.7500
Episode 123000 | Reward: -11.968 | Epsilon: 0.0100 | Loss: 466356.3125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:18).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:18).dict
Episode 123050 | Reward:  -9.631 | Epsilon: 0.0100 | Loss: 503362.9688
Episode 123100 | Reward: -12.040 | Epsilon: 0.0100 | Loss: 533021.1875
Episode 123150 | Reward: -10.136 | Epsilon: 0.0100 | Loss: 715408.5000
Episode 123200 | Reward:  -9.057 | Epsilon: 0.0100 | Loss: 642105.5625
Episode 123250 | Reward: -12.512 | Epsilon: 0.0100 | Loss: 531339.4375
Episode 123300 | Reward: -13.351 | Epsilon: 0.0100 | Loss: 401610.7500
Episode 123350 | Reward:  -7.147 | Epsilon: 0.0100 | Loss: 646598.2500
Episode 123400 | Reward:  -5.207 | Epsilon: 0.0100 | Loss: 549128.8125
Episode 123450 | Reward:  -8.823 | Epsilon: 0.0100 | Loss: 504713.8438
Episode 123500 | Reward: -10.867 | Epsilon: 0.0100 | Loss: 369168.3750
Episode 123550 | Reward: -10.450 | Epsilon: 0.0100 | Loss: 637063.7500
Episode 123600 | Reward:  -6.563 | Epsilon: 0.0100 | Loss: 496733.0312
Episode 123650 | Reward: -13.291 | Epsilon: 0.0100 | Loss: 514310.2500
Episode 123700 | Reward: -13.114 | Epsilon: 0.0100 | Loss: 416611.0312
Episode 123750 | Reward:  -8.270 | Epsilon: 0.0100 | Loss: 460603.8125
Episode 123800 | Reward: -14.146 | Epsilon: 0.0100 | Loss: 667229.3750
Episode 123850 | Reward: -18.853 | Epsilon: 0.0100 | Loss: 555279.7500
Episode 123900 | Reward: -15.784 | Epsilon: 0.0100 | Loss: 430094.6875
Episode 123950 | Reward: -10.419 | Epsilon: 0.0100 | Loss: 574390.1250
Episode 124000 | Reward: -10.819 | Epsilon: 0.0100 | Loss: 657849.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:22).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:22).dict
Episode 124050 | Reward: -10.879 | Epsilon: 0.0100 | Loss: 426507.2188
Episode 124100 | Reward:  -6.524 | Epsilon: 0.0100 | Loss: 512687.8750
Episode 124150 | Reward:  -9.584 | Epsilon: 0.0100 | Loss: 527491.5625
Episode 124200 | Reward: -10.027 | Epsilon: 0.0100 | Loss: 498218.6250
Episode 124250 | Reward: -10.451 | Epsilon: 0.0100 | Loss: 599207.0625
Episode 124300 | Reward:  -7.618 | Epsilon: 0.0100 | Loss: 403451.9062
Episode 124350 | Reward:  -6.455 | Epsilon: 0.0100 | Loss: 613650.7500
Episode 124400 | Reward: -13.190 | Epsilon: 0.0100 | Loss: 480829.4062
Episode 124450 | Reward: -13.098 | Epsilon: 0.0100 | Loss: 478747.3750
Episode 124500 | Reward:  -9.572 | Epsilon: 0.0100 | Loss: 454781.5312
Episode 124550 | Reward: -11.348 | Epsilon: 0.0100 | Loss: 540167.8125
Episode 124600 | Reward:  -8.905 | Epsilon: 0.0100 | Loss: 556074.5625
Episode 124650 | Reward: -11.456 | Epsilon: 0.0100 | Loss: 406734.1875
Episode 124700 | Reward:  -8.804 | Epsilon: 0.0100 | Loss: 528813.0000
Episode 124750 | Reward:  -9.097 | Epsilon: 0.0100 | Loss: 477175.7812
Episode 124800 | Reward:  -8.339 | Epsilon: 0.0100 | Loss: 513813.2500
Episode 124850 | Reward:  -8.352 | Epsilon: 0.0100 | Loss: 593317.3750
Episode 124900 | Reward: -10.668 | Epsilon: 0.0100 | Loss: 443203.2500
Episode 124950 | Reward: -13.577 | Epsilon: 0.0100 | Loss: 497185.1875
Episode 125000 | Reward: -15.903 | Epsilon: 0.0100 | Loss: 638280.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:26).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:26).dict
Episode 125050 | Reward: -12.564 | Epsilon: 0.0100 | Loss: 426873.1562
Episode 125100 | Reward: -10.492 | Epsilon: 0.0100 | Loss: 422927.5000
Episode 125150 | Reward:  -6.554 | Epsilon: 0.0100 | Loss: 548002.6875
Episode 125200 | Reward:  -9.996 | Epsilon: 0.0100 | Loss: 490350.5625
Episode 125250 | Reward: -12.531 | Epsilon: 0.0100 | Loss: 503393.5000
Episode 125300 | Reward: -10.448 | Epsilon: 0.0100 | Loss: 482483.2812
Episode 125350 | Reward: -15.347 | Epsilon: 0.0100 | Loss: 569211.0000
Episode 125400 | Reward: -14.688 | Epsilon: 0.0100 | Loss: 382281.5000
Episode 125450 | Reward: -14.546 | Epsilon: 0.0100 | Loss: 601048.3125
Episode 125500 | Reward: -13.769 | Epsilon: 0.0100 | Loss: 430576.0000
Episode 125550 | Reward:  -9.914 | Epsilon: 0.0100 | Loss: 431898.6562
Episode 125600 | Reward: -11.351 | Epsilon: 0.0100 | Loss: 485897.4688
Episode 125650 | Reward:  -9.242 | Epsilon: 0.0100 | Loss: 556395.0625
Episode 125700 | Reward: -10.027 | Epsilon: 0.0100 | Loss: 562084.8125
Episode 125750 | Reward:  -6.507 | Epsilon: 0.0100 | Loss: 517230.4375
Episode 125800 | Reward: -11.330 | Epsilon: 0.0100 | Loss: 573804.3750
Episode 125850 | Reward: -13.564 | Epsilon: 0.0100 | Loss: 456968.1875
Episode 125900 | Reward:  -8.848 | Epsilon: 0.0100 | Loss: 430668.0312
Episode 125950 | Reward: -11.342 | Epsilon: 0.0100 | Loss: 587006.4375
Episode 126000 | Reward: -11.616 | Epsilon: 0.0100 | Loss: 434807.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:30).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:30).dict
Episode 126050 | Reward:  -7.708 | Epsilon: 0.0100 | Loss: 351192.4375
Episode 126100 | Reward: -11.009 | Epsilon: 0.0100 | Loss: 459489.3750
Episode 126150 | Reward: -12.694 | Epsilon: 0.0100 | Loss: 508062.1250
Episode 126200 | Reward:  -6.583 | Epsilon: 0.0100 | Loss: 478121.5625
Episode 126250 | Reward: -10.024 | Epsilon: 0.0100 | Loss: 475167.7500
Episode 126300 | Reward: -10.935 | Epsilon: 0.0100 | Loss: 526008.1875
Episode 126350 | Reward: -15.906 | Epsilon: 0.0100 | Loss: 517581.9062
Episode 126400 | Reward: -12.598 | Epsilon: 0.0100 | Loss: 562060.1250
Episode 126450 | Reward: -11.046 | Epsilon: 0.0100 | Loss: 528518.7500
Episode 126500 | Reward: -14.341 | Epsilon: 0.0100 | Loss: 520192.0312
Episode 126550 | Reward: -12.682 | Epsilon: 0.0100 | Loss: 438875.3125
Episode 126600 | Reward: -10.116 | Epsilon: 0.0100 | Loss: 432557.0625
Episode 126650 | Reward: -10.667 | Epsilon: 0.0100 | Loss: 419116.5000
Episode 126700 | Reward: -12.554 | Epsilon: 0.0100 | Loss: 394154.4062
Episode 126750 | Reward: -11.713 | Epsilon: 0.0100 | Loss: 433982.6875
Episode 126800 | Reward:  -8.920 | Epsilon: 0.0100 | Loss: 515051.3125
Episode 126850 | Reward: -12.222 | Epsilon: 0.0100 | Loss: 626350.1875
Episode 126900 | Reward:  -9.505 | Epsilon: 0.0100 | Loss: 656192.6875
Episode 126950 | Reward:  -9.262 | Epsilon: 0.0100 | Loss: 507450.7812
Episode 127000 | Reward: -10.612 | Epsilon: 0.0100 | Loss: 528632.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:34).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:34).dict
Episode 127050 | Reward: -10.583 | Epsilon: 0.0100 | Loss: 551509.1250
Episode 127100 | Reward: -15.184 | Epsilon: 0.0100 | Loss: 520054.2500
Episode 127150 | Reward:  -9.839 | Epsilon: 0.0100 | Loss: 543178.0625
Episode 127200 | Reward: -17.615 | Epsilon: 0.0100 | Loss: 537570.5000
Episode 127250 | Reward: -11.610 | Epsilon: 0.0100 | Loss: 583787.6250
Episode 127300 | Reward: -10.981 | Epsilon: 0.0100 | Loss: 529816.6250
Episode 127350 | Reward:  -8.643 | Epsilon: 0.0100 | Loss: 531574.0000
Episode 127400 | Reward: -11.064 | Epsilon: 0.0100 | Loss: 506166.0000
Episode 127450 | Reward: -11.097 | Epsilon: 0.0100 | Loss: 453141.5625
Episode 127500 | Reward: -13.762 | Epsilon: 0.0100 | Loss: 637339.1875
Episode 127550 | Reward: -11.361 | Epsilon: 0.0100 | Loss: 489687.6875
Episode 127600 | Reward:  -9.805 | Epsilon: 0.0100 | Loss: 484179.9688
Episode 127650 | Reward:  -9.245 | Epsilon: 0.0100 | Loss: 424398.9688
Episode 127700 | Reward: -10.837 | Epsilon: 0.0100 | Loss: 545250.3125
Episode 127750 | Reward:  -9.933 | Epsilon: 0.0100 | Loss: 575713.6875
Episode 127800 | Reward:  -7.063 | Epsilon: 0.0100 | Loss: 559142.2500
Episode 127850 | Reward:  -7.901 | Epsilon: 0.0100 | Loss: 668993.7500
Episode 127900 | Reward: -12.093 | Epsilon: 0.0100 | Loss: 478542.8750
Episode 127950 | Reward: -11.144 | Epsilon: 0.0100 | Loss: 442534.6562
Episode 128000 | Reward:  -9.757 | Epsilon: 0.0100 | Loss: 555888.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:38).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:38).dict
Episode 128050 | Reward: -10.758 | Epsilon: 0.0100 | Loss: 525437.3750
Episode 128100 | Reward:  -8.019 | Epsilon: 0.0100 | Loss: 504411.9375
Episode 128150 | Reward: -10.729 | Epsilon: 0.0100 | Loss: 508311.8438
Episode 128200 | Reward: -10.673 | Epsilon: 0.0100 | Loss: 460576.6875
Episode 128250 | Reward:  -9.911 | Epsilon: 0.0100 | Loss: 673977.3125
Episode 128300 | Reward: -11.770 | Epsilon: 0.0100 | Loss: 500893.1875
Episode 128350 | Reward: -14.059 | Epsilon: 0.0100 | Loss: 449206.5625
Episode 128400 | Reward: -12.365 | Epsilon: 0.0100 | Loss: 590044.8750
Episode 128450 | Reward: -13.816 | Epsilon: 0.0100 | Loss: 587137.2500
Episode 128500 | Reward: -10.548 | Epsilon: 0.0100 | Loss: 530646.6875
Episode 128550 | Reward: -10.940 | Epsilon: 0.0100 | Loss: 648027.5000
Episode 128600 | Reward:  -9.380 | Epsilon: 0.0100 | Loss: 493282.5625
Episode 128650 | Reward: -11.075 | Epsilon: 0.0100 | Loss: 590133.7500
Episode 128700 | Reward:  -8.604 | Epsilon: 0.0100 | Loss: 419607.1250
Episode 128750 | Reward:  -7.219 | Epsilon: 0.0100 | Loss: 539914.1875
Episode 128800 | Reward: -12.091 | Epsilon: 0.0100 | Loss: 667600.1875
Episode 128850 | Reward: -11.149 | Epsilon: 0.0100 | Loss: 557749.5000
Episode 128900 | Reward: -12.050 | Epsilon: 0.0100 | Loss: 599062.9375
Episode 128950 | Reward: -14.874 | Epsilon: 0.0100 | Loss: 546850.6875
Episode 129000 | Reward: -13.043 | Epsilon: 0.0100 | Loss: 604845.6250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:42).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:42).dict
Episode 129050 | Reward: -10.467 | Epsilon: 0.0100 | Loss: 551507.8750
Episode 129100 | Reward: -10.467 | Epsilon: 0.0100 | Loss: 458860.2188
Episode 129150 | Reward: -13.986 | Epsilon: 0.0100 | Loss: 528093.5000
Episode 129200 | Reward: -11.712 | Epsilon: 0.0100 | Loss: 539751.0000
Episode 129250 | Reward:  -9.159 | Epsilon: 0.0100 | Loss: 415797.0625
Episode 129300 | Reward: -14.019 | Epsilon: 0.0100 | Loss: 472132.9688
Episode 129350 | Reward: -11.968 | Epsilon: 0.0100 | Loss: 555791.1250
Episode 129400 | Reward:  -8.848 | Epsilon: 0.0100 | Loss: 490642.7812
Episode 129450 | Reward: -10.157 | Epsilon: 0.0100 | Loss: 427825.8750
Episode 129500 | Reward: -10.275 | Epsilon: 0.0100 | Loss: 609879.0000
Episode 129550 | Reward: -10.428 | Epsilon: 0.0100 | Loss: 488136.9688
Episode 129600 | Reward:  -9.552 | Epsilon: 0.0100 | Loss: 549010.3750
Episode 129650 | Reward: -10.643 | Epsilon: 0.0100 | Loss: 575497.6250
Episode 129700 | Reward:  -9.998 | Epsilon: 0.0100 | Loss: 432230.0000
Episode 129750 | Reward:  -9.868 | Epsilon: 0.0100 | Loss: 550466.1250
Episode 129800 | Reward:  -9.559 | Epsilon: 0.0100 | Loss: 669902.0000
Episode 129850 | Reward:  -8.475 | Epsilon: 0.0100 | Loss: 460081.9375
Episode 129900 | Reward: -14.190 | Epsilon: 0.0100 | Loss: 504073.6250
Episode 129950 | Reward: -12.764 | Epsilon: 0.0100 | Loss: 537860.6250
Episode 130000 | Reward:  -8.804 | Epsilon: 0.0100 | Loss: 504991.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:46).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:46).dict
Episode 130050 | Reward: -12.272 | Epsilon: 0.0100 | Loss: 595624.6875
Episode 130100 | Reward: -10.515 | Epsilon: 0.0100 | Loss: 560406.6875
Episode 130150 | Reward:  -8.580 | Epsilon: 0.0100 | Loss: 579810.0000
Episode 130200 | Reward:  -3.517 | Epsilon: 0.0100 | Loss: 523878.2500
Episode 130250 | Reward: -12.290 | Epsilon: 0.0100 | Loss: 464893.5312
Episode 130300 | Reward:  -5.500 | Epsilon: 0.0100 | Loss: 475680.7500
Episode 130350 | Reward:  -5.015 | Epsilon: 0.0100 | Loss: 624422.2500
Episode 130400 | Reward: -11.606 | Epsilon: 0.0100 | Loss: 599027.6250
Episode 130450 | Reward:  -5.729 | Epsilon: 0.0100 | Loss: 527329.2500
Episode 130500 | Reward:  -8.579 | Epsilon: 0.0100 | Loss: 486709.9062
Episode 130550 | Reward: -14.883 | Epsilon: 0.0100 | Loss: 497763.4375
Episode 130600 | Reward:  -9.108 | Epsilon: 0.0100 | Loss: 582279.0625
Episode 130650 | Reward: -11.383 | Epsilon: 0.0100 | Loss: 492472.1562
Episode 130700 | Reward: -10.240 | Epsilon: 0.0100 | Loss: 546454.3125
Episode 130750 | Reward:  -7.811 | Epsilon: 0.0100 | Loss: 482053.8438
Episode 130800 | Reward: -11.414 | Epsilon: 0.0100 | Loss: 438802.9688
Episode 130850 | Reward: -12.653 | Epsilon: 0.0100 | Loss: 585056.4375
Episode 130900 | Reward:  -7.425 | Epsilon: 0.0100 | Loss: 314636.9688
Episode 130950 | Reward: -13.655 | Epsilon: 0.0100 | Loss: 562784.4375
Episode 131000 | Reward:  -9.664 | Epsilon: 0.0100 | Loss: 391800.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:50).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:50).dict
Episode 131050 | Reward: -11.376 | Epsilon: 0.0100 | Loss: 440163.6250
Episode 131100 | Reward: -12.879 | Epsilon: 0.0100 | Loss: 445603.0625
Episode 131150 | Reward:  -9.697 | Epsilon: 0.0100 | Loss: 481704.5312
Episode 131200 | Reward: -10.766 | Epsilon: 0.0100 | Loss: 419304.1562
Episode 131250 | Reward: -11.070 | Epsilon: 0.0100 | Loss: 379124.6250
Episode 131300 | Reward: -10.452 | Epsilon: 0.0100 | Loss: 509236.1562
Episode 131350 | Reward: -13.217 | Epsilon: 0.0100 | Loss: 321652.5000
Episode 131400 | Reward: -20.640 | Epsilon: 0.0100 | Loss: 429179.6250
Episode 131450 | Reward: -18.713 | Epsilon: 0.0100 | Loss: 525134.5625
Episode 131500 | Reward: -11.110 | Epsilon: 0.0100 | Loss: 516523.7812
Episode 131550 | Reward: -11.748 | Epsilon: 0.0100 | Loss: 480732.5938
Episode 131600 | Reward: -13.854 | Epsilon: 0.0100 | Loss: 387164.9688
Episode 131650 | Reward: -10.475 | Epsilon: 0.0100 | Loss: 563600.7500
Episode 131700 | Reward: -15.541 | Epsilon: 0.0100 | Loss: 541512.7500
Episode 131750 | Reward: -12.933 | Epsilon: 0.0100 | Loss: 601212.5625
Episode 131800 | Reward: -14.096 | Epsilon: 0.0100 | Loss: 665903.5000
Episode 131850 | Reward: -11.961 | Epsilon: 0.0100 | Loss: 417656.2500
Episode 131900 | Reward: -10.413 | Epsilon: 0.0100 | Loss: 412635.6562
Episode 131950 | Reward: -13.220 | Epsilon: 0.0100 | Loss: 501839.6250
Episode 132000 | Reward:  -9.844 | Epsilon: 0.0100 | Loss: 474117.0312
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:54).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:54).dict
Episode 132050 | Reward: -10.454 | Epsilon: 0.0100 | Loss: 508710.8750
Episode 132100 | Reward: -11.058 | Epsilon: 0.0100 | Loss: 577946.9375
Episode 132150 | Reward: -12.093 | Epsilon: 0.0100 | Loss: 595434.8750
Episode 132200 | Reward: -12.125 | Epsilon: 0.0100 | Loss: 523424.6250
Episode 132250 | Reward: -10.846 | Epsilon: 0.0100 | Loss: 616804.9375
Episode 132300 | Reward:  -9.905 | Epsilon: 0.0100 | Loss: 476323.8438
Episode 132350 | Reward: -10.357 | Epsilon: 0.0100 | Loss: 563125.2500
Episode 132400 | Reward:  -8.519 | Epsilon: 0.0100 | Loss: 527229.1250
Episode 132450 | Reward:  -9.344 | Epsilon: 0.0100 | Loss: 594845.7500
Episode 132500 | Reward:  -7.115 | Epsilon: 0.0100 | Loss: 431579.1250
Episode 132550 | Reward: -10.097 | Epsilon: 0.0100 | Loss: 630752.6250
Episode 132600 | Reward:  -8.158 | Epsilon: 0.0100 | Loss: 538714.4375
Episode 132650 | Reward:  -6.752 | Epsilon: 0.0100 | Loss: 484466.0625
Episode 132700 | Reward: -11.099 | Epsilon: 0.0100 | Loss: 534551.6250
Episode 132750 | Reward: -11.494 | Epsilon: 0.0100 | Loss: 543320.7500
Episode 132800 | Reward:  -9.842 | Epsilon: 0.0100 | Loss: 634854.1875
Episode 132850 | Reward:  -8.611 | Epsilon: 0.0100 | Loss: 549975.4375
Episode 132900 | Reward: -10.436 | Epsilon: 0.0100 | Loss: 599076.2500
Episode 132950 | Reward: -12.275 | Epsilon: 0.0100 | Loss: 486463.3438
Episode 133000 | Reward:  -5.119 | Epsilon: 0.0100 | Loss: 455570.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:58).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(09:58).dict
Episode 133050 | Reward: -11.411 | Epsilon: 0.0100 | Loss: 631252.3750
Episode 133100 | Reward: -11.536 | Epsilon: 0.0100 | Loss: 587771.4375
Episode 133150 | Reward: -10.807 | Epsilon: 0.0100 | Loss: 560905.1250
Episode 133200 | Reward:  -6.317 | Epsilon: 0.0100 | Loss: 623684.8125
Episode 133250 | Reward:  -8.200 | Epsilon: 0.0100 | Loss: 622264.6250
Episode 133300 | Reward: -12.289 | Epsilon: 0.0100 | Loss: 541826.6875
Episode 133350 | Reward: -10.393 | Epsilon: 0.0100 | Loss: 457293.5938
Episode 133400 | Reward:  -9.893 | Epsilon: 0.0100 | Loss: 596499.1875
Episode 133450 | Reward:  -8.627 | Epsilon: 0.0100 | Loss: 572529.4375
Episode 133500 | Reward: -10.149 | Epsilon: 0.0100 | Loss: 545636.6875
Episode 133550 | Reward:  -7.214 | Epsilon: 0.0100 | Loss: 594530.1250
Episode 133600 | Reward: -10.330 | Epsilon: 0.0100 | Loss: 550033.5625
Episode 133650 | Reward: -13.070 | Epsilon: 0.0100 | Loss: 527667.0625
Episode 133700 | Reward: -12.423 | Epsilon: 0.0100 | Loss: 605941.9375
Episode 133750 | Reward:  -8.194 | Epsilon: 0.0100 | Loss: 590287.1250
Episode 133800 | Reward: -12.486 | Epsilon: 0.0100 | Loss: 520865.2500
Episode 133850 | Reward: -12.059 | Epsilon: 0.0100 | Loss: 483165.5625
Episode 133900 | Reward: -12.497 | Epsilon: 0.0100 | Loss: 656305.6250
Episode 133950 | Reward: -12.135 | Epsilon: 0.0100 | Loss: 496785.1875
Episode 134000 | Reward: -11.808 | Epsilon: 0.0100 | Loss: 494157.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:02).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:02).dict
Episode 134050 | Reward:  -8.731 | Epsilon: 0.0100 | Loss: 367451.5312
Episode 134100 | Reward: -10.369 | Epsilon: 0.0100 | Loss: 493631.0938
Episode 134150 | Reward:  -9.642 | Epsilon: 0.0100 | Loss: 504620.7500
Episode 134200 | Reward:  -8.528 | Epsilon: 0.0100 | Loss: 413681.0625
Episode 134250 | Reward: -10.333 | Epsilon: 0.0100 | Loss: 548180.3125
Episode 134300 | Reward:  -8.636 | Epsilon: 0.0100 | Loss: 507244.4375
Episode 134350 | Reward: -12.358 | Epsilon: 0.0100 | Loss: 614443.1250
Episode 134400 | Reward: -10.978 | Epsilon: 0.0100 | Loss: 639635.2500
Episode 134450 | Reward: -12.632 | Epsilon: 0.0100 | Loss: 650882.3125
Episode 134500 | Reward:  -6.893 | Epsilon: 0.0100 | Loss: 601153.5000
Episode 134550 | Reward: -12.302 | Epsilon: 0.0100 | Loss: 557044.3125
Episode 134600 | Reward:  -7.167 | Epsilon: 0.0100 | Loss: 556162.1250
Episode 134650 | Reward:  -8.706 | Epsilon: 0.0100 | Loss: 590695.3750
Episode 134700 | Reward: -12.087 | Epsilon: 0.0100 | Loss: 685388.7500
Episode 134750 | Reward: -14.503 | Epsilon: 0.0100 | Loss: 642565.2500
Episode 134800 | Reward: -12.575 | Epsilon: 0.0100 | Loss: 547032.1875
Episode 134850 | Reward: -11.019 | Epsilon: 0.0100 | Loss: 665519.9375
Episode 134900 | Reward: -14.207 | Epsilon: 0.0100 | Loss: 555520.0625
Episode 134950 | Reward: -12.647 | Epsilon: 0.0100 | Loss: 514061.2812
Episode 135000 | Reward: -10.933 | Epsilon: 0.0100 | Loss: 571995.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:06).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:06).dict
Episode 135050 | Reward: -10.644 | Epsilon: 0.0100 | Loss: 555456.0000
Episode 135100 | Reward: -12.417 | Epsilon: 0.0100 | Loss: 584636.3125
Episode 135150 | Reward: -12.650 | Epsilon: 0.0100 | Loss: 387211.9375
Episode 135200 | Reward: -11.094 | Epsilon: 0.0100 | Loss: 470234.6250
Episode 135250 | Reward:  -9.977 | Epsilon: 0.0100 | Loss: 585639.5000
Episode 135300 | Reward:  -9.701 | Epsilon: 0.0100 | Loss: 368007.5000
Episode 135350 | Reward: -12.530 | Epsilon: 0.0100 | Loss: 485737.7188
Episode 135400 | Reward: -10.112 | Epsilon: 0.0100 | Loss: 515057.6250
Episode 135450 | Reward: -12.185 | Epsilon: 0.0100 | Loss: 462124.8438
Episode 135500 | Reward:  -9.611 | Epsilon: 0.0100 | Loss: 464218.0000
Episode 135550 | Reward:  -8.353 | Epsilon: 0.0100 | Loss: 440512.8750
Episode 135600 | Reward:  -7.715 | Epsilon: 0.0100 | Loss: 527192.3125
Episode 135650 | Reward:  -8.436 | Epsilon: 0.0100 | Loss: 597914.0000
Episode 135700 | Reward: -11.220 | Epsilon: 0.0100 | Loss: 531441.1250
Episode 135750 | Reward: -11.633 | Epsilon: 0.0100 | Loss: 520358.3125
Episode 135800 | Reward:  -5.981 | Epsilon: 0.0100 | Loss: 492051.8125
Episode 135850 | Reward:  -6.186 | Epsilon: 0.0100 | Loss: 561301.3125
Episode 135900 | Reward:  -7.226 | Epsilon: 0.0100 | Loss: 429857.9688
Episode 135950 | Reward: -12.245 | Epsilon: 0.0100 | Loss: 439632.0625
Episode 136000 | Reward:  -4.707 | Epsilon: 0.0100 | Loss: 536341.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:10).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:10).dict
Episode 136050 | Reward: -11.691 | Epsilon: 0.0100 | Loss: 511322.4375
Episode 136100 | Reward: -13.845 | Epsilon: 0.0100 | Loss: 463102.5938
Episode 136150 | Reward:  -8.673 | Epsilon: 0.0100 | Loss: 342889.9688
Episode 136200 | Reward:  -9.753 | Epsilon: 0.0100 | Loss: 593879.6250
Episode 136250 | Reward:  -6.980 | Epsilon: 0.0100 | Loss: 386537.6250
Episode 136300 | Reward: -11.108 | Epsilon: 0.0100 | Loss: 552107.5625
Episode 136350 | Reward:  -9.493 | Epsilon: 0.0100 | Loss: 458833.4062
Episode 136400 | Reward:  -6.925 | Epsilon: 0.0100 | Loss: 595429.8750
Episode 136450 | Reward: -12.591 | Epsilon: 0.0100 | Loss: 483142.1875
Episode 136500 | Reward: -11.644 | Epsilon: 0.0100 | Loss: 510489.4375
Episode 136550 | Reward: -11.286 | Epsilon: 0.0100 | Loss: 517425.0625
Episode 136600 | Reward: -12.978 | Epsilon: 0.0100 | Loss: 544774.0625
Episode 136650 | Reward: -12.424 | Epsilon: 0.0100 | Loss: 552145.1875
Episode 136700 | Reward: -11.684 | Epsilon: 0.0100 | Loss: 604855.3750
Episode 136750 | Reward: -11.715 | Epsilon: 0.0100 | Loss: 585174.4375
Episode 136800 | Reward:  -7.969 | Epsilon: 0.0100 | Loss: 457326.2812
Episode 136850 | Reward:  -9.733 | Epsilon: 0.0100 | Loss: 546009.5625
Episode 136900 | Reward: -12.200 | Epsilon: 0.0100 | Loss: 623731.3125
Episode 136950 | Reward:  -7.996 | Epsilon: 0.0100 | Loss: 599739.8125
Episode 137000 | Reward: -11.194 | Epsilon: 0.0100 | Loss: 466486.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:14).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:14).dict
Episode 137050 | Reward: -11.711 | Epsilon: 0.0100 | Loss: 470500.7188
Episode 137100 | Reward:  -9.135 | Epsilon: 0.0100 | Loss: 580214.9375
Episode 137150 | Reward:  -9.224 | Epsilon: 0.0100 | Loss: 499167.4062
Episode 137200 | Reward:  -8.182 | Epsilon: 0.0100 | Loss: 477863.3125
Episode 137250 | Reward:  -9.560 | Epsilon: 0.0100 | Loss: 412160.6562
Episode 137300 | Reward:  -9.000 | Epsilon: 0.0100 | Loss: 432180.1875
Episode 137350 | Reward: -12.265 | Epsilon: 0.0100 | Loss: 429047.4062
Episode 137400 | Reward:  -9.707 | Epsilon: 0.0100 | Loss: 462970.0938
Episode 137450 | Reward:  -9.149 | Epsilon: 0.0100 | Loss: 460784.0938
Episode 137500 | Reward: -11.650 | Epsilon: 0.0100 | Loss: 517928.1875
Episode 137550 | Reward: -11.526 | Epsilon: 0.0100 | Loss: 636087.1250
Episode 137600 | Reward:  -7.796 | Epsilon: 0.0100 | Loss: 470277.6250
Episode 137650 | Reward:  -5.493 | Epsilon: 0.0100 | Loss: 499120.0000
Episode 137700 | Reward:  -7.044 | Epsilon: 0.0100 | Loss: 517309.5312
Episode 137750 | Reward:  -9.602 | Epsilon: 0.0100 | Loss: 658135.6250
Episode 137800 | Reward:  -9.979 | Epsilon: 0.0100 | Loss: 679900.8750
Episode 137850 | Reward:  -9.413 | Epsilon: 0.0100 | Loss: 607760.6250
Episode 137900 | Reward:  -7.844 | Epsilon: 0.0100 | Loss: 591827.0000
Episode 137950 | Reward: -12.581 | Epsilon: 0.0100 | Loss: 579233.8125
Episode 138000 | Reward: -13.201 | Epsilon: 0.0100 | Loss: 681485.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:18).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:18).dict
Episode 138050 | Reward: -13.319 | Epsilon: 0.0100 | Loss: 608707.7500
Episode 138100 | Reward: -11.491 | Epsilon: 0.0100 | Loss: 603490.6875
Episode 138150 | Reward: -12.939 | Epsilon: 0.0100 | Loss: 723180.8750
Episode 138200 | Reward: -14.734 | Epsilon: 0.0100 | Loss: 512034.2188
Episode 138250 | Reward: -10.328 | Epsilon: 0.0100 | Loss: 496981.2188
Episode 138300 | Reward: -13.884 | Epsilon: 0.0100 | Loss: 441840.7812
Episode 138350 | Reward: -11.935 | Epsilon: 0.0100 | Loss: 466244.4062
Episode 138400 | Reward:  -7.197 | Epsilon: 0.0100 | Loss: 441206.4688
Episode 138450 | Reward:  -7.539 | Epsilon: 0.0100 | Loss: 492535.1562
Episode 138500 | Reward: -11.028 | Epsilon: 0.0100 | Loss: 563979.3750
Episode 138550 | Reward: -12.826 | Epsilon: 0.0100 | Loss: 641174.2500
Episode 138600 | Reward:  -7.518 | Epsilon: 0.0100 | Loss: 606408.0000
Episode 138650 | Reward: -13.962 | Epsilon: 0.0100 | Loss: 587025.2500
Episode 138700 | Reward: -10.548 | Epsilon: 0.0100 | Loss: 522054.9375
Episode 138750 | Reward: -11.526 | Epsilon: 0.0100 | Loss: 527738.9375
Episode 138800 | Reward: -10.804 | Epsilon: 0.0100 | Loss: 636479.8125
Episode 138850 | Reward: -12.652 | Epsilon: 0.0100 | Loss: 660890.1875
Episode 138900 | Reward: -10.930 | Epsilon: 0.0100 | Loss: 612349.8750
Episode 138950 | Reward: -13.636 | Epsilon: 0.0100 | Loss: 493145.2500
Episode 139000 | Reward: -12.713 | Epsilon: 0.0100 | Loss: 638272.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:22).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:22).dict
Episode 139050 | Reward: -10.157 | Epsilon: 0.0100 | Loss: 477175.3438
Episode 139100 | Reward:  -9.685 | Epsilon: 0.0100 | Loss: 632145.5000
Episode 139150 | Reward: -12.377 | Epsilon: 0.0100 | Loss: 598144.1250
Episode 139200 | Reward: -11.274 | Epsilon: 0.0100 | Loss: 494939.5625
Episode 139250 | Reward: -11.083 | Epsilon: 0.0100 | Loss: 492706.3750
Episode 139300 | Reward: -10.361 | Epsilon: 0.0100 | Loss: 594422.3750
Episode 139350 | Reward:  -9.583 | Epsilon: 0.0100 | Loss: 439359.3750
Episode 139400 | Reward:  -9.327 | Epsilon: 0.0100 | Loss: 590306.8750
Episode 139450 | Reward: -13.926 | Epsilon: 0.0100 | Loss: 436418.2812
Episode 139500 | Reward: -12.557 | Epsilon: 0.0100 | Loss: 541645.8750
Episode 139550 | Reward: -13.400 | Epsilon: 0.0100 | Loss: 417352.3750
Episode 139600 | Reward: -14.356 | Epsilon: 0.0100 | Loss: 550793.9375
Episode 139650 | Reward: -12.640 | Epsilon: 0.0100 | Loss: 341606.3125
Episode 139700 | Reward: -10.080 | Epsilon: 0.0100 | Loss: 667306.7500
Episode 139750 | Reward: -10.494 | Epsilon: 0.0100 | Loss: 465680.7500
Episode 139800 | Reward:  -9.340 | Epsilon: 0.0100 | Loss: 634143.9375
Episode 139850 | Reward: -11.958 | Epsilon: 0.0100 | Loss: 584343.3750
Episode 139900 | Reward:  -9.232 | Epsilon: 0.0100 | Loss: 584711.6875
Episode 139950 | Reward:  -6.933 | Epsilon: 0.0100 | Loss: 455368.3125
Episode 140000 | Reward:  -6.969 | Epsilon: 0.0100 | Loss: 469911.9062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:26).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:26).dict
Episode 140050 | Reward: -10.878 | Epsilon: 0.0100 | Loss: 561852.8750
Episode 140100 | Reward: -10.627 | Epsilon: 0.0100 | Loss: 581826.0000
Episode 140150 | Reward:  -6.298 | Epsilon: 0.0100 | Loss: 608967.5625
Episode 140200 | Reward:  -5.668 | Epsilon: 0.0100 | Loss: 570809.1250
Episode 140250 | Reward: -10.301 | Epsilon: 0.0100 | Loss: 582844.5000
Episode 140300 | Reward: -12.987 | Epsilon: 0.0100 | Loss: 438305.1250
Episode 140350 | Reward: -12.292 | Epsilon: 0.0100 | Loss: 465953.7500
Episode 140400 | Reward: -13.108 | Epsilon: 0.0100 | Loss: 666976.9375
Episode 140450 | Reward: -12.275 | Epsilon: 0.0100 | Loss: 553813.1875
Episode 140500 | Reward: -11.108 | Epsilon: 0.0100 | Loss: 557650.0000
Episode 140550 | Reward: -13.313 | Epsilon: 0.0100 | Loss: 450524.3750
Episode 140600 | Reward: -11.042 | Epsilon: 0.0100 | Loss: 732933.1875
Episode 140650 | Reward: -10.594 | Epsilon: 0.0100 | Loss: 586195.3125
Episode 140700 | Reward: -14.406 | Epsilon: 0.0100 | Loss: 393798.6250
Episode 140750 | Reward: -12.167 | Epsilon: 0.0100 | Loss: 632885.3750
Episode 140800 | Reward: -14.347 | Epsilon: 0.0100 | Loss: 562215.9375
Episode 140850 | Reward: -10.932 | Epsilon: 0.0100 | Loss: 513040.4375
Episode 140900 | Reward: -12.736 | Epsilon: 0.0100 | Loss: 508014.2812
Episode 140950 | Reward:  -7.599 | Epsilon: 0.0100 | Loss: 667614.7500
Episode 141000 | Reward:  -9.978 | Epsilon: 0.0100 | Loss: 480266.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:30).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:30).dict
Episode 141050 | Reward:  -6.591 | Epsilon: 0.0100 | Loss: 524563.0625
Episode 141100 | Reward: -10.557 | Epsilon: 0.0100 | Loss: 470001.2500
Episode 141150 | Reward:  -8.350 | Epsilon: 0.0100 | Loss: 506653.5625
Episode 141200 | Reward: -10.917 | Epsilon: 0.0100 | Loss: 550820.5000
Episode 141250 | Reward: -12.253 | Epsilon: 0.0100 | Loss: 524164.7812
Episode 141300 | Reward:  -9.957 | Epsilon: 0.0100 | Loss: 522922.0312
Episode 141350 | Reward:  -9.685 | Epsilon: 0.0100 | Loss: 576674.1250
Episode 141400 | Reward: -10.497 | Epsilon: 0.0100 | Loss: 518717.3750
Episode 141450 | Reward: -10.488 | Epsilon: 0.0100 | Loss: 534196.8750
Episode 141500 | Reward:  -9.357 | Epsilon: 0.0100 | Loss: 714361.7500
Episode 141550 | Reward: -11.874 | Epsilon: 0.0100 | Loss: 555594.0000
Episode 141600 | Reward: -12.050 | Epsilon: 0.0100 | Loss: 483636.0938
Episode 141650 | Reward: -12.453 | Epsilon: 0.0100 | Loss: 711097.5625
Episode 141700 | Reward:  -8.642 | Epsilon: 0.0100 | Loss: 640413.5000
Episode 141750 | Reward: -12.621 | Epsilon: 0.0100 | Loss: 602244.0625
Episode 141800 | Reward: -10.770 | Epsilon: 0.0100 | Loss: 509307.7812
Episode 141850 | Reward:  -9.228 | Epsilon: 0.0100 | Loss: 513538.3125
Episode 141900 | Reward: -14.685 | Epsilon: 0.0100 | Loss: 455419.5000
Episode 141950 | Reward: -14.937 | Epsilon: 0.0100 | Loss: 631857.5625
Episode 142000 | Reward: -13.340 | Epsilon: 0.0100 | Loss: 598461.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:34).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:34).dict
Episode 142050 | Reward: -12.294 | Epsilon: 0.0100 | Loss: 655432.3125
Episode 142100 | Reward: -12.869 | Epsilon: 0.0100 | Loss: 507470.2500
Episode 142150 | Reward:  -9.462 | Epsilon: 0.0100 | Loss: 600622.8125
Episode 142200 | Reward:  -9.655 | Epsilon: 0.0100 | Loss: 575673.6250
Episode 142250 | Reward:  -6.443 | Epsilon: 0.0100 | Loss: 527219.5625
Episode 142300 | Reward: -12.343 | Epsilon: 0.0100 | Loss: 659770.5000
Episode 142350 | Reward: -11.386 | Epsilon: 0.0100 | Loss: 494679.0312
Episode 142400 | Reward: -11.415 | Epsilon: 0.0100 | Loss: 504909.6875
Episode 142450 | Reward:  -9.844 | Epsilon: 0.0100 | Loss: 539476.6250
Episode 142500 | Reward: -12.368 | Epsilon: 0.0100 | Loss: 642937.8125
Episode 142550 | Reward: -12.066 | Epsilon: 0.0100 | Loss: 539455.2500
Episode 142600 | Reward: -12.304 | Epsilon: 0.0100 | Loss: 581181.6875
Episode 142650 | Reward: -12.071 | Epsilon: 0.0100 | Loss: 645190.6875
Episode 142700 | Reward: -12.394 | Epsilon: 0.0100 | Loss: 543501.8750
Episode 142750 | Reward: -11.573 | Epsilon: 0.0100 | Loss: 615892.3750
Episode 142800 | Reward: -17.324 | Epsilon: 0.0100 | Loss: 546826.3125
Episode 142850 | Reward:  -8.780 | Epsilon: 0.0100 | Loss: 693374.6250
Episode 142900 | Reward: -11.576 | Epsilon: 0.0100 | Loss: 393457.1875
Episode 142950 | Reward: -12.647 | Epsilon: 0.0100 | Loss: 504919.2188
Episode 143000 | Reward:  -8.255 | Epsilon: 0.0100 | Loss: 555934.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:38).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:38).dict
Episode 143050 | Reward:  -8.558 | Epsilon: 0.0100 | Loss: 518904.7188
Episode 143100 | Reward:  -9.655 | Epsilon: 0.0100 | Loss: 511382.8750
Episode 143150 | Reward: -13.602 | Epsilon: 0.0100 | Loss: 615946.6875
Episode 143200 | Reward:  -6.684 | Epsilon: 0.0100 | Loss: 660113.1875
Episode 143250 | Reward:  -8.723 | Epsilon: 0.0100 | Loss: 498701.7188
Episode 143300 | Reward:  -7.184 | Epsilon: 0.0100 | Loss: 501167.0000
Episode 143350 | Reward:  -7.892 | Epsilon: 0.0100 | Loss: 455577.5625
Episode 143400 | Reward:  -8.111 | Epsilon: 0.0100 | Loss: 483840.0938
Episode 143450 | Reward:  -6.807 | Epsilon: 0.0100 | Loss: 487455.2500
Episode 143500 | Reward:  -9.426 | Epsilon: 0.0100 | Loss: 680955.6875
Episode 143550 | Reward:  -8.036 | Epsilon: 0.0100 | Loss: 604230.7500
Episode 143600 | Reward:  -7.839 | Epsilon: 0.0100 | Loss: 624180.6250
Episode 143650 | Reward:  -9.314 | Epsilon: 0.0100 | Loss: 470548.6562
Episode 143700 | Reward: -11.430 | Epsilon: 0.0100 | Loss: 435783.0625
Episode 143750 | Reward:  -9.826 | Epsilon: 0.0100 | Loss: 580872.3125
Episode 143800 | Reward: -10.204 | Epsilon: 0.0100 | Loss: 538555.0000
Episode 143850 | Reward:  -9.143 | Epsilon: 0.0100 | Loss: 439097.5938
Episode 143900 | Reward: -10.141 | Epsilon: 0.0100 | Loss: 608622.6250
Episode 143950 | Reward: -10.588 | Epsilon: 0.0100 | Loss: 540226.6250
Episode 144000 | Reward: -10.897 | Epsilon: 0.0100 | Loss: 506132.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:42).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:42).dict
Episode 144050 | Reward: -12.125 | Epsilon: 0.0100 | Loss: 484047.4375
Episode 144100 | Reward: -11.275 | Epsilon: 0.0100 | Loss: 593708.5625
Episode 144150 | Reward: -10.410 | Epsilon: 0.0100 | Loss: 464905.0938
Episode 144200 | Reward: -11.604 | Epsilon: 0.0100 | Loss: 514524.8750
Episode 144250 | Reward: -11.637 | Epsilon: 0.0100 | Loss: 483979.6250
Episode 144300 | Reward:  -9.954 | Epsilon: 0.0100 | Loss: 528885.5000
Episode 144350 | Reward: -10.855 | Epsilon: 0.0100 | Loss: 507188.6875
Episode 144400 | Reward: -10.748 | Epsilon: 0.0100 | Loss: 466620.5625
Episode 144450 | Reward: -13.639 | Epsilon: 0.0100 | Loss: 357317.7188
Episode 144500 | Reward: -13.085 | Epsilon: 0.0100 | Loss: 507728.2812
Episode 144550 | Reward:  -8.738 | Epsilon: 0.0100 | Loss: 480945.5625
Episode 144600 | Reward:  -9.056 | Epsilon: 0.0100 | Loss: 439772.9062
Episode 144650 | Reward: -14.291 | Epsilon: 0.0100 | Loss: 392607.2812
Episode 144700 | Reward: -12.456 | Epsilon: 0.0100 | Loss: 455074.0312
Episode 144750 | Reward: -10.885 | Epsilon: 0.0100 | Loss: 527622.1250
Episode 144800 | Reward: -11.213 | Epsilon: 0.0100 | Loss: 525072.6250
Episode 144850 | Reward: -10.580 | Epsilon: 0.0100 | Loss: 426714.4062
Episode 144900 | Reward: -10.256 | Epsilon: 0.0100 | Loss: 506122.3438
Episode 144950 | Reward:  -9.647 | Epsilon: 0.0100 | Loss: 394146.6250
Episode 145000 | Reward:  -5.453 | Epsilon: 0.0100 | Loss: 477061.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:46).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:46).dict
Episode 145050 | Reward:  -8.040 | Epsilon: 0.0100 | Loss: 501789.9375
Episode 145100 | Reward:  -9.270 | Epsilon: 0.0100 | Loss: 482153.9688
Episode 145150 | Reward: -13.183 | Epsilon: 0.0100 | Loss: 461915.2812
Episode 145200 | Reward: -13.267 | Epsilon: 0.0100 | Loss: 405658.1875
Episode 145250 | Reward: -15.018 | Epsilon: 0.0100 | Loss: 459115.0312
Episode 145300 | Reward: -13.444 | Epsilon: 0.0100 | Loss: 433883.1562
Episode 145350 | Reward: -10.000 | Epsilon: 0.0100 | Loss: 470353.8750
Episode 145400 | Reward: -12.633 | Epsilon: 0.0100 | Loss: 454239.9688
Episode 145450 | Reward: -13.012 | Epsilon: 0.0100 | Loss: 488272.1875
Episode 145500 | Reward: -13.181 | Epsilon: 0.0100 | Loss: 380140.2812
Episode 145550 | Reward:  -9.998 | Epsilon: 0.0100 | Loss: 376308.8750
Episode 145600 | Reward:  -9.746 | Epsilon: 0.0100 | Loss: 404108.5312
Episode 145650 | Reward:  -9.255 | Epsilon: 0.0100 | Loss: 498957.9062
Episode 145700 | Reward: -12.048 | Epsilon: 0.0100 | Loss: 475733.5938
Episode 145750 | Reward: -10.020 | Epsilon: 0.0100 | Loss: 359428.8750
Episode 145800 | Reward: -13.120 | Epsilon: 0.0100 | Loss: 393132.2812
Episode 145850 | Reward: -13.604 | Epsilon: 0.0100 | Loss: 472270.0000
Episode 145900 | Reward:  -9.638 | Epsilon: 0.0100 | Loss: 594766.5000
Episode 145950 | Reward: -12.253 | Epsilon: 0.0100 | Loss: 481317.6562
Episode 146000 | Reward:  -9.647 | Epsilon: 0.0100 | Loss: 438397.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:50).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:50).dict
Episode 146050 | Reward: -11.422 | Epsilon: 0.0100 | Loss: 512054.9062
Episode 146100 | Reward: -12.146 | Epsilon: 0.0100 | Loss: 336879.5938
Episode 146150 | Reward: -11.380 | Epsilon: 0.0100 | Loss: 451892.1562
Episode 146200 | Reward:  -9.973 | Epsilon: 0.0100 | Loss: 397503.0312
Episode 146250 | Reward: -10.955 | Epsilon: 0.0100 | Loss: 409692.3125
Episode 146300 | Reward: -10.215 | Epsilon: 0.0100 | Loss: 520938.2188
Episode 146350 | Reward:  -9.295 | Epsilon: 0.0100 | Loss: 515427.4062
Episode 146400 | Reward: -10.999 | Epsilon: 0.0100 | Loss: 474101.3125
Episode 146450 | Reward: -11.584 | Epsilon: 0.0100 | Loss: 513807.7500
Episode 146500 | Reward: -10.259 | Epsilon: 0.0100 | Loss: 471070.4375
Episode 146550 | Reward:  -7.163 | Epsilon: 0.0100 | Loss: 459012.2812
Episode 146600 | Reward:  -7.298 | Epsilon: 0.0100 | Loss: 641897.0000
Episode 146650 | Reward: -12.146 | Epsilon: 0.0100 | Loss: 397228.4375
Episode 146700 | Reward: -14.625 | Epsilon: 0.0100 | Loss: 461098.6875
Episode 146750 | Reward: -10.766 | Epsilon: 0.0100 | Loss: 500875.8438
Episode 146800 | Reward:  -8.431 | Epsilon: 0.0100 | Loss: 423930.0312
Episode 146850 | Reward:  -8.802 | Epsilon: 0.0100 | Loss: 434764.9375
Episode 146900 | Reward:  -6.365 | Epsilon: 0.0100 | Loss: 480067.3750
Episode 146950 | Reward:  -8.233 | Epsilon: 0.0100 | Loss: 428060.7188
Episode 147000 | Reward:  -9.420 | Epsilon: 0.0100 | Loss: 372936.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:54).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:54).dict
Episode 147050 | Reward: -12.375 | Epsilon: 0.0100 | Loss: 332026.8438
Episode 147100 | Reward:  -9.314 | Epsilon: 0.0100 | Loss: 408592.0625
Episode 147150 | Reward: -12.419 | Epsilon: 0.0100 | Loss: 422158.6875
Episode 147200 | Reward: -12.790 | Epsilon: 0.0100 | Loss: 440130.1250
Episode 147250 | Reward: -11.995 | Epsilon: 0.0100 | Loss: 413694.6562
Episode 147300 | Reward: -13.693 | Epsilon: 0.0100 | Loss: 431051.8750
Episode 147350 | Reward:  -9.557 | Epsilon: 0.0100 | Loss: 457384.9375
Episode 147400 | Reward: -12.371 | Epsilon: 0.0100 | Loss: 407063.5625
Episode 147450 | Reward: -10.068 | Epsilon: 0.0100 | Loss: 428105.1562
Episode 147500 | Reward: -15.503 | Epsilon: 0.0100 | Loss: 432430.9688
Episode 147550 | Reward:  -7.930 | Epsilon: 0.0100 | Loss: 443491.5000
Episode 147600 | Reward:  -8.780 | Epsilon: 0.0100 | Loss: 386637.0000
Episode 147650 | Reward:  -8.837 | Epsilon: 0.0100 | Loss: 594435.0000
Episode 147700 | Reward: -14.045 | Epsilon: 0.0100 | Loss: 306385.8125
Episode 147750 | Reward: -13.419 | Epsilon: 0.0100 | Loss: 557367.1250
Episode 147800 | Reward: -11.106 | Epsilon: 0.0100 | Loss: 584930.0000
Episode 147850 | Reward:  -9.789 | Epsilon: 0.0100 | Loss: 552947.8750
Episode 147900 | Reward: -10.574 | Epsilon: 0.0100 | Loss: 417797.6875
Episode 147950 | Reward: -13.505 | Epsilon: 0.0100 | Loss: 492017.6250
Episode 148000 | Reward: -12.209 | Epsilon: 0.0100 | Loss: 400575.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:58).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(10:58).dict
Episode 148050 | Reward:  -6.015 | Epsilon: 0.0100 | Loss: 467891.0625
Episode 148100 | Reward:  -7.014 | Epsilon: 0.0100 | Loss: 590010.7500
Episode 148150 | Reward:  -9.056 | Epsilon: 0.0100 | Loss: 464363.0625
Episode 148200 | Reward:  -7.588 | Epsilon: 0.0100 | Loss: 376192.4688
Episode 148250 | Reward: -11.364 | Epsilon: 0.0100 | Loss: 457871.5625
Episode 148300 | Reward: -11.136 | Epsilon: 0.0100 | Loss: 483330.5000
Episode 148350 | Reward: -12.057 | Epsilon: 0.0100 | Loss: 511770.1250
Episode 148400 | Reward: -12.292 | Epsilon: 0.0100 | Loss: 500000.5938
Episode 148450 | Reward: -10.504 | Epsilon: 0.0100 | Loss: 439469.1562
Episode 148500 | Reward: -11.551 | Epsilon: 0.0100 | Loss: 511615.3438
Episode 148550 | Reward:  -5.029 | Epsilon: 0.0100 | Loss: 528891.0000
Episode 148600 | Reward: -10.746 | Epsilon: 0.0100 | Loss: 482682.4375
Episode 148650 | Reward:  -9.551 | Epsilon: 0.0100 | Loss: 443514.1250
Episode 148700 | Reward:  -9.519 | Epsilon: 0.0100 | Loss: 346449.0000
Episode 148750 | Reward:  -9.934 | Epsilon: 0.0100 | Loss: 581014.2500
Episode 148800 | Reward:  -9.845 | Epsilon: 0.0100 | Loss: 491253.3750
Episode 148850 | Reward: -12.293 | Epsilon: 0.0100 | Loss: 508246.7500
Episode 148900 | Reward: -11.327 | Epsilon: 0.0100 | Loss: 345097.5000
Episode 148950 | Reward: -13.908 | Epsilon: 0.0100 | Loss: 400766.3750
Episode 149000 | Reward: -13.016 | Epsilon: 0.0100 | Loss: 496102.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:02).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:02).dict
Episode 149050 | Reward: -10.533 | Epsilon: 0.0100 | Loss: 500745.2812
Episode 149100 | Reward: -10.023 | Epsilon: 0.0100 | Loss: 468599.6562
Episode 149150 | Reward:  -8.926 | Epsilon: 0.0100 | Loss: 544462.8750
Episode 149200 | Reward: -12.949 | Epsilon: 0.0100 | Loss: 396005.1250
Episode 149250 | Reward: -12.689 | Epsilon: 0.0100 | Loss: 552065.6875
Episode 149300 | Reward: -11.689 | Epsilon: 0.0100 | Loss: 475738.7188
Episode 149350 | Reward:  -6.134 | Epsilon: 0.0100 | Loss: 414589.1875
Episode 149400 | Reward:  -9.210 | Epsilon: 0.0100 | Loss: 565026.7500
Episode 149450 | Reward:  -5.803 | Epsilon: 0.0100 | Loss: 447014.0000
Episode 149500 | Reward:  -8.582 | Epsilon: 0.0100 | Loss: 525305.4375
Episode 149550 | Reward: -13.810 | Epsilon: 0.0100 | Loss: 400558.9375
Episode 149600 | Reward: -10.175 | Epsilon: 0.0100 | Loss: 513392.6250
Episode 149650 | Reward: -12.343 | Epsilon: 0.0100 | Loss: 484672.3125
Episode 149700 | Reward: -12.036 | Epsilon: 0.0100 | Loss: 640203.5625
Episode 149750 | Reward: -11.577 | Epsilon: 0.0100 | Loss: 497393.7812
Episode 149800 | Reward: -11.800 | Epsilon: 0.0100 | Loss: 481724.3750
Episode 149850 | Reward: -10.570 | Epsilon: 0.0100 | Loss: 425562.4062
Episode 149900 | Reward: -10.166 | Epsilon: 0.0100 | Loss: 393623.2812
Episode 149950 | Reward:  -9.092 | Epsilon: 0.0100 | Loss: 512156.8750
Episode 150000 | Reward: -12.170 | Epsilon: 0.0100 | Loss: 399748.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:06).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:06).dict
Episode 150050 | Reward:  -8.192 | Epsilon: 0.0100 | Loss: 427989.0000
Episode 150100 | Reward:  -6.847 | Epsilon: 0.0100 | Loss: 373284.3750
Episode 150150 | Reward: -15.295 | Epsilon: 0.0100 | Loss: 396726.2188
Episode 150200 | Reward: -10.216 | Epsilon: 0.0100 | Loss: 469994.1250
Episode 150250 | Reward: -11.160 | Epsilon: 0.0100 | Loss: 498030.8125
Episode 150300 | Reward: -10.181 | Epsilon: 0.0100 | Loss: 465119.2188
Episode 150350 | Reward: -13.352 | Epsilon: 0.0100 | Loss: 390171.8438
Episode 150400 | Reward:  -8.157 | Epsilon: 0.0100 | Loss: 507607.5625
Episode 150450 | Reward: -14.928 | Epsilon: 0.0100 | Loss: 412954.4062
Episode 150500 | Reward: -13.364 | Epsilon: 0.0100 | Loss: 476254.0938
Episode 150550 | Reward: -11.475 | Epsilon: 0.0100 | Loss: 407748.5000
Episode 150600 | Reward:  -8.870 | Epsilon: 0.0100 | Loss: 463654.8750
Episode 150650 | Reward: -12.950 | Epsilon: 0.0100 | Loss: 484321.0938
Episode 150700 | Reward: -10.765 | Epsilon: 0.0100 | Loss: 437455.2188
Episode 150750 | Reward:  -7.256 | Epsilon: 0.0100 | Loss: 463434.3125
Episode 150800 | Reward: -11.057 | Epsilon: 0.0100 | Loss: 395648.7500
Episode 150850 | Reward: -11.991 | Epsilon: 0.0100 | Loss: 329365.4375
Episode 150900 | Reward: -11.029 | Epsilon: 0.0100 | Loss: 535431.5625
Episode 150950 | Reward: -10.825 | Epsilon: 0.0100 | Loss: 378977.5000
Episode 151000 | Reward:  -5.693 | Epsilon: 0.0100 | Loss: 420597.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:11).dict
Episode 151050 | Reward:  -8.604 | Epsilon: 0.0100 | Loss: 311827.1250
Episode 151100 | Reward: -10.328 | Epsilon: 0.0100 | Loss: 411105.0000
Episode 151150 | Reward:  -8.386 | Epsilon: 0.0100 | Loss: 493066.0625
Episode 151200 | Reward:  -6.415 | Epsilon: 0.0100 | Loss: 434625.2500
Episode 151250 | Reward: -10.720 | Epsilon: 0.0100 | Loss: 474689.7500
Episode 151300 | Reward: -10.956 | Epsilon: 0.0100 | Loss: 485274.5625
Episode 151350 | Reward: -13.356 | Epsilon: 0.0100 | Loss: 398492.9062
Episode 151400 | Reward: -11.272 | Epsilon: 0.0100 | Loss: 343410.0938
Episode 151450 | Reward: -11.538 | Epsilon: 0.0100 | Loss: 334103.6250
Episode 151500 | Reward:  -8.336 | Epsilon: 0.0100 | Loss: 498158.3438
Episode 151550 | Reward: -10.776 | Epsilon: 0.0100 | Loss: 438476.5625
Episode 151600 | Reward:  -6.901 | Epsilon: 0.0100 | Loss: 343418.0625
Episode 151650 | Reward: -10.184 | Epsilon: 0.0100 | Loss: 491873.8438
Episode 151700 | Reward: -10.677 | Epsilon: 0.0100 | Loss: 413795.7500
Episode 151750 | Reward:  -6.648 | Epsilon: 0.0100 | Loss: 382459.3125
Episode 151800 | Reward: -13.076 | Epsilon: 0.0100 | Loss: 312536.4688
Episode 151850 | Reward:  -7.983 | Epsilon: 0.0100 | Loss: 307606.5312
Episode 151900 | Reward:  -9.956 | Epsilon: 0.0100 | Loss: 390876.3125
Episode 151950 | Reward: -10.157 | Epsilon: 0.0100 | Loss: 404272.8750
Episode 152000 | Reward:  -9.826 | Epsilon: 0.0100 | Loss: 438643.4688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:15).dict
Episode 152050 | Reward:  -7.464 | Epsilon: 0.0100 | Loss: 327647.0938
Episode 152100 | Reward: -11.147 | Epsilon: 0.0100 | Loss: 478674.3750
Episode 152150 | Reward: -10.567 | Epsilon: 0.0100 | Loss: 492728.5312
Episode 152200 | Reward: -15.422 | Epsilon: 0.0100 | Loss: 361759.4375
Episode 152250 | Reward: -11.940 | Epsilon: 0.0100 | Loss: 349716.5938
Episode 152300 | Reward: -12.483 | Epsilon: 0.0100 | Loss: 548120.5000
Episode 152350 | Reward: -11.171 | Epsilon: 0.0100 | Loss: 429022.8750
Episode 152400 | Reward: -13.772 | Epsilon: 0.0100 | Loss: 377919.0625
Episode 152450 | Reward: -15.990 | Epsilon: 0.0100 | Loss: 398363.5312
Episode 152500 | Reward:  -6.997 | Epsilon: 0.0100 | Loss: 528229.6250
Episode 152550 | Reward:  -6.642 | Epsilon: 0.0100 | Loss: 488823.8750
Episode 152600 | Reward: -10.748 | Epsilon: 0.0100 | Loss: 471463.9688
Episode 152650 | Reward:  -9.942 | Epsilon: 0.0100 | Loss: 466877.8750
Episode 152700 | Reward: -11.987 | Epsilon: 0.0100 | Loss: 583605.0000
Episode 152750 | Reward:  -9.747 | Epsilon: 0.0100 | Loss: 533263.8750
Episode 152800 | Reward:  -9.972 | Epsilon: 0.0100 | Loss: 510498.2188
Episode 152850 | Reward: -10.572 | Epsilon: 0.0100 | Loss: 441483.1875
Episode 152900 | Reward: -10.498 | Epsilon: 0.0100 | Loss: 595006.7500
Episode 152950 | Reward:  -7.014 | Epsilon: 0.0100 | Loss: 401034.6875
Episode 153000 | Reward:  -7.586 | Epsilon: 0.0100 | Loss: 473558.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:19).dict
Episode 153050 | Reward:  -8.069 | Epsilon: 0.0100 | Loss: 595124.2500
Episode 153100 | Reward: -11.965 | Epsilon: 0.0100 | Loss: 455764.5000
Episode 153150 | Reward: -10.178 | Epsilon: 0.0100 | Loss: 470548.7812
Episode 153200 | Reward:  -6.863 | Epsilon: 0.0100 | Loss: 542164.5625
Episode 153250 | Reward: -12.693 | Epsilon: 0.0100 | Loss: 536628.7500
Episode 153300 | Reward: -10.679 | Epsilon: 0.0100 | Loss: 443623.8750
Episode 153350 | Reward:  -8.220 | Epsilon: 0.0100 | Loss: 505168.1875
Episode 153400 | Reward: -13.919 | Epsilon: 0.0100 | Loss: 464853.0938
Episode 153450 | Reward: -10.826 | Epsilon: 0.0100 | Loss: 538230.0000
Episode 153500 | Reward:  -8.031 | Epsilon: 0.0100 | Loss: 407792.7500
Episode 153550 | Reward: -10.996 | Epsilon: 0.0100 | Loss: 412309.8750
Episode 153600 | Reward: -11.504 | Epsilon: 0.0100 | Loss: 504983.2500
Episode 153650 | Reward:  -7.740 | Epsilon: 0.0100 | Loss: 426939.5000
Episode 153700 | Reward:  -8.720 | Epsilon: 0.0100 | Loss: 418814.7812
Episode 153750 | Reward: -12.410 | Epsilon: 0.0100 | Loss: 468586.3438
Episode 153800 | Reward:  -9.261 | Epsilon: 0.0100 | Loss: 510414.1875
Episode 153850 | Reward:  -8.015 | Epsilon: 0.0100 | Loss: 596452.3750
Episode 153900 | Reward:  -9.739 | Epsilon: 0.0100 | Loss: 426166.5625
Episode 153950 | Reward:  -9.101 | Epsilon: 0.0100 | Loss: 512329.7188
Episode 154000 | Reward: -12.511 | Epsilon: 0.0100 | Loss: 447886.9688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:23).dict
Episode 154050 | Reward: -10.305 | Epsilon: 0.0100 | Loss: 473739.9375
Episode 154100 | Reward: -10.628 | Epsilon: 0.0100 | Loss: 521411.5938
Episode 154150 | Reward:  -7.887 | Epsilon: 0.0100 | Loss: 597049.0625
Episode 154200 | Reward:  -9.393 | Epsilon: 0.0100 | Loss: 369979.0000
Episode 154250 | Reward: -12.089 | Epsilon: 0.0100 | Loss: 397154.5625
Episode 154300 | Reward: -10.057 | Epsilon: 0.0100 | Loss: 454569.1562
Episode 154350 | Reward:  -8.665 | Epsilon: 0.0100 | Loss: 433627.1875
Episode 154400 | Reward: -13.759 | Epsilon: 0.0100 | Loss: 486711.0625
Episode 154450 | Reward: -13.463 | Epsilon: 0.0100 | Loss: 599350.1250
Episode 154500 | Reward: -10.760 | Epsilon: 0.0100 | Loss: 470114.1562
Episode 154550 | Reward:  -8.819 | Epsilon: 0.0100 | Loss: 522338.8750
Episode 154600 | Reward:  -9.716 | Epsilon: 0.0100 | Loss: 491741.6250
Episode 154650 | Reward:  -6.478 | Epsilon: 0.0100 | Loss: 419408.3125
Episode 154700 | Reward: -12.619 | Epsilon: 0.0100 | Loss: 471109.8125
Episode 154750 | Reward:  -8.106 | Epsilon: 0.0100 | Loss: 397615.3438
Episode 154800 | Reward:  -9.889 | Epsilon: 0.0100 | Loss: 502966.2812
Episode 154850 | Reward: -10.791 | Epsilon: 0.0100 | Loss: 496762.4375
Episode 154900 | Reward:  -9.474 | Epsilon: 0.0100 | Loss: 459279.8125
Episode 154950 | Reward: -10.863 | Epsilon: 0.0100 | Loss: 315941.5938
Episode 155000 | Reward:  -9.793 | Epsilon: 0.0100 | Loss: 354681.7188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:27).dict
Episode 155050 | Reward: -11.313 | Epsilon: 0.0100 | Loss: 567701.3750
Episode 155100 | Reward: -10.095 | Epsilon: 0.0100 | Loss: 432162.0312
Episode 155150 | Reward:  -8.137 | Epsilon: 0.0100 | Loss: 450165.9062
Episode 155200 | Reward:  -8.973 | Epsilon: 0.0100 | Loss: 472353.1562
Episode 155250 | Reward:  -6.215 | Epsilon: 0.0100 | Loss: 390120.6562
Episode 155300 | Reward:  -9.516 | Epsilon: 0.0100 | Loss: 379907.6250
Episode 155350 | Reward:  -5.609 | Epsilon: 0.0100 | Loss: 379909.6562
Episode 155400 | Reward:  -9.265 | Epsilon: 0.0100 | Loss: 451657.3125
Episode 155450 | Reward:  -8.539 | Epsilon: 0.0100 | Loss: 413099.9688
Episode 155500 | Reward:  -8.394 | Epsilon: 0.0100 | Loss: 397622.1875
Episode 155550 | Reward:  -7.744 | Epsilon: 0.0100 | Loss: 403586.5312
Episode 155600 | Reward:  -8.112 | Epsilon: 0.0100 | Loss: 460034.1875
Episode 155650 | Reward:  -5.021 | Epsilon: 0.0100 | Loss: 433078.6875
Episode 155700 | Reward:  -9.932 | Epsilon: 0.0100 | Loss: 438589.0312
Episode 155750 | Reward:  -9.623 | Epsilon: 0.0100 | Loss: 389316.7500
Episode 155800 | Reward:  -9.397 | Epsilon: 0.0100 | Loss: 470883.5000
Episode 155850 | Reward:  -9.143 | Epsilon: 0.0100 | Loss: 323748.9375
Episode 155900 | Reward:  -9.809 | Epsilon: 0.0100 | Loss: 410191.4688
Episode 155950 | Reward: -13.308 | Epsilon: 0.0100 | Loss: 393277.6250
Episode 156000 | Reward: -12.843 | Epsilon: 0.0100 | Loss: 458741.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:31).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:31).dict
Episode 156050 | Reward:  -7.270 | Epsilon: 0.0100 | Loss: 371640.9688
Episode 156100 | Reward:  -8.370 | Epsilon: 0.0100 | Loss: 470361.7500
Episode 156150 | Reward:  -8.141 | Epsilon: 0.0100 | Loss: 349683.8750
Episode 156200 | Reward: -11.033 | Epsilon: 0.0100 | Loss: 470164.7500
Episode 156250 | Reward: -15.071 | Epsilon: 0.0100 | Loss: 345455.0000
Episode 156300 | Reward: -13.820 | Epsilon: 0.0100 | Loss: 361481.0312
Episode 156350 | Reward: -14.344 | Epsilon: 0.0100 | Loss: 529112.2500
Episode 156400 | Reward: -15.367 | Epsilon: 0.0100 | Loss: 415215.5312
Episode 156450 | Reward: -12.488 | Epsilon: 0.0100 | Loss: 385034.4062
Episode 156500 | Reward: -11.859 | Epsilon: 0.0100 | Loss: 395049.3750
Episode 156550 | Reward: -15.234 | Epsilon: 0.0100 | Loss: 403929.7188
Episode 156600 | Reward: -16.146 | Epsilon: 0.0100 | Loss: 419375.8438
Episode 156650 | Reward: -14.098 | Epsilon: 0.0100 | Loss: 435962.6250
Episode 156700 | Reward: -16.732 | Epsilon: 0.0100 | Loss: 491403.2500
Episode 156750 | Reward: -12.596 | Epsilon: 0.0100 | Loss: 506079.6562
Episode 156800 | Reward: -11.422 | Epsilon: 0.0100 | Loss: 502745.7188
Episode 156850 | Reward: -10.723 | Epsilon: 0.0100 | Loss: 391771.0938
Episode 156900 | Reward: -11.702 | Epsilon: 0.0100 | Loss: 529406.0625
Episode 156950 | Reward: -10.221 | Epsilon: 0.0100 | Loss: 512014.3750
Episode 157000 | Reward: -10.716 | Epsilon: 0.0100 | Loss: 493427.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:35).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:35).dict
Episode 157050 | Reward: -13.929 | Epsilon: 0.0100 | Loss: 426007.6875
Episode 157100 | Reward: -11.291 | Epsilon: 0.0100 | Loss: 548026.6875
Episode 157150 | Reward: -10.510 | Epsilon: 0.0100 | Loss: 503835.5000
Episode 157200 | Reward:  -6.289 | Epsilon: 0.0100 | Loss: 590809.1250
Episode 157250 | Reward: -10.033 | Epsilon: 0.0100 | Loss: 514481.1875
Episode 157300 | Reward:  -9.466 | Epsilon: 0.0100 | Loss: 455057.5938
Episode 157350 | Reward: -13.414 | Epsilon: 0.0100 | Loss: 638201.5625
Episode 157400 | Reward:  -7.658 | Epsilon: 0.0100 | Loss: 570823.0000
Episode 157450 | Reward:  -9.920 | Epsilon: 0.0100 | Loss: 523269.0000
Episode 157500 | Reward: -11.067 | Epsilon: 0.0100 | Loss: 528968.3750
Episode 157550 | Reward:  -6.911 | Epsilon: 0.0100 | Loss: 640401.5000
Episode 157600 | Reward:  -9.043 | Epsilon: 0.0100 | Loss: 504456.7188
Episode 157650 | Reward: -11.590 | Epsilon: 0.0100 | Loss: 581670.9375
Episode 157700 | Reward: -10.474 | Epsilon: 0.0100 | Loss: 396343.3125
Episode 157750 | Reward:  -9.903 | Epsilon: 0.0100 | Loss: 450695.1250
Episode 157800 | Reward:  -7.424 | Epsilon: 0.0100 | Loss: 438509.3125
Episode 157850 | Reward: -10.221 | Epsilon: 0.0100 | Loss: 585321.3125
Episode 157900 | Reward:  -6.698 | Epsilon: 0.0100 | Loss: 535438.9375
Episode 157950 | Reward: -11.648 | Epsilon: 0.0100 | Loss: 662323.0000
Episode 158000 | Reward:  -9.708 | Epsilon: 0.0100 | Loss: 437631.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:39).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:39).dict
Episode 158050 | Reward: -10.859 | Epsilon: 0.0100 | Loss: 474457.1562
Episode 158100 | Reward: -13.341 | Epsilon: 0.0100 | Loss: 520595.2500
Episode 158150 | Reward:  -8.316 | Epsilon: 0.0100 | Loss: 429258.5625
Episode 158200 | Reward:  -8.028 | Epsilon: 0.0100 | Loss: 539988.3125
Episode 158250 | Reward:  -5.694 | Epsilon: 0.0100 | Loss: 631895.9375
Episode 158300 | Reward:  -8.124 | Epsilon: 0.0100 | Loss: 616422.0000
Episode 158350 | Reward:  -5.112 | Epsilon: 0.0100 | Loss: 559076.3750
Episode 158400 | Reward:  -7.662 | Epsilon: 0.0100 | Loss: 521547.3125
Episode 158450 | Reward: -11.098 | Epsilon: 0.0100 | Loss: 394134.8438
Episode 158500 | Reward: -10.822 | Epsilon: 0.0100 | Loss: 415930.5625
Episode 158550 | Reward:  -8.893 | Epsilon: 0.0100 | Loss: 731642.5625
Episode 158600 | Reward:  -9.492 | Epsilon: 0.0100 | Loss: 439061.7500
Episode 158650 | Reward: -12.330 | Epsilon: 0.0100 | Loss: 509557.6562
Episode 158700 | Reward: -12.746 | Epsilon: 0.0100 | Loss: 520601.5000
Episode 158750 | Reward: -10.941 | Epsilon: 0.0100 | Loss: 453127.8125
Episode 158800 | Reward: -13.988 | Epsilon: 0.0100 | Loss: 445540.7500
Episode 158850 | Reward: -12.204 | Epsilon: 0.0100 | Loss: 506990.4375
Episode 158900 | Reward: -14.534 | Epsilon: 0.0100 | Loss: 614774.6875
Episode 158950 | Reward: -11.619 | Epsilon: 0.0100 | Loss: 572133.3125
Episode 159000 | Reward: -10.769 | Epsilon: 0.0100 | Loss: 545004.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:43).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:43).dict
Episode 159050 | Reward:  -8.431 | Epsilon: 0.0100 | Loss: 459575.6250
Episode 159100 | Reward: -10.052 | Epsilon: 0.0100 | Loss: 551932.6875
Episode 159150 | Reward: -10.463 | Epsilon: 0.0100 | Loss: 595580.8125
Episode 159200 | Reward:  -7.702 | Epsilon: 0.0100 | Loss: 459913.5312
Episode 159250 | Reward:  -7.925 | Epsilon: 0.0100 | Loss: 548486.7500
Episode 159300 | Reward:  -9.723 | Epsilon: 0.0100 | Loss: 516775.1250
Episode 159350 | Reward: -10.115 | Epsilon: 0.0100 | Loss: 465891.3125
Episode 159400 | Reward: -11.603 | Epsilon: 0.0100 | Loss: 563879.3750
Episode 159450 | Reward:  -7.647 | Epsilon: 0.0100 | Loss: 549301.3750
Episode 159500 | Reward:  -8.443 | Epsilon: 0.0100 | Loss: 461553.6250
Episode 159550 | Reward:  -8.894 | Epsilon: 0.0100 | Loss: 521398.8125
Episode 159600 | Reward: -10.915 | Epsilon: 0.0100 | Loss: 495292.1875
Episode 159650 | Reward: -10.295 | Epsilon: 0.0100 | Loss: 636208.9375
Episode 159700 | Reward: -12.135 | Epsilon: 0.0100 | Loss: 523541.5625
Episode 159750 | Reward: -11.468 | Epsilon: 0.0100 | Loss: 591459.5625
Episode 159800 | Reward: -11.184 | Epsilon: 0.0100 | Loss: 618013.2500
Episode 159850 | Reward: -11.649 | Epsilon: 0.0100 | Loss: 544356.6250
Episode 159900 | Reward: -12.070 | Epsilon: 0.0100 | Loss: 445542.0000
Episode 159950 | Reward: -12.744 | Epsilon: 0.0100 | Loss: 524058.0625
Episode 160000 | Reward: -11.307 | Epsilon: 0.0100 | Loss: 572694.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:47).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:47).dict
Episode 160050 | Reward:  -8.817 | Epsilon: 0.0100 | Loss: 634541.6875
Episode 160100 | Reward:  -5.616 | Epsilon: 0.0100 | Loss: 462286.0000
Episode 160150 | Reward:  -6.966 | Epsilon: 0.0100 | Loss: 634483.1875
Episode 160200 | Reward:  -9.967 | Epsilon: 0.0100 | Loss: 571875.3750
Episode 160250 | Reward:  -5.338 | Epsilon: 0.0100 | Loss: 627214.8125
Episode 160300 | Reward: -10.663 | Epsilon: 0.0100 | Loss: 544220.9375
Episode 160350 | Reward:  -9.465 | Epsilon: 0.0100 | Loss: 644402.4375
Episode 160400 | Reward:  -9.572 | Epsilon: 0.0100 | Loss: 550233.6875
Episode 160450 | Reward: -10.100 | Epsilon: 0.0100 | Loss: 503997.3125
Episode 160500 | Reward:  -8.993 | Epsilon: 0.0100 | Loss: 480702.9688
Episode 160550 | Reward:  -7.339 | Epsilon: 0.0100 | Loss: 526711.7500
Episode 160600 | Reward:  -8.018 | Epsilon: 0.0100 | Loss: 575172.3750
Episode 160650 | Reward:  -8.795 | Epsilon: 0.0100 | Loss: 497111.3750
Episode 160700 | Reward: -10.620 | Epsilon: 0.0100 | Loss: 527246.3125
Episode 160750 | Reward: -10.768 | Epsilon: 0.0100 | Loss: 667037.3750
Episode 160800 | Reward: -11.618 | Epsilon: 0.0100 | Loss: 587716.0625
Episode 160850 | Reward:  -7.671 | Epsilon: 0.0100 | Loss: 464230.8750
Episode 160900 | Reward:  -8.027 | Epsilon: 0.0100 | Loss: 628728.0625
Episode 160950 | Reward: -11.731 | Epsilon: 0.0100 | Loss: 521984.6250
Episode 161000 | Reward: -12.278 | Epsilon: 0.0100 | Loss: 639243.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:51).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:51).dict
Episode 161050 | Reward: -12.006 | Epsilon: 0.0100 | Loss: 654067.0000
Episode 161100 | Reward: -14.879 | Epsilon: 0.0100 | Loss: 591830.0000
Episode 161150 | Reward:  -8.985 | Epsilon: 0.0100 | Loss: 438365.0938
Episode 161200 | Reward:  -6.529 | Epsilon: 0.0100 | Loss: 492651.7188
Episode 161250 | Reward: -11.031 | Epsilon: 0.0100 | Loss: 454786.5312
Episode 161300 | Reward: -11.425 | Epsilon: 0.0100 | Loss: 550232.5625
Episode 161350 | Reward: -11.342 | Epsilon: 0.0100 | Loss: 629653.1250
Episode 161400 | Reward:  -8.289 | Epsilon: 0.0100 | Loss: 515844.3125
Episode 161450 | Reward: -10.772 | Epsilon: 0.0100 | Loss: 499096.9062
Episode 161500 | Reward: -10.654 | Epsilon: 0.0100 | Loss: 593193.6250
Episode 161550 | Reward:  -8.345 | Epsilon: 0.0100 | Loss: 529457.5000
Episode 161600 | Reward: -12.660 | Epsilon: 0.0100 | Loss: 540506.0000
Episode 161650 | Reward:  -9.166 | Epsilon: 0.0100 | Loss: 425809.3750
Episode 161700 | Reward: -11.604 | Epsilon: 0.0100 | Loss: 528871.0000
Episode 161750 | Reward: -10.356 | Epsilon: 0.0100 | Loss: 656732.3125
Episode 161800 | Reward:  -9.118 | Epsilon: 0.0100 | Loss: 540636.7500
Episode 161850 | Reward:  -9.597 | Epsilon: 0.0100 | Loss: 523800.0938
Episode 161900 | Reward:  -9.903 | Epsilon: 0.0100 | Loss: 482363.6562
Episode 161950 | Reward:  -8.158 | Epsilon: 0.0100 | Loss: 541137.4375
Episode 162000 | Reward:  -5.814 | Epsilon: 0.0100 | Loss: 563342.8750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:55).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:55).dict
Episode 162050 | Reward: -11.118 | Epsilon: 0.0100 | Loss: 654366.8750
Episode 162100 | Reward:  -7.939 | Epsilon: 0.0100 | Loss: 473182.0312
Episode 162150 | Reward:  -9.795 | Epsilon: 0.0100 | Loss: 401876.5625
Episode 162200 | Reward: -12.466 | Epsilon: 0.0100 | Loss: 383346.4375
Episode 162250 | Reward: -12.311 | Epsilon: 0.0100 | Loss: 654160.2500
Episode 162300 | Reward: -10.410 | Epsilon: 0.0100 | Loss: 538833.0000
Episode 162350 | Reward: -12.220 | Epsilon: 0.0100 | Loss: 511992.0625
Episode 162400 | Reward: -11.414 | Epsilon: 0.0100 | Loss: 479053.6875
Episode 162450 | Reward:  -8.642 | Epsilon: 0.0100 | Loss: 478900.2188
Episode 162500 | Reward:  -8.770 | Epsilon: 0.0100 | Loss: 491620.3125
Episode 162550 | Reward:  -9.685 | Epsilon: 0.0100 | Loss: 490676.1250
Episode 162600 | Reward:  -8.353 | Epsilon: 0.0100 | Loss: 665341.4375
Episode 162650 | Reward:  -8.060 | Epsilon: 0.0100 | Loss: 423350.4375
Episode 162700 | Reward: -12.004 | Epsilon: 0.0100 | Loss: 639921.6250
Episode 162750 | Reward: -14.806 | Epsilon: 0.0100 | Loss: 483060.0938
Episode 162800 | Reward:  -9.023 | Epsilon: 0.0100 | Loss: 459454.1250
Episode 162850 | Reward:  -5.777 | Epsilon: 0.0100 | Loss: 488628.5312
Episode 162900 | Reward:  -9.354 | Epsilon: 0.0100 | Loss: 481089.7500
Episode 162950 | Reward:  -6.535 | Epsilon: 0.0100 | Loss: 422705.0312
Episode 163000 | Reward:  -8.537 | Epsilon: 0.0100 | Loss: 407073.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:59).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(11:59).dict
Episode 163050 | Reward:  -6.631 | Epsilon: 0.0100 | Loss: 507257.9062
Episode 163100 | Reward:  -7.996 | Epsilon: 0.0100 | Loss: 404592.4375
Episode 163150 | Reward:  -7.055 | Epsilon: 0.0100 | Loss: 379209.9375
Episode 163200 | Reward:  -5.193 | Epsilon: 0.0100 | Loss: 523470.5625
Episode 163250 | Reward:  -6.739 | Epsilon: 0.0100 | Loss: 543026.3750
Episode 163300 | Reward:  -7.624 | Epsilon: 0.0100 | Loss: 441324.0625
Episode 163350 | Reward:  -9.029 | Epsilon: 0.0100 | Loss: 868328.9375
Episode 163400 | Reward: -12.672 | Epsilon: 0.0100 | Loss: 578719.5000
Episode 163450 | Reward:  -4.911 | Epsilon: 0.0100 | Loss: 450950.5625
Episode 163500 | Reward:  -7.804 | Epsilon: 0.0100 | Loss: 389652.0625
Episode 163550 | Reward: -11.965 | Epsilon: 0.0100 | Loss: 404540.0938
Episode 163600 | Reward: -10.529 | Epsilon: 0.0100 | Loss: 458151.9688
Episode 163650 | Reward:  -9.820 | Epsilon: 0.0100 | Loss: 598547.4375
Episode 163700 | Reward: -11.666 | Epsilon: 0.0100 | Loss: 514068.4688
Episode 163750 | Reward: -10.565 | Epsilon: 0.0100 | Loss: 341472.6250
Episode 163800 | Reward:  -8.247 | Epsilon: 0.0100 | Loss: 546746.0000
Episode 163850 | Reward:  -5.113 | Epsilon: 0.0100 | Loss: 486487.8438
Episode 163900 | Reward: -10.172 | Epsilon: 0.0100 | Loss: 568652.1250
Episode 163950 | Reward:  -9.464 | Epsilon: 0.0100 | Loss: 561912.7500
Episode 164000 | Reward:  -9.485 | Epsilon: 0.0100 | Loss: 459575.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:03).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:03).dict
Episode 164050 | Reward:  -8.360 | Epsilon: 0.0100 | Loss: 517693.2812
Episode 164100 | Reward:  -8.136 | Epsilon: 0.0100 | Loss: 474860.8438
Episode 164150 | Reward:  -7.236 | Epsilon: 0.0100 | Loss: 491502.9375
Episode 164200 | Reward:  -6.558 | Epsilon: 0.0100 | Loss: 426582.5000
Episode 164250 | Reward: -10.293 | Epsilon: 0.0100 | Loss: 430158.7500
Episode 164300 | Reward:  -7.572 | Epsilon: 0.0100 | Loss: 413245.5938
Episode 164350 | Reward: -10.806 | Epsilon: 0.0100 | Loss: 478244.8750
Episode 164400 | Reward: -10.010 | Epsilon: 0.0100 | Loss: 396006.0312
Episode 164450 | Reward:  -9.830 | Epsilon: 0.0100 | Loss: 427376.5625
Episode 164500 | Reward: -11.599 | Epsilon: 0.0100 | Loss: 405992.0625
Episode 164550 | Reward:  -9.638 | Epsilon: 0.0100 | Loss: 446133.5938
Episode 164600 | Reward: -10.864 | Epsilon: 0.0100 | Loss: 460450.3750
Episode 164650 | Reward: -11.229 | Epsilon: 0.0100 | Loss: 386291.8125
Episode 164700 | Reward: -13.774 | Epsilon: 0.0100 | Loss: 456797.5000
Episode 164750 | Reward: -14.187 | Epsilon: 0.0100 | Loss: 468567.1562
Episode 164800 | Reward: -12.488 | Epsilon: 0.0100 | Loss: 448192.4375
Episode 164850 | Reward: -10.470 | Epsilon: 0.0100 | Loss: 376510.1562
Episode 164900 | Reward: -11.291 | Epsilon: 0.0100 | Loss: 407423.5938
Episode 164950 | Reward: -13.014 | Epsilon: 0.0100 | Loss: 435967.8750
Episode 165000 | Reward: -13.000 | Epsilon: 0.0100 | Loss: 487937.9062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:07).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:07).dict
Episode 165050 | Reward: -15.040 | Epsilon: 0.0100 | Loss: 487727.4375
Episode 165100 | Reward:  -9.727 | Epsilon: 0.0100 | Loss: 412394.0625
Episode 165150 | Reward:  -7.492 | Epsilon: 0.0100 | Loss: 428495.8125
Episode 165200 | Reward: -10.560 | Epsilon: 0.0100 | Loss: 385501.5625
Episode 165250 | Reward: -12.260 | Epsilon: 0.0100 | Loss: 557261.1875
Episode 165300 | Reward: -11.331 | Epsilon: 0.0100 | Loss: 482922.8438
Episode 165350 | Reward: -12.161 | Epsilon: 0.0100 | Loss: 658697.7500
Episode 165400 | Reward: -11.689 | Epsilon: 0.0100 | Loss: 474271.6562
Episode 165450 | Reward: -13.673 | Epsilon: 0.0100 | Loss: 557514.6250
Episode 165500 | Reward: -10.638 | Epsilon: 0.0100 | Loss: 425500.3125
Episode 165550 | Reward: -10.885 | Epsilon: 0.0100 | Loss: 424632.8125
Episode 165600 | Reward:  -7.606 | Epsilon: 0.0100 | Loss: 352239.8750
Episode 165650 | Reward: -11.736 | Epsilon: 0.0100 | Loss: 391088.7188
Episode 165700 | Reward:  -9.976 | Epsilon: 0.0100 | Loss: 360309.9375
Episode 165750 | Reward: -12.825 | Epsilon: 0.0100 | Loss: 332202.5625
Episode 165800 | Reward:  -9.788 | Epsilon: 0.0100 | Loss: 413930.8125
Episode 165850 | Reward: -10.950 | Epsilon: 0.0100 | Loss: 506687.4062
Episode 165900 | Reward:  -7.707 | Epsilon: 0.0100 | Loss: 323471.8750
Episode 165950 | Reward: -11.450 | Epsilon: 0.0100 | Loss: 407629.2188
Episode 166000 | Reward: -12.646 | Epsilon: 0.0100 | Loss: 331372.3438
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:11).dict
Episode 166050 | Reward:  -9.630 | Epsilon: 0.0100 | Loss: 444320.1250
Episode 166100 | Reward:  -9.276 | Epsilon: 0.0100 | Loss: 467712.6875
Episode 166150 | Reward:  -9.482 | Epsilon: 0.0100 | Loss: 358338.8125
Episode 166200 | Reward: -11.707 | Epsilon: 0.0100 | Loss: 375919.8438
Episode 166250 | Reward: -10.906 | Epsilon: 0.0100 | Loss: 487339.5938
Episode 166300 | Reward: -10.131 | Epsilon: 0.0100 | Loss: 414361.3750
Episode 166350 | Reward: -11.295 | Epsilon: 0.0100 | Loss: 352409.3438
Episode 166400 | Reward:  -9.548 | Epsilon: 0.0100 | Loss: 384619.3438
Episode 166450 | Reward: -11.932 | Epsilon: 0.0100 | Loss: 374273.2500
Episode 166500 | Reward: -11.727 | Epsilon: 0.0100 | Loss: 326128.2812
Episode 166550 | Reward: -10.956 | Epsilon: 0.0100 | Loss: 484583.1875
Episode 166600 | Reward: -14.982 | Epsilon: 0.0100 | Loss: 488176.6250
Episode 166650 | Reward: -13.796 | Epsilon: 0.0100 | Loss: 460198.4688
Episode 166700 | Reward: -12.608 | Epsilon: 0.0100 | Loss: 374703.9062
Episode 166750 | Reward:  -9.549 | Epsilon: 0.0100 | Loss: 336278.0625
Episode 166800 | Reward: -12.637 | Epsilon: 0.0100 | Loss: 422125.4688
Episode 166850 | Reward: -11.080 | Epsilon: 0.0100 | Loss: 359501.1562
Episode 166900 | Reward:  -5.410 | Epsilon: 0.0100 | Loss: 382074.0312
Episode 166950 | Reward:  -4.726 | Epsilon: 0.0100 | Loss: 428102.3438
Episode 167000 | Reward:  -7.861 | Epsilon: 0.0100 | Loss: 415694.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:15).dict
Episode 167050 | Reward: -11.490 | Epsilon: 0.0100 | Loss: 416302.3125
Episode 167100 | Reward: -12.096 | Epsilon: 0.0100 | Loss: 425658.0312
Episode 167150 | Reward:  -6.350 | Epsilon: 0.0100 | Loss: 448465.0000
Episode 167200 | Reward: -10.205 | Epsilon: 0.0100 | Loss: 480196.6562
Episode 167250 | Reward: -11.015 | Epsilon: 0.0100 | Loss: 447496.5312
Episode 167300 | Reward:  -7.635 | Epsilon: 0.0100 | Loss: 511826.2500
Episode 167350 | Reward: -12.371 | Epsilon: 0.0100 | Loss: 492484.5312
Episode 167400 | Reward:  -7.826 | Epsilon: 0.0100 | Loss: 403181.2812
Episode 167450 | Reward:  -5.882 | Epsilon: 0.0100 | Loss: 372767.5625
Episode 167500 | Reward: -11.181 | Epsilon: 0.0100 | Loss: 396797.3750
Episode 167550 | Reward:  -7.773 | Epsilon: 0.0100 | Loss: 353077.0312
Episode 167600 | Reward:  -8.422 | Epsilon: 0.0100 | Loss: 453142.5312
Episode 167650 | Reward:  -9.190 | Epsilon: 0.0100 | Loss: 343747.7188
Episode 167700 | Reward:  -7.812 | Epsilon: 0.0100 | Loss: 461420.9375
Episode 167750 | Reward: -12.828 | Epsilon: 0.0100 | Loss: 428570.2188
Episode 167800 | Reward:  -9.940 | Epsilon: 0.0100 | Loss: 431974.0000
Episode 167850 | Reward:  -8.639 | Epsilon: 0.0100 | Loss: 450152.4062
Episode 167900 | Reward: -12.178 | Epsilon: 0.0100 | Loss: 373664.0000
Episode 167950 | Reward:  -9.714 | Epsilon: 0.0100 | Loss: 408990.0000
Episode 168000 | Reward:  -9.898 | Epsilon: 0.0100 | Loss: 420411.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:19).dict
Episode 168050 | Reward:  -9.731 | Epsilon: 0.0100 | Loss: 361698.9062
Episode 168100 | Reward:  -8.713 | Epsilon: 0.0100 | Loss: 450275.9688
Episode 168150 | Reward: -10.841 | Epsilon: 0.0100 | Loss: 367307.6875
Episode 168200 | Reward:  -8.203 | Epsilon: 0.0100 | Loss: 474762.0000
Episode 168250 | Reward: -12.204 | Epsilon: 0.0100 | Loss: 434226.2188
Episode 168300 | Reward: -13.684 | Epsilon: 0.0100 | Loss: 495579.3750
Episode 168350 | Reward: -10.662 | Epsilon: 0.0100 | Loss: 391833.2812
Episode 168400 | Reward: -10.922 | Epsilon: 0.0100 | Loss: 492424.2500
Episode 168450 | Reward: -12.146 | Epsilon: 0.0100 | Loss: 436448.2812
Episode 168500 | Reward: -11.529 | Epsilon: 0.0100 | Loss: 416797.3125
Episode 168550 | Reward: -10.465 | Epsilon: 0.0100 | Loss: 528865.4375
Episode 168600 | Reward: -13.117 | Epsilon: 0.0100 | Loss: 420071.5625
Episode 168650 | Reward: -11.080 | Epsilon: 0.0100 | Loss: 413804.7188
Episode 168700 | Reward:  -8.214 | Epsilon: 0.0100 | Loss: 480746.9688
Episode 168750 | Reward: -10.926 | Epsilon: 0.0100 | Loss: 435640.7500
Episode 168800 | Reward: -10.615 | Epsilon: 0.0100 | Loss: 463669.2812
Episode 168850 | Reward:  -6.255 | Epsilon: 0.0100 | Loss: 429085.7812
Episode 168900 | Reward:  -4.940 | Epsilon: 0.0100 | Loss: 396172.5938
Episode 168950 | Reward:  -9.441 | Epsilon: 0.0100 | Loss: 452852.9062
Episode 169000 | Reward: -15.485 | Epsilon: 0.0100 | Loss: 508032.9062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:23).dict
Episode 169050 | Reward: -12.431 | Epsilon: 0.0100 | Loss: 419202.4375
Episode 169100 | Reward: -12.420 | Epsilon: 0.0100 | Loss: 346838.3438
Episode 169150 | Reward: -10.706 | Epsilon: 0.0100 | Loss: 519968.5938
Episode 169200 | Reward: -10.201 | Epsilon: 0.0100 | Loss: 427697.0000
Episode 169250 | Reward:  -9.035 | Epsilon: 0.0100 | Loss: 581711.1250
Episode 169300 | Reward:  -8.226 | Epsilon: 0.0100 | Loss: 455218.7812
Episode 169350 | Reward:  -8.629 | Epsilon: 0.0100 | Loss: 528678.3750
Episode 169400 | Reward:  -9.430 | Epsilon: 0.0100 | Loss: 407060.5938
Episode 169450 | Reward:  -9.714 | Epsilon: 0.0100 | Loss: 412440.3438
Episode 169500 | Reward: -10.287 | Epsilon: 0.0100 | Loss: 419241.0625
Episode 169550 | Reward: -12.756 | Epsilon: 0.0100 | Loss: 413478.5938
Episode 169600 | Reward:  -8.999 | Epsilon: 0.0100 | Loss: 443104.9688
Episode 169650 | Reward:  -9.360 | Epsilon: 0.0100 | Loss: 548616.6250
Episode 169700 | Reward: -14.242 | Epsilon: 0.0100 | Loss: 454384.5000
Episode 169750 | Reward: -12.688 | Epsilon: 0.0100 | Loss: 417527.5000
Episode 169800 | Reward:  -9.990 | Epsilon: 0.0100 | Loss: 340267.0625
Episode 169850 | Reward:  -6.336 | Epsilon: 0.0100 | Loss: 465197.8750
Episode 169900 | Reward:  -8.524 | Epsilon: 0.0100 | Loss: 455317.6562
Episode 169950 | Reward:  -9.002 | Epsilon: 0.0100 | Loss: 390694.5000
Episode 170000 | Reward:  -7.844 | Epsilon: 0.0100 | Loss: 468364.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:27).dict
Episode 170050 | Reward:  -5.798 | Epsilon: 0.0100 | Loss: 448786.1250
Episode 170100 | Reward: -10.338 | Epsilon: 0.0100 | Loss: 454733.7812
Episode 170150 | Reward: -10.629 | Epsilon: 0.0100 | Loss: 402754.1562
Episode 170200 | Reward: -13.211 | Epsilon: 0.0100 | Loss: 513275.6250
Episode 170250 | Reward:  -9.456 | Epsilon: 0.0100 | Loss: 435711.4062
Episode 170300 | Reward:  -8.392 | Epsilon: 0.0100 | Loss: 526399.5000
Episode 170350 | Reward:  -9.499 | Epsilon: 0.0100 | Loss: 447291.3125
Episode 170400 | Reward:  -7.826 | Epsilon: 0.0100 | Loss: 508242.0312
Episode 170450 | Reward:  -6.748 | Epsilon: 0.0100 | Loss: 498987.8750
Episode 170500 | Reward:  -9.301 | Epsilon: 0.0100 | Loss: 385434.9688
Episode 170550 | Reward: -11.299 | Epsilon: 0.0100 | Loss: 539451.4375
Episode 170600 | Reward:  -5.777 | Epsilon: 0.0100 | Loss: 368785.6250
Episode 170650 | Reward:  -8.604 | Epsilon: 0.0100 | Loss: 429412.6875
Episode 170700 | Reward:  -9.589 | Epsilon: 0.0100 | Loss: 365068.3125
Episode 170750 | Reward: -13.498 | Epsilon: 0.0100 | Loss: 400583.4688
Episode 170800 | Reward: -10.339 | Epsilon: 0.0100 | Loss: 441965.1562
Episode 170850 | Reward: -10.486 | Epsilon: 0.0100 | Loss: 483475.0938
Episode 170900 | Reward: -10.843 | Epsilon: 0.0100 | Loss: 466040.4062
Episode 170950 | Reward:  -8.836 | Epsilon: 0.0100 | Loss: 393544.1250
Episode 171000 | Reward:  -9.795 | Epsilon: 0.0100 | Loss: 376943.2188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:31).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:31).dict
Episode 171050 | Reward:  -7.660 | Epsilon: 0.0100 | Loss: 410470.7812
Episode 171100 | Reward:  -7.807 | Epsilon: 0.0100 | Loss: 325875.0625
Episode 171150 | Reward: -11.433 | Epsilon: 0.0100 | Loss: 353368.4375
Episode 171200 | Reward:  -9.849 | Epsilon: 0.0100 | Loss: 391871.2188
Episode 171250 | Reward: -10.775 | Epsilon: 0.0100 | Loss: 491942.6562
Episode 171300 | Reward: -12.023 | Epsilon: 0.0100 | Loss: 415538.5625
Episode 171350 | Reward: -12.278 | Epsilon: 0.0100 | Loss: 389763.5312
Episode 171400 | Reward:  -9.707 | Epsilon: 0.0100 | Loss: 378908.8125
Episode 171450 | Reward:  -7.593 | Epsilon: 0.0100 | Loss: 288792.6875
Episode 171500 | Reward: -10.225 | Epsilon: 0.0100 | Loss: 317668.4375
Episode 171550 | Reward: -10.836 | Epsilon: 0.0100 | Loss: 427865.4375
Episode 171600 | Reward: -10.942 | Epsilon: 0.0100 | Loss: 352997.0312
Episode 171650 | Reward:  -8.215 | Epsilon: 0.0100 | Loss: 343714.3125
Episode 171700 | Reward:  -8.288 | Epsilon: 0.0100 | Loss: 366473.3438
Episode 171750 | Reward: -11.063 | Epsilon: 0.0100 | Loss: 428695.6562
Episode 171800 | Reward:  -9.948 | Epsilon: 0.0100 | Loss: 394047.5000
Episode 171850 | Reward: -14.299 | Epsilon: 0.0100 | Loss: 353496.3125
Episode 171900 | Reward: -13.000 | Epsilon: 0.0100 | Loss: 325149.6875
Episode 171950 | Reward:  -9.574 | Epsilon: 0.0100 | Loss: 460866.3438
Episode 172000 | Reward: -11.604 | Epsilon: 0.0100 | Loss: 320336.3125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:36).dict
Episode 172050 | Reward:  -7.234 | Epsilon: 0.0100 | Loss: 473516.0000
Episode 172100 | Reward:  -7.405 | Epsilon: 0.0100 | Loss: 395927.2188
Episode 172150 | Reward:  -6.720 | Epsilon: 0.0100 | Loss: 308041.0938
Episode 172200 | Reward:  -7.787 | Epsilon: 0.0100 | Loss: 382466.3750
Episode 172250 | Reward:  -5.745 | Epsilon: 0.0100 | Loss: 297990.8750
Episode 172300 | Reward:  -8.626 | Epsilon: 0.0100 | Loss: 369326.7500
Episode 172350 | Reward:  -9.907 | Epsilon: 0.0100 | Loss: 409435.7500
Episode 172400 | Reward: -11.907 | Epsilon: 0.0100 | Loss: 244453.9062
Episode 172450 | Reward:  -9.028 | Epsilon: 0.0100 | Loss: 311566.9062
Episode 172500 | Reward:  -9.812 | Epsilon: 0.0100 | Loss: 367446.3750
Episode 172550 | Reward: -10.564 | Epsilon: 0.0100 | Loss: 339088.9375
Episode 172600 | Reward:  -7.701 | Epsilon: 0.0100 | Loss: 344272.6562
Episode 172650 | Reward:  -7.521 | Epsilon: 0.0100 | Loss: 357832.8750
Episode 172700 | Reward:  -7.817 | Epsilon: 0.0100 | Loss: 269031.5312
Episode 172750 | Reward:  -9.966 | Epsilon: 0.0100 | Loss: 316576.3125
Episode 172800 | Reward: -11.780 | Epsilon: 0.0100 | Loss: 336228.3438
Episode 172850 | Reward: -14.196 | Epsilon: 0.0100 | Loss: 394762.3125
Episode 172900 | Reward: -12.886 | Epsilon: 0.0100 | Loss: 335969.5625
Episode 172950 | Reward:  -9.206 | Epsilon: 0.0100 | Loss: 315335.3750
Episode 173000 | Reward: -11.397 | Epsilon: 0.0100 | Loss: 388463.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:40).dict
Episode 173050 | Reward:  -8.463 | Epsilon: 0.0100 | Loss: 424099.5938
Episode 173100 | Reward: -11.428 | Epsilon: 0.0100 | Loss: 389843.4375
Episode 173150 | Reward: -11.200 | Epsilon: 0.0100 | Loss: 353840.3125
Episode 173200 | Reward:  -9.918 | Epsilon: 0.0100 | Loss: 319792.1250
Episode 173250 | Reward: -11.421 | Epsilon: 0.0100 | Loss: 443417.7500
Episode 173300 | Reward:  -8.630 | Epsilon: 0.0100 | Loss: 340440.0000
Episode 173350 | Reward:  -8.611 | Epsilon: 0.0100 | Loss: 286542.6562
Episode 173400 | Reward:  -6.777 | Epsilon: 0.0100 | Loss: 334662.0312
Episode 173450 | Reward:  -6.318 | Epsilon: 0.0100 | Loss: 378744.5000
Episode 173500 | Reward:  -6.098 | Epsilon: 0.0100 | Loss: 415298.0312
Episode 173550 | Reward: -10.297 | Epsilon: 0.0100 | Loss: 335894.9688
Episode 173600 | Reward: -10.200 | Epsilon: 0.0100 | Loss: 315365.6250
Episode 173650 | Reward: -11.787 | Epsilon: 0.0100 | Loss: 396940.5000
Episode 173700 | Reward: -11.595 | Epsilon: 0.0100 | Loss: 343487.5000
Episode 173750 | Reward: -10.143 | Epsilon: 0.0100 | Loss: 409232.4688
Episode 173800 | Reward:  -9.529 | Epsilon: 0.0100 | Loss: 321452.8750
Episode 173850 | Reward:  -7.815 | Epsilon: 0.0100 | Loss: 423855.2812
Episode 173900 | Reward:  -8.670 | Epsilon: 0.0100 | Loss: 430205.2500
Episode 173950 | Reward:  -7.745 | Epsilon: 0.0100 | Loss: 317524.5000
Episode 174000 | Reward: -11.794 | Epsilon: 0.0100 | Loss: 382691.0938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:44).dict
Episode 174050 | Reward:  -9.876 | Epsilon: 0.0100 | Loss: 322744.2812
Episode 174100 | Reward: -12.804 | Epsilon: 0.0100 | Loss: 465523.5625
Episode 174150 | Reward: -10.615 | Epsilon: 0.0100 | Loss: 419124.1875
Episode 174200 | Reward:  -9.447 | Epsilon: 0.0100 | Loss: 334382.2812
Episode 174250 | Reward:  -7.692 | Epsilon: 0.0100 | Loss: 373952.8125
Episode 174300 | Reward:  -8.771 | Epsilon: 0.0100 | Loss: 427487.1875
Episode 174350 | Reward:  -9.157 | Epsilon: 0.0100 | Loss: 331323.8438
Episode 174400 | Reward:  -6.255 | Epsilon: 0.0100 | Loss: 370868.2812
Episode 174450 | Reward:  -9.271 | Epsilon: 0.0100 | Loss: 444618.6250
Episode 174500 | Reward: -11.091 | Epsilon: 0.0100 | Loss: 386533.4375
Episode 174550 | Reward:  -6.928 | Epsilon: 0.0100 | Loss: 374554.1250
Episode 174600 | Reward:  -5.679 | Epsilon: 0.0100 | Loss: 471291.8125
Episode 174650 | Reward:  -9.606 | Epsilon: 0.0100 | Loss: 406510.0938
Episode 174700 | Reward:  -7.475 | Epsilon: 0.0100 | Loss: 509768.0312
Episode 174750 | Reward: -10.912 | Epsilon: 0.0100 | Loss: 365184.3125
Episode 174800 | Reward:  -7.961 | Epsilon: 0.0100 | Loss: 417680.2188
Episode 174850 | Reward: -11.014 | Epsilon: 0.0100 | Loss: 383624.7500
Episode 174900 | Reward: -11.774 | Epsilon: 0.0100 | Loss: 400629.2812
Episode 174950 | Reward:  -8.672 | Epsilon: 0.0100 | Loss: 347471.8750
Episode 175000 | Reward:  -8.775 | Epsilon: 0.0100 | Loss: 467333.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:48).dict
Episode 175050 | Reward:  -6.969 | Epsilon: 0.0100 | Loss: 418756.5625
Episode 175100 | Reward:  -7.558 | Epsilon: 0.0100 | Loss: 433684.8438
Episode 175150 | Reward: -10.053 | Epsilon: 0.0100 | Loss: 519566.7812
Episode 175200 | Reward:  -8.660 | Epsilon: 0.0100 | Loss: 444756.5312
Episode 175250 | Reward: -10.132 | Epsilon: 0.0100 | Loss: 374172.9062
Episode 175300 | Reward: -10.752 | Epsilon: 0.0100 | Loss: 358090.0312
Episode 175350 | Reward: -10.728 | Epsilon: 0.0100 | Loss: 556057.5625
Episode 175400 | Reward: -11.610 | Epsilon: 0.0100 | Loss: 312205.8438
Episode 175450 | Reward:  -7.479 | Epsilon: 0.0100 | Loss: 491889.3438
Episode 175500 | Reward:  -8.418 | Epsilon: 0.0100 | Loss: 389094.0000
Episode 175550 | Reward:  -8.002 | Epsilon: 0.0100 | Loss: 399143.6562
Episode 175600 | Reward: -10.572 | Epsilon: 0.0100 | Loss: 488694.6875
Episode 175650 | Reward: -15.255 | Epsilon: 0.0100 | Loss: 412928.4375
Episode 175700 | Reward: -10.801 | Epsilon: 0.0100 | Loss: 431228.3750
Episode 175750 | Reward: -12.409 | Epsilon: 0.0100 | Loss: 350781.7500
Episode 175800 | Reward:  -8.618 | Epsilon: 0.0100 | Loss: 317210.6250
Episode 175850 | Reward:  -9.166 | Epsilon: 0.0100 | Loss: 412120.6875
Episode 175900 | Reward: -12.452 | Epsilon: 0.0100 | Loss: 419854.7812
Episode 175950 | Reward: -10.298 | Epsilon: 0.0100 | Loss: 318603.4375
Episode 176000 | Reward: -12.217 | Epsilon: 0.0100 | Loss: 436758.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:52).dict
Episode 176050 | Reward: -10.822 | Epsilon: 0.0100 | Loss: 423173.5312
Episode 176100 | Reward:  -8.872 | Epsilon: 0.0100 | Loss: 337180.1250
Episode 176150 | Reward: -12.801 | Epsilon: 0.0100 | Loss: 364776.9062
Episode 176200 | Reward: -13.176 | Epsilon: 0.0100 | Loss: 391308.3125
Episode 176250 | Reward: -16.655 | Epsilon: 0.0100 | Loss: 360222.4062
Episode 176300 | Reward:  -8.477 | Epsilon: 0.0100 | Loss: 303255.6250
Episode 176350 | Reward:  -9.023 | Epsilon: 0.0100 | Loss: 310191.1875
Episode 176400 | Reward: -12.576 | Epsilon: 0.0100 | Loss: 390409.1562
Episode 176450 | Reward: -10.209 | Epsilon: 0.0100 | Loss: 373891.1250
Episode 176500 | Reward: -16.045 | Epsilon: 0.0100 | Loss: 329945.6250
Episode 176550 | Reward: -11.206 | Epsilon: 0.0100 | Loss: 283144.0000
Episode 176600 | Reward: -11.046 | Epsilon: 0.0100 | Loss: 350193.5625
Episode 176650 | Reward: -11.226 | Epsilon: 0.0100 | Loss: 474790.8750
Episode 176700 | Reward: -17.677 | Epsilon: 0.0100 | Loss: 402566.5312
Episode 176750 | Reward:  -7.525 | Epsilon: 0.0100 | Loss: 344632.6875
Episode 176800 | Reward:  -9.555 | Epsilon: 0.0100 | Loss: 382223.6562
Episode 176850 | Reward:  -9.237 | Epsilon: 0.0100 | Loss: 431622.8438
Episode 176900 | Reward: -12.781 | Epsilon: 0.0100 | Loss: 341385.5000
Episode 176950 | Reward: -13.558 | Epsilon: 0.0100 | Loss: 396102.3750
Episode 177000 | Reward: -13.498 | Epsilon: 0.0100 | Loss: 373231.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(12:56).dict
Episode 177050 | Reward: -12.873 | Epsilon: 0.0100 | Loss: 323639.8125
Episode 177100 | Reward: -10.516 | Epsilon: 0.0100 | Loss: 283962.9688
Episode 177150 | Reward: -11.125 | Epsilon: 0.0100 | Loss: 304654.6250
Episode 177200 | Reward: -12.654 | Epsilon: 0.0100 | Loss: 325746.7812
Episode 177250 | Reward:  -6.994 | Epsilon: 0.0100 | Loss: 372505.6562
Episode 177300 | Reward: -11.241 | Epsilon: 0.0100 | Loss: 347151.6562
Episode 177350 | Reward: -12.375 | Epsilon: 0.0100 | Loss: 281693.1875
Episode 177400 | Reward: -11.149 | Epsilon: 0.0100 | Loss: 323272.0938
Episode 177450 | Reward: -11.394 | Epsilon: 0.0100 | Loss: 514841.6250
Episode 177500 | Reward:  -9.449 | Epsilon: 0.0100 | Loss: 309600.5000
Episode 177550 | Reward: -11.721 | Epsilon: 0.0100 | Loss: 342579.0625
Episode 177600 | Reward: -10.274 | Epsilon: 0.0100 | Loss: 299227.6250
Episode 177650 | Reward: -11.928 | Epsilon: 0.0100 | Loss: 385557.2188
Episode 177700 | Reward: -13.920 | Epsilon: 0.0100 | Loss: 307522.6562
Episode 177750 | Reward: -12.584 | Epsilon: 0.0100 | Loss: 335444.4375
Episode 177800 | Reward: -16.054 | Epsilon: 0.0100 | Loss: 384263.1875
Episode 177850 | Reward: -14.111 | Epsilon: 0.0100 | Loss: 402908.0625
Episode 177900 | Reward:  -9.453 | Epsilon: 0.0100 | Loss: 360645.4688
Episode 177950 | Reward:  -8.724 | Epsilon: 0.0100 | Loss: 448437.5938
Episode 178000 | Reward:  -7.604 | Epsilon: 0.0100 | Loss: 533477.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:00).dict
Episode 178050 | Reward:  -6.453 | Epsilon: 0.0100 | Loss: 328955.7812
Episode 178100 | Reward:  -7.176 | Epsilon: 0.0100 | Loss: 400639.4062
Episode 178150 | Reward:  -5.673 | Epsilon: 0.0100 | Loss: 389287.3750
Episode 178200 | Reward:  -7.889 | Epsilon: 0.0100 | Loss: 306424.4062
Episode 178250 | Reward:  -8.294 | Epsilon: 0.0100 | Loss: 352642.6562
Episode 178300 | Reward: -10.667 | Epsilon: 0.0100 | Loss: 387419.0938
Episode 178350 | Reward: -13.934 | Epsilon: 0.0100 | Loss: 315952.3750
Episode 178400 | Reward: -10.023 | Epsilon: 0.0100 | Loss: 404203.1250
Episode 178450 | Reward: -11.497 | Epsilon: 0.0100 | Loss: 333825.4062
Episode 178500 | Reward: -14.180 | Epsilon: 0.0100 | Loss: 419429.4375
Episode 178550 | Reward: -16.042 | Epsilon: 0.0100 | Loss: 356009.0625
Episode 178600 | Reward:  -9.567 | Epsilon: 0.0100 | Loss: 414227.5938
Episode 178650 | Reward:  -4.621 | Epsilon: 0.0100 | Loss: 409359.5625
Episode 178700 | Reward: -11.760 | Epsilon: 0.0100 | Loss: 473515.3750
Episode 178750 | Reward:  -8.404 | Epsilon: 0.0100 | Loss: 484565.4375
Episode 178800 | Reward:  -6.036 | Epsilon: 0.0100 | Loss: 429904.1250
Episode 178850 | Reward:  -6.728 | Epsilon: 0.0100 | Loss: 388074.0938
Episode 178900 | Reward:  -8.308 | Epsilon: 0.0100 | Loss: 370190.3750
Episode 178950 | Reward: -11.977 | Epsilon: 0.0100 | Loss: 431845.3750
Episode 179000 | Reward: -13.112 | Epsilon: 0.0100 | Loss: 463667.3125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:04).dict
Episode 179050 | Reward: -11.993 | Epsilon: 0.0100 | Loss: 483851.0625
Episode 179100 | Reward: -10.031 | Epsilon: 0.0100 | Loss: 398866.5625
Episode 179150 | Reward:  -5.833 | Epsilon: 0.0100 | Loss: 540191.3750
Episode 179200 | Reward: -11.716 | Epsilon: 0.0100 | Loss: 378991.1250
Episode 179250 | Reward: -10.959 | Epsilon: 0.0100 | Loss: 323252.5938
Episode 179300 | Reward: -11.140 | Epsilon: 0.0100 | Loss: 476221.2812
Episode 179350 | Reward:  -8.906 | Epsilon: 0.0100 | Loss: 517025.0625
Episode 179400 | Reward:  -7.266 | Epsilon: 0.0100 | Loss: 436645.2500
Episode 179450 | Reward:  -8.972 | Epsilon: 0.0100 | Loss: 400486.3125
Episode 179500 | Reward: -10.093 | Epsilon: 0.0100 | Loss: 457263.5625
Episode 179550 | Reward:  -5.218 | Epsilon: 0.0100 | Loss: 357357.0938
Episode 179600 | Reward:  -6.356 | Epsilon: 0.0100 | Loss: 453976.7500
Episode 179650 | Reward:  -6.751 | Epsilon: 0.0100 | Loss: 455549.1250
Episode 179700 | Reward:  -8.499 | Epsilon: 0.0100 | Loss: 471320.6875
Episode 179750 | Reward:  -6.472 | Epsilon: 0.0100 | Loss: 418681.8125
Episode 179800 | Reward:  -8.479 | Epsilon: 0.0100 | Loss: 434795.6562
Episode 179850 | Reward:  -9.117 | Epsilon: 0.0100 | Loss: 447687.6562
Episode 179900 | Reward:  -9.317 | Epsilon: 0.0100 | Loss: 392447.2188
Episode 179950 | Reward: -10.967 | Epsilon: 0.0100 | Loss: 414404.1875
Episode 180000 | Reward:  -9.595 | Epsilon: 0.0100 | Loss: 433462.7188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:08).dict
Episode 180050 | Reward: -11.775 | Epsilon: 0.0100 | Loss: 376979.1250
Episode 180100 | Reward: -13.067 | Epsilon: 0.0100 | Loss: 413775.3438
Episode 180150 | Reward:  -8.821 | Epsilon: 0.0100 | Loss: 480099.9688
Episode 180200 | Reward: -10.987 | Epsilon: 0.0100 | Loss: 484868.4688
Episode 180250 | Reward: -10.278 | Epsilon: 0.0100 | Loss: 342057.8125
Episode 180300 | Reward: -10.978 | Epsilon: 0.0100 | Loss: 442698.3125
Episode 180350 | Reward: -15.526 | Epsilon: 0.0100 | Loss: 390273.5312
Episode 180400 | Reward:  -7.618 | Epsilon: 0.0100 | Loss: 384102.1562
Episode 180450 | Reward: -10.034 | Epsilon: 0.0100 | Loss: 322072.7500
Episode 180500 | Reward: -10.330 | Epsilon: 0.0100 | Loss: 504420.8750
Episode 180550 | Reward:  -9.603 | Epsilon: 0.0100 | Loss: 496640.4688
Episode 180600 | Reward: -11.015 | Epsilon: 0.0100 | Loss: 452422.5312
Episode 180650 | Reward:  -8.308 | Epsilon: 0.0100 | Loss: 427397.5000
Episode 180700 | Reward:  -5.776 | Epsilon: 0.0100 | Loss: 455636.2500
Episode 180750 | Reward:  -9.711 | Epsilon: 0.0100 | Loss: 439599.5000
Episode 180800 | Reward: -10.538 | Epsilon: 0.0100 | Loss: 366569.3125
Episode 180850 | Reward: -10.011 | Epsilon: 0.0100 | Loss: 361788.3438
Episode 180900 | Reward: -13.090 | Epsilon: 0.0100 | Loss: 499393.6250
Episode 180950 | Reward: -11.004 | Epsilon: 0.0100 | Loss: 352320.3125
Episode 181000 | Reward:  -9.428 | Epsilon: 0.0100 | Loss: 394556.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:12).dict
Episode 181050 | Reward:  -4.093 | Epsilon: 0.0100 | Loss: 374358.4375
Episode 181100 | Reward:  -8.500 | Epsilon: 0.0100 | Loss: 439423.0938
Episode 181150 | Reward:  -9.979 | Epsilon: 0.0100 | Loss: 405878.3750
Episode 181200 | Reward:  -9.691 | Epsilon: 0.0100 | Loss: 369242.3750
Episode 181250 | Reward: -10.862 | Epsilon: 0.0100 | Loss: 386888.1250
Episode 181300 | Reward: -11.110 | Epsilon: 0.0100 | Loss: 332928.9062
Episode 181350 | Reward:  -6.914 | Epsilon: 0.0100 | Loss: 491831.9375
Episode 181400 | Reward: -11.171 | Epsilon: 0.0100 | Loss: 401845.0938
Episode 181450 | Reward:  -8.883 | Epsilon: 0.0100 | Loss: 479903.6250
Episode 181500 | Reward: -11.563 | Epsilon: 0.0100 | Loss: 461734.1875
Episode 181550 | Reward:  -9.749 | Epsilon: 0.0100 | Loss: 375056.8125
Episode 181600 | Reward: -11.093 | Epsilon: 0.0100 | Loss: 434582.9688
Episode 181650 | Reward:  -9.258 | Epsilon: 0.0100 | Loss: 434275.8750
Episode 181700 | Reward:  -9.533 | Epsilon: 0.0100 | Loss: 316367.6250
Episode 181750 | Reward:  -8.921 | Epsilon: 0.0100 | Loss: 343450.0625
Episode 181800 | Reward:  -5.969 | Epsilon: 0.0100 | Loss: 376586.4062
Episode 181850 | Reward: -10.907 | Epsilon: 0.0100 | Loss: 347239.6562
Episode 181900 | Reward:  -8.785 | Epsilon: 0.0100 | Loss: 390916.1250
Episode 181950 | Reward:  -9.559 | Epsilon: 0.0100 | Loss: 336250.4062
Episode 182000 | Reward:  -9.275 | Epsilon: 0.0100 | Loss: 382700.2812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:16).dict
Episode 182050 | Reward: -10.897 | Epsilon: 0.0100 | Loss: 359604.2188
Episode 182100 | Reward:  -9.156 | Epsilon: 0.0100 | Loss: 329975.9062
Episode 182150 | Reward: -11.110 | Epsilon: 0.0100 | Loss: 288938.0625
Episode 182200 | Reward: -12.388 | Epsilon: 0.0100 | Loss: 377982.3438
Episode 182250 | Reward:  -8.922 | Epsilon: 0.0100 | Loss: 407538.5000
Episode 182300 | Reward: -11.541 | Epsilon: 0.0100 | Loss: 497509.2500
Episode 182350 | Reward:  -8.399 | Epsilon: 0.0100 | Loss: 450606.8438
Episode 182400 | Reward: -10.058 | Epsilon: 0.0100 | Loss: 298504.5000
Episode 182450 | Reward: -11.638 | Epsilon: 0.0100 | Loss: 355097.1250
Episode 182500 | Reward:  -9.729 | Epsilon: 0.0100 | Loss: 394953.0938
Episode 182550 | Reward:  -6.730 | Epsilon: 0.0100 | Loss: 332996.0000
Episode 182600 | Reward:  -7.156 | Epsilon: 0.0100 | Loss: 382101.0938
Episode 182650 | Reward:  -5.523 | Epsilon: 0.0100 | Loss: 281210.3750
Episode 182700 | Reward:  -6.725 | Epsilon: 0.0100 | Loss: 328840.8750
Episode 182750 | Reward:  -8.756 | Epsilon: 0.0100 | Loss: 311231.8750
Episode 182800 | Reward:  -7.161 | Epsilon: 0.0100 | Loss: 319349.6562
Episode 182850 | Reward:  -6.858 | Epsilon: 0.0100 | Loss: 321516.7500
Episode 182900 | Reward: -11.202 | Epsilon: 0.0100 | Loss: 342304.0000
Episode 182950 | Reward: -12.413 | Epsilon: 0.0100 | Loss: 283654.0000
Episode 183000 | Reward:  -9.185 | Epsilon: 0.0100 | Loss: 284682.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:20).dict
Episode 183050 | Reward: -10.076 | Epsilon: 0.0100 | Loss: 292793.7812
Episode 183100 | Reward:  -8.556 | Epsilon: 0.0100 | Loss: 275279.0625
Episode 183150 | Reward: -11.857 | Epsilon: 0.0100 | Loss: 311771.8438
Episode 183200 | Reward: -10.757 | Epsilon: 0.0100 | Loss: 378656.6875
Episode 183250 | Reward:  -8.362 | Epsilon: 0.0100 | Loss: 435325.3438
Episode 183300 | Reward:  -5.941 | Epsilon: 0.0100 | Loss: 302095.8750
Episode 183350 | Reward:  -6.224 | Epsilon: 0.0100 | Loss: 309044.1875
Episode 183400 | Reward:  -7.483 | Epsilon: 0.0100 | Loss: 377899.9688
Episode 183450 | Reward:  -8.782 | Epsilon: 0.0100 | Loss: 291530.7812
Episode 183500 | Reward:  -5.932 | Epsilon: 0.0100 | Loss: 388690.6250
Episode 183550 | Reward:  -9.413 | Epsilon: 0.0100 | Loss: 308312.1250
Episode 183600 | Reward: -11.718 | Epsilon: 0.0100 | Loss: 330332.5938
Episode 183650 | Reward:  -8.560 | Epsilon: 0.0100 | Loss: 342785.8438
Episode 183700 | Reward:  -8.768 | Epsilon: 0.0100 | Loss: 290698.7500
Episode 183750 | Reward: -11.727 | Epsilon: 0.0100 | Loss: 415142.4062
Episode 183800 | Reward:  -8.571 | Epsilon: 0.0100 | Loss: 316875.5000
Episode 183850 | Reward:  -7.880 | Epsilon: 0.0100 | Loss: 303222.7500
Episode 183900 | Reward: -10.691 | Epsilon: 0.0100 | Loss: 252738.6562
Episode 183950 | Reward: -14.300 | Epsilon: 0.0100 | Loss: 321805.6562
Episode 184000 | Reward: -12.973 | Epsilon: 0.0100 | Loss: 322557.9062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:24).dict
Episode 184050 | Reward: -12.659 | Epsilon: 0.0100 | Loss: 346354.0000
Episode 184100 | Reward: -11.618 | Epsilon: 0.0100 | Loss: 311533.0625
Episode 184150 | Reward:  -9.414 | Epsilon: 0.0100 | Loss: 359055.4375
Episode 184200 | Reward:  -9.247 | Epsilon: 0.0100 | Loss: 342228.3750
Episode 184250 | Reward: -10.043 | Epsilon: 0.0100 | Loss: 328020.8438
Episode 184300 | Reward: -10.158 | Epsilon: 0.0100 | Loss: 287558.6875
Episode 184350 | Reward: -11.126 | Epsilon: 0.0100 | Loss: 261971.7188
Episode 184400 | Reward:  -9.976 | Epsilon: 0.0100 | Loss: 292014.7812
Episode 184450 | Reward: -12.177 | Epsilon: 0.0100 | Loss: 286989.3750
Episode 184500 | Reward:  -9.779 | Epsilon: 0.0100 | Loss: 320261.7812
Episode 184550 | Reward:  -7.025 | Epsilon: 0.0100 | Loss: 247260.9375
Episode 184600 | Reward:  -8.962 | Epsilon: 0.0100 | Loss: 300877.8125
Episode 184650 | Reward: -11.492 | Epsilon: 0.0100 | Loss: 304804.3438
Episode 184700 | Reward:  -8.071 | Epsilon: 0.0100 | Loss: 348550.0625
Episode 184750 | Reward:  -9.583 | Epsilon: 0.0100 | Loss: 295065.8750
Episode 184800 | Reward: -11.035 | Epsilon: 0.0100 | Loss: 294404.0312
Episode 184850 | Reward: -11.477 | Epsilon: 0.0100 | Loss: 455766.1562
Episode 184900 | Reward:  -9.786 | Epsilon: 0.0100 | Loss: 335500.7188
Episode 184950 | Reward:  -3.957 | Epsilon: 0.0100 | Loss: 320041.6562
Episode 185000 | Reward: -11.761 | Epsilon: 0.0100 | Loss: 262821.7188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:28).dict
Episode 185050 | Reward:  -8.424 | Epsilon: 0.0100 | Loss: 307620.5000
Episode 185100 | Reward:  -8.569 | Epsilon: 0.0100 | Loss: 233184.5625
Episode 185150 | Reward:  -9.524 | Epsilon: 0.0100 | Loss: 274164.1250
Episode 185200 | Reward:  -8.965 | Epsilon: 0.0100 | Loss: 329124.2500
Episode 185250 | Reward:  -9.090 | Epsilon: 0.0100 | Loss: 327052.1250
Episode 185300 | Reward: -11.013 | Epsilon: 0.0100 | Loss: 344740.1875
Episode 185350 | Reward: -11.355 | Epsilon: 0.0100 | Loss: 241736.0625
Episode 185400 | Reward:  -7.653 | Epsilon: 0.0100 | Loss: 318632.2188
Episode 185450 | Reward:  -8.108 | Epsilon: 0.0100 | Loss: 419373.0938
Episode 185500 | Reward:  -6.963 | Epsilon: 0.0100 | Loss: 299894.7500
Episode 185550 | Reward:  -5.920 | Epsilon: 0.0100 | Loss: 365037.7500
Episode 185600 | Reward:  -9.108 | Epsilon: 0.0100 | Loss: 323976.8438
Episode 185650 | Reward:  -7.719 | Epsilon: 0.0100 | Loss: 383890.8125
Episode 185700 | Reward:  -4.718 | Epsilon: 0.0100 | Loss: 306772.3750
Episode 185750 | Reward:  -4.296 | Epsilon: 0.0100 | Loss: 318392.2812
Episode 185800 | Reward:  -6.682 | Epsilon: 0.0100 | Loss: 351190.7812
Episode 185850 | Reward:  -5.217 | Epsilon: 0.0100 | Loss: 365444.6875
Episode 185900 | Reward:  -8.729 | Epsilon: 0.0100 | Loss: 269824.5312
Episode 185950 | Reward:  -9.880 | Epsilon: 0.0100 | Loss: 349570.0000
Episode 186000 | Reward: -11.066 | Epsilon: 0.0100 | Loss: 350339.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:32).dict
Episode 186050 | Reward: -10.153 | Epsilon: 0.0100 | Loss: 313437.3750
Episode 186100 | Reward: -11.699 | Epsilon: 0.0100 | Loss: 421655.4062
Episode 186150 | Reward: -10.847 | Epsilon: 0.0100 | Loss: 435589.6250
Episode 186200 | Reward: -11.273 | Epsilon: 0.0100 | Loss: 395561.0000
Episode 186250 | Reward: -10.112 | Epsilon: 0.0100 | Loss: 393429.8750
Episode 186300 | Reward: -11.672 | Epsilon: 0.0100 | Loss: 352404.8750
Episode 186350 | Reward:  -8.660 | Epsilon: 0.0100 | Loss: 393995.4375
Episode 186400 | Reward:  -8.418 | Epsilon: 0.0100 | Loss: 345035.1562
Episode 186450 | Reward:  -9.484 | Epsilon: 0.0100 | Loss: 395801.4062
Episode 186500 | Reward:  -8.714 | Epsilon: 0.0100 | Loss: 384589.8438
Episode 186550 | Reward:  -8.850 | Epsilon: 0.0100 | Loss: 364732.6562
Episode 186600 | Reward: -12.317 | Epsilon: 0.0100 | Loss: 360002.4375
Episode 186650 | Reward: -13.129 | Epsilon: 0.0100 | Loss: 472290.5000
Episode 186700 | Reward: -11.571 | Epsilon: 0.0100 | Loss: 309826.5938
Episode 186750 | Reward: -13.747 | Epsilon: 0.0100 | Loss: 418056.4375
Episode 186800 | Reward: -12.755 | Epsilon: 0.0100 | Loss: 485863.3125
Episode 186850 | Reward: -15.886 | Epsilon: 0.0100 | Loss: 402111.9375
Episode 186900 | Reward: -13.747 | Epsilon: 0.0100 | Loss: 511947.5625
Episode 186950 | Reward: -13.203 | Epsilon: 0.0100 | Loss: 420392.7188
Episode 187000 | Reward:  -6.015 | Epsilon: 0.0100 | Loss: 396288.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:36).dict
Episode 187050 | Reward: -11.887 | Epsilon: 0.0100 | Loss: 431897.5625
Episode 187100 | Reward: -13.832 | Epsilon: 0.0100 | Loss: 317981.0625
Episode 187150 | Reward:  -9.604 | Epsilon: 0.0100 | Loss: 413985.0938
Episode 187200 | Reward:  -7.721 | Epsilon: 0.0100 | Loss: 374232.2812
Episode 187250 | Reward:  -9.347 | Epsilon: 0.0100 | Loss: 419216.0000
Episode 187300 | Reward: -10.967 | Epsilon: 0.0100 | Loss: 377674.1562
Episode 187350 | Reward: -10.433 | Epsilon: 0.0100 | Loss: 340724.1250
Episode 187400 | Reward:  -8.903 | Epsilon: 0.0100 | Loss: 387500.4375
Episode 187450 | Reward:  -8.919 | Epsilon: 0.0100 | Loss: 475003.5938
Episode 187500 | Reward: -12.783 | Epsilon: 0.0100 | Loss: 409320.5000
Episode 187550 | Reward: -10.650 | Epsilon: 0.0100 | Loss: 366900.8125
Episode 187600 | Reward: -10.341 | Epsilon: 0.0100 | Loss: 409611.4688
Episode 187650 | Reward:  -8.455 | Epsilon: 0.0100 | Loss: 390288.2812
Episode 187700 | Reward:  -7.649 | Epsilon: 0.0100 | Loss: 524438.1250
Episode 187750 | Reward:  -8.305 | Epsilon: 0.0100 | Loss: 346937.0938
Episode 187800 | Reward:  -9.223 | Epsilon: 0.0100 | Loss: 357987.9688
Episode 187850 | Reward: -12.775 | Epsilon: 0.0100 | Loss: 448595.3750
Episode 187900 | Reward: -13.696 | Epsilon: 0.0100 | Loss: 295219.3125
Episode 187950 | Reward: -11.388 | Epsilon: 0.0100 | Loss: 401952.0312
Episode 188000 | Reward:  -8.659 | Epsilon: 0.0100 | Loss: 348556.3125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:40).dict
Episode 188050 | Reward: -10.934 | Epsilon: 0.0100 | Loss: 464041.0938
Episode 188100 | Reward: -11.450 | Epsilon: 0.0100 | Loss: 395496.7500
Episode 188150 | Reward: -11.811 | Epsilon: 0.0100 | Loss: 408204.1875
Episode 188200 | Reward: -10.091 | Epsilon: 0.0100 | Loss: 410192.4062
Episode 188250 | Reward: -11.342 | Epsilon: 0.0100 | Loss: 393935.1250
Episode 188300 | Reward:  -9.476 | Epsilon: 0.0100 | Loss: 401555.1875
Episode 188350 | Reward:  -5.509 | Epsilon: 0.0100 | Loss: 368070.1250
Episode 188400 | Reward:  -5.920 | Epsilon: 0.0100 | Loss: 433095.3125
Episode 188450 | Reward:  -8.106 | Epsilon: 0.0100 | Loss: 353013.3125
Episode 188500 | Reward: -10.032 | Epsilon: 0.0100 | Loss: 378412.8750
Episode 188550 | Reward:  -9.649 | Epsilon: 0.0100 | Loss: 346817.3750
Episode 188600 | Reward:  -9.005 | Epsilon: 0.0100 | Loss: 329751.7812
Episode 188650 | Reward:  -7.996 | Epsilon: 0.0100 | Loss: 428316.4062
Episode 188700 | Reward: -10.079 | Epsilon: 0.0100 | Loss: 438346.8750
Episode 188750 | Reward: -13.026 | Epsilon: 0.0100 | Loss: 385429.5000
Episode 188800 | Reward:  -7.969 | Epsilon: 0.0100 | Loss: 400772.0625
Episode 188850 | Reward:  -9.534 | Epsilon: 0.0100 | Loss: 311822.9688
Episode 188900 | Reward:  -9.415 | Epsilon: 0.0100 | Loss: 360661.1250
Episode 188950 | Reward:  -9.887 | Epsilon: 0.0100 | Loss: 368051.0625
Episode 189000 | Reward:  -6.361 | Epsilon: 0.0100 | Loss: 403155.5938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:44).dict
Episode 189050 | Reward:  -7.296 | Epsilon: 0.0100 | Loss: 389241.2812
Episode 189100 | Reward:  -8.725 | Epsilon: 0.0100 | Loss: 317893.6250
Episode 189150 | Reward:  -7.457 | Epsilon: 0.0100 | Loss: 408447.1875
Episode 189200 | Reward: -12.893 | Epsilon: 0.0100 | Loss: 350366.0000
Episode 189250 | Reward: -10.440 | Epsilon: 0.0100 | Loss: 387652.0312
Episode 189300 | Reward: -10.453 | Epsilon: 0.0100 | Loss: 363999.2500
Episode 189350 | Reward:  -6.783 | Epsilon: 0.0100 | Loss: 433328.6250
Episode 189400 | Reward: -10.842 | Epsilon: 0.0100 | Loss: 430617.8438
Episode 189450 | Reward: -14.228 | Epsilon: 0.0100 | Loss: 319886.0000
Episode 189500 | Reward: -14.115 | Epsilon: 0.0100 | Loss: 618497.6875
Episode 189550 | Reward: -10.805 | Epsilon: 0.0100 | Loss: 387586.3125
Episode 189600 | Reward:  -5.954 | Epsilon: 0.0100 | Loss: 465324.7188
Episode 189650 | Reward:  -7.452 | Epsilon: 0.0100 | Loss: 421568.4375
Episode 189700 | Reward:  -7.747 | Epsilon: 0.0100 | Loss: 393690.5938
Episode 189750 | Reward:  -8.932 | Epsilon: 0.0100 | Loss: 445018.4062
Episode 189800 | Reward: -10.244 | Epsilon: 0.0100 | Loss: 369105.1562
Episode 189850 | Reward:  -6.466 | Epsilon: 0.0100 | Loss: 424281.9062
Episode 189900 | Reward:  -7.551 | Epsilon: 0.0100 | Loss: 263352.0312
Episode 189950 | Reward:  -9.369 | Epsilon: 0.0100 | Loss: 341047.2500
Episode 190000 | Reward:  -4.952 | Epsilon: 0.0100 | Loss: 434390.9688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:48).dict
Episode 190050 | Reward:  -7.416 | Epsilon: 0.0100 | Loss: 370396.1250
Episode 190100 | Reward:  -7.311 | Epsilon: 0.0100 | Loss: 403981.4375
Episode 190150 | Reward: -14.940 | Epsilon: 0.0100 | Loss: 423078.6250
Episode 190200 | Reward:  -9.096 | Epsilon: 0.0100 | Loss: 493286.1562
Episode 190250 | Reward:  -8.919 | Epsilon: 0.0100 | Loss: 408538.2500
Episode 190300 | Reward: -13.880 | Epsilon: 0.0100 | Loss: 431249.7500
Episode 190350 | Reward: -11.372 | Epsilon: 0.0100 | Loss: 355011.1875
Episode 190400 | Reward:  -9.227 | Epsilon: 0.0100 | Loss: 345770.7812
Episode 190450 | Reward:  -6.549 | Epsilon: 0.0100 | Loss: 474251.9375
Episode 190500 | Reward: -11.847 | Epsilon: 0.0100 | Loss: 292459.4375
Episode 190550 | Reward: -11.081 | Epsilon: 0.0100 | Loss: 381793.8750
Episode 190600 | Reward:  -9.970 | Epsilon: 0.0100 | Loss: 368049.5938
Episode 190650 | Reward:  -7.591 | Epsilon: 0.0100 | Loss: 393395.3750
Episode 190700 | Reward: -11.524 | Epsilon: 0.0100 | Loss: 291007.3125
Episode 190750 | Reward:  -7.087 | Epsilon: 0.0100 | Loss: 473786.9062
Episode 190800 | Reward:  -7.288 | Epsilon: 0.0100 | Loss: 392776.2500
Episode 190850 | Reward:  -6.192 | Epsilon: 0.0100 | Loss: 384187.5312
Episode 190900 | Reward:  -8.065 | Epsilon: 0.0100 | Loss: 433657.3750
Episode 190950 | Reward: -10.292 | Epsilon: 0.0100 | Loss: 381477.8750
Episode 191000 | Reward:  -7.649 | Epsilon: 0.0100 | Loss: 584436.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:52).dict
Episode 191050 | Reward: -12.126 | Epsilon: 0.0100 | Loss: 472699.1875
Episode 191100 | Reward: -12.619 | Epsilon: 0.0100 | Loss: 370011.0000
Episode 191150 | Reward: -11.382 | Epsilon: 0.0100 | Loss: 450603.7188
Episode 191200 | Reward:  -7.383 | Epsilon: 0.0100 | Loss: 332794.0938
Episode 191250 | Reward: -11.205 | Epsilon: 0.0100 | Loss: 335588.8125
Episode 191300 | Reward:  -9.284 | Epsilon: 0.0100 | Loss: 368917.7500
Episode 191350 | Reward: -11.724 | Epsilon: 0.0100 | Loss: 435859.1562
Episode 191400 | Reward:  -9.623 | Epsilon: 0.0100 | Loss: 509995.5000
Episode 191450 | Reward: -10.858 | Epsilon: 0.0100 | Loss: 392700.6250
Episode 191500 | Reward: -11.089 | Epsilon: 0.0100 | Loss: 335328.9688
Episode 191550 | Reward:  -6.913 | Epsilon: 0.0100 | Loss: 404370.2500
Episode 191600 | Reward:  -8.324 | Epsilon: 0.0100 | Loss: 391830.0312
Episode 191650 | Reward:  -5.782 | Epsilon: 0.0100 | Loss: 430560.6250
Episode 191700 | Reward:  -7.341 | Epsilon: 0.0100 | Loss: 442423.1875
Episode 191750 | Reward:  -9.625 | Epsilon: 0.0100 | Loss: 359667.2500
Episode 191800 | Reward:  -9.696 | Epsilon: 0.0100 | Loss: 379635.5625
Episode 191850 | Reward: -10.094 | Epsilon: 0.0100 | Loss: 391196.9375
Episode 191900 | Reward: -12.658 | Epsilon: 0.0100 | Loss: 338168.0000
Episode 191950 | Reward: -10.634 | Epsilon: 0.0100 | Loss: 303367.7188
Episode 192000 | Reward:  -7.497 | Epsilon: 0.0100 | Loss: 409892.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(13:56).dict
Episode 192050 | Reward: -10.189 | Epsilon: 0.0100 | Loss: 452320.7500
Episode 192100 | Reward:  -4.866 | Epsilon: 0.0100 | Loss: 423120.1875
Episode 192150 | Reward:  -7.283 | Epsilon: 0.0100 | Loss: 430732.7188
Episode 192200 | Reward:  -6.780 | Epsilon: 0.0100 | Loss: 394537.3125
Episode 192250 | Reward:  -6.509 | Epsilon: 0.0100 | Loss: 381226.4688
Episode 192300 | Reward:  -3.295 | Epsilon: 0.0100 | Loss: 410660.9688
Episode 192350 | Reward:  -3.866 | Epsilon: 0.0100 | Loss: 350684.6250
Episode 192400 | Reward:  -8.439 | Epsilon: 0.0100 | Loss: 441975.7188
Episode 192450 | Reward:  -5.686 | Epsilon: 0.0100 | Loss: 447366.0000
Episode 192500 | Reward:  -6.226 | Epsilon: 0.0100 | Loss: 430987.5938
Episode 192550 | Reward:  -3.733 | Epsilon: 0.0100 | Loss: 406699.0312
Episode 192600 | Reward: -11.240 | Epsilon: 0.0100 | Loss: 345427.3750
Episode 192650 | Reward:  -8.431 | Epsilon: 0.0100 | Loss: 382249.9062
Episode 192700 | Reward:  -5.000 | Epsilon: 0.0100 | Loss: 287625.6875
Episode 192750 | Reward:  -7.638 | Epsilon: 0.0100 | Loss: 350755.5625
Episode 192800 | Reward:  -9.835 | Epsilon: 0.0100 | Loss: 247269.2812
Episode 192850 | Reward:  -6.578 | Epsilon: 0.0100 | Loss: 296299.6562
Episode 192900 | Reward:  -8.573 | Epsilon: 0.0100 | Loss: 319759.9375
Episode 192950 | Reward: -12.585 | Epsilon: 0.0100 | Loss: 383306.0000
Episode 193000 | Reward:  -8.071 | Epsilon: 0.0100 | Loss: 373911.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:00).dict
Episode 193050 | Reward:  -6.867 | Epsilon: 0.0100 | Loss: 278203.4375
Episode 193100 | Reward:  -5.031 | Epsilon: 0.0100 | Loss: 388183.9688
Episode 193150 | Reward: -10.152 | Epsilon: 0.0100 | Loss: 338537.3125
Episode 193200 | Reward:  -4.953 | Epsilon: 0.0100 | Loss: 338940.5625
Episode 193250 | Reward:  -9.719 | Epsilon: 0.0100 | Loss: 298446.1250
Episode 193300 | Reward:  -6.797 | Epsilon: 0.0100 | Loss: 373103.8750
Episode 193350 | Reward:  -7.092 | Epsilon: 0.0100 | Loss: 407690.1250
Episode 193400 | Reward:  -4.801 | Epsilon: 0.0100 | Loss: 476100.1250
Episode 193450 | Reward: -10.077 | Epsilon: 0.0100 | Loss: 304886.6250
Episode 193500 | Reward: -10.358 | Epsilon: 0.0100 | Loss: 372191.0625
Episode 193550 | Reward:  -7.056 | Epsilon: 0.0100 | Loss: 396478.3750
Episode 193600 | Reward:  -7.274 | Epsilon: 0.0100 | Loss: 328289.1562
Episode 193650 | Reward:  -7.094 | Epsilon: 0.0100 | Loss: 368783.3750
Episode 193700 | Reward: -10.798 | Epsilon: 0.0100 | Loss: 354858.3438
Episode 193750 | Reward:  -7.711 | Epsilon: 0.0100 | Loss: 373261.3750
Episode 193800 | Reward:  -8.470 | Epsilon: 0.0100 | Loss: 237169.6094
Episode 193850 | Reward:  -8.535 | Epsilon: 0.0100 | Loss: 348510.6250
Episode 193900 | Reward:  -7.961 | Epsilon: 0.0100 | Loss: 504570.8750
Episode 193950 | Reward: -10.312 | Epsilon: 0.0100 | Loss: 387877.5625
Episode 194000 | Reward: -10.552 | Epsilon: 0.0100 | Loss: 350701.2812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:05).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:05).dict
Episode 194050 | Reward:  -7.637 | Epsilon: 0.0100 | Loss: 474817.6250
Episode 194100 | Reward:  -8.938 | Epsilon: 0.0100 | Loss: 427017.0000
Episode 194150 | Reward: -11.838 | Epsilon: 0.0100 | Loss: 269055.4688
Episode 194200 | Reward: -11.907 | Epsilon: 0.0100 | Loss: 338662.1875
Episode 194250 | Reward: -11.222 | Epsilon: 0.0100 | Loss: 507180.7500
Episode 194300 | Reward: -12.358 | Epsilon: 0.0100 | Loss: 363822.6250
Episode 194350 | Reward: -11.629 | Epsilon: 0.0100 | Loss: 367859.6562
Episode 194400 | Reward: -10.699 | Epsilon: 0.0100 | Loss: 390165.0000
Episode 194450 | Reward: -13.601 | Epsilon: 0.0100 | Loss: 383463.3750
Episode 194500 | Reward:  -6.990 | Epsilon: 0.0100 | Loss: 407247.4375
Episode 194550 | Reward: -11.004 | Epsilon: 0.0100 | Loss: 341156.9688
Episode 194600 | Reward:  -8.800 | Epsilon: 0.0100 | Loss: 430942.5000
Episode 194650 | Reward:  -8.068 | Epsilon: 0.0100 | Loss: 292634.0312
Episode 194700 | Reward: -10.472 | Epsilon: 0.0100 | Loss: 463106.3125
Episode 194750 | Reward: -10.482 | Epsilon: 0.0100 | Loss: 312930.6875
Episode 194800 | Reward:  -7.549 | Epsilon: 0.0100 | Loss: 361720.8438
Episode 194850 | Reward:  -8.019 | Epsilon: 0.0100 | Loss: 367936.0625
Episode 194900 | Reward: -11.778 | Epsilon: 0.0100 | Loss: 365942.5625
Episode 194950 | Reward:  -8.396 | Epsilon: 0.0100 | Loss: 350672.1875
Episode 195000 | Reward:  -8.854 | Epsilon: 0.0100 | Loss: 347655.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:09).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:09).dict
Episode 195050 | Reward:  -8.937 | Epsilon: 0.0100 | Loss: 379413.7812
Episode 195100 | Reward:  -7.217 | Epsilon: 0.0100 | Loss: 332868.6250
Episode 195150 | Reward:  -9.317 | Epsilon: 0.0100 | Loss: 375272.5938
Episode 195200 | Reward: -11.211 | Epsilon: 0.0100 | Loss: 366477.7500
Episode 195250 | Reward:  -7.167 | Epsilon: 0.0100 | Loss: 333436.7188
Episode 195300 | Reward: -12.230 | Epsilon: 0.0100 | Loss: 363513.5625
Episode 195350 | Reward:  -7.308 | Epsilon: 0.0100 | Loss: 249771.1562
Episode 195400 | Reward:  -8.711 | Epsilon: 0.0100 | Loss: 326873.4688
Episode 195450 | Reward: -11.540 | Epsilon: 0.0100 | Loss: 314851.7812
Episode 195500 | Reward:  -9.518 | Epsilon: 0.0100 | Loss: 338044.4375
Episode 195550 | Reward:  -8.639 | Epsilon: 0.0100 | Loss: 298839.6250
Episode 195600 | Reward:  -9.932 | Epsilon: 0.0100 | Loss: 269902.9375
Episode 195650 | Reward:  -8.185 | Epsilon: 0.0100 | Loss: 294917.4688
Episode 195700 | Reward:  -6.711 | Epsilon: 0.0100 | Loss: 378553.9688
Episode 195750 | Reward:  -9.425 | Epsilon: 0.0100 | Loss: 467634.1875
Episode 195800 | Reward: -11.713 | Epsilon: 0.0100 | Loss: 323874.8438
Episode 195850 | Reward: -13.689 | Epsilon: 0.0100 | Loss: 371671.5625
Episode 195900 | Reward: -12.243 | Epsilon: 0.0100 | Loss: 327693.0938
Episode 195950 | Reward: -10.667 | Epsilon: 0.0100 | Loss: 368447.3438
Episode 196000 | Reward: -11.234 | Epsilon: 0.0100 | Loss: 372155.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:13).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:13).dict
Episode 196050 | Reward: -12.912 | Epsilon: 0.0100 | Loss: 470806.2812
Episode 196100 | Reward:  -8.655 | Epsilon: 0.0100 | Loss: 440204.2812
Episode 196150 | Reward:  -9.896 | Epsilon: 0.0100 | Loss: 401638.3750
Episode 196200 | Reward: -10.435 | Epsilon: 0.0100 | Loss: 379723.8438
Episode 196250 | Reward:  -7.341 | Epsilon: 0.0100 | Loss: 420327.1875
Episode 196300 | Reward:  -6.651 | Epsilon: 0.0100 | Loss: 402653.0938
Episode 196350 | Reward: -13.842 | Epsilon: 0.0100 | Loss: 284755.1250
Episode 196400 | Reward: -12.297 | Epsilon: 0.0100 | Loss: 398938.3750
Episode 196450 | Reward: -10.353 | Epsilon: 0.0100 | Loss: 298430.5938
Episode 196500 | Reward: -12.199 | Epsilon: 0.0100 | Loss: 284510.0938
Episode 196550 | Reward:  -8.832 | Epsilon: 0.0100 | Loss: 287868.4375
Episode 196600 | Reward: -10.578 | Epsilon: 0.0100 | Loss: 363308.3125
Episode 196650 | Reward:  -7.490 | Epsilon: 0.0100 | Loss: 406952.0625
Episode 196700 | Reward:  -6.354 | Epsilon: 0.0100 | Loss: 394847.8125
Episode 196750 | Reward:  -8.361 | Epsilon: 0.0100 | Loss: 372520.2188
Episode 196800 | Reward:  -6.154 | Epsilon: 0.0100 | Loss: 363405.6250
Episode 196850 | Reward:  -7.271 | Epsilon: 0.0100 | Loss: 340851.4688
Episode 196900 | Reward: -12.854 | Epsilon: 0.0100 | Loss: 370532.9375
Episode 196950 | Reward: -11.421 | Epsilon: 0.0100 | Loss: 282399.9375
Episode 197000 | Reward:  -7.529 | Epsilon: 0.0100 | Loss: 420844.7188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:17).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:17).dict
Episode 197050 | Reward:  -6.511 | Epsilon: 0.0100 | Loss: 231255.5625
Episode 197100 | Reward:  -5.473 | Epsilon: 0.0100 | Loss: 279307.0625
Episode 197150 | Reward:  -8.600 | Epsilon: 0.0100 | Loss: 336628.9688
Episode 197200 | Reward:  -9.896 | Epsilon: 0.0100 | Loss: 399231.4062
Episode 197250 | Reward:  -8.471 | Epsilon: 0.0100 | Loss: 327631.1875
Episode 197300 | Reward: -13.575 | Epsilon: 0.0100 | Loss: 394407.5938
Episode 197350 | Reward: -13.449 | Epsilon: 0.0100 | Loss: 324402.3125
Episode 197400 | Reward:  -7.693 | Epsilon: 0.0100 | Loss: 299341.5625
Episode 197450 | Reward:  -9.153 | Epsilon: 0.0100 | Loss: 309802.3750
Episode 197500 | Reward: -10.151 | Epsilon: 0.0100 | Loss: 370802.0938
Episode 197550 | Reward:  -9.328 | Epsilon: 0.0100 | Loss: 340532.5312
Episode 197600 | Reward:  -9.463 | Epsilon: 0.0100 | Loss: 280553.7188
Episode 197650 | Reward:  -8.880 | Epsilon: 0.0100 | Loss: 269860.7500
Episode 197700 | Reward: -12.033 | Epsilon: 0.0100 | Loss: 304303.9375
Episode 197750 | Reward: -15.425 | Epsilon: 0.0100 | Loss: 267804.6562
Episode 197800 | Reward: -11.727 | Epsilon: 0.0100 | Loss: 366804.2812
Episode 197850 | Reward: -12.772 | Epsilon: 0.0100 | Loss: 309811.7188
Episode 197900 | Reward: -14.802 | Epsilon: 0.0100 | Loss: 331935.5312
Episode 197950 | Reward: -12.842 | Epsilon: 0.0100 | Loss: 370535.5625
Episode 198000 | Reward: -12.144 | Epsilon: 0.0100 | Loss: 366009.9688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:21).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:21).dict
Episode 198050 | Reward:  -6.423 | Epsilon: 0.0100 | Loss: 380041.8125
Episode 198100 | Reward:  -7.223 | Epsilon: 0.0100 | Loss: 370880.0000
Episode 198150 | Reward:  -9.826 | Epsilon: 0.0100 | Loss: 267752.5312
Episode 198200 | Reward: -14.255 | Epsilon: 0.0100 | Loss: 315017.0625
Episode 198250 | Reward: -10.576 | Epsilon: 0.0100 | Loss: 362774.2500
Episode 198300 | Reward: -10.595 | Epsilon: 0.0100 | Loss: 344374.0000
Episode 198350 | Reward:  -7.028 | Epsilon: 0.0100 | Loss: 390375.4688
Episode 198400 | Reward:  -8.129 | Epsilon: 0.0100 | Loss: 400851.6250
Episode 198450 | Reward: -10.429 | Epsilon: 0.0100 | Loss: 353286.8125
Episode 198500 | Reward:  -5.154 | Epsilon: 0.0100 | Loss: 229798.3594
Episode 198550 | Reward: -10.415 | Epsilon: 0.0100 | Loss: 292495.1875
Episode 198600 | Reward: -10.907 | Epsilon: 0.0100 | Loss: 347570.5938
Episode 198650 | Reward: -12.694 | Epsilon: 0.0100 | Loss: 276782.9688
Episode 198700 | Reward:  -8.830 | Epsilon: 0.0100 | Loss: 369498.1250
Episode 198750 | Reward:  -8.748 | Epsilon: 0.0100 | Loss: 269171.0625
Episode 198800 | Reward:  -4.025 | Epsilon: 0.0100 | Loss: 301502.2188
Episode 198850 | Reward:  -5.097 | Epsilon: 0.0100 | Loss: 345763.0938
Episode 198900 | Reward:  -6.239 | Epsilon: 0.0100 | Loss: 460079.7812
Episode 198950 | Reward: -11.011 | Epsilon: 0.0100 | Loss: 374151.1562
Episode 199000 | Reward:  -9.705 | Epsilon: 0.0100 | Loss: 298966.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:25).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:25).dict
Episode 199050 | Reward:  -9.747 | Epsilon: 0.0100 | Loss: 379342.5625
Episode 199100 | Reward: -11.759 | Epsilon: 0.0100 | Loss: 401480.5312
Episode 199150 | Reward: -12.197 | Epsilon: 0.0100 | Loss: 374308.4375
Episode 199200 | Reward: -11.455 | Epsilon: 0.0100 | Loss: 286156.1875
Episode 199250 | Reward: -12.282 | Epsilon: 0.0100 | Loss: 377844.6250
Episode 199300 | Reward:  -8.935 | Epsilon: 0.0100 | Loss: 283617.9062
Episode 199350 | Reward: -10.429 | Epsilon: 0.0100 | Loss: 364329.9062
Episode 199400 | Reward: -10.496 | Epsilon: 0.0100 | Loss: 334099.4375
Episode 199450 | Reward:  -8.643 | Epsilon: 0.0100 | Loss: 383833.3125
Episode 199500 | Reward:  -8.005 | Epsilon: 0.0100 | Loss: 433037.8438
Episode 199550 | Reward:  -7.331 | Epsilon: 0.0100 | Loss: 392895.1875
Episode 199600 | Reward:  -8.678 | Epsilon: 0.0100 | Loss: 290323.9375
Episode 199650 | Reward:  -9.348 | Epsilon: 0.0100 | Loss: 358226.3438
Episode 199700 | Reward:  -8.995 | Epsilon: 0.0100 | Loss: 420353.1250
Episode 199750 | Reward: -12.055 | Epsilon: 0.0100 | Loss: 357647.2500
Episode 199800 | Reward:  -7.846 | Epsilon: 0.0100 | Loss: 372704.5625
Episode 199850 | Reward:  -7.694 | Epsilon: 0.0100 | Loss: 384107.9062
Episode 199900 | Reward: -13.165 | Epsilon: 0.0100 | Loss: 298022.5938
Episode 199950 | Reward:  -8.703 | Epsilon: 0.0100 | Loss: 322003.2500
Episode 200000 | Reward:  -8.332 | Epsilon: 0.0100 | Loss: 377698.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:29).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:29).dict
Episode 200050 | Reward: -12.389 | Epsilon: 0.0100 | Loss: 335176.3750
Episode 200100 | Reward: -11.695 | Epsilon: 0.0100 | Loss: 363373.4062
Episode 200150 | Reward:  -8.624 | Epsilon: 0.0100 | Loss: 348857.3438
Episode 200200 | Reward:  -9.869 | Epsilon: 0.0100 | Loss: 294686.0625
Episode 200250 | Reward: -10.098 | Epsilon: 0.0100 | Loss: 359759.1875
Episode 200300 | Reward: -13.832 | Epsilon: 0.0100 | Loss: 352713.5312
Episode 200350 | Reward: -10.214 | Epsilon: 0.0100 | Loss: 383006.1250
Episode 200400 | Reward: -11.920 | Epsilon: 0.0100 | Loss: 358273.1250
Episode 200450 | Reward: -13.545 | Epsilon: 0.0100 | Loss: 328444.7188
Episode 200500 | Reward: -11.119 | Epsilon: 0.0100 | Loss: 318794.1250
Episode 200550 | Reward: -11.471 | Epsilon: 0.0100 | Loss: 356636.4688
Episode 200600 | Reward:  -9.371 | Epsilon: 0.0100 | Loss: 280050.5312
Episode 200650 | Reward: -11.509 | Epsilon: 0.0100 | Loss: 324488.0938
Episode 200700 | Reward: -12.404 | Epsilon: 0.0100 | Loss: 340803.9375
Episode 200750 | Reward:  -9.665 | Epsilon: 0.0100 | Loss: 276611.9062
Episode 200800 | Reward:  -9.280 | Epsilon: 0.0100 | Loss: 357299.9375
Episode 200850 | Reward:  -6.813 | Epsilon: 0.0100 | Loss: 396799.6250
Episode 200900 | Reward:  -9.465 | Epsilon: 0.0100 | Loss: 303395.5938
Episode 200950 | Reward:  -8.951 | Epsilon: 0.0100 | Loss: 290728.6250
Episode 201000 | Reward: -11.356 | Epsilon: 0.0100 | Loss: 281529.9688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:33).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:33).dict
Episode 201050 | Reward: -12.166 | Epsilon: 0.0100 | Loss: 238580.7500
Episode 201100 | Reward: -13.051 | Epsilon: 0.0100 | Loss: 321600.9375
Episode 201150 | Reward: -12.355 | Epsilon: 0.0100 | Loss: 414391.7812
Episode 201200 | Reward: -10.993 | Epsilon: 0.0100 | Loss: 297793.6250
Episode 201250 | Reward:  -8.200 | Epsilon: 0.0100 | Loss: 406179.0000
Episode 201300 | Reward:  -7.097 | Epsilon: 0.0100 | Loss: 459695.1250
Episode 201350 | Reward:  -8.798 | Epsilon: 0.0100 | Loss: 296829.7188
Episode 201400 | Reward: -11.476 | Epsilon: 0.0100 | Loss: 366868.3750
Episode 201450 | Reward:  -9.210 | Epsilon: 0.0100 | Loss: 347480.6875
Episode 201500 | Reward:  -7.673 | Epsilon: 0.0100 | Loss: 366061.5000
Episode 201550 | Reward:  -5.936 | Epsilon: 0.0100 | Loss: 386823.5938
Episode 201600 | Reward: -10.521 | Epsilon: 0.0100 | Loss: 306381.9375
Episode 201650 | Reward: -11.076 | Epsilon: 0.0100 | Loss: 331619.4375
Episode 201700 | Reward: -11.546 | Epsilon: 0.0100 | Loss: 352952.0625
Episode 201750 | Reward:  -8.092 | Epsilon: 0.0100 | Loss: 304856.8438
Episode 201800 | Reward: -11.712 | Epsilon: 0.0100 | Loss: 379674.9062
Episode 201850 | Reward: -10.145 | Epsilon: 0.0100 | Loss: 427297.6250
Episode 201900 | Reward: -11.433 | Epsilon: 0.0100 | Loss: 348902.3438
Episode 201950 | Reward: -13.049 | Epsilon: 0.0100 | Loss: 344438.9375
Episode 202000 | Reward: -13.107 | Epsilon: 0.0100 | Loss: 361087.8438
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:37).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:37).dict
Episode 202050 | Reward: -15.923 | Epsilon: 0.0100 | Loss: 315412.5938
Episode 202100 | Reward: -12.921 | Epsilon: 0.0100 | Loss: 446725.5938
Episode 202150 | Reward:  -9.438 | Epsilon: 0.0100 | Loss: 294644.0312
Episode 202200 | Reward:  -9.162 | Epsilon: 0.0100 | Loss: 313017.3438
Episode 202250 | Reward:  -9.275 | Epsilon: 0.0100 | Loss: 330574.3750
Episode 202300 | Reward:  -9.201 | Epsilon: 0.0100 | Loss: 432444.1250
Episode 202350 | Reward:  -6.893 | Epsilon: 0.0100 | Loss: 445437.6562
Episode 202400 | Reward: -10.391 | Epsilon: 0.0100 | Loss: 421826.4062
Episode 202450 | Reward: -10.124 | Epsilon: 0.0100 | Loss: 258457.8750
Episode 202500 | Reward:  -9.983 | Epsilon: 0.0100 | Loss: 355262.4375
Episode 202550 | Reward:  -7.167 | Epsilon: 0.0100 | Loss: 356439.7188
Episode 202600 | Reward: -13.056 | Epsilon: 0.0100 | Loss: 460287.7500
Episode 202650 | Reward: -10.842 | Epsilon: 0.0100 | Loss: 430560.4375
Episode 202700 | Reward:  -5.460 | Epsilon: 0.0100 | Loss: 388724.9062
Episode 202750 | Reward:  -7.605 | Epsilon: 0.0100 | Loss: 326066.3438
Episode 202800 | Reward:  -7.937 | Epsilon: 0.0100 | Loss: 281091.1875
Episode 202850 | Reward:  -7.068 | Epsilon: 0.0100 | Loss: 378242.5938
Episode 202900 | Reward:  -8.016 | Epsilon: 0.0100 | Loss: 369438.7500
Episode 202950 | Reward: -11.407 | Epsilon: 0.0100 | Loss: 259687.7031
Episode 203000 | Reward: -13.482 | Epsilon: 0.0100 | Loss: 286078.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:41).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:41).dict
Episode 203050 | Reward:  -8.843 | Epsilon: 0.0100 | Loss: 322128.1562
Episode 203100 | Reward:  -8.648 | Epsilon: 0.0100 | Loss: 292164.8750
Episode 203150 | Reward:  -9.741 | Epsilon: 0.0100 | Loss: 288317.9375
Episode 203200 | Reward: -10.799 | Epsilon: 0.0100 | Loss: 359862.2812
Episode 203250 | Reward:  -6.431 | Epsilon: 0.0100 | Loss: 335660.9062
Episode 203300 | Reward:  -6.892 | Epsilon: 0.0100 | Loss: 304696.0938
Episode 203350 | Reward:  -9.382 | Epsilon: 0.0100 | Loss: 289439.9062
Episode 203400 | Reward:  -4.851 | Epsilon: 0.0100 | Loss: 290562.5625
Episode 203450 | Reward:  -8.187 | Epsilon: 0.0100 | Loss: 346246.3438
Episode 203500 | Reward:  -8.758 | Epsilon: 0.0100 | Loss: 399976.3125
Episode 203550 | Reward:  -9.226 | Epsilon: 0.0100 | Loss: 342294.0000
Episode 203600 | Reward:  -6.446 | Epsilon: 0.0100 | Loss: 323684.5000
Episode 203650 | Reward:  -7.261 | Epsilon: 0.0100 | Loss: 406335.4688
Episode 203700 | Reward: -11.940 | Epsilon: 0.0100 | Loss: 350076.1562
Episode 203750 | Reward: -11.300 | Epsilon: 0.0100 | Loss: 284825.1562
Episode 203800 | Reward:  -9.098 | Epsilon: 0.0100 | Loss: 294360.9375
Episode 203850 | Reward:  -7.032 | Epsilon: 0.0100 | Loss: 316638.7812
Episode 203900 | Reward:  -5.824 | Epsilon: 0.0100 | Loss: 328127.5312
Episode 203950 | Reward: -12.363 | Epsilon: 0.0100 | Loss: 403574.6875
Episode 204000 | Reward: -10.308 | Epsilon: 0.0100 | Loss: 323366.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:45).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:45).dict
Episode 204050 | Reward: -11.673 | Epsilon: 0.0100 | Loss: 304006.1250
Episode 204100 | Reward:  -9.410 | Epsilon: 0.0100 | Loss: 298487.8750
Episode 204150 | Reward:  -5.259 | Epsilon: 0.0100 | Loss: 293025.1875
Episode 204200 | Reward:  -7.055 | Epsilon: 0.0100 | Loss: 258340.7812
Episode 204250 | Reward:  -7.917 | Epsilon: 0.0100 | Loss: 319968.5312
Episode 204300 | Reward:  -8.095 | Epsilon: 0.0100 | Loss: 372617.2812
Episode 204350 | Reward:  -7.145 | Epsilon: 0.0100 | Loss: 318193.4375
Episode 204400 | Reward:  -8.914 | Epsilon: 0.0100 | Loss: 431949.3125
Episode 204450 | Reward:  -5.820 | Epsilon: 0.0100 | Loss: 301104.4375
Episode 204500 | Reward: -10.484 | Epsilon: 0.0100 | Loss: 277718.8438
Episode 204550 | Reward:  -8.623 | Epsilon: 0.0100 | Loss: 215664.3438
Episode 204600 | Reward:  -5.339 | Epsilon: 0.0100 | Loss: 274067.8438
Episode 204650 | Reward:  -6.052 | Epsilon: 0.0100 | Loss: 271806.6250
Episode 204700 | Reward: -10.666 | Epsilon: 0.0100 | Loss: 290478.7188
Episode 204750 | Reward:  -4.429 | Epsilon: 0.0100 | Loss: 240173.5781
Episode 204800 | Reward:  -5.810 | Epsilon: 0.0100 | Loss: 267778.0312
Episode 204850 | Reward:  -7.913 | Epsilon: 0.0100 | Loss: 337149.6250
Episode 204900 | Reward:  -7.863 | Epsilon: 0.0100 | Loss: 339223.0938
Episode 204950 | Reward:  -8.647 | Epsilon: 0.0100 | Loss: 251760.4375
Episode 205000 | Reward:  -8.360 | Epsilon: 0.0100 | Loss: 301152.9688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:49).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:49).dict
Episode 205050 | Reward:  -7.249 | Epsilon: 0.0100 | Loss: 215078.4375
Episode 205100 | Reward:  -3.219 | Epsilon: 0.0100 | Loss: 306385.5000
Episode 205150 | Reward: -10.612 | Epsilon: 0.0100 | Loss: 262057.1250
Episode 205200 | Reward:  -6.400 | Epsilon: 0.0100 | Loss: 271324.3438
Episode 205250 | Reward: -11.581 | Epsilon: 0.0100 | Loss: 219100.1875
Episode 205300 | Reward:  -6.603 | Epsilon: 0.0100 | Loss: 253628.2344
Episode 205350 | Reward:  -6.054 | Epsilon: 0.0100 | Loss: 260198.0469
Episode 205400 | Reward:  -6.449 | Epsilon: 0.0100 | Loss: 217711.5156
Episode 205450 | Reward:  -8.089 | Epsilon: 0.0100 | Loss: 240980.9219
Episode 205500 | Reward:  -5.353 | Epsilon: 0.0100 | Loss: 301579.4688
Episode 205550 | Reward:  -8.015 | Epsilon: 0.0100 | Loss: 271946.7500
Episode 205600 | Reward:  -9.559 | Epsilon: 0.0100 | Loss: 243476.4531
Episode 205650 | Reward:  -1.628 | Epsilon: 0.0100 | Loss: 249914.3281
Episode 205700 | Reward:  -7.566 | Epsilon: 0.0100 | Loss: 165551.3594
Episode 205750 | Reward:  -8.777 | Epsilon: 0.0100 | Loss: 181818.7500
Episode 205800 | Reward: -13.030 | Epsilon: 0.0100 | Loss: 121502.2422
Episode 205850 | Reward:  -5.663 | Epsilon: 0.0100 | Loss: 249686.6719
Episode 205900 | Reward:  -6.103 | Epsilon: 0.0100 | Loss: 255992.0312
Episode 205950 | Reward:  -7.664 | Epsilon: 0.0100 | Loss: 176608.5938
Episode 206000 | Reward:  -8.441 | Epsilon: 0.0100 | Loss: 177836.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:53).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:53).dict
Episode 206050 | Reward: -10.280 | Epsilon: 0.0100 | Loss: 131622.0938
Episode 206100 | Reward:  -6.273 | Epsilon: 0.0100 | Loss: 196644.1875
Episode 206150 | Reward:  -5.419 | Epsilon: 0.0100 | Loss: 127475.3594
Episode 206200 | Reward:  -5.900 | Epsilon: 0.0100 | Loss: 94025.8594
Episode 206250 | Reward: -16.428 | Epsilon: 0.0100 | Loss: 114547.0312
Episode 206300 | Reward: -17.464 | Epsilon: 0.0100 | Loss: 67282.7969
Episode 206350 | Reward: -13.871 | Epsilon: 0.0100 | Loss: 94300.9062
Episode 206400 | Reward: -15.558 | Epsilon: 0.0100 | Loss: 139783.9531
Episode 206450 | Reward: -17.288 | Epsilon: 0.0100 | Loss: 121175.0703
Episode 206500 | Reward: -17.059 | Epsilon: 0.0100 | Loss: 90220.3438
Episode 206550 | Reward: -22.440 | Epsilon: 0.0100 | Loss: 72551.3359
Episode 206600 | Reward: -23.324 | Epsilon: 0.0100 | Loss: 71841.4844
Episode 206650 | Reward: -20.311 | Epsilon: 0.0100 | Loss: 80969.6562
Episode 206700 | Reward: -11.714 | Epsilon: 0.0100 | Loss: 71973.0078
Episode 206750 | Reward: -14.991 | Epsilon: 0.0100 | Loss: 56467.8359
Episode 206800 | Reward:  -9.308 | Epsilon: 0.0100 | Loss: 53619.0312
Episode 206850 | Reward: -16.074 | Epsilon: 0.0100 | Loss: 53108.7500
Episode 206900 | Reward: -17.753 | Epsilon: 0.0100 | Loss: 45014.1484
Episode 206950 | Reward: -18.319 | Epsilon: 0.0100 | Loss: 37108.7188
Episode 207000 | Reward: -19.197 | Epsilon: 0.0100 | Loss: 34775.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:57).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(14:57).dict
Episode 207050 | Reward: -20.137 | Epsilon: 0.0100 | Loss: 37453.7422
Episode 207100 | Reward: -19.857 | Epsilon: 0.0100 | Loss: 30063.4785
Episode 207150 | Reward: -13.346 | Epsilon: 0.0100 | Loss: 24751.5781
Episode 207200 | Reward: -12.860 | Epsilon: 0.0100 | Loss: 29173.6309
Episode 207250 | Reward: -15.380 | Epsilon: 0.0100 | Loss: 20836.7051
Episode 207300 | Reward: -15.730 | Epsilon: 0.0100 | Loss: 24398.1914
Episode 207350 | Reward: -13.113 | Epsilon: 0.0100 | Loss: 22706.1348
Episode 207400 | Reward: -12.325 | Epsilon: 0.0100 | Loss: 19312.0605
Episode 207450 | Reward: -15.597 | Epsilon: 0.0100 | Loss: 19985.3926
Episode 207500 | Reward: -15.786 | Epsilon: 0.0100 | Loss: 18544.3047
Episode 207550 | Reward: -14.926 | Epsilon: 0.0100 | Loss: 12025.7705
Episode 207600 | Reward: -12.489 | Epsilon: 0.0100 | Loss: 10770.3164
Episode 207650 | Reward: -16.713 | Epsilon: 0.0100 | Loss: 12445.2588
Episode 207700 | Reward: -16.908 | Epsilon: 0.0100 | Loss: 12196.8242
Episode 207750 | Reward: -12.017 | Epsilon: 0.0100 | Loss: 11448.1699
Episode 207800 | Reward: -19.643 | Epsilon: 0.0100 | Loss: 12312.2266
Episode 207850 | Reward: -22.249 | Epsilon: 0.0100 | Loss: 10903.2451
Episode 207900 | Reward: -17.645 | Epsilon: 0.0100 | Loss: 7366.9238
Episode 207950 | Reward: -18.999 | Epsilon: 0.0100 | Loss: 11137.7695
Episode 208000 | Reward: -18.296 | Epsilon: 0.0100 | Loss: 7585.5967
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:00).dict
Episode 208050 | Reward: -18.810 | Epsilon: 0.0100 | Loss: 7590.9863
Episode 208100 | Reward: -14.297 | Epsilon: 0.0100 | Loss: 5965.6851
Episode 208150 | Reward: -13.975 | Epsilon: 0.0100 | Loss: 5715.0757
Episode 208200 | Reward: -14.771 | Epsilon: 0.0100 | Loss: 6424.8931
Episode 208250 | Reward: -11.806 | Epsilon: 0.0100 | Loss: 5318.8052
Episode 208300 | Reward: -12.430 | Epsilon: 0.0100 | Loss: 8908.1406
Episode 208350 | Reward: -13.136 | Epsilon: 0.0100 | Loss: 6463.9185
Episode 208400 | Reward: -12.724 | Epsilon: 0.0100 | Loss: 4425.4741
Episode 208450 | Reward: -14.040 | Epsilon: 0.0100 | Loss: 3369.6389
Episode 208500 | Reward: -11.640 | Epsilon: 0.0100 | Loss: 3074.8972
Episode 208550 | Reward: -10.692 | Epsilon: 0.0100 | Loss: 4598.4082
Episode 208600 | Reward: -15.565 | Epsilon: 0.0100 | Loss: 2853.1785
Episode 208650 | Reward: -15.217 | Epsilon: 0.0100 | Loss: 3437.6282
Episode 208700 | Reward: -16.365 | Epsilon: 0.0100 | Loss: 2926.3054
Episode 208750 | Reward: -12.810 | Epsilon: 0.0100 | Loss: 4949.4561
Episode 208800 | Reward:  -8.810 | Epsilon: 0.0100 | Loss: 2517.5610
Episode 208850 | Reward: -15.129 | Epsilon: 0.0100 | Loss: 2465.5676
Episode 208900 | Reward: -12.395 | Epsilon: 0.0100 | Loss: 2684.7771
Episode 208950 | Reward: -10.544 | Epsilon: 0.0100 | Loss: 21107.3750
Episode 209000 | Reward: -12.365 | Epsilon: 0.0100 | Loss: 2459.8762
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:04).dict
Episode 209050 | Reward: -13.614 | Epsilon: 0.0100 | Loss: 1910.6194
Episode 209100 | Reward: -12.934 | Epsilon: 0.0100 | Loss: 2459.8999
Episode 209150 | Reward: -13.783 | Epsilon: 0.0100 | Loss: 9310.1494
Episode 209200 | Reward: -17.070 | Epsilon: 0.0100 | Loss: 2118.8022
Episode 209250 | Reward: -13.885 | Epsilon: 0.0100 | Loss: 1983.1927
Episode 209300 | Reward: -18.706 | Epsilon: 0.0100 | Loss: 1510.4457
Episode 209350 | Reward: -19.485 | Epsilon: 0.0100 | Loss: 929.3448
Episode 209400 | Reward: -15.680 | Epsilon: 0.0100 | Loss: 1437.5051
Episode 209450 | Reward: -18.193 | Epsilon: 0.0100 | Loss: 9914.0684
Episode 209500 | Reward: -15.944 | Epsilon: 0.0100 | Loss: 1393.7496
Episode 209550 | Reward: -16.806 | Epsilon: 0.0100 | Loss: 1139.5844
Episode 209600 | Reward: -15.866 | Epsilon: 0.0100 | Loss: 1131.2770
Episode 209650 | Reward: -18.382 | Epsilon: 0.0100 | Loss: 700.7014
Episode 209700 | Reward: -19.943 | Epsilon: 0.0100 | Loss: 777.1683
Episode 209750 | Reward: -15.883 | Epsilon: 0.0100 | Loss: 921.1229
Episode 209800 | Reward: -17.870 | Epsilon: 0.0100 | Loss: 889.2707
Episode 209850 | Reward: -17.635 | Epsilon: 0.0100 | Loss: 711.2574
Episode 209900 | Reward: -15.382 | Epsilon: 0.0100 | Loss: 967.9780
Episode 209950 | Reward: -11.915 | Epsilon: 0.0100 | Loss: 764.3822
Episode 210000 | Reward: -13.120 | Epsilon: 0.0100 | Loss: 730.6942
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:08).dict
Episode 210050 | Reward: -11.711 | Epsilon: 0.0100 | Loss: 1576.7122
Episode 210100 | Reward: -12.919 | Epsilon: 0.0100 | Loss: 901.8523
Episode 210150 | Reward: -15.346 | Epsilon: 0.0100 | Loss: 764.9711
Episode 210200 | Reward: -18.402 | Epsilon: 0.0100 | Loss: 699.5214
Episode 210250 | Reward: -16.166 | Epsilon: 0.0100 | Loss: 922.2370
Episode 210300 | Reward: -16.918 | Epsilon: 0.0100 | Loss: 5021.9644
Episode 210350 | Reward: -19.246 | Epsilon: 0.0100 | Loss: 641.6344
Episode 210400 | Reward: -18.321 | Epsilon: 0.0100 | Loss: 929.1723
Episode 210450 | Reward: -17.030 | Epsilon: 0.0100 | Loss: 526.5801
Episode 210500 | Reward: -19.351 | Epsilon: 0.0100 | Loss: 3239.1860
Episode 210550 | Reward: -19.003 | Epsilon: 0.0100 | Loss: 715.0615
Episode 210600 | Reward: -17.534 | Epsilon: 0.0100 | Loss: 435.6941
Episode 210650 | Reward: -16.405 | Epsilon: 0.0100 | Loss: 641.0209
Episode 210700 | Reward: -14.559 | Epsilon: 0.0100 | Loss: 502.3805
Episode 210750 | Reward: -15.888 | Epsilon: 0.0100 | Loss: 984.8524
Episode 210800 | Reward: -18.781 | Epsilon: 0.0100 | Loss: 620.2742
Episode 210850 | Reward: -18.279 | Epsilon: 0.0100 | Loss: 2696.9648
Episode 210900 | Reward: -14.106 | Epsilon: 0.0100 | Loss: 681.0843
Episode 210950 | Reward: -11.997 | Epsilon: 0.0100 | Loss: 682.1459
Episode 211000 | Reward: -18.450 | Epsilon: 0.0100 | Loss: 417.5725
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:12).dict
Episode 211050 | Reward: -21.646 | Epsilon: 0.0100 | Loss: 1978.4722
Episode 211100 | Reward: -18.330 | Epsilon: 0.0100 | Loss: 419.0069
Episode 211150 | Reward: -17.444 | Epsilon: 0.0100 | Loss: 561.3047
Episode 211200 | Reward: -18.812 | Epsilon: 0.0100 | Loss: 5301.0762
Episode 211250 | Reward: -19.871 | Epsilon: 0.0100 | Loss: 475.6664
Episode 211300 | Reward: -16.802 | Epsilon: 0.0100 | Loss: 797.1635
Episode 211350 | Reward: -18.077 | Epsilon: 0.0100 | Loss: 6207.6206
Episode 211400 | Reward: -19.831 | Epsilon: 0.0100 | Loss: 789.7065
Episode 211450 | Reward: -18.396 | Epsilon: 0.0100 | Loss: 1999.4757
Episode 211500 | Reward: -19.863 | Epsilon: 0.0100 | Loss: 949.2098
Episode 211550 | Reward: -20.277 | Epsilon: 0.0100 | Loss: 5370.5771
Episode 211600 | Reward: -16.396 | Epsilon: 0.0100 | Loss: 663.1823
Episode 211650 | Reward: -18.500 | Epsilon: 0.0100 | Loss: 744.6086
Episode 211700 | Reward: -21.063 | Epsilon: 0.0100 | Loss: 845.7040
Episode 211750 | Reward: -19.115 | Epsilon: 0.0100 | Loss: 949.3290
Episode 211800 | Reward: -19.474 | Epsilon: 0.0100 | Loss: 1076.4658
Episode 211850 | Reward: -19.407 | Epsilon: 0.0100 | Loss: 1017.1899
Episode 211900 | Reward: -18.243 | Epsilon: 0.0100 | Loss: 920.0193
Episode 211950 | Reward: -17.937 | Epsilon: 0.0100 | Loss: 690.7794
Episode 212000 | Reward: -18.914 | Epsilon: 0.0100 | Loss: 554.7598
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:15).dict
Episode 212050 | Reward: -17.652 | Epsilon: 0.0100 | Loss: 634.6042
Episode 212100 | Reward: -18.308 | Epsilon: 0.0100 | Loss: 594.4859
Episode 212150 | Reward: -19.471 | Epsilon: 0.0100 | Loss: 1146.7433
Episode 212200 | Reward: -19.474 | Epsilon: 0.0100 | Loss: 652.8890
Episode 212250 | Reward: -16.847 | Epsilon: 0.0100 | Loss: 519.0071
Episode 212300 | Reward: -18.301 | Epsilon: 0.0100 | Loss: 830.4886
Episode 212350 | Reward: -15.732 | Epsilon: 0.0100 | Loss: 796.4963
Episode 212400 | Reward: -17.707 | Epsilon: 0.0100 | Loss: 1023.8796
Episode 212450 | Reward: -17.804 | Epsilon: 0.0100 | Loss: 566.6198
Episode 212500 | Reward: -15.040 | Epsilon: 0.0100 | Loss: 490.4940
Episode 212550 | Reward: -18.365 | Epsilon: 0.0100 | Loss: 953.0398
Episode 212600 | Reward: -13.991 | Epsilon: 0.0100 | Loss: 732.9540
Episode 212650 | Reward: -18.010 | Epsilon: 0.0100 | Loss: 675.6934
Episode 212700 | Reward: -20.109 | Epsilon: 0.0100 | Loss: 4331.9746
Episode 212750 | Reward: -17.405 | Epsilon: 0.0100 | Loss: 1019.4393
Episode 212800 | Reward: -17.305 | Epsilon: 0.0100 | Loss: 925.9467
Episode 212850 | Reward: -13.217 | Epsilon: 0.0100 | Loss: 917.7507
Episode 212900 | Reward: -15.538 | Epsilon: 0.0100 | Loss: 830.6251
Episode 212950 | Reward: -12.191 | Epsilon: 0.0100 | Loss: 536.1144
Episode 213000 | Reward: -10.768 | Epsilon: 0.0100 | Loss: 673.9988
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:19).dict
Episode 213050 | Reward: -11.248 | Epsilon: 0.0100 | Loss: 605.4821
Episode 213100 | Reward: -13.388 | Epsilon: 0.0100 | Loss: 823.0372
Episode 213150 | Reward: -16.215 | Epsilon: 0.0100 | Loss: 623.4874
Episode 213200 | Reward: -17.486 | Epsilon: 0.0100 | Loss: 946.2451
Episode 213250 | Reward: -20.550 | Epsilon: 0.0100 | Loss: 1159.9526
Episode 213300 | Reward: -16.547 | Epsilon: 0.0100 | Loss: 502.1884
Episode 213350 | Reward: -19.089 | Epsilon: 0.0100 | Loss: 629.9373
Episode 213400 | Reward: -17.621 | Epsilon: 0.0100 | Loss: 926.6109
Episode 213450 | Reward: -14.771 | Epsilon: 0.0100 | Loss: 628.0931
Episode 213500 | Reward: -16.199 | Epsilon: 0.0100 | Loss: 678.0172
Episode 213550 | Reward: -13.599 | Epsilon: 0.0100 | Loss: 5309.0898
Episode 213600 | Reward: -18.999 | Epsilon: 0.0100 | Loss: 626.5256
Episode 213650 | Reward: -21.314 | Epsilon: 0.0100 | Loss: 649.2047
Episode 213700 | Reward: -17.769 | Epsilon: 0.0100 | Loss: 753.0110
Episode 213750 | Reward: -16.343 | Epsilon: 0.0100 | Loss: 510.9917
Episode 213800 | Reward: -17.262 | Epsilon: 0.0100 | Loss: 581.8487
Episode 213850 | Reward: -18.283 | Epsilon: 0.0100 | Loss: 724.3046
Episode 213900 | Reward: -21.684 | Epsilon: 0.0100 | Loss: 1366.7065
Episode 213950 | Reward: -20.360 | Epsilon: 0.0100 | Loss: 6534.6187
Episode 214000 | Reward: -14.142 | Epsilon: 0.0100 | Loss: 902.1160
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:23).dict
Episode 214050 | Reward: -15.031 | Epsilon: 0.0100 | Loss: 1024.8044
Episode 214100 | Reward: -16.571 | Epsilon: 0.0100 | Loss: 711.7325
Episode 214150 | Reward: -19.600 | Epsilon: 0.0100 | Loss: 4679.6216
Episode 214200 | Reward: -18.883 | Epsilon: 0.0100 | Loss: 684.6514
Episode 214250 | Reward: -16.833 | Epsilon: 0.0100 | Loss: 3492.2034
Episode 214300 | Reward: -20.623 | Epsilon: 0.0100 | Loss: 674.4560
Episode 214350 | Reward: -18.126 | Epsilon: 0.0100 | Loss: 936.8256
Episode 214400 | Reward: -18.603 | Epsilon: 0.0100 | Loss: 557.4476
Episode 214450 | Reward: -14.522 | Epsilon: 0.0100 | Loss: 1530.6642
Episode 214500 | Reward: -15.768 | Epsilon: 0.0100 | Loss: 546.7786
Episode 214550 | Reward: -21.512 | Epsilon: 0.0100 | Loss: 1070.1555
Episode 214600 | Reward: -19.864 | Epsilon: 0.0100 | Loss: 1230.5012
Episode 214650 | Reward: -20.440 | Epsilon: 0.0100 | Loss: 869.4512
Episode 214700 | Reward: -18.404 | Epsilon: 0.0100 | Loss: 538.3079
Episode 214750 | Reward: -17.960 | Epsilon: 0.0100 | Loss: 466.4268
Episode 214800 | Reward: -22.860 | Epsilon: 0.0100 | Loss: 585.1462
Episode 214850 | Reward: -19.204 | Epsilon: 0.0100 | Loss: 1083.6617
Episode 214900 | Reward: -19.784 | Epsilon: 0.0100 | Loss: 1011.4395
Episode 214950 | Reward: -14.541 | Epsilon: 0.0100 | Loss: 948.9262
Episode 215000 | Reward: -20.155 | Epsilon: 0.0100 | Loss: 845.1833
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:27).dict
Episode 215050 | Reward: -21.703 | Epsilon: 0.0100 | Loss: 410.1820
Episode 215100 | Reward: -20.777 | Epsilon: 0.0100 | Loss: 1351.0631
Episode 215150 | Reward: -15.077 | Epsilon: 0.0100 | Loss: 928.9877
Episode 215200 | Reward: -18.643 | Epsilon: 0.0100 | Loss: 1018.5984
Episode 215250 | Reward: -20.798 | Epsilon: 0.0100 | Loss: 1218.8123
Episode 215300 | Reward: -22.540 | Epsilon: 0.0100 | Loss: 681.0785
Episode 215350 | Reward: -22.487 | Epsilon: 0.0100 | Loss: 393.6302
Episode 215400 | Reward: -20.434 | Epsilon: 0.0100 | Loss: 1552.5183
Episode 215450 | Reward: -18.806 | Epsilon: 0.0100 | Loss: 643.9643
Episode 215500 | Reward: -17.534 | Epsilon: 0.0100 | Loss: 945.0641
Episode 215550 | Reward: -18.766 | Epsilon: 0.0100 | Loss: 549.3795
Episode 215600 | Reward: -16.702 | Epsilon: 0.0100 | Loss: 524.8865
Episode 215650 | Reward: -18.566 | Epsilon: 0.0100 | Loss: 1005.1438
Episode 215700 | Reward: -18.109 | Epsilon: 0.0100 | Loss: 1376.1841
Episode 215750 | Reward: -17.390 | Epsilon: 0.0100 | Loss: 1236.9612
Episode 215800 | Reward: -18.789 | Epsilon: 0.0100 | Loss: 957.9893
Episode 215850 | Reward: -19.095 | Epsilon: 0.0100 | Loss: 897.5608
Episode 215900 | Reward: -16.684 | Epsilon: 0.0100 | Loss: 1064.1182
Episode 215950 | Reward: -15.695 | Epsilon: 0.0100 | Loss: 1195.9017
Episode 216000 | Reward: -16.532 | Epsilon: 0.0100 | Loss: 758.5463
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:30).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:30).dict
Episode 216050 | Reward: -18.527 | Epsilon: 0.0100 | Loss: 1002.4110
Episode 216100 | Reward: -23.287 | Epsilon: 0.0100 | Loss: 857.1888
Episode 216150 | Reward: -21.436 | Epsilon: 0.0100 | Loss: 1128.4827
Episode 216200 | Reward: -21.458 | Epsilon: 0.0100 | Loss: 1107.9098
Episode 216250 | Reward: -18.289 | Epsilon: 0.0100 | Loss: 1473.6194
Episode 216300 | Reward: -16.622 | Epsilon: 0.0100 | Loss: 803.2269
Episode 216350 | Reward: -18.539 | Epsilon: 0.0100 | Loss: 529.3058
Episode 216400 | Reward: -21.023 | Epsilon: 0.0100 | Loss: 5437.7695
Episode 216450 | Reward: -17.054 | Epsilon: 0.0100 | Loss: 817.3176
Episode 216500 | Reward: -16.679 | Epsilon: 0.0100 | Loss: 1290.0558
Episode 216550 | Reward: -18.532 | Epsilon: 0.0100 | Loss: 790.9873
Episode 216600 | Reward: -16.708 | Epsilon: 0.0100 | Loss: 1182.6971
Episode 216650 | Reward: -20.190 | Epsilon: 0.0100 | Loss: 1548.8281
Episode 216700 | Reward: -14.116 | Epsilon: 0.0100 | Loss: 1047.5642
Episode 216750 | Reward: -14.330 | Epsilon: 0.0100 | Loss: 1175.4777
Episode 216800 | Reward: -14.542 | Epsilon: 0.0100 | Loss: 1365.9353
Episode 216850 | Reward: -19.794 | Epsilon: 0.0100 | Loss: 992.8102
Episode 216900 | Reward: -20.214 | Epsilon: 0.0100 | Loss: 1059.3715
Episode 216950 | Reward: -21.092 | Epsilon: 0.0100 | Loss: 1313.8370
Episode 217000 | Reward: -19.932 | Epsilon: 0.0100 | Loss: 1066.5925
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:34).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:34).dict
Episode 217050 | Reward: -19.283 | Epsilon: 0.0100 | Loss: 600.7659
Episode 217100 | Reward: -14.487 | Epsilon: 0.0100 | Loss: 980.6242
Episode 217150 | Reward: -18.005 | Epsilon: 0.0100 | Loss: 1114.6410
Episode 217200 | Reward: -17.306 | Epsilon: 0.0100 | Loss: 869.8713
Episode 217250 | Reward: -13.635 | Epsilon: 0.0100 | Loss: 2128.9814
Episode 217300 | Reward: -16.112 | Epsilon: 0.0100 | Loss: 805.0834
Episode 217350 | Reward: -14.913 | Epsilon: 0.0100 | Loss: 1198.1084
Episode 217400 | Reward: -15.334 | Epsilon: 0.0100 | Loss: 1096.5094
Episode 217450 | Reward: -12.060 | Epsilon: 0.0100 | Loss: 603.1918
Episode 217500 | Reward: -16.182 | Epsilon: 0.0100 | Loss: 747.8947
Episode 217550 | Reward: -18.390 | Epsilon: 0.0100 | Loss: 1557.2085
Episode 217600 | Reward: -16.343 | Epsilon: 0.0100 | Loss: 751.2482
Episode 217650 | Reward: -19.283 | Epsilon: 0.0100 | Loss: 1451.9899
Episode 217700 | Reward: -13.426 | Epsilon: 0.0100 | Loss: 890.5544
Episode 217750 | Reward: -16.978 | Epsilon: 0.0100 | Loss: 1123.2788
Episode 217800 | Reward: -19.878 | Epsilon: 0.0100 | Loss: 703.4744
Episode 217850 | Reward: -22.540 | Epsilon: 0.0100 | Loss: 965.0457
Episode 217900 | Reward: -20.262 | Epsilon: 0.0100 | Loss: 1159.2015
Episode 217950 | Reward: -18.760 | Epsilon: 0.0100 | Loss: 907.6223
Episode 218000 | Reward: -18.910 | Epsilon: 0.0100 | Loss: 1457.8507
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:38).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:38).dict
Episode 218050 | Reward: -17.445 | Epsilon: 0.0100 | Loss: 914.7480
Episode 218100 | Reward: -19.418 | Epsilon: 0.0100 | Loss: 825.0912
Episode 218150 | Reward: -16.606 | Epsilon: 0.0100 | Loss: 1434.2369
Episode 218200 | Reward: -15.823 | Epsilon: 0.0100 | Loss: 786.9294
Episode 218250 | Reward: -20.780 | Epsilon: 0.0100 | Loss: 906.3655
Episode 218300 | Reward: -16.980 | Epsilon: 0.0100 | Loss: 3093.2710
Episode 218350 | Reward: -18.686 | Epsilon: 0.0100 | Loss: 840.1538
Episode 218400 | Reward: -21.008 | Epsilon: 0.0100 | Loss: 1496.8959
Episode 218450 | Reward: -20.904 | Epsilon: 0.0100 | Loss: 1966.2328
Episode 218500 | Reward: -22.096 | Epsilon: 0.0100 | Loss: 2148.9236
Episode 218550 | Reward: -16.537 | Epsilon: 0.0100 | Loss: 760.7614
Episode 218600 | Reward: -19.409 | Epsilon: 0.0100 | Loss: 992.8063
Episode 218650 | Reward: -17.027 | Epsilon: 0.0100 | Loss: 1199.3274
Episode 218700 | Reward: -15.041 | Epsilon: 0.0100 | Loss: 1318.4108
Episode 218750 | Reward: -19.684 | Epsilon: 0.0100 | Loss: 1185.5145
Episode 218800 | Reward: -19.430 | Epsilon: 0.0100 | Loss: 782.8385
Episode 218850 | Reward: -18.108 | Epsilon: 0.0100 | Loss: 1469.4851
Episode 218900 | Reward: -19.321 | Epsilon: 0.0100 | Loss: 1260.4088
Episode 218950 | Reward: -16.062 | Epsilon: 0.0100 | Loss: 916.3945
Episode 219000 | Reward: -14.454 | Epsilon: 0.0100 | Loss: 1107.3044
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:42).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:42).dict
Episode 219050 | Reward: -21.425 | Epsilon: 0.0100 | Loss: 1804.4659
Episode 219100 | Reward: -21.497 | Epsilon: 0.0100 | Loss: 1308.7570
Episode 219150 | Reward: -19.828 | Epsilon: 0.0100 | Loss: 1115.2151
Episode 219200 | Reward: -18.446 | Epsilon: 0.0100 | Loss: 1354.2590
Episode 219250 | Reward: -19.444 | Epsilon: 0.0100 | Loss: 1039.2959
Episode 219300 | Reward: -19.507 | Epsilon: 0.0100 | Loss: 681.5121
Episode 219350 | Reward: -17.584 | Epsilon: 0.0100 | Loss: 1095.4838
Episode 219400 | Reward: -18.887 | Epsilon: 0.0100 | Loss: 1045.9725
Episode 219450 | Reward: -19.201 | Epsilon: 0.0100 | Loss: 1193.8245
Episode 219500 | Reward: -16.290 | Epsilon: 0.0100 | Loss: 904.5911
Episode 219550 | Reward: -15.175 | Epsilon: 0.0100 | Loss: 1000.0167
Episode 219600 | Reward: -20.121 | Epsilon: 0.0100 | Loss: 704.9704
Episode 219650 | Reward: -18.436 | Epsilon: 0.0100 | Loss: 731.4695
Episode 219700 | Reward: -19.322 | Epsilon: 0.0100 | Loss: 1069.0939
Episode 219750 | Reward: -15.127 | Epsilon: 0.0100 | Loss: 1054.6768
Episode 219800 | Reward: -16.718 | Epsilon: 0.0100 | Loss: 867.6022
Episode 219850 | Reward: -18.586 | Epsilon: 0.0100 | Loss: 1032.7660
Episode 219900 | Reward: -19.894 | Epsilon: 0.0100 | Loss: 781.8423
Episode 219950 | Reward: -18.787 | Epsilon: 0.0100 | Loss: 796.0657
Episode 220000 | Reward: -17.904 | Epsilon: 0.0100 | Loss: 812.9932
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:46).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:46).dict
Episode 220050 | Reward: -15.856 | Epsilon: 0.0100 | Loss: 970.0200
Episode 220100 | Reward: -16.394 | Epsilon: 0.0100 | Loss: 1334.5599
Episode 220150 | Reward: -14.757 | Epsilon: 0.0100 | Loss: 890.9236
Episode 220200 | Reward: -18.479 | Epsilon: 0.0100 | Loss: 640.5570
Episode 220250 | Reward: -15.448 | Epsilon: 0.0100 | Loss: 600.4238
Episode 220300 | Reward: -21.795 | Epsilon: 0.0100 | Loss: 745.4587
Episode 220350 | Reward: -20.312 | Epsilon: 0.0100 | Loss: 1103.9303
Episode 220400 | Reward: -18.466 | Epsilon: 0.0100 | Loss: 937.6948
Episode 220450 | Reward: -19.931 | Epsilon: 0.0100 | Loss: 1010.8696
Episode 220500 | Reward: -17.987 | Epsilon: 0.0100 | Loss: 1004.1383
Episode 220550 | Reward: -17.920 | Epsilon: 0.0100 | Loss: 1638.4247
Episode 220600 | Reward: -17.632 | Epsilon: 0.0100 | Loss: 987.5031
Episode 220650 | Reward: -15.388 | Epsilon: 0.0100 | Loss: 1414.1218
Episode 220700 | Reward: -17.431 | Epsilon: 0.0100 | Loss: 1073.8730
Episode 220750 | Reward: -16.661 | Epsilon: 0.0100 | Loss: 1070.8073
Episode 220800 | Reward: -16.844 | Epsilon: 0.0100 | Loss: 1847.6913
Episode 220850 | Reward: -16.024 | Epsilon: 0.0100 | Loss: 1237.0393
Episode 220900 | Reward: -16.973 | Epsilon: 0.0100 | Loss: 1828.1726
Episode 220950 | Reward: -14.504 | Epsilon: 0.0100 | Loss: 1818.2147
Episode 221000 | Reward: -18.623 | Epsilon: 0.0100 | Loss: 1150.0334
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:49).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:49).dict
Episode 221050 | Reward: -15.121 | Epsilon: 0.0100 | Loss: 1159.0645
Episode 221100 | Reward: -18.517 | Epsilon: 0.0100 | Loss: 1291.1350
Episode 221150 | Reward: -16.909 | Epsilon: 0.0100 | Loss: 1863.9316
Episode 221200 | Reward: -17.102 | Epsilon: 0.0100 | Loss: 1280.1609
Episode 221250 | Reward: -15.665 | Epsilon: 0.0100 | Loss: 910.4126
Episode 221300 | Reward: -15.526 | Epsilon: 0.0100 | Loss: 1618.5970
Episode 221350 | Reward: -19.620 | Epsilon: 0.0100 | Loss: 1855.7456
Episode 221400 | Reward: -19.067 | Epsilon: 0.0100 | Loss: 1788.7997
Episode 221450 | Reward: -18.535 | Epsilon: 0.0100 | Loss: 1954.7054
Episode 221500 | Reward: -15.264 | Epsilon: 0.0100 | Loss: 1507.3778
Episode 221550 | Reward: -16.588 | Epsilon: 0.0100 | Loss: 1032.0770
Episode 221600 | Reward: -16.641 | Epsilon: 0.0100 | Loss: 1914.4700
Episode 221650 | Reward: -17.631 | Epsilon: 0.0100 | Loss: 1082.6050
Episode 221700 | Reward: -19.607 | Epsilon: 0.0100 | Loss: 1879.9080
Episode 221750 | Reward: -21.370 | Epsilon: 0.0100 | Loss: 1447.4653
Episode 221800 | Reward: -19.675 | Epsilon: 0.0100 | Loss: 1717.5571
Episode 221850 | Reward: -19.481 | Epsilon: 0.0100 | Loss: 1568.7424
Episode 221900 | Reward: -21.907 | Epsilon: 0.0100 | Loss: 1564.8416
Episode 221950 | Reward: -19.460 | Epsilon: 0.0100 | Loss: 2227.1013
Episode 222000 | Reward: -16.775 | Epsilon: 0.0100 | Loss: 1458.3663
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:53).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:53).dict
Episode 222050 | Reward: -19.742 | Epsilon: 0.0100 | Loss: 1218.9198
Episode 222100 | Reward: -17.041 | Epsilon: 0.0100 | Loss: 1279.4880
Episode 222150 | Reward: -15.134 | Epsilon: 0.0100 | Loss: 1431.6400
Episode 222200 | Reward: -14.486 | Epsilon: 0.0100 | Loss: 1145.2092
Episode 222250 | Reward: -17.931 | Epsilon: 0.0100 | Loss: 1014.5574
Episode 222300 | Reward: -17.866 | Epsilon: 0.0100 | Loss: 923.0252
Episode 222350 | Reward: -19.512 | Epsilon: 0.0100 | Loss: 1405.7732
Episode 222400 | Reward: -17.239 | Epsilon: 0.0100 | Loss: 975.0983
Episode 222450 | Reward: -17.009 | Epsilon: 0.0100 | Loss: 1558.3306
Episode 222500 | Reward: -17.369 | Epsilon: 0.0100 | Loss: 2161.4707
Episode 222550 | Reward: -20.906 | Epsilon: 0.0100 | Loss: 1592.7864
Episode 222600 | Reward: -21.034 | Epsilon: 0.0100 | Loss: 1272.1936
Episode 222650 | Reward: -21.393 | Epsilon: 0.0100 | Loss: 1393.9016
Episode 222700 | Reward: -19.771 | Epsilon: 0.0100 | Loss: 2187.8564
Episode 222750 | Reward: -13.585 | Epsilon: 0.0100 | Loss: 1382.6674
Episode 222800 | Reward: -17.547 | Epsilon: 0.0100 | Loss: 1105.7191
Episode 222850 | Reward: -17.866 | Epsilon: 0.0100 | Loss: 1589.9365
Episode 222900 | Reward: -17.980 | Epsilon: 0.0100 | Loss: 2202.2859
Episode 222950 | Reward: -20.505 | Epsilon: 0.0100 | Loss: 1849.2644
Episode 223000 | Reward: -22.566 | Epsilon: 0.0100 | Loss: 1844.3342
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:57).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(15:57).dict
Episode 223050 | Reward: -19.412 | Epsilon: 0.0100 | Loss: 1630.2214
Episode 223100 | Reward: -19.252 | Epsilon: 0.0100 | Loss: 1002.6906
Episode 223150 | Reward: -19.640 | Epsilon: 0.0100 | Loss: 2416.3743
Episode 223200 | Reward: -17.872 | Epsilon: 0.0100 | Loss: 3193.3643
Episode 223250 | Reward: -18.827 | Epsilon: 0.0100 | Loss: 1216.8586
Episode 223300 | Reward: -18.967 | Epsilon: 0.0100 | Loss: 1496.4563
Episode 223350 | Reward: -16.628 | Epsilon: 0.0100 | Loss: 1949.6136
Episode 223400 | Reward: -18.729 | Epsilon: 0.0100 | Loss: 1874.5154
Episode 223450 | Reward: -20.926 | Epsilon: 0.0100 | Loss: 1580.4613
Episode 223500 | Reward: -16.425 | Epsilon: 0.0100 | Loss: 1471.5535
Episode 223550 | Reward: -17.192 | Epsilon: 0.0100 | Loss: 2585.7207
Episode 223600 | Reward: -15.780 | Epsilon: 0.0100 | Loss: 1785.8507
Episode 223650 | Reward: -18.496 | Epsilon: 0.0100 | Loss: 1716.9229
Episode 223700 | Reward: -17.230 | Epsilon: 0.0100 | Loss: 1804.8124
Episode 223750 | Reward: -15.329 | Epsilon: 0.0100 | Loss: 2451.9556
Episode 223800 | Reward: -16.778 | Epsilon: 0.0100 | Loss: 1138.1198
Episode 223850 | Reward: -19.357 | Epsilon: 0.0100 | Loss: 1595.5203
Episode 223900 | Reward: -20.752 | Epsilon: 0.0100 | Loss: 1108.9825
Episode 223950 | Reward: -18.653 | Epsilon: 0.0100 | Loss: 2003.7773
Episode 224000 | Reward: -16.135 | Epsilon: 0.0100 | Loss: 1971.8132
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:01).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:01).dict
Episode 224050 | Reward: -18.088 | Epsilon: 0.0100 | Loss: 1981.1621
Episode 224100 | Reward: -18.324 | Epsilon: 0.0100 | Loss: 1599.4797
Episode 224150 | Reward: -15.750 | Epsilon: 0.0100 | Loss: 1723.7205
Episode 224200 | Reward: -12.921 | Epsilon: 0.0100 | Loss: 1977.6528
Episode 224250 | Reward: -15.927 | Epsilon: 0.0100 | Loss: 2181.4277
Episode 224300 | Reward: -18.861 | Epsilon: 0.0100 | Loss: 3620.7373
Episode 224350 | Reward: -17.730 | Epsilon: 0.0100 | Loss: 2245.3870
Episode 224400 | Reward: -18.419 | Epsilon: 0.0100 | Loss: 2459.4478
Episode 224450 | Reward: -18.315 | Epsilon: 0.0100 | Loss: 2409.1548
Episode 224500 | Reward: -14.732 | Epsilon: 0.0100 | Loss: 3437.7786
Episode 224550 | Reward: -17.645 | Epsilon: 0.0100 | Loss: 2256.0884
Episode 224600 | Reward: -18.145 | Epsilon: 0.0100 | Loss: 2500.1184
Episode 224650 | Reward: -15.239 | Epsilon: 0.0100 | Loss: 2339.1555
Episode 224700 | Reward: -17.055 | Epsilon: 0.0100 | Loss: 2407.7917
Episode 224750 | Reward: -20.422 | Epsilon: 0.0100 | Loss: 2476.7773
Episode 224800 | Reward: -16.350 | Epsilon: 0.0100 | Loss: 2721.5625
Episode 224850 | Reward: -16.934 | Epsilon: 0.0100 | Loss: 1837.1781
Episode 224900 | Reward: -14.400 | Epsilon: 0.0100 | Loss: 4505.0947
Episode 224950 | Reward: -15.513 | Epsilon: 0.0100 | Loss: 3510.0496
Episode 225000 | Reward: -16.512 | Epsilon: 0.0100 | Loss: 3394.5547
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:05).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:05).dict
Episode 225050 | Reward: -19.809 | Epsilon: 0.0100 | Loss: 1926.5233
Episode 225100 | Reward: -15.281 | Epsilon: 0.0100 | Loss: 3165.8813
Episode 225150 | Reward: -13.264 | Epsilon: 0.0100 | Loss: 1771.9260
Episode 225200 | Reward: -13.684 | Epsilon: 0.0100 | Loss: 2910.8357
Episode 225250 | Reward: -13.221 | Epsilon: 0.0100 | Loss: 2887.1294
Episode 225300 | Reward: -11.751 | Epsilon: 0.0100 | Loss: 3604.3130
Episode 225350 | Reward: -12.008 | Epsilon: 0.0100 | Loss: 4819.6582
Episode 225400 | Reward: -15.753 | Epsilon: 0.0100 | Loss: 2421.5820
Episode 225450 | Reward: -12.363 | Epsilon: 0.0100 | Loss: 4943.4731
Episode 225500 | Reward: -16.638 | Epsilon: 0.0100 | Loss: 3540.6782
Episode 225550 | Reward: -15.879 | Epsilon: 0.0100 | Loss: 3817.4387
Episode 225600 | Reward: -15.749 | Epsilon: 0.0100 | Loss: 5176.9902
Episode 225650 | Reward: -14.966 | Epsilon: 0.0100 | Loss: 6332.0015
Episode 225700 | Reward: -15.994 | Epsilon: 0.0100 | Loss: 4519.4268
Episode 225750 | Reward: -13.815 | Epsilon: 0.0100 | Loss: 2173.9758
Episode 225800 | Reward: -14.320 | Epsilon: 0.0100 | Loss: 4214.1704
Episode 225850 | Reward: -13.323 | Epsilon: 0.0100 | Loss: 4561.7061
Episode 225900 | Reward: -18.859 | Epsilon: 0.0100 | Loss: 2683.5349
Episode 225950 | Reward: -19.066 | Epsilon: 0.0100 | Loss: 3526.4753
Episode 226000 | Reward: -18.224 | Epsilon: 0.0100 | Loss: 2501.2432
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:09).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:09).dict
Episode 226050 | Reward: -19.046 | Epsilon: 0.0100 | Loss: 2984.6516
Episode 226100 | Reward: -17.898 | Epsilon: 0.0100 | Loss: 4056.6860
Episode 226150 | Reward: -14.339 | Epsilon: 0.0100 | Loss: 3311.8931
Episode 226200 | Reward: -12.052 | Epsilon: 0.0100 | Loss: 5026.3735
Episode 226250 | Reward: -15.979 | Epsilon: 0.0100 | Loss: 3638.7058
Episode 226300 | Reward: -14.689 | Epsilon: 0.0100 | Loss: 4417.2817
Episode 226350 | Reward: -17.981 | Epsilon: 0.0100 | Loss: 4660.1978
Episode 226400 | Reward: -13.420 | Epsilon: 0.0100 | Loss: 4901.3550
Episode 226450 | Reward: -16.421 | Epsilon: 0.0100 | Loss: 3604.3103
Episode 226500 | Reward: -15.510 | Epsilon: 0.0100 | Loss: 5357.6396
Episode 226550 | Reward: -17.684 | Epsilon: 0.0100 | Loss: 5925.0249
Episode 226600 | Reward: -12.903 | Epsilon: 0.0100 | Loss: 5056.9995
Episode 226650 | Reward: -18.833 | Epsilon: 0.0100 | Loss: 4207.8086
Episode 226700 | Reward: -15.946 | Epsilon: 0.0100 | Loss: 4111.8213
Episode 226750 | Reward: -14.419 | Epsilon: 0.0100 | Loss: 7798.7744
Episode 226800 | Reward: -17.209 | Epsilon: 0.0100 | Loss: 6257.9863
Episode 226850 | Reward: -15.329 | Epsilon: 0.0100 | Loss: 6558.8496
Episode 226900 | Reward: -17.468 | Epsilon: 0.0100 | Loss: 6736.2969
Episode 226950 | Reward: -13.781 | Epsilon: 0.0100 | Loss: 7404.3203
Episode 227000 | Reward: -14.234 | Epsilon: 0.0100 | Loss: 7283.4087
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:13).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:13).dict
Episode 227050 | Reward: -20.387 | Epsilon: 0.0100 | Loss: 7060.4131
Episode 227100 | Reward: -18.413 | Epsilon: 0.0100 | Loss: 8484.0029
Episode 227150 | Reward: -16.093 | Epsilon: 0.0100 | Loss: 9971.1094
Episode 227200 | Reward: -15.578 | Epsilon: 0.0100 | Loss: 11441.0791
Episode 227250 | Reward: -15.332 | Epsilon: 0.0100 | Loss: 9589.5518
Episode 227300 | Reward: -13.849 | Epsilon: 0.0100 | Loss: 9307.1504
Episode 227350 | Reward: -10.297 | Epsilon: 0.0100 | Loss: 11162.7676
Episode 227400 | Reward: -11.904 | Epsilon: 0.0100 | Loss: 8872.0205
Episode 227450 | Reward: -11.909 | Epsilon: 0.0100 | Loss: 14452.2617
Episode 227500 | Reward: -13.321 | Epsilon: 0.0100 | Loss: 18040.2793
Episode 227550 | Reward: -12.651 | Epsilon: 0.0100 | Loss: 20183.0586
Episode 227600 | Reward: -11.309 | Epsilon: 0.0100 | Loss: 25987.9141
Episode 227650 | Reward: -15.194 | Epsilon: 0.0100 | Loss: 28282.1172
Episode 227700 | Reward: -15.779 | Epsilon: 0.0100 | Loss: 40166.8555
Episode 227750 | Reward: -13.746 | Epsilon: 0.0100 | Loss: 59837.5078
Episode 227800 | Reward: -16.731 | Epsilon: 0.0100 | Loss: 90500.4688
Episode 227850 | Reward: -10.950 | Epsilon: 0.0100 | Loss: 114085.1406
Episode 227900 | Reward: -17.247 | Epsilon: 0.0100 | Loss: 158343.9688
Episode 227950 | Reward: -16.426 | Epsilon: 0.0100 | Loss: 119594.6562
Episode 228000 | Reward: -17.312 | Epsilon: 0.0100 | Loss: 140784.2188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:17).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:17).dict
Episode 228050 | Reward: -15.050 | Epsilon: 0.0100 | Loss: 147934.6250
Episode 228100 | Reward: -16.632 | Epsilon: 0.0100 | Loss: 149176.8125
Episode 228150 | Reward: -16.552 | Epsilon: 0.0100 | Loss: 201772.7188
Episode 228200 | Reward: -11.953 | Epsilon: 0.0100 | Loss: 152081.6719
Episode 228250 | Reward: -16.765 | Epsilon: 0.0100 | Loss: 141588.4375
Episode 228300 | Reward: -17.503 | Epsilon: 0.0100 | Loss: 170107.5000
Episode 228350 | Reward: -13.515 | Epsilon: 0.0100 | Loss: 167706.3594
Episode 228400 | Reward: -11.845 | Epsilon: 0.0100 | Loss: 172646.9375
Episode 228450 | Reward: -16.191 | Epsilon: 0.0100 | Loss: 145871.0469
Episode 228500 | Reward: -15.900 | Epsilon: 0.0100 | Loss: 199138.8438
Episode 228550 | Reward: -15.854 | Epsilon: 0.0100 | Loss: 160907.5156
Episode 228600 | Reward: -19.445 | Epsilon: 0.0100 | Loss: 156034.9219
Episode 228650 | Reward: -15.300 | Epsilon: 0.0100 | Loss: 171243.5469
Episode 228700 | Reward: -16.955 | Epsilon: 0.0100 | Loss: 165992.8438
Episode 228750 | Reward: -13.420 | Epsilon: 0.0100 | Loss: 144523.2500
Episode 228800 | Reward:  -9.930 | Epsilon: 0.0100 | Loss: 154477.7969
Episode 228850 | Reward: -11.888 | Epsilon: 0.0100 | Loss: 156913.3906
Episode 228900 | Reward: -14.011 | Epsilon: 0.0100 | Loss: 182713.5938
Episode 228950 | Reward: -12.172 | Epsilon: 0.0100 | Loss: 138929.1719
Episode 229000 | Reward: -12.077 | Epsilon: 0.0100 | Loss: 165648.6250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:21).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:21).dict
Episode 229050 | Reward: -16.112 | Epsilon: 0.0100 | Loss: 166193.6719
Episode 229100 | Reward: -16.523 | Epsilon: 0.0100 | Loss: 182874.7500
Episode 229150 | Reward: -16.597 | Epsilon: 0.0100 | Loss: 130137.3125
Episode 229200 | Reward: -15.471 | Epsilon: 0.0100 | Loss: 181197.9375
Episode 229250 | Reward: -15.138 | Epsilon: 0.0100 | Loss: 213979.9219
Episode 229300 | Reward: -12.642 | Epsilon: 0.0100 | Loss: 190444.9688
Episode 229350 | Reward: -17.229 | Epsilon: 0.0100 | Loss: 169997.8594
Episode 229400 | Reward: -16.000 | Epsilon: 0.0100 | Loss: 187178.7344
Episode 229450 | Reward: -14.517 | Epsilon: 0.0100 | Loss: 186527.6875
Episode 229500 | Reward: -14.048 | Epsilon: 0.0100 | Loss: 125189.8906
Episode 229550 | Reward: -15.780 | Epsilon: 0.0100 | Loss: 198243.8594
Episode 229600 | Reward: -14.019 | Epsilon: 0.0100 | Loss: 172335.3125
Episode 229650 | Reward: -16.126 | Epsilon: 0.0100 | Loss: 149101.1562
Episode 229700 | Reward: -10.925 | Epsilon: 0.0100 | Loss: 194622.4219
Episode 229750 | Reward: -16.512 | Epsilon: 0.0100 | Loss: 170664.0938
Episode 229800 | Reward: -16.011 | Epsilon: 0.0100 | Loss: 203783.0312
Episode 229850 | Reward: -12.771 | Epsilon: 0.0100 | Loss: 181231.8750
Episode 229900 | Reward: -11.773 | Epsilon: 0.0100 | Loss: 189846.5625
Episode 229950 | Reward:  -8.638 | Epsilon: 0.0100 | Loss: 172112.5781
Episode 230000 | Reward: -11.613 | Epsilon: 0.0100 | Loss: 215278.3594
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:24).dict
Episode 230050 | Reward:  -8.540 | Epsilon: 0.0100 | Loss: 223907.1094
Episode 230100 | Reward: -11.502 | Epsilon: 0.0100 | Loss: 240998.0469
Episode 230150 | Reward: -12.588 | Epsilon: 0.0100 | Loss: 216323.1094
Episode 230200 | Reward: -14.519 | Epsilon: 0.0100 | Loss: 222567.5938
Episode 230250 | Reward: -10.259 | Epsilon: 0.0100 | Loss: 218661.0625
Episode 230300 | Reward:  -9.640 | Epsilon: 0.0100 | Loss: 188333.4062
Episode 230350 | Reward: -12.561 | Epsilon: 0.0100 | Loss: 220673.6875
Episode 230400 | Reward: -11.380 | Epsilon: 0.0100 | Loss: 156593.3281
Episode 230450 | Reward: -11.950 | Epsilon: 0.0100 | Loss: 160838.3906
Episode 230500 | Reward: -14.843 | Epsilon: 0.0100 | Loss: 204271.9062
Episode 230550 | Reward: -13.070 | Epsilon: 0.0100 | Loss: 206067.7500
Episode 230600 | Reward:  -7.875 | Epsilon: 0.0100 | Loss: 214478.1875
Episode 230650 | Reward: -11.338 | Epsilon: 0.0100 | Loss: 172962.2031
Episode 230700 | Reward:  -8.894 | Epsilon: 0.0100 | Loss: 177239.4219
Episode 230750 | Reward: -11.006 | Epsilon: 0.0100 | Loss: 212049.1250
Episode 230800 | Reward:  -9.636 | Epsilon: 0.0100 | Loss: 189616.0625
Episode 230850 | Reward: -13.736 | Epsilon: 0.0100 | Loss: 203923.8750
Episode 230900 | Reward:  -8.571 | Epsilon: 0.0100 | Loss: 188711.5781
Episode 230950 | Reward:  -9.761 | Epsilon: 0.0100 | Loss: 181949.2500
Episode 231000 | Reward: -15.250 | Epsilon: 0.0100 | Loss: 165417.6406
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:28).dict
Episode 231050 | Reward:  -8.779 | Epsilon: 0.0100 | Loss: 165778.1875
Episode 231100 | Reward:  -8.363 | Epsilon: 0.0100 | Loss: 179857.9219
Episode 231150 | Reward:  -8.859 | Epsilon: 0.0100 | Loss: 177521.1562
Episode 231200 | Reward:  -8.131 | Epsilon: 0.0100 | Loss: 196340.7188
Episode 231250 | Reward: -10.476 | Epsilon: 0.0100 | Loss: 128296.7500
Episode 231300 | Reward: -14.145 | Epsilon: 0.0100 | Loss: 144696.1250
Episode 231350 | Reward: -10.088 | Epsilon: 0.0100 | Loss: 207421.5938
Episode 231400 | Reward: -11.305 | Epsilon: 0.0100 | Loss: 192264.2188
Episode 231450 | Reward: -10.067 | Epsilon: 0.0100 | Loss: 189278.8750
Episode 231500 | Reward: -13.301 | Epsilon: 0.0100 | Loss: 189371.0781
Episode 231550 | Reward: -10.644 | Epsilon: 0.0100 | Loss: 164950.4219
Episode 231600 | Reward:  -8.198 | Epsilon: 0.0100 | Loss: 164336.0938
Episode 231650 | Reward:  -7.938 | Epsilon: 0.0100 | Loss: 159293.0625
Episode 231700 | Reward:  -7.894 | Epsilon: 0.0100 | Loss: 162100.2812
Episode 231750 | Reward:  -9.838 | Epsilon: 0.0100 | Loss: 164261.3438
Episode 231800 | Reward:  -6.969 | Epsilon: 0.0100 | Loss: 203700.6250
Episode 231850 | Reward:  -6.393 | Epsilon: 0.0100 | Loss: 207165.8438
Episode 231900 | Reward:  -7.340 | Epsilon: 0.0100 | Loss: 192200.9062
Episode 231950 | Reward:  -7.289 | Epsilon: 0.0100 | Loss: 180071.8906
Episode 232000 | Reward: -10.070 | Epsilon: 0.0100 | Loss: 189252.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:32).dict
Episode 232050 | Reward:  -9.768 | Epsilon: 0.0100 | Loss: 191234.6094
Episode 232100 | Reward:  -7.362 | Epsilon: 0.0100 | Loss: 198310.2031
Episode 232150 | Reward:  -7.593 | Epsilon: 0.0100 | Loss: 169568.9062
Episode 232200 | Reward: -10.450 | Epsilon: 0.0100 | Loss: 160896.0312
Episode 232250 | Reward: -10.689 | Epsilon: 0.0100 | Loss: 209324.0312
Episode 232300 | Reward:  -6.031 | Epsilon: 0.0100 | Loss: 124951.0469
Episode 232350 | Reward:  -8.433 | Epsilon: 0.0100 | Loss: 164098.2344
Episode 232400 | Reward:  -9.064 | Epsilon: 0.0100 | Loss: 157694.2031
Episode 232450 | Reward:  -4.941 | Epsilon: 0.0100 | Loss: 137865.2031
Episode 232500 | Reward:  -8.698 | Epsilon: 0.0100 | Loss: 195790.2500
Episode 232550 | Reward:  -8.347 | Epsilon: 0.0100 | Loss: 164533.7344
Episode 232600 | Reward: -10.358 | Epsilon: 0.0100 | Loss: 189486.2812
Episode 232650 | Reward:  -9.087 | Epsilon: 0.0100 | Loss: 195552.7188
Episode 232700 | Reward:  -6.595 | Epsilon: 0.0100 | Loss: 206934.9844
Episode 232750 | Reward:  -4.770 | Epsilon: 0.0100 | Loss: 215388.2812
Episode 232800 | Reward:  -6.731 | Epsilon: 0.0100 | Loss: 139629.9375
Episode 232850 | Reward:  -7.164 | Epsilon: 0.0100 | Loss: 136342.8906
Episode 232900 | Reward:  -6.872 | Epsilon: 0.0100 | Loss: 206621.0312
Episode 232950 | Reward:  -3.487 | Epsilon: 0.0100 | Loss: 185841.1250
Episode 233000 | Reward: -12.176 | Epsilon: 0.0100 | Loss: 195576.8906
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:36).dict
Episode 233050 | Reward: -11.661 | Epsilon: 0.0100 | Loss: 199878.6875
Episode 233100 | Reward: -14.699 | Epsilon: 0.0100 | Loss: 145062.5156
Episode 233150 | Reward: -12.272 | Epsilon: 0.0100 | Loss: 168288.4375
Episode 233200 | Reward: -11.975 | Epsilon: 0.0100 | Loss: 204645.4531
Episode 233250 | Reward:  -9.420 | Epsilon: 0.0100 | Loss: 249643.1562
Episode 233300 | Reward: -12.269 | Epsilon: 0.0100 | Loss: 253389.0625
Episode 233350 | Reward: -11.680 | Epsilon: 0.0100 | Loss: 208291.6094
Episode 233400 | Reward:  -9.807 | Epsilon: 0.0100 | Loss: 257990.7500
Episode 233450 | Reward: -10.119 | Epsilon: 0.0100 | Loss: 216665.1250
Episode 233500 | Reward:  -8.985 | Epsilon: 0.0100 | Loss: 199156.7344
Episode 233550 | Reward: -11.874 | Epsilon: 0.0100 | Loss: 260306.8438
Episode 233600 | Reward: -16.131 | Epsilon: 0.0100 | Loss: 280689.9375
Episode 233650 | Reward: -10.248 | Epsilon: 0.0100 | Loss: 202321.0781
Episode 233700 | Reward:  -9.994 | Epsilon: 0.0100 | Loss: 236842.2500
Episode 233750 | Reward: -14.380 | Epsilon: 0.0100 | Loss: 245216.2188
Episode 233800 | Reward: -11.437 | Epsilon: 0.0100 | Loss: 251171.8750
Episode 233850 | Reward:  -8.715 | Epsilon: 0.0100 | Loss: 259774.2656
Episode 233900 | Reward:  -6.947 | Epsilon: 0.0100 | Loss: 212708.3750
Episode 233950 | Reward:  -7.406 | Epsilon: 0.0100 | Loss: 264872.8125
Episode 234000 | Reward: -12.455 | Epsilon: 0.0100 | Loss: 206384.0938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:40).dict
Episode 234050 | Reward:  -8.331 | Epsilon: 0.0100 | Loss: 266555.7500
Episode 234100 | Reward: -10.659 | Epsilon: 0.0100 | Loss: 219207.5312
Episode 234150 | Reward: -10.595 | Epsilon: 0.0100 | Loss: 274677.8438
Episode 234200 | Reward: -11.375 | Epsilon: 0.0100 | Loss: 289339.3438
Episode 234250 | Reward: -11.179 | Epsilon: 0.0100 | Loss: 212323.2812
Episode 234300 | Reward: -11.509 | Epsilon: 0.0100 | Loss: 246136.2031
Episode 234350 | Reward: -12.697 | Epsilon: 0.0100 | Loss: 213309.7656
Episode 234400 | Reward:  -8.432 | Epsilon: 0.0100 | Loss: 267419.0312
Episode 234450 | Reward: -10.165 | Epsilon: 0.0100 | Loss: 298879.4062
Episode 234500 | Reward: -13.676 | Epsilon: 0.0100 | Loss: 246661.6094
Episode 234550 | Reward: -12.275 | Epsilon: 0.0100 | Loss: 246515.8281
Episode 234600 | Reward: -12.672 | Epsilon: 0.0100 | Loss: 218371.0781
Episode 234650 | Reward:  -6.671 | Epsilon: 0.0100 | Loss: 241294.8125
Episode 234700 | Reward:  -8.678 | Epsilon: 0.0100 | Loss: 349080.5312
Episode 234750 | Reward:  -8.188 | Epsilon: 0.0100 | Loss: 249789.8438
Episode 234800 | Reward: -11.011 | Epsilon: 0.0100 | Loss: 296809.1875
Episode 234850 | Reward: -12.142 | Epsilon: 0.0100 | Loss: 244574.7188
Episode 234900 | Reward:  -6.832 | Epsilon: 0.0100 | Loss: 250340.1250
Episode 234950 | Reward:  -7.331 | Epsilon: 0.0100 | Loss: 274642.5625
Episode 235000 | Reward: -10.217 | Epsilon: 0.0100 | Loss: 271019.7812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:44).dict
Episode 235050 | Reward:  -7.954 | Epsilon: 0.0100 | Loss: 271133.4062
Episode 235100 | Reward:  -5.701 | Epsilon: 0.0100 | Loss: 403502.2812
Episode 235150 | Reward:  -6.324 | Epsilon: 0.0100 | Loss: 325736.1875
Episode 235200 | Reward: -10.750 | Epsilon: 0.0100 | Loss: 346430.5312
Episode 235250 | Reward: -10.752 | Epsilon: 0.0100 | Loss: 324081.5625
Episode 235300 | Reward:  -3.636 | Epsilon: 0.0100 | Loss: 369055.0625
Episode 235350 | Reward: -12.232 | Epsilon: 0.0100 | Loss: 260368.7812
Episode 235400 | Reward:  -9.997 | Epsilon: 0.0100 | Loss: 286223.0312
Episode 235450 | Reward: -10.881 | Epsilon: 0.0100 | Loss: 318029.8438
Episode 235500 | Reward: -12.384 | Epsilon: 0.0100 | Loss: 324240.4062
Episode 235550 | Reward:  -9.421 | Epsilon: 0.0100 | Loss: 333373.8438
Episode 235600 | Reward:  -8.504 | Epsilon: 0.0100 | Loss: 391915.1875
Episode 235650 | Reward:  -8.978 | Epsilon: 0.0100 | Loss: 402876.0000
Episode 235700 | Reward:  -9.171 | Epsilon: 0.0100 | Loss: 496864.1875
Episode 235750 | Reward: -13.483 | Epsilon: 0.0100 | Loss: 381963.9062
Episode 235800 | Reward:  -8.173 | Epsilon: 0.0100 | Loss: 374840.0938
Episode 235850 | Reward: -10.487 | Epsilon: 0.0100 | Loss: 397338.9375
Episode 235900 | Reward: -13.406 | Epsilon: 0.0100 | Loss: 439938.8750
Episode 235950 | Reward:  -8.533 | Epsilon: 0.0100 | Loss: 409549.2188
Episode 236000 | Reward:  -9.256 | Epsilon: 0.0100 | Loss: 404138.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:49).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:49).dict
Episode 236050 | Reward:  -6.268 | Epsilon: 0.0100 | Loss: 431039.2188
Episode 236100 | Reward:  -9.378 | Epsilon: 0.0100 | Loss: 429221.0938
Episode 236150 | Reward: -11.274 | Epsilon: 0.0100 | Loss: 451235.4062
Episode 236200 | Reward: -10.335 | Epsilon: 0.0100 | Loss: 472058.9375
Episode 236250 | Reward:  -6.347 | Epsilon: 0.0100 | Loss: 457120.7188
Episode 236300 | Reward:  -9.638 | Epsilon: 0.0100 | Loss: 402314.1562
Episode 236350 | Reward:  -8.789 | Epsilon: 0.0100 | Loss: 354154.7812
Episode 236400 | Reward:  -9.826 | Epsilon: 0.0100 | Loss: 490203.2812
Episode 236450 | Reward: -10.137 | Epsilon: 0.0100 | Loss: 443781.6875
Episode 236500 | Reward:  -7.014 | Epsilon: 0.0100 | Loss: 569372.6250
Episode 236550 | Reward:  -8.582 | Epsilon: 0.0100 | Loss: 512541.4688
Episode 236600 | Reward:  -9.364 | Epsilon: 0.0100 | Loss: 519685.9375
Episode 236650 | Reward:  -5.443 | Epsilon: 0.0100 | Loss: 541763.0625
Episode 236700 | Reward:  -8.139 | Epsilon: 0.0100 | Loss: 515401.5000
Episode 236750 | Reward:  -9.331 | Epsilon: 0.0100 | Loss: 402217.7500
Episode 236800 | Reward: -10.094 | Epsilon: 0.0100 | Loss: 650840.0625
Episode 236850 | Reward:  -7.385 | Epsilon: 0.0100 | Loss: 649724.3750
Episode 236900 | Reward: -10.526 | Epsilon: 0.0100 | Loss: 476598.8438
Episode 236950 | Reward: -14.004 | Epsilon: 0.0100 | Loss: 575246.8125
Episode 237000 | Reward: -11.452 | Epsilon: 0.0100 | Loss: 585352.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:53).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:53).dict
Episode 237050 | Reward: -14.167 | Epsilon: 0.0100 | Loss: 648124.8750
Episode 237100 | Reward:  -9.876 | Epsilon: 0.0100 | Loss: 484558.4062
Episode 237150 | Reward: -11.411 | Epsilon: 0.0100 | Loss: 589776.6875
Episode 237200 | Reward: -11.689 | Epsilon: 0.0100 | Loss: 702736.7500
Episode 237250 | Reward: -11.739 | Epsilon: 0.0100 | Loss: 699510.3750
Episode 237300 | Reward: -10.448 | Epsilon: 0.0100 | Loss: 575949.6250
Episode 237350 | Reward: -14.661 | Epsilon: 0.0100 | Loss: 682997.5000
Episode 237400 | Reward: -13.240 | Epsilon: 0.0100 | Loss: 678239.5625
Episode 237450 | Reward: -15.401 | Epsilon: 0.0100 | Loss: 581675.5000
Episode 237500 | Reward: -13.171 | Epsilon: 0.0100 | Loss: 553050.0000
Episode 237550 | Reward: -11.780 | Epsilon: 0.0100 | Loss: 538717.8750
Episode 237600 | Reward:  -8.407 | Epsilon: 0.0100 | Loss: 850390.1875
Episode 237650 | Reward: -11.624 | Epsilon: 0.0100 | Loss: 604984.3125
Episode 237700 | Reward: -12.580 | Epsilon: 0.0100 | Loss: 841356.8750
Episode 237750 | Reward: -15.737 | Epsilon: 0.0100 | Loss: 712719.4375
Episode 237800 | Reward:  -9.362 | Epsilon: 0.0100 | Loss: 478113.5312
Episode 237850 | Reward:  -8.892 | Epsilon: 0.0100 | Loss: 644948.7500
Episode 237900 | Reward: -14.518 | Epsilon: 0.0100 | Loss: 644505.0000
Episode 237950 | Reward: -10.980 | Epsilon: 0.0100 | Loss: 631526.2500
Episode 238000 | Reward:  -9.692 | Epsilon: 0.0100 | Loss: 722222.3125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:57).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(16:57).dict
Episode 238050 | Reward:  -9.933 | Epsilon: 0.0100 | Loss: 698719.4375
Episode 238100 | Reward: -12.723 | Epsilon: 0.0100 | Loss: 765833.2500
Episode 238150 | Reward: -13.754 | Epsilon: 0.0100 | Loss: 726577.3125
Episode 238200 | Reward: -12.797 | Epsilon: 0.0100 | Loss: 732450.4375
Episode 238250 | Reward:  -9.044 | Epsilon: 0.0100 | Loss: 765491.5000
Episode 238300 | Reward: -11.284 | Epsilon: 0.0100 | Loss: 566494.3750
Episode 238350 | Reward: -11.840 | Epsilon: 0.0100 | Loss: 840802.8750
Episode 238400 | Reward: -13.214 | Epsilon: 0.0100 | Loss: 609731.8750
Episode 238450 | Reward: -11.736 | Epsilon: 0.0100 | Loss: 822834.1250
Episode 238500 | Reward: -12.469 | Epsilon: 0.0100 | Loss: 706010.1875
Episode 238550 | Reward: -14.684 | Epsilon: 0.0100 | Loss: 608510.1250
Episode 238600 | Reward:  -9.620 | Epsilon: 0.0100 | Loss: 499223.2500
Episode 238650 | Reward:  -9.819 | Epsilon: 0.0100 | Loss: 649892.6250
Episode 238700 | Reward: -10.052 | Epsilon: 0.0100 | Loss: 734790.3750
Episode 238750 | Reward: -11.029 | Epsilon: 0.0100 | Loss: 557952.6250
Episode 238800 | Reward: -11.323 | Epsilon: 0.0100 | Loss: 609402.1250
Episode 238850 | Reward: -12.917 | Epsilon: 0.0100 | Loss: 668919.5000
Episode 238900 | Reward: -16.598 | Epsilon: 0.0100 | Loss: 750756.7500
Episode 238950 | Reward: -12.791 | Epsilon: 0.0100 | Loss: 510760.0625
Episode 239000 | Reward: -13.176 | Epsilon: 0.0100 | Loss: 878434.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:01).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:01).dict
Episode 239050 | Reward: -12.876 | Epsilon: 0.0100 | Loss: 756821.8125
Episode 239100 | Reward: -12.449 | Epsilon: 0.0100 | Loss: 785891.2500
Episode 239150 | Reward: -15.485 | Epsilon: 0.0100 | Loss: 727971.8125
Episode 239200 | Reward: -10.384 | Epsilon: 0.0100 | Loss: 682187.3750
Episode 239250 | Reward: -12.830 | Epsilon: 0.0100 | Loss: 682851.6875
Episode 239300 | Reward: -12.623 | Epsilon: 0.0100 | Loss: 778589.1250
Episode 239350 | Reward: -10.530 | Epsilon: 0.0100 | Loss: 724178.0000
Episode 239400 | Reward: -11.076 | Epsilon: 0.0100 | Loss: 531476.9375
Episode 239450 | Reward: -10.538 | Epsilon: 0.0100 | Loss: 797498.2500
Episode 239500 | Reward: -11.663 | Epsilon: 0.0100 | Loss: 745216.1250
Episode 239550 | Reward: -14.772 | Epsilon: 0.0100 | Loss: 758750.7500
Episode 239600 | Reward: -13.035 | Epsilon: 0.0100 | Loss: 820344.4375
Episode 239650 | Reward: -13.570 | Epsilon: 0.0100 | Loss: 642550.0000
Episode 239700 | Reward: -10.696 | Epsilon: 0.0100 | Loss: 665814.1875
Episode 239750 | Reward:  -7.602 | Epsilon: 0.0100 | Loss: 799012.5000
Episode 239800 | Reward:  -7.229 | Epsilon: 0.0100 | Loss: 559505.5000
Episode 239850 | Reward:  -9.578 | Epsilon: 0.0100 | Loss: 730369.5625
Episode 239900 | Reward:  -9.867 | Epsilon: 0.0100 | Loss: 637336.7500
Episode 239950 | Reward:  -8.407 | Epsilon: 0.0100 | Loss: 598802.0625
Episode 240000 | Reward: -13.156 | Epsilon: 0.0100 | Loss: 649975.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:05).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:05).dict
Episode 240050 | Reward: -13.050 | Epsilon: 0.0100 | Loss: 702520.5000
Episode 240100 | Reward: -13.663 | Epsilon: 0.0100 | Loss: 692268.6250
Episode 240150 | Reward: -13.406 | Epsilon: 0.0100 | Loss: 823655.5000
Episode 240200 | Reward: -10.456 | Epsilon: 0.0100 | Loss: 1053542.7500
Episode 240250 | Reward: -10.597 | Epsilon: 0.0100 | Loss: 575884.3750
Episode 240300 | Reward: -11.537 | Epsilon: 0.0100 | Loss: 704013.0000
Episode 240350 | Reward: -12.093 | Epsilon: 0.0100 | Loss: 659701.5625
Episode 240400 | Reward: -12.367 | Epsilon: 0.0100 | Loss: 731140.4375
Episode 240450 | Reward: -13.158 | Epsilon: 0.0100 | Loss: 712691.4375
Episode 240500 | Reward:  -9.390 | Epsilon: 0.0100 | Loss: 648513.5625
Episode 240550 | Reward:  -7.879 | Epsilon: 0.0100 | Loss: 732925.1875
Episode 240600 | Reward: -10.855 | Epsilon: 0.0100 | Loss: 748040.1250
Episode 240650 | Reward:  -9.093 | Epsilon: 0.0100 | Loss: 752009.3125
Episode 240700 | Reward:  -7.281 | Epsilon: 0.0100 | Loss: 811205.6250
Episode 240750 | Reward: -10.317 | Epsilon: 0.0100 | Loss: 930887.2500
Episode 240800 | Reward: -12.199 | Epsilon: 0.0100 | Loss: 636109.4375
Episode 240850 | Reward: -11.300 | Epsilon: 0.0100 | Loss: 578704.5000
Episode 240900 | Reward:  -8.403 | Epsilon: 0.0100 | Loss: 485579.5000
Episode 240950 | Reward: -10.911 | Epsilon: 0.0100 | Loss: 808171.9375
Episode 241000 | Reward: -12.202 | Epsilon: 0.0100 | Loss: 820435.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:09).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:09).dict
Episode 241050 | Reward: -11.854 | Epsilon: 0.0100 | Loss: 770447.7500
Episode 241100 | Reward: -13.192 | Epsilon: 0.0100 | Loss: 557629.1250
Episode 241150 | Reward: -11.982 | Epsilon: 0.0100 | Loss: 499161.8750
Episode 241200 | Reward: -12.918 | Epsilon: 0.0100 | Loss: 769054.5000
Episode 241250 | Reward:  -9.660 | Epsilon: 0.0100 | Loss: 527790.4375
Episode 241300 | Reward:  -8.803 | Epsilon: 0.0100 | Loss: 667960.9375
Episode 241350 | Reward:  -6.521 | Epsilon: 0.0100 | Loss: 801389.9375
Episode 241400 | Reward:  -8.013 | Epsilon: 0.0100 | Loss: 633755.0000
Episode 241450 | Reward:  -7.529 | Epsilon: 0.0100 | Loss: 730288.3750
Episode 241500 | Reward:  -9.088 | Epsilon: 0.0100 | Loss: 565516.3125
Episode 241550 | Reward:  -8.654 | Epsilon: 0.0100 | Loss: 709249.5625
Episode 241600 | Reward: -12.679 | Epsilon: 0.0100 | Loss: 539950.3750
Episode 241650 | Reward:  -7.534 | Epsilon: 0.0100 | Loss: 753729.3750
Episode 241700 | Reward:  -7.599 | Epsilon: 0.0100 | Loss: 618967.3750
Episode 241750 | Reward:  -8.913 | Epsilon: 0.0100 | Loss: 532824.1875
Episode 241800 | Reward:  -7.047 | Epsilon: 0.0100 | Loss: 734160.1250
Episode 241850 | Reward: -10.383 | Epsilon: 0.0100 | Loss: 567687.2500
Episode 241900 | Reward: -10.472 | Epsilon: 0.0100 | Loss: 740441.5000
Episode 241950 | Reward: -11.140 | Epsilon: 0.0100 | Loss: 494054.1875
Episode 242000 | Reward: -13.009 | Epsilon: 0.0100 | Loss: 589487.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:13).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:13).dict
Episode 242050 | Reward: -11.834 | Epsilon: 0.0100 | Loss: 598083.2500
Episode 242100 | Reward:  -6.283 | Epsilon: 0.0100 | Loss: 658936.8750
Episode 242150 | Reward:  -6.487 | Epsilon: 0.0100 | Loss: 769271.8750
Episode 242200 | Reward:  -6.196 | Epsilon: 0.0100 | Loss: 699823.2500
Episode 242250 | Reward:  -6.854 | Epsilon: 0.0100 | Loss: 612542.0000
Episode 242300 | Reward:  -8.979 | Epsilon: 0.0100 | Loss: 485334.8125
Episode 242350 | Reward: -11.326 | Epsilon: 0.0100 | Loss: 572409.5000
Episode 242400 | Reward:  -7.467 | Epsilon: 0.0100 | Loss: 616013.6875
Episode 242450 | Reward:  -6.858 | Epsilon: 0.0100 | Loss: 685494.2500
Episode 242500 | Reward:  -6.453 | Epsilon: 0.0100 | Loss: 437634.3438
Episode 242550 | Reward: -11.290 | Epsilon: 0.0100 | Loss: 633743.8750
Episode 242600 | Reward:  -9.022 | Epsilon: 0.0100 | Loss: 636718.5000
Episode 242650 | Reward: -12.813 | Epsilon: 0.0100 | Loss: 623956.0000
Episode 242700 | Reward: -11.416 | Epsilon: 0.0100 | Loss: 455883.3125
Episode 242750 | Reward:  -9.386 | Epsilon: 0.0100 | Loss: 478298.6250
Episode 242800 | Reward: -10.565 | Epsilon: 0.0100 | Loss: 519251.7188
Episode 242850 | Reward:  -9.295 | Epsilon: 0.0100 | Loss: 721688.6875
Episode 242900 | Reward: -11.081 | Epsilon: 0.0100 | Loss: 526217.2500
Episode 242950 | Reward:  -8.169 | Epsilon: 0.0100 | Loss: 736697.1250
Episode 243000 | Reward:  -7.541 | Epsilon: 0.0100 | Loss: 622400.6250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:17).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:17).dict
Episode 243050 | Reward: -10.845 | Epsilon: 0.0100 | Loss: 490433.1875
Episode 243100 | Reward:  -8.826 | Epsilon: 0.0100 | Loss: 740983.1875
Episode 243150 | Reward: -12.501 | Epsilon: 0.0100 | Loss: 746076.1250
Episode 243200 | Reward: -11.898 | Epsilon: 0.0100 | Loss: 559411.8750
Episode 243250 | Reward: -13.871 | Epsilon: 0.0100 | Loss: 602969.1250
Episode 243300 | Reward:  -8.397 | Epsilon: 0.0100 | Loss: 682805.4375
Episode 243350 | Reward: -10.775 | Epsilon: 0.0100 | Loss: 565970.8750
Episode 243400 | Reward: -14.946 | Epsilon: 0.0100 | Loss: 513719.7500
Episode 243450 | Reward: -13.357 | Epsilon: 0.0100 | Loss: 571543.1250
Episode 243500 | Reward: -11.314 | Epsilon: 0.0100 | Loss: 550959.5000
Episode 243550 | Reward: -11.850 | Epsilon: 0.0100 | Loss: 539435.1250
Episode 243600 | Reward: -11.655 | Epsilon: 0.0100 | Loss: 581189.8125
Episode 243650 | Reward: -13.696 | Epsilon: 0.0100 | Loss: 554172.8750
Episode 243700 | Reward:  -9.368 | Epsilon: 0.0100 | Loss: 548799.6250
Episode 243750 | Reward:  -6.451 | Epsilon: 0.0100 | Loss: 598953.4375
Episode 243800 | Reward:  -8.540 | Epsilon: 0.0100 | Loss: 685526.1250
Episode 243850 | Reward: -11.962 | Epsilon: 0.0100 | Loss: 578946.0625
Episode 243900 | Reward: -11.845 | Epsilon: 0.0100 | Loss: 644771.3750
Episode 243950 | Reward:  -8.599 | Epsilon: 0.0100 | Loss: 666539.2500
Episode 244000 | Reward:  -8.868 | Epsilon: 0.0100 | Loss: 530280.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:21).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:21).dict
Episode 244050 | Reward:  -9.764 | Epsilon: 0.0100 | Loss: 525396.1250
Episode 244100 | Reward: -11.397 | Epsilon: 0.0100 | Loss: 557602.6875
Episode 244150 | Reward: -14.189 | Epsilon: 0.0100 | Loss: 655642.1250
Episode 244200 | Reward: -13.056 | Epsilon: 0.0100 | Loss: 553572.0000
Episode 244250 | Reward: -11.190 | Epsilon: 0.0100 | Loss: 523054.4688
Episode 244300 | Reward: -10.100 | Epsilon: 0.0100 | Loss: 519837.4375
Episode 244350 | Reward:  -9.454 | Epsilon: 0.0100 | Loss: 513584.5312
Episode 244400 | Reward:  -9.041 | Epsilon: 0.0100 | Loss: 553775.3125
Episode 244450 | Reward: -10.734 | Epsilon: 0.0100 | Loss: 505740.7188
Episode 244500 | Reward: -10.742 | Epsilon: 0.0100 | Loss: 688732.6250
Episode 244550 | Reward:  -8.696 | Epsilon: 0.0100 | Loss: 601243.2500
Episode 244600 | Reward: -10.486 | Epsilon: 0.0100 | Loss: 455963.7812
Episode 244650 | Reward:  -5.369 | Epsilon: 0.0100 | Loss: 545430.0625
Episode 244700 | Reward: -10.195 | Epsilon: 0.0100 | Loss: 495164.0000
Episode 244750 | Reward: -16.399 | Epsilon: 0.0100 | Loss: 349305.0938
Episode 244800 | Reward: -10.888 | Epsilon: 0.0100 | Loss: 659966.1875
Episode 244850 | Reward: -15.054 | Epsilon: 0.0100 | Loss: 637811.7500
Episode 244900 | Reward: -17.712 | Epsilon: 0.0100 | Loss: 684148.6250
Episode 244950 | Reward: -16.132 | Epsilon: 0.0100 | Loss: 750603.5625
Episode 245000 | Reward: -14.051 | Epsilon: 0.0100 | Loss: 519507.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:25).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:25).dict
Episode 245050 | Reward: -10.563 | Epsilon: 0.0100 | Loss: 694590.1250
Episode 245100 | Reward: -11.527 | Epsilon: 0.0100 | Loss: 696034.2500
Episode 245150 | Reward: -11.713 | Epsilon: 0.0100 | Loss: 561397.0000
Episode 245200 | Reward: -15.190 | Epsilon: 0.0100 | Loss: 514786.3125
Episode 245250 | Reward:  -7.375 | Epsilon: 0.0100 | Loss: 639865.1250
Episode 245300 | Reward: -14.274 | Epsilon: 0.0100 | Loss: 434071.3438
Episode 245350 | Reward: -15.771 | Epsilon: 0.0100 | Loss: 613673.0625
Episode 245400 | Reward: -15.794 | Epsilon: 0.0100 | Loss: 586185.2500


Training interrupted by user
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:27).dict.dict
✓ Final model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(17:27).dict
