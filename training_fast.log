nohup: ignoring input
Using device: cpu (CUDA not available)
======================================================================
FAST TRAINING MODE - Optimizations:
- M=8 rules (doubled capacity for learning strategies)
- Learning rate: 0.003 (3x normal)
- Batch size: 128 (smaller for faster updates)
- Update every game
- Target network sync every 50 episodes
- No rendering/visualization
======================================================================
Episode    50 | Reward:  -9.794 | Epsilon: 0.7783
Episode   100 | Reward: -14.036 | Epsilon: 0.6058 | Loss: 168.9323
Episode   150 | Reward: -14.595 | Epsilon: 0.4715 | Loss: 134.7429
Episode   200 | Reward: -14.927 | Epsilon: 0.3670 | Loss: 125.5004
Episode   250 | Reward: -15.093 | Epsilon: 0.2856 | Loss: 125.3129
Episode   300 | Reward: -17.371 | Epsilon: 0.2223 | Loss: 145.0423
Episode   350 | Reward: -14.393 | Epsilon: 0.1730 | Loss: 157.5722
Episode   400 | Reward: -12.974 | Epsilon: 0.1347 | Loss: 137.3930
Episode   450 | Reward: -13.254 | Epsilon: 0.1048 | Loss: 165.6779
Episode   500 | Reward: -15.547 | Epsilon: 0.0816 | Loss: 196.5649
Episode   550 | Reward: -11.592 | Epsilon: 0.0635 | Loss: 157.9968
Episode   600 | Reward: -11.740 | Epsilon: 0.0494 | Loss: 149.4623
Episode   650 | Reward:  -8.868 | Epsilon: 0.0385 | Loss: 197.6252
Episode   700 | Reward: -10.471 | Epsilon: 0.0299 | Loss: 217.7977
Episode   750 | Reward:  -8.613 | Epsilon: 0.0233 | Loss: 235.1001
Episode   800 | Reward:  -3.680 | Epsilon: 0.0181 | Loss: 184.4224
Episode   850 | Reward: -12.640 | Epsilon: 0.0141 | Loss: 210.4557
Episode   900 | Reward: -12.704 | Epsilon: 0.0110 | Loss: 188.6836
Episode   950 | Reward:  -7.951 | Epsilon: 0.0100 | Loss: 219.6819
Episode  1000 | Reward:  -7.014 | Epsilon: 0.0100 | Loss: 259.8365
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:07).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:07).dict
Episode  1050 | Reward:  -8.935 | Epsilon: 0.0100 | Loss: 220.1659
Episode  1100 | Reward:  -6.520 | Epsilon: 0.0100 | Loss: 221.7290
Episode  1150 | Reward: -12.185 | Epsilon: 0.0100 | Loss: 224.2964
Episode  1200 | Reward:  -7.243 | Epsilon: 0.0100 | Loss: 246.4423
Episode  1250 | Reward:  -9.248 | Epsilon: 0.0100 | Loss: 254.4575
Episode  1300 | Reward: -11.539 | Epsilon: 0.0100 | Loss: 213.9631
Episode  1350 | Reward:  -7.199 | Epsilon: 0.0100 | Loss: 290.3609
Episode  1400 | Reward:  -4.891 | Epsilon: 0.0100 | Loss: 210.5294
Episode  1450 | Reward:  -6.158 | Epsilon: 0.0100 | Loss: 233.0381
Episode  1500 | Reward:  -9.840 | Epsilon: 0.0100 | Loss: 271.1498
Episode  1550 | Reward: -10.590 | Epsilon: 0.0100 | Loss: 306.5050
Episode  1600 | Reward:  -4.715 | Epsilon: 0.0100 | Loss: 235.8869
Episode  1650 | Reward:  -6.252 | Epsilon: 0.0100 | Loss: 237.3643
Episode  1700 | Reward:  -6.501 | Epsilon: 0.0100 | Loss: 221.7454
Episode  1750 | Reward:  -6.245 | Epsilon: 0.0100 | Loss: 244.9742
Episode  1800 | Reward:  -9.068 | Epsilon: 0.0100 | Loss: 299.0086
Episode  1850 | Reward:  -8.526 | Epsilon: 0.0100 | Loss: 308.6432
Episode  1900 | Reward:  -9.752 | Epsilon: 0.0100 | Loss: 250.3983
Episode  1950 | Reward:  -7.074 | Epsilon: 0.0100 | Loss: 292.7786
Episode  2000 | Reward:  -8.955 | Epsilon: 0.0100 | Loss: 277.6908
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:11).dict
Episode  2050 | Reward: -10.308 | Epsilon: 0.0100 | Loss: 242.1243
Episode  2100 | Reward:  -9.805 | Epsilon: 0.0100 | Loss: 311.2138
Episode  2150 | Reward:  -8.890 | Epsilon: 0.0100 | Loss: 245.0133
Episode  2200 | Reward:  -4.048 | Epsilon: 0.0100 | Loss: 293.2262
Episode  2250 | Reward:  -3.521 | Epsilon: 0.0100 | Loss: 254.2869
Episode  2300 | Reward:  -3.559 | Epsilon: 0.0100 | Loss: 333.6530
Episode  2350 | Reward:  -3.331 | Epsilon: 0.0100 | Loss: 266.1555
Episode  2400 | Reward: -10.858 | Epsilon: 0.0100 | Loss: 356.9975
Episode  2450 | Reward:  -7.944 | Epsilon: 0.0100 | Loss: 254.3834
Episode  2500 | Reward:  -3.349 | Epsilon: 0.0100 | Loss: 265.8495
Episode  2550 | Reward:  -6.167 | Epsilon: 0.0100 | Loss: 310.0538
Episode  2600 | Reward:  -5.881 | Epsilon: 0.0100 | Loss: 287.0134
Episode  2650 | Reward:  -7.121 | Epsilon: 0.0100 | Loss: 298.6323
Episode  2700 | Reward:  -7.449 | Epsilon: 0.0100 | Loss: 298.4295
Episode  2750 | Reward:  -9.094 | Epsilon: 0.0100 | Loss: 334.6619
Episode  2800 | Reward:  -0.928 | Epsilon: 0.0100 | Loss: 293.2818
Episode  2850 | Reward:  -3.793 | Epsilon: 0.0100 | Loss: 328.6668
Episode  2900 | Reward:  -4.401 | Epsilon: 0.0100 | Loss: 314.2172
Episode  2950 | Reward:  -7.343 | Epsilon: 0.0100 | Loss: 296.3185
Episode  3000 | Reward:  -4.989 | Epsilon: 0.0100 | Loss: 343.6557
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:15).dict
Episode  3050 | Reward:  -3.420 | Epsilon: 0.0100 | Loss: 351.4048
Episode  3100 | Reward:  -6.190 | Epsilon: 0.0100 | Loss: 258.6961
Episode  3150 | Reward:  -5.546 | Epsilon: 0.0100 | Loss: 364.4614
Episode  3200 | Reward:  -6.978 | Epsilon: 0.0100 | Loss: 227.0124
Episode  3250 | Reward:  -9.149 | Epsilon: 0.0100 | Loss: 271.3748
Episode  3300 | Reward:  -5.384 | Epsilon: 0.0100 | Loss: 277.7891
Episode  3350 | Reward:  -4.946 | Epsilon: 0.0100 | Loss: 271.6643
Episode  3400 | Reward:  -2.205 | Epsilon: 0.0100 | Loss: 312.8954
Episode  3450 | Reward:  -5.228 | Epsilon: 0.0100 | Loss: 263.4374
Episode  3500 | Reward:  -6.081 | Epsilon: 0.0100 | Loss: 287.4793
Episode  3550 | Reward:  -6.719 | Epsilon: 0.0100 | Loss: 244.3526
Episode  3600 | Reward:  -5.458 | Epsilon: 0.0100 | Loss: 360.4090
Episode  3650 | Reward:  -9.862 | Epsilon: 0.0100 | Loss: 269.7737
Episode  3700 | Reward:  -4.733 | Epsilon: 0.0100 | Loss: 250.1100
Episode  3750 | Reward:  -6.769 | Epsilon: 0.0100 | Loss: 338.5780
Episode  3800 | Reward:  -6.697 | Epsilon: 0.0100 | Loss: 305.3136
Episode  3850 | Reward:  -8.659 | Epsilon: 0.0100 | Loss: 316.1570
Episode  3900 | Reward:  -5.859 | Epsilon: 0.0100 | Loss: 341.2029
Episode  3950 | Reward:  -5.121 | Epsilon: 0.0100 | Loss: 240.0228
Episode  4000 | Reward:  -7.633 | Epsilon: 0.0100 | Loss: 320.2288
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:19).dict
Episode  4050 | Reward:  -3.679 | Epsilon: 0.0100 | Loss: 324.0897
Episode  4100 | Reward:  -3.186 | Epsilon: 0.0100 | Loss: 282.3937
Episode  4150 | Reward:  -3.905 | Epsilon: 0.0100 | Loss: 284.5053
Episode  4200 | Reward:  -4.339 | Epsilon: 0.0100 | Loss: 308.7262
Episode  4250 | Reward:  -3.050 | Epsilon: 0.0100 | Loss: 280.2762
Episode  4300 | Reward:  -1.584 | Epsilon: 0.0100 | Loss: 268.3507
Episode  4350 | Reward:  -3.890 | Epsilon: 0.0100 | Loss: 242.3276
Episode  4400 | Reward:  -6.544 | Epsilon: 0.0100 | Loss: 346.0942
Episode  4450 | Reward:  -8.535 | Epsilon: 0.0100 | Loss: 195.1305
Episode  4500 | Reward:  -7.575 | Epsilon: 0.0100 | Loss: 322.1723
Episode  4550 | Reward:  -5.118 | Epsilon: 0.0100 | Loss: 285.7951
Episode  4600 | Reward:  -6.268 | Epsilon: 0.0100 | Loss: 310.4099
Episode  4650 | Reward:  -0.355 | Epsilon: 0.0100 | Loss: 342.6944
Episode  4700 | Reward:  -2.800 | Epsilon: 0.0100 | Loss: 326.2209
Episode  4750 | Reward:  -4.261 | Epsilon: 0.0100 | Loss: 386.3354
Episode  4800 | Reward:  -3.077 | Epsilon: 0.0100 | Loss: 270.2320
Episode  4850 | Reward:  -3.920 | Epsilon: 0.0100 | Loss: 305.0900
Episode  4900 | Reward:  -3.371 | Epsilon: 0.0100 | Loss: 409.8623
Episode  4950 | Reward:  -7.387 | Epsilon: 0.0100 | Loss: 352.6458
Episode  5000 | Reward:  -6.457 | Epsilon: 0.0100 | Loss: 254.6013
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:23).dict
Episode  5050 | Reward:  -1.377 | Epsilon: 0.0100 | Loss: 341.2880
Episode  5100 | Reward:  -2.809 | Epsilon: 0.0100 | Loss: 315.4394
Episode  5150 | Reward:  -6.478 | Epsilon: 0.0100 | Loss: 290.3045
Episode  5200 | Reward:  -2.753 | Epsilon: 0.0100 | Loss: 342.4021
Episode  5250 | Reward:  -1.003 | Epsilon: 0.0100 | Loss: 292.4580
Episode  5300 | Reward:  -1.640 | Epsilon: 0.0100 | Loss: 387.9058
Episode  5350 | Reward:  -3.089 | Epsilon: 0.0100 | Loss: 316.2260
Episode  5400 | Reward:   1.140 | Epsilon: 0.0100 | Loss: 240.2615
Episode  5450 | Reward:  -4.441 | Epsilon: 0.0100 | Loss: 351.2535
Episode  5500 | Reward:  -3.381 | Epsilon: 0.0100 | Loss: 305.0460
Episode  5550 | Reward:  -6.555 | Epsilon: 0.0100 | Loss: 360.0563
Episode  5600 | Reward:  -3.567 | Epsilon: 0.0100 | Loss: 307.3590
Episode  5650 | Reward:  -6.310 | Epsilon: 0.0100 | Loss: 336.5711
Episode  5700 | Reward:  -8.304 | Epsilon: 0.0100 | Loss: 365.3198
Episode  5750 | Reward:  -4.324 | Epsilon: 0.0100 | Loss: 274.0853
Episode  5800 | Reward:  -4.928 | Epsilon: 0.0100 | Loss: 334.7840
Episode  5850 | Reward:  -4.896 | Epsilon: 0.0100 | Loss: 250.4067
Episode  5900 | Reward:  -6.111 | Epsilon: 0.0100 | Loss: 364.9890
Episode  5950 | Reward:   1.265 | Epsilon: 0.0100 | Loss: 353.5979
Episode  6000 | Reward:  -0.368 | Epsilon: 0.0100 | Loss: 298.3632
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:27).dict
Episode  6050 | Reward:  -3.320 | Epsilon: 0.0100 | Loss: 255.8552
Episode  6100 | Reward:  -5.995 | Epsilon: 0.0100 | Loss: 206.6287
Episode  6150 | Reward:  -6.119 | Epsilon: 0.0100 | Loss: 390.9024
Episode  6200 | Reward:  -3.716 | Epsilon: 0.0100 | Loss: 273.5657
Episode  6250 | Reward:  -3.735 | Epsilon: 0.0100 | Loss: 281.0341
Episode  6300 | Reward:  -4.845 | Epsilon: 0.0100 | Loss: 242.2547
Episode  6350 | Reward:  -0.774 | Epsilon: 0.0100 | Loss: 305.3502
Episode  6400 | Reward:  -8.390 | Epsilon: 0.0100 | Loss: 359.5810
Episode  6450 | Reward:  -5.224 | Epsilon: 0.0100 | Loss: 293.2729
Episode  6500 | Reward:  -7.681 | Epsilon: 0.0100 | Loss: 266.9776
Episode  6550 | Reward:  -3.321 | Epsilon: 0.0100 | Loss: 380.0767
Episode  6600 | Reward:  -7.471 | Epsilon: 0.0100 | Loss: 351.8943
Episode  6650 | Reward:  -5.256 | Epsilon: 0.0100 | Loss: 267.2741
Episode  6700 | Reward:  -9.358 | Epsilon: 0.0100 | Loss: 352.4360
Episode  6750 | Reward:  -5.934 | Epsilon: 0.0100 | Loss: 292.9062
Episode  6800 | Reward:  -1.349 | Epsilon: 0.0100 | Loss: 300.6693
Episode  6850 | Reward:  -0.635 | Epsilon: 0.0100 | Loss: 316.1520
Episode  6900 | Reward:  -1.586 | Epsilon: 0.0100 | Loss: 400.0742
Episode  6950 | Reward:  -2.370 | Epsilon: 0.0100 | Loss: 326.3937
Episode  7000 | Reward:  -2.075 | Epsilon: 0.0100 | Loss: 313.4004
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:31).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:31).dict
Episode  7050 | Reward:  -4.037 | Epsilon: 0.0100 | Loss: 312.9584
Episode  7100 | Reward:  -1.875 | Epsilon: 0.0100 | Loss: 352.0840
Episode  7150 | Reward:  -4.455 | Epsilon: 0.0100 | Loss: 217.4478
Episode  7200 | Reward:  -2.218 | Epsilon: 0.0100 | Loss: 333.0567
Episode  7250 | Reward:  -6.847 | Epsilon: 0.0100 | Loss: 273.3566
Episode  7300 | Reward:  -7.253 | Epsilon: 0.0100 | Loss: 383.0188
Episode  7350 | Reward:  -6.552 | Epsilon: 0.0100 | Loss: 382.0359
Episode  7400 | Reward:  -3.959 | Epsilon: 0.0100 | Loss: 397.6829
Episode  7450 | Reward:  -3.821 | Epsilon: 0.0100 | Loss: 387.4198
Episode  7500 | Reward:  -4.834 | Epsilon: 0.0100 | Loss: 330.4619
Episode  7550 | Reward:  -9.681 | Epsilon: 0.0100 | Loss: 337.1889
Episode  7600 | Reward:  -5.953 | Epsilon: 0.0100 | Loss: 386.6297
Episode  7650 | Reward:  -3.523 | Epsilon: 0.0100 | Loss: 339.1820
Episode  7700 | Reward:  -7.132 | Epsilon: 0.0100 | Loss: 317.1823
Episode  7750 | Reward:  -7.236 | Epsilon: 0.0100 | Loss: 350.6108
Episode  7800 | Reward:  -8.502 | Epsilon: 0.0100 | Loss: 331.9010
Episode  7850 | Reward: -13.464 | Epsilon: 0.0100 | Loss: 267.8882
Episode  7900 | Reward:  -9.096 | Epsilon: 0.0100 | Loss: 255.4489
Episode  7950 | Reward:  -6.186 | Epsilon: 0.0100 | Loss: 408.4542
Episode  8000 | Reward:  -3.635 | Epsilon: 0.0100 | Loss: 315.8721
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:35).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:35).dict
Episode  8050 | Reward:  -2.572 | Epsilon: 0.0100 | Loss: 390.0157
Episode  8100 | Reward:  -5.338 | Epsilon: 0.0100 | Loss: 292.8403
Episode  8150 | Reward:  -6.235 | Epsilon: 0.0100 | Loss: 512.5615
Episode  8200 | Reward:  -6.135 | Epsilon: 0.0100 | Loss: 358.3991
Episode  8250 | Reward:  -6.062 | Epsilon: 0.0100 | Loss: 308.9561
Episode  8300 | Reward:  -2.421 | Epsilon: 0.0100 | Loss: 361.1167
Episode  8350 | Reward:  -3.776 | Epsilon: 0.0100 | Loss: 300.5286
Episode  8400 | Reward:  -2.404 | Epsilon: 0.0100 | Loss: 357.3381
Episode  8450 | Reward:  -3.197 | Epsilon: 0.0100 | Loss: 348.4893
Episode  8500 | Reward:  -2.682 | Epsilon: 0.0100 | Loss: 304.7883
Episode  8550 | Reward:  -1.374 | Epsilon: 0.0100 | Loss: 338.8085
Episode  8600 | Reward:  -6.824 | Epsilon: 0.0100 | Loss: 370.6172
Episode  8650 | Reward:  -5.866 | Epsilon: 0.0100 | Loss: 403.2705
Episode  8700 | Reward:  -4.531 | Epsilon: 0.0100 | Loss: 434.8113
Episode  8750 | Reward:  -7.769 | Epsilon: 0.0100 | Loss: 356.5875
Episode  8800 | Reward:  -4.456 | Epsilon: 0.0100 | Loss: 207.2579
Episode  8850 | Reward:  -5.757 | Epsilon: 0.0100 | Loss: 397.5918
Episode  8900 | Reward:  -6.752 | Epsilon: 0.0100 | Loss: 390.7084
Episode  8950 | Reward:  -5.923 | Epsilon: 0.0100 | Loss: 357.1490
Episode  9000 | Reward:  -2.316 | Epsilon: 0.0100 | Loss: 374.4799
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:39).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:39).dict
Episode  9050 | Reward:  -5.295 | Epsilon: 0.0100 | Loss: 315.5856
Episode  9100 | Reward:  -9.280 | Epsilon: 0.0100 | Loss: 373.7147
Episode  9150 | Reward:  -5.485 | Epsilon: 0.0100 | Loss: 306.9443
Episode  9200 | Reward:  -8.796 | Epsilon: 0.0100 | Loss: 364.1805
Episode  9250 | Reward:  -6.103 | Epsilon: 0.0100 | Loss: 368.3338
Episode  9300 | Reward:  -5.086 | Epsilon: 0.0100 | Loss: 395.7409
Episode  9350 | Reward:  -7.212 | Epsilon: 0.0100 | Loss: 396.7062
Episode  9400 | Reward:  -6.959 | Epsilon: 0.0100 | Loss: 404.8238
Episode  9450 | Reward:  -6.390 | Epsilon: 0.0100 | Loss: 311.6382
Episode  9500 | Reward:  -1.818 | Epsilon: 0.0100 | Loss: 349.3392
Episode  9550 | Reward:  -3.111 | Epsilon: 0.0100 | Loss: 353.8939
Episode  9600 | Reward:  -7.405 | Epsilon: 0.0100 | Loss: 354.0074
Episode  9650 | Reward:  -4.311 | Epsilon: 0.0100 | Loss: 364.9801
Episode  9700 | Reward:  -3.200 | Epsilon: 0.0100 | Loss: 351.4666
Episode  9750 | Reward:  -8.581 | Epsilon: 0.0100 | Loss: 394.8224
Episode  9800 | Reward:  -3.575 | Epsilon: 0.0100 | Loss: 332.4576
Episode  9850 | Reward:  -6.533 | Epsilon: 0.0100 | Loss: 361.2695
Episode  9900 | Reward:  -6.649 | Epsilon: 0.0100 | Loss: 358.1016
Episode  9950 | Reward:  -7.731 | Epsilon: 0.0100 | Loss: 231.0884
Episode 10000 | Reward:  -6.617 | Epsilon: 0.0100 | Loss: 421.0938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:43).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:43).dict
Episode 10050 | Reward:  -9.194 | Epsilon: 0.0100 | Loss: 440.7867
Episode 10100 | Reward:  -9.882 | Epsilon: 0.0100 | Loss: 409.7072
Episode 10150 | Reward:  -6.825 | Epsilon: 0.0100 | Loss: 285.7183
Episode 10200 | Reward:  -8.281 | Epsilon: 0.0100 | Loss: 307.0660
Episode 10250 | Reward:  -5.226 | Epsilon: 0.0100 | Loss: 370.2766
Episode 10300 | Reward:  -5.447 | Epsilon: 0.0100 | Loss: 234.4301
Episode 10350 | Reward:  -8.176 | Epsilon: 0.0100 | Loss: 358.6227
Episode 10400 | Reward: -10.237 | Epsilon: 0.0100 | Loss: 286.4575
Episode 10450 | Reward:  -9.797 | Epsilon: 0.0100 | Loss: 312.0504
Episode 10500 | Reward: -10.511 | Epsilon: 0.0100 | Loss: 339.9561
Episode 10550 | Reward:  -9.944 | Epsilon: 0.0100 | Loss: 399.0337
Episode 10600 | Reward:  -2.742 | Epsilon: 0.0100 | Loss: 425.9214
Episode 10650 | Reward:  -5.279 | Epsilon: 0.0100 | Loss: 393.4025
Episode 10700 | Reward:  -6.054 | Epsilon: 0.0100 | Loss: 303.1968
Episode 10750 | Reward: -11.139 | Epsilon: 0.0100 | Loss: 323.4059
Episode 10800 | Reward: -12.360 | Epsilon: 0.0100 | Loss: 304.3079
Episode 10850 | Reward:  -9.876 | Epsilon: 0.0100 | Loss: 316.2768
Episode 10900 | Reward:  -7.931 | Epsilon: 0.0100 | Loss: 277.6008
Episode 10950 | Reward:  -6.911 | Epsilon: 0.0100 | Loss: 362.7436
Episode 11000 | Reward:  -2.963 | Epsilon: 0.0100 | Loss: 279.9217
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:47).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:47).dict
Episode 11050 | Reward:  -6.921 | Epsilon: 0.0100 | Loss: 425.6168
Episode 11100 | Reward:  -4.046 | Epsilon: 0.0100 | Loss: 354.5161
Episode 11150 | Reward:  -5.040 | Epsilon: 0.0100 | Loss: 413.7012
Episode 11200 | Reward:  -5.168 | Epsilon: 0.0100 | Loss: 394.2428
Episode 11250 | Reward:  -8.286 | Epsilon: 0.0100 | Loss: 392.6112
Episode 11300 | Reward:  -6.966 | Epsilon: 0.0100 | Loss: 402.6342
Episode 11350 | Reward:  -8.892 | Epsilon: 0.0100 | Loss: 391.2658
Episode 11400 | Reward:  -4.216 | Epsilon: 0.0100 | Loss: 373.1984
Episode 11450 | Reward:  -9.033 | Epsilon: 0.0100 | Loss: 375.8400
Episode 11500 | Reward: -10.468 | Epsilon: 0.0100 | Loss: 351.1786
Episode 11550 | Reward:  -9.875 | Epsilon: 0.0100 | Loss: 356.0105
Episode 11600 | Reward: -11.483 | Epsilon: 0.0100 | Loss: 471.6036
Episode 11650 | Reward: -11.374 | Epsilon: 0.0100 | Loss: 429.5354
Episode 11700 | Reward:  -3.503 | Epsilon: 0.0100 | Loss: 483.2887
Episode 11750 | Reward:  -8.689 | Epsilon: 0.0100 | Loss: 445.8614
Episode 11800 | Reward: -10.310 | Epsilon: 0.0100 | Loss: 271.5497
Episode 11850 | Reward:  -4.787 | Epsilon: 0.0100 | Loss: 342.9770
Episode 11900 | Reward:  -5.710 | Epsilon: 0.0100 | Loss: 344.4077
Episode 11950 | Reward:  -6.128 | Epsilon: 0.0100 | Loss: 505.1266
Episode 12000 | Reward:  -8.122 | Epsilon: 0.0100 | Loss: 448.4852
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:51).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:51).dict
Episode 12050 | Reward:  -4.750 | Epsilon: 0.0100 | Loss: 586.7662
Episode 12100 | Reward:  -4.943 | Epsilon: 0.0100 | Loss: 520.0784
Episode 12150 | Reward:  -4.302 | Epsilon: 0.0100 | Loss: 408.4809
Episode 12200 | Reward:  -5.017 | Epsilon: 0.0100 | Loss: 404.4241
Episode 12250 | Reward:  -9.224 | Epsilon: 0.0100 | Loss: 347.1594
Episode 12300 | Reward:  -8.762 | Epsilon: 0.0100 | Loss: 370.1365
Episode 12350 | Reward:  -6.725 | Epsilon: 0.0100 | Loss: 375.6532
Episode 12400 | Reward:  -8.134 | Epsilon: 0.0100 | Loss: 484.3892
Episode 12450 | Reward:  -8.395 | Epsilon: 0.0100 | Loss: 436.3488
Episode 12500 | Reward:  -5.059 | Epsilon: 0.0100 | Loss: 464.3962
Episode 12550 | Reward:  -5.933 | Epsilon: 0.0100 | Loss: 479.1015
Episode 12600 | Reward:  -7.378 | Epsilon: 0.0100 | Loss: 458.9956
Episode 12650 | Reward:  -6.359 | Epsilon: 0.0100 | Loss: 594.9951
Episode 12700 | Reward: -10.005 | Epsilon: 0.0100 | Loss: 632.0894
Episode 12750 | Reward: -12.797 | Epsilon: 0.0100 | Loss: 436.9865
Episode 12800 | Reward:  -8.096 | Epsilon: 0.0100 | Loss: 526.6245
Episode 12850 | Reward:  -3.620 | Epsilon: 0.0100 | Loss: 531.9869
Episode 12900 | Reward:  -3.013 | Epsilon: 0.0100 | Loss: 602.2859
Episode 12950 | Reward:  -8.928 | Epsilon: 0.0100 | Loss: 519.4984
Episode 13000 | Reward:  -7.947 | Epsilon: 0.0100 | Loss: 504.0713
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:55).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:55).dict
Episode 13050 | Reward: -10.293 | Epsilon: 0.0100 | Loss: 486.3450
Episode 13100 | Reward:  -5.196 | Epsilon: 0.0100 | Loss: 689.5452
Episode 13150 | Reward:  -5.573 | Epsilon: 0.0100 | Loss: 555.1044
Episode 13200 | Reward:  -2.081 | Epsilon: 0.0100 | Loss: 633.2874
Episode 13250 | Reward:  -6.975 | Epsilon: 0.0100 | Loss: 558.5043
Episode 13300 | Reward:  -9.168 | Epsilon: 0.0100 | Loss: 556.1238
Episode 13350 | Reward:  -8.415 | Epsilon: 0.0100 | Loss: 566.4802
Episode 13400 | Reward:  -4.987 | Epsilon: 0.0100 | Loss: 577.6959
Episode 13450 | Reward:  -5.964 | Epsilon: 0.0100 | Loss: 578.1879
Episode 13500 | Reward:  -5.186 | Epsilon: 0.0100 | Loss: 282.7482
Episode 13550 | Reward:  -4.291 | Epsilon: 0.0100 | Loss: 648.7049
Episode 13600 | Reward:  -3.330 | Epsilon: 0.0100 | Loss: 521.4188
Episode 13650 | Reward:  -2.298 | Epsilon: 0.0100 | Loss: 550.7197
Episode 13700 | Reward:  -3.336 | Epsilon: 0.0100 | Loss: 534.5420
Episode 13750 | Reward:  -7.642 | Epsilon: 0.0100 | Loss: 703.8216
Episode 13800 | Reward:  -8.132 | Epsilon: 0.0100 | Loss: 634.9241
Episode 13850 | Reward:  -6.685 | Epsilon: 0.0100 | Loss: 525.5409
Episode 13900 | Reward:  -2.513 | Epsilon: 0.0100 | Loss: 608.6684
Episode 13950 | Reward:  -4.842 | Epsilon: 0.0100 | Loss: 690.0179
Episode 14000 | Reward:  -4.477 | Epsilon: 0.0100 | Loss: 527.2338
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:59).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(01:59).dict
Episode 14050 | Reward:  -5.823 | Epsilon: 0.0100 | Loss: 609.9561
Episode 14100 | Reward:  -7.339 | Epsilon: 0.0100 | Loss: 599.8611
Episode 14150 | Reward: -10.404 | Epsilon: 0.0100 | Loss: 497.6542
Episode 14200 | Reward: -11.802 | Epsilon: 0.0100 | Loss: 528.6818
Episode 14250 | Reward:  -8.682 | Epsilon: 0.0100 | Loss: 568.0593
Episode 14300 | Reward:  -8.212 | Epsilon: 0.0100 | Loss: 570.9252
Episode 14350 | Reward:  -3.669 | Epsilon: 0.0100 | Loss: 520.3203
Episode 14400 | Reward:  -5.487 | Epsilon: 0.0100 | Loss: 458.8148
Episode 14450 | Reward:  -4.339 | Epsilon: 0.0100 | Loss: 565.2724
Episode 14500 | Reward:  -6.114 | Epsilon: 0.0100 | Loss: 548.6002
Episode 14550 | Reward: -11.231 | Epsilon: 0.0100 | Loss: 427.4100
Episode 14600 | Reward:  -7.247 | Epsilon: 0.0100 | Loss: 467.8864
Episode 14650 | Reward:  -4.879 | Epsilon: 0.0100 | Loss: 422.7119
Episode 14700 | Reward:  -4.561 | Epsilon: 0.0100 | Loss: 485.3140
Episode 14750 | Reward:  -1.922 | Epsilon: 0.0100 | Loss: 390.3515
Episode 14800 | Reward: -11.386 | Epsilon: 0.0100 | Loss: 507.2319
Episode 14850 | Reward:  -7.393 | Epsilon: 0.0100 | Loss: 595.6957
Episode 14900 | Reward:  -8.966 | Epsilon: 0.0100 | Loss: 540.6078
Episode 14950 | Reward:  -4.097 | Epsilon: 0.0100 | Loss: 499.8517
Episode 15000 | Reward:  -7.644 | Epsilon: 0.0100 | Loss: 523.3839
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:03).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:03).dict
Episode 15050 | Reward: -11.453 | Epsilon: 0.0100 | Loss: 426.1686
Episode 15100 | Reward:  -6.750 | Epsilon: 0.0100 | Loss: 609.7834
Episode 15150 | Reward:  -7.358 | Epsilon: 0.0100 | Loss: 357.6180
Episode 15200 | Reward:  -8.949 | Epsilon: 0.0100 | Loss: 543.1511
Episode 15250 | Reward:  -8.210 | Epsilon: 0.0100 | Loss: 641.0079
Episode 15300 | Reward:  -9.692 | Epsilon: 0.0100 | Loss: 629.6071
Episode 15350 | Reward: -10.112 | Epsilon: 0.0100 | Loss: 692.5609
Episode 15400 | Reward: -11.229 | Epsilon: 0.0100 | Loss: 570.0730
Episode 15450 | Reward: -10.000 | Epsilon: 0.0100 | Loss: 498.9732
Episode 15500 | Reward:  -6.198 | Epsilon: 0.0100 | Loss: 522.8079
Episode 15550 | Reward:  -6.805 | Epsilon: 0.0100 | Loss: 521.5084
Episode 15600 | Reward: -13.487 | Epsilon: 0.0100 | Loss: 796.9832
Episode 15650 | Reward: -15.103 | Epsilon: 0.0100 | Loss: 566.7864
Episode 15700 | Reward:  -9.310 | Epsilon: 0.0100 | Loss: 733.5717
Episode 15750 | Reward:  -7.573 | Epsilon: 0.0100 | Loss: 372.6942
Episode 15800 | Reward:  -6.330 | Epsilon: 0.0100 | Loss: 628.4660
Episode 15850 | Reward:  -6.961 | Epsilon: 0.0100 | Loss: 379.1384
Episode 15900 | Reward:  -4.967 | Epsilon: 0.0100 | Loss: 582.2410
Episode 15950 | Reward:  -7.302 | Epsilon: 0.0100 | Loss: 439.8287
Episode 16000 | Reward:  -8.586 | Epsilon: 0.0100 | Loss: 573.6304
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:07).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:07).dict
Episode 16050 | Reward:  -7.845 | Epsilon: 0.0100 | Loss: 647.4645
Episode 16100 | Reward:  -9.547 | Epsilon: 0.0100 | Loss: 636.3641
Episode 16150 | Reward:  -7.642 | Epsilon: 0.0100 | Loss: 533.0068
Episode 16200 | Reward:  -5.583 | Epsilon: 0.0100 | Loss: 573.1762
Episode 16250 | Reward:  -2.207 | Epsilon: 0.0100 | Loss: 561.1449
Episode 16300 | Reward:  -7.434 | Epsilon: 0.0100 | Loss: 521.3799
Episode 16350 | Reward:  -5.260 | Epsilon: 0.0100 | Loss: 467.7144
Episode 16400 | Reward: -11.977 | Epsilon: 0.0100 | Loss: 497.8287
Episode 16450 | Reward:  -3.938 | Epsilon: 0.0100 | Loss: 487.1426
Episode 16500 | Reward:  -3.687 | Epsilon: 0.0100 | Loss: 559.5478
Episode 16550 | Reward:  -2.964 | Epsilon: 0.0100 | Loss: 536.9007
Episode 16600 | Reward:  -4.764 | Epsilon: 0.0100 | Loss: 504.7383
Episode 16650 | Reward:  -6.976 | Epsilon: 0.0100 | Loss: 494.8686
Episode 16700 | Reward:  -4.710 | Epsilon: 0.0100 | Loss: 581.2158
Episode 16750 | Reward:  -2.920 | Epsilon: 0.0100 | Loss: 627.8469
Episode 16800 | Reward:  -3.817 | Epsilon: 0.0100 | Loss: 504.6410
Episode 16850 | Reward:  -5.010 | Epsilon: 0.0100 | Loss: 635.9022
Episode 16900 | Reward:  -7.348 | Epsilon: 0.0100 | Loss: 468.6729
Episode 16950 | Reward:  -5.692 | Epsilon: 0.0100 | Loss: 707.8201
Episode 17000 | Reward:  -9.704 | Epsilon: 0.0100 | Loss: 457.9349
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:11).dict
Episode 17050 | Reward:  -7.263 | Epsilon: 0.0100 | Loss: 731.8945
Episode 17100 | Reward:  -6.265 | Epsilon: 0.0100 | Loss: 726.0003
Episode 17150 | Reward:  -3.880 | Epsilon: 0.0100 | Loss: 677.1733
Episode 17200 | Reward:  -7.561 | Epsilon: 0.0100 | Loss: 681.5648
Episode 17250 | Reward:  -5.428 | Epsilon: 0.0100 | Loss: 622.4689
Episode 17300 | Reward:  -7.527 | Epsilon: 0.0100 | Loss: 656.5275
Episode 17350 | Reward:  -8.199 | Epsilon: 0.0100 | Loss: 574.4487
Episode 17400 | Reward:  -9.435 | Epsilon: 0.0100 | Loss: 593.4701
Episode 17450 | Reward: -10.386 | Epsilon: 0.0100 | Loss: 636.1678
Episode 17500 | Reward: -11.222 | Epsilon: 0.0100 | Loss: 453.1348
Episode 17550 | Reward: -10.813 | Epsilon: 0.0100 | Loss: 562.7097
Episode 17600 | Reward:  -9.825 | Epsilon: 0.0100 | Loss: 605.9893
Episode 17650 | Reward:  -2.426 | Epsilon: 0.0100 | Loss: 516.0023
Episode 17700 | Reward:  -7.180 | Epsilon: 0.0100 | Loss: 524.5940
Episode 17750 | Reward:  -8.853 | Epsilon: 0.0100 | Loss: 521.0340
Episode 17800 | Reward:  -5.773 | Epsilon: 0.0100 | Loss: 575.6946
Episode 17850 | Reward:  -3.859 | Epsilon: 0.0100 | Loss: 575.0355
Episode 17900 | Reward:  -5.430 | Epsilon: 0.0100 | Loss: 498.3717
Episode 17950 | Reward:  -7.052 | Epsilon: 0.0100 | Loss: 411.3793
Episode 18000 | Reward:  -6.711 | Epsilon: 0.0100 | Loss: 541.3459
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:15).dict
Episode 18050 | Reward:  -5.567 | Epsilon: 0.0100 | Loss: 680.8770
Episode 18100 | Reward:   0.228 | Epsilon: 0.0100 | Loss: 656.8277
Episode 18150 | Reward:  -3.378 | Epsilon: 0.0100 | Loss: 434.0187
Episode 18200 | Reward:  -3.733 | Epsilon: 0.0100 | Loss: 528.4227
Episode 18250 | Reward:  -4.734 | Epsilon: 0.0100 | Loss: 482.7637
Episode 18300 | Reward:  -4.956 | Epsilon: 0.0100 | Loss: 516.6314
Episode 18350 | Reward:  -4.125 | Epsilon: 0.0100 | Loss: 508.5850
Episode 18400 | Reward:  -6.633 | Epsilon: 0.0100 | Loss: 471.3449
Episode 18450 | Reward:  -8.148 | Epsilon: 0.0100 | Loss: 510.1443
Episode 18500 | Reward:  -6.713 | Epsilon: 0.0100 | Loss: 527.7671
Episode 18550 | Reward:  -6.459 | Epsilon: 0.0100 | Loss: 547.1879
Episode 18600 | Reward:  -2.574 | Epsilon: 0.0100 | Loss: 446.9273
Episode 18650 | Reward:  -4.837 | Epsilon: 0.0100 | Loss: 507.2714
Episode 18700 | Reward:  -3.785 | Epsilon: 0.0100 | Loss: 553.8550
Episode 18750 | Reward:  -7.842 | Epsilon: 0.0100 | Loss: 658.5917
Episode 18800 | Reward:  -5.943 | Epsilon: 0.0100 | Loss: 556.6152
Episode 18850 | Reward:  -8.622 | Epsilon: 0.0100 | Loss: 372.1400
Episode 18900 | Reward:  -8.704 | Epsilon: 0.0100 | Loss: 571.2936
Episode 18950 | Reward:  -7.359 | Epsilon: 0.0100 | Loss: 427.1776
Episode 19000 | Reward:  -6.767 | Epsilon: 0.0100 | Loss: 393.9003
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:19).dict
Episode 19050 | Reward:  -5.512 | Epsilon: 0.0100 | Loss: 493.1027
Episode 19100 | Reward:  -6.632 | Epsilon: 0.0100 | Loss: 531.7175
Episode 19150 | Reward:  -8.493 | Epsilon: 0.0100 | Loss: 433.2559
Episode 19200 | Reward:  -9.219 | Epsilon: 0.0100 | Loss: 477.2155
Episode 19250 | Reward:  -5.308 | Epsilon: 0.0100 | Loss: 523.4648
Episode 19300 | Reward:  -7.357 | Epsilon: 0.0100 | Loss: 533.5153
Episode 19350 | Reward:  -7.899 | Epsilon: 0.0100 | Loss: 430.9903
Episode 19400 | Reward: -10.498 | Epsilon: 0.0100 | Loss: 525.2471
Episode 19450 | Reward:  -7.339 | Epsilon: 0.0100 | Loss: 508.0274
Episode 19500 | Reward:  -2.982 | Epsilon: 0.0100 | Loss: 593.5460
Episode 19550 | Reward:  -8.890 | Epsilon: 0.0100 | Loss: 320.9682
Episode 19600 | Reward: -11.236 | Epsilon: 0.0100 | Loss: 524.4878
Episode 19650 | Reward:  -8.594 | Epsilon: 0.0100 | Loss: 492.9721
Episode 19700 | Reward:  -7.830 | Epsilon: 0.0100 | Loss: 395.6765
Episode 19750 | Reward:  -6.543 | Epsilon: 0.0100 | Loss: 379.2006
Episode 19800 | Reward:  -8.575 | Epsilon: 0.0100 | Loss: 581.8560
Episode 19850 | Reward:  -4.497 | Epsilon: 0.0100 | Loss: 464.5403
Episode 19900 | Reward:  -9.154 | Epsilon: 0.0100 | Loss: 497.3504
Episode 19950 | Reward: -11.495 | Epsilon: 0.0100 | Loss: 493.7328
Episode 20000 | Reward:  -8.844 | Epsilon: 0.0100 | Loss: 490.9796
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:23).dict
Episode 20050 | Reward:  -6.222 | Epsilon: 0.0100 | Loss: 508.7732
Episode 20100 | Reward:  -6.218 | Epsilon: 0.0100 | Loss: 478.3805
Episode 20150 | Reward:  -5.655 | Epsilon: 0.0100 | Loss: 488.2120
Episode 20200 | Reward:  -4.200 | Epsilon: 0.0100 | Loss: 462.9913
Episode 20250 | Reward:  -7.965 | Epsilon: 0.0100 | Loss: 338.5023
Episode 20300 | Reward:  -6.499 | Epsilon: 0.0100 | Loss: 555.0377
Episode 20350 | Reward:  -4.207 | Epsilon: 0.0100 | Loss: 480.4344
Episode 20400 | Reward:  -6.494 | Epsilon: 0.0100 | Loss: 580.1677
Episode 20450 | Reward:  -5.728 | Epsilon: 0.0100 | Loss: 575.4919
Episode 20500 | Reward:  -5.651 | Epsilon: 0.0100 | Loss: 554.4167
Episode 20550 | Reward:  -4.547 | Epsilon: 0.0100 | Loss: 593.1636
Episode 20600 | Reward:  -6.239 | Epsilon: 0.0100 | Loss: 614.8160
Episode 20650 | Reward:  -4.857 | Epsilon: 0.0100 | Loss: 555.3944
Episode 20700 | Reward:  -4.846 | Epsilon: 0.0100 | Loss: 719.1940
Episode 20750 | Reward:  -8.470 | Epsilon: 0.0100 | Loss: 559.8193
Episode 20800 | Reward:  -7.231 | Epsilon: 0.0100 | Loss: 511.3970
Episode 20850 | Reward:  -4.760 | Epsilon: 0.0100 | Loss: 545.7463
Episode 20900 | Reward:  -8.344 | Epsilon: 0.0100 | Loss: 645.0160
Episode 20950 | Reward:  -3.206 | Epsilon: 0.0100 | Loss: 770.4101
Episode 21000 | Reward:  -7.114 | Epsilon: 0.0100 | Loss: 662.7615
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:27).dict
Episode 21050 | Reward:  -4.423 | Epsilon: 0.0100 | Loss: 688.1955
Episode 21100 | Reward:  -4.508 | Epsilon: 0.0100 | Loss: 553.8780
Episode 21150 | Reward:  -6.646 | Epsilon: 0.0100 | Loss: 721.3814
Episode 21200 | Reward:  -8.443 | Epsilon: 0.0100 | Loss: 808.5131
Episode 21250 | Reward:  -7.117 | Epsilon: 0.0100 | Loss: 746.7266
Episode 21300 | Reward:  -3.144 | Epsilon: 0.0100 | Loss: 579.4944
Episode 21350 | Reward:  -1.555 | Epsilon: 0.0100 | Loss: 766.7521
Episode 21400 | Reward:  -3.687 | Epsilon: 0.0100 | Loss: 672.7001
Episode 21450 | Reward:  -5.131 | Epsilon: 0.0100 | Loss: 907.4791
Episode 21500 | Reward:  -1.141 | Epsilon: 0.0100 | Loss: 972.6287
Episode 21550 | Reward:  -3.866 | Epsilon: 0.0100 | Loss: 997.0081
Episode 21600 | Reward:  -3.608 | Epsilon: 0.0100 | Loss: 763.0565
Episode 21650 | Reward:  -9.006 | Epsilon: 0.0100 | Loss: 834.5942
Episode 21700 | Reward:  -1.280 | Epsilon: 0.0100 | Loss: 936.4106
Episode 21750 | Reward:  -5.601 | Epsilon: 0.0100 | Loss: 963.1552
Episode 21800 | Reward:  -2.977 | Epsilon: 0.0100 | Loss: 732.7397
Episode 21850 | Reward:  -5.785 | Epsilon: 0.0100 | Loss: 811.9314
Episode 21900 | Reward:  -1.926 | Epsilon: 0.0100 | Loss: 1069.2422
Episode 21950 | Reward:  -5.734 | Epsilon: 0.0100 | Loss: 874.6390
Episode 22000 | Reward:  -8.487 | Epsilon: 0.0100 | Loss: 904.2197
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:31).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:31).dict
Episode 22050 | Reward:  -4.085 | Epsilon: 0.0100 | Loss: 810.4187
Episode 22100 | Reward:  -7.321 | Epsilon: 0.0100 | Loss: 991.7050
Episode 22150 | Reward:  -4.352 | Epsilon: 0.0100 | Loss: 1080.5330
Episode 22200 | Reward:  -2.748 | Epsilon: 0.0100 | Loss: 721.4049
Episode 22250 | Reward:  -5.697 | Epsilon: 0.0100 | Loss: 1013.0134
Episode 22300 | Reward:  -5.442 | Epsilon: 0.0100 | Loss: 876.1938
Episode 22350 | Reward:  -4.638 | Epsilon: 0.0100 | Loss: 973.0903
Episode 22400 | Reward:  -4.407 | Epsilon: 0.0100 | Loss: 1026.2577
Episode 22450 | Reward:  -7.413 | Epsilon: 0.0100 | Loss: 1041.0940
Episode 22500 | Reward:   0.060 | Epsilon: 0.0100 | Loss: 963.5442
Episode 22550 | Reward:  -0.955 | Epsilon: 0.0100 | Loss: 902.0478
Episode 22600 | Reward:  -2.667 | Epsilon: 0.0100 | Loss: 1063.0903
Episode 22650 | Reward:  -4.666 | Epsilon: 0.0100 | Loss: 1148.3007
Episode 22700 | Reward:  -2.176 | Epsilon: 0.0100 | Loss: 664.6765
Episode 22750 | Reward:  -5.934 | Epsilon: 0.0100 | Loss: 1185.1360
Episode 22800 | Reward:  -5.501 | Epsilon: 0.0100 | Loss: 1138.6733
Episode 22850 | Reward:  -7.479 | Epsilon: 0.0100 | Loss: 1209.8817
Episode 22900 | Reward:  -5.957 | Epsilon: 0.0100 | Loss: 1223.3656
Episode 22950 | Reward:  -4.001 | Epsilon: 0.0100 | Loss: 1319.0787
Episode 23000 | Reward:  -6.821 | Epsilon: 0.0100 | Loss: 1165.5972
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:35).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:35).dict
Episode 23050 | Reward:  -2.609 | Epsilon: 0.0100 | Loss: 1395.7908
Episode 23100 | Reward:  -5.396 | Epsilon: 0.0100 | Loss: 1177.9775
Episode 23150 | Reward:  -1.406 | Epsilon: 0.0100 | Loss: 1131.1118
Episode 23200 | Reward:   0.616 | Epsilon: 0.0100 | Loss: 772.8470
Episode 23250 | Reward:  -4.895 | Epsilon: 0.0100 | Loss: 1214.8789
Episode 23300 | Reward:  -3.803 | Epsilon: 0.0100 | Loss: 1244.7719
Episode 23350 | Reward:  -0.046 | Epsilon: 0.0100 | Loss: 956.9385
Episode 23400 | Reward:   0.845 | Epsilon: 0.0100 | Loss: 649.5473
Episode 23450 | Reward:  -0.834 | Epsilon: 0.0100 | Loss: 927.1549
Episode 23500 | Reward:  -5.901 | Epsilon: 0.0100 | Loss: 809.1049
Episode 23550 | Reward:  -7.745 | Epsilon: 0.0100 | Loss: 764.5334
Episode 23600 | Reward:  -2.893 | Epsilon: 0.0100 | Loss: 1090.0332
Episode 23650 | Reward:  -5.612 | Epsilon: 0.0100 | Loss: 816.1044
Episode 23700 | Reward:  -3.599 | Epsilon: 0.0100 | Loss: 1048.6687
Episode 23750 | Reward:  -3.278 | Epsilon: 0.0100 | Loss: 931.2760
Episode 23800 | Reward:  -6.106 | Epsilon: 0.0100 | Loss: 968.0642
Episode 23850 | Reward:  -6.900 | Epsilon: 0.0100 | Loss: 881.0052
Episode 23900 | Reward:  -4.330 | Epsilon: 0.0100 | Loss: 1092.0690
Episode 23950 | Reward:  -6.710 | Epsilon: 0.0100 | Loss: 1124.3345
Episode 24000 | Reward:  -8.740 | Epsilon: 0.0100 | Loss: 896.2775
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:39).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:39).dict
Episode 24050 | Reward:  -6.078 | Epsilon: 0.0100 | Loss: 862.7134
Episode 24100 | Reward:  -8.569 | Epsilon: 0.0100 | Loss: 958.2376
Episode 24150 | Reward:  -6.846 | Epsilon: 0.0100 | Loss: 1066.8704
Episode 24200 | Reward:  -5.790 | Epsilon: 0.0100 | Loss: 860.3399
Episode 24250 | Reward:  -9.387 | Epsilon: 0.0100 | Loss: 957.2382
Episode 24300 | Reward:  -6.297 | Epsilon: 0.0100 | Loss: 925.8608
Episode 24350 | Reward:  -2.616 | Epsilon: 0.0100 | Loss: 1091.7686
Episode 24400 | Reward:  -6.628 | Epsilon: 0.0100 | Loss: 958.3806
Episode 24450 | Reward:  -4.229 | Epsilon: 0.0100 | Loss: 743.2314
Episode 24500 | Reward:   0.082 | Epsilon: 0.0100 | Loss: 906.7540
Episode 24550 | Reward:  -2.518 | Epsilon: 0.0100 | Loss: 968.7439
Episode 24600 | Reward:  -4.062 | Epsilon: 0.0100 | Loss: 951.7085
Episode 24650 | Reward:  -6.133 | Epsilon: 0.0100 | Loss: 635.4844
Episode 24700 | Reward:  -4.802 | Epsilon: 0.0100 | Loss: 920.2160
Episode 24750 | Reward:  -5.562 | Epsilon: 0.0100 | Loss: 945.6402
Episode 24800 | Reward:  -5.256 | Epsilon: 0.0100 | Loss: 910.7773
Episode 24850 | Reward:  -6.531 | Epsilon: 0.0100 | Loss: 872.9873
Episode 24900 | Reward:  -8.452 | Epsilon: 0.0100 | Loss: 657.5724
Episode 24950 | Reward:  -6.888 | Epsilon: 0.0100 | Loss: 780.3875
Episode 25000 | Reward:  -8.638 | Epsilon: 0.0100 | Loss: 1133.6544
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:43).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:43).dict
Episode 25050 | Reward: -13.440 | Epsilon: 0.0100 | Loss: 1049.9753
Episode 25100 | Reward: -11.177 | Epsilon: 0.0100 | Loss: 1075.5055
Episode 25150 | Reward: -11.477 | Epsilon: 0.0100 | Loss: 954.6226
Episode 25200 | Reward:  -9.978 | Epsilon: 0.0100 | Loss: 883.4669
Episode 25250 | Reward: -11.811 | Epsilon: 0.0100 | Loss: 1048.7711
Episode 25300 | Reward: -11.698 | Epsilon: 0.0100 | Loss: 918.2342
Episode 25350 | Reward: -11.654 | Epsilon: 0.0100 | Loss: 894.0679
Episode 25400 | Reward:  -6.911 | Epsilon: 0.0100 | Loss: 908.4521
Episode 25450 | Reward: -10.465 | Epsilon: 0.0100 | Loss: 750.7166
Episode 25500 | Reward:  -8.261 | Epsilon: 0.0100 | Loss: 1081.4508
Episode 25550 | Reward:  -8.515 | Epsilon: 0.0100 | Loss: 978.5529
Episode 25600 | Reward:  -8.344 | Epsilon: 0.0100 | Loss: 835.1334
Episode 25650 | Reward: -11.143 | Epsilon: 0.0100 | Loss: 998.4712
Episode 25700 | Reward:  -9.757 | Epsilon: 0.0100 | Loss: 745.3810
Episode 25750 | Reward:  -8.617 | Epsilon: 0.0100 | Loss: 985.6836
Episode 25800 | Reward:  -9.519 | Epsilon: 0.0100 | Loss: 806.7087
Episode 25850 | Reward: -12.619 | Epsilon: 0.0100 | Loss: 909.1178
Episode 25900 | Reward: -11.292 | Epsilon: 0.0100 | Loss: 1280.5706
Episode 25950 | Reward:  -5.465 | Epsilon: 0.0100 | Loss: 1070.0232
Episode 26000 | Reward:  -4.121 | Epsilon: 0.0100 | Loss: 1273.4036
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:47).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:47).dict
Episode 26050 | Reward:  -4.328 | Epsilon: 0.0100 | Loss: 1151.9675
Episode 26100 | Reward:  -6.849 | Epsilon: 0.0100 | Loss: 1025.7722
Episode 26150 | Reward:  -3.512 | Epsilon: 0.0100 | Loss: 1073.8960
Episode 26200 | Reward:  -4.981 | Epsilon: 0.0100 | Loss: 1191.2648
Episode 26250 | Reward:  -6.675 | Epsilon: 0.0100 | Loss: 1124.9110
Episode 26300 | Reward:  -4.095 | Epsilon: 0.0100 | Loss: 1223.9803
Episode 26350 | Reward:  -6.118 | Epsilon: 0.0100 | Loss: 885.8792
Episode 26400 | Reward:  -4.178 | Epsilon: 0.0100 | Loss: 1107.9879
Episode 26450 | Reward:  -3.703 | Epsilon: 0.0100 | Loss: 1122.2136
Episode 26500 | Reward:  -2.821 | Epsilon: 0.0100 | Loss: 1051.3513
Episode 26550 | Reward:  -7.087 | Epsilon: 0.0100 | Loss: 1017.5996
Episode 26600 | Reward: -11.022 | Epsilon: 0.0100 | Loss: 858.2413
Episode 26650 | Reward:  -7.821 | Epsilon: 0.0100 | Loss: 1126.8820
Episode 26700 | Reward:  -9.503 | Epsilon: 0.0100 | Loss: 948.5587
Episode 26750 | Reward:  -6.938 | Epsilon: 0.0100 | Loss: 1299.9871
Episode 26800 | Reward:  -5.741 | Epsilon: 0.0100 | Loss: 1028.7638
Episode 26850 | Reward:  -2.302 | Epsilon: 0.0100 | Loss: 1019.2161
Episode 26900 | Reward:  -5.903 | Epsilon: 0.0100 | Loss: 1105.9886
Episode 26950 | Reward:  -8.622 | Epsilon: 0.0100 | Loss: 1451.7021
Episode 27000 | Reward:  -3.316 | Epsilon: 0.0100 | Loss: 1229.6249
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:51).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:51).dict
Episode 27050 | Reward:  -1.735 | Epsilon: 0.0100 | Loss: 1119.1428
Episode 27100 | Reward:  -5.383 | Epsilon: 0.0100 | Loss: 1029.9398
Episode 27150 | Reward:  -0.602 | Epsilon: 0.0100 | Loss: 1053.7577
Episode 27200 | Reward:  -2.973 | Epsilon: 0.0100 | Loss: 838.3926
Episode 27250 | Reward:  -5.618 | Epsilon: 0.0100 | Loss: 1291.5529
Episode 27300 | Reward:  -6.442 | Epsilon: 0.0100 | Loss: 855.2108
Episode 27350 | Reward:  -8.597 | Epsilon: 0.0100 | Loss: 1138.7461
Episode 27400 | Reward:  -5.540 | Epsilon: 0.0100 | Loss: 1203.6521
Episode 27450 | Reward:  -5.014 | Epsilon: 0.0100 | Loss: 1221.0956
Episode 27500 | Reward:  -3.800 | Epsilon: 0.0100 | Loss: 1180.8894
Episode 27550 | Reward:  -4.823 | Epsilon: 0.0100 | Loss: 1270.5134
Episode 27600 | Reward: -13.008 | Epsilon: 0.0100 | Loss: 1191.5239
Episode 27650 | Reward:  -9.208 | Epsilon: 0.0100 | Loss: 957.3134
Episode 27700 | Reward:  -4.690 | Epsilon: 0.0100 | Loss: 1086.5803
Episode 27750 | Reward:  -6.952 | Epsilon: 0.0100 | Loss: 1195.0753
Episode 27800 | Reward:  -5.566 | Epsilon: 0.0100 | Loss: 947.6342
Episode 27850 | Reward:  -4.683 | Epsilon: 0.0100 | Loss: 1180.4039
Episode 27900 | Reward:  -7.377 | Epsilon: 0.0100 | Loss: 1104.9520
Episode 27950 | Reward:  -6.080 | Epsilon: 0.0100 | Loss: 1276.5001
Episode 28000 | Reward:  -5.672 | Epsilon: 0.0100 | Loss: 1094.6851
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:55).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:55).dict
Episode 28050 | Reward:  -6.195 | Epsilon: 0.0100 | Loss: 1197.4236
Episode 28100 | Reward:  -9.492 | Epsilon: 0.0100 | Loss: 951.5021
Episode 28150 | Reward:  -5.060 | Epsilon: 0.0100 | Loss: 1122.4686
Episode 28200 | Reward:  -5.869 | Epsilon: 0.0100 | Loss: 1089.0026
Episode 28250 | Reward:  -3.182 | Epsilon: 0.0100 | Loss: 1257.2286
Episode 28300 | Reward:  -4.064 | Epsilon: 0.0100 | Loss: 1085.1459
Episode 28350 | Reward:  -2.812 | Epsilon: 0.0100 | Loss: 1211.3356
Episode 28400 | Reward:  -6.066 | Epsilon: 0.0100 | Loss: 901.0864
Episode 28450 | Reward:  -6.228 | Epsilon: 0.0100 | Loss: 1276.3378
Episode 28500 | Reward:  -7.601 | Epsilon: 0.0100 | Loss: 1250.5701
Episode 28550 | Reward:  -6.216 | Epsilon: 0.0100 | Loss: 925.9893
Episode 28600 | Reward:  -5.939 | Epsilon: 0.0100 | Loss: 1227.2695
Episode 28650 | Reward:  -6.928 | Epsilon: 0.0100 | Loss: 815.7454
Episode 28700 | Reward:  -9.272 | Epsilon: 0.0100 | Loss: 995.1695
Episode 28750 | Reward:  -6.650 | Epsilon: 0.0100 | Loss: 1142.3635
Episode 28800 | Reward:  -9.497 | Epsilon: 0.0100 | Loss: 1193.9810
Episode 28850 | Reward:  -6.450 | Epsilon: 0.0100 | Loss: 1104.3232
Episode 28900 | Reward:  -9.708 | Epsilon: 0.0100 | Loss: 901.2446
Episode 28950 | Reward:  -6.989 | Epsilon: 0.0100 | Loss: 1152.5868
Episode 29000 | Reward:  -6.513 | Epsilon: 0.0100 | Loss: 835.2638
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:59).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(02:59).dict
Episode 29050 | Reward: -13.880 | Epsilon: 0.0100 | Loss: 1148.7209
Episode 29100 | Reward:  -6.520 | Epsilon: 0.0100 | Loss: 792.1266
Episode 29150 | Reward:  -5.452 | Epsilon: 0.0100 | Loss: 888.4022
Episode 29200 | Reward:  -4.439 | Epsilon: 0.0100 | Loss: 967.9067
Episode 29250 | Reward:  -6.599 | Epsilon: 0.0100 | Loss: 981.7548
Episode 29300 | Reward:  -3.381 | Epsilon: 0.0100 | Loss: 1150.5337
Episode 29350 | Reward:  -4.959 | Epsilon: 0.0100 | Loss: 925.6444
Episode 29400 | Reward:  -7.187 | Epsilon: 0.0100 | Loss: 1109.5828
Episode 29450 | Reward:  -6.153 | Epsilon: 0.0100 | Loss: 885.4008
Episode 29500 | Reward:  -8.292 | Epsilon: 0.0100 | Loss: 881.7413
Episode 29550 | Reward:  -9.719 | Epsilon: 0.0100 | Loss: 1003.2634
Episode 29600 | Reward:  -7.492 | Epsilon: 0.0100 | Loss: 957.8946
Episode 29650 | Reward:  -7.707 | Epsilon: 0.0100 | Loss: 1138.5859
Episode 29700 | Reward:  -6.770 | Epsilon: 0.0100 | Loss: 1151.0275
Episode 29750 | Reward:  -7.351 | Epsilon: 0.0100 | Loss: 1186.8215
Episode 29800 | Reward:  -8.062 | Epsilon: 0.0100 | Loss: 892.6574
Episode 29850 | Reward:  -8.646 | Epsilon: 0.0100 | Loss: 794.0525
Episode 29900 | Reward:  -5.674 | Epsilon: 0.0100 | Loss: 1060.6974
Episode 29950 | Reward:  -6.512 | Epsilon: 0.0100 | Loss: 1196.2568
Episode 30000 | Reward:  -3.026 | Epsilon: 0.0100 | Loss: 1049.6072
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:03).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:03).dict
Episode 30050 | Reward:  -5.227 | Epsilon: 0.0100 | Loss: 1137.5127
Episode 30100 | Reward:  -6.171 | Epsilon: 0.0100 | Loss: 1109.3489
Episode 30150 | Reward:  -6.499 | Epsilon: 0.0100 | Loss: 902.7052
Episode 30200 | Reward:  -6.157 | Epsilon: 0.0100 | Loss: 1265.0880
Episode 30250 | Reward:  -3.765 | Epsilon: 0.0100 | Loss: 1330.5979
Episode 30300 | Reward:  -5.157 | Epsilon: 0.0100 | Loss: 1573.5898
Episode 30350 | Reward:  -8.763 | Epsilon: 0.0100 | Loss: 868.1934
Episode 30400 | Reward:  -9.361 | Epsilon: 0.0100 | Loss: 1447.9669
Episode 30450 | Reward:  -8.984 | Epsilon: 0.0100 | Loss: 1530.6285
Episode 30500 | Reward:  -8.292 | Epsilon: 0.0100 | Loss: 1362.5587
Episode 30550 | Reward:  -9.981 | Epsilon: 0.0100 | Loss: 1201.0193
Episode 30600 | Reward:  -7.964 | Epsilon: 0.0100 | Loss: 1230.5380
Episode 30650 | Reward:  -7.431 | Epsilon: 0.0100 | Loss: 1019.9131
Episode 30700 | Reward:  -7.495 | Epsilon: 0.0100 | Loss: 1319.1536
Episode 30750 | Reward:  -6.624 | Epsilon: 0.0100 | Loss: 1647.1924
Episode 30800 | Reward:  -5.078 | Epsilon: 0.0100 | Loss: 1414.6964
Episode 30850 | Reward:  -8.119 | Epsilon: 0.0100 | Loss: 1477.8661
Episode 30900 | Reward:  -7.774 | Epsilon: 0.0100 | Loss: 1059.5977
Episode 30950 | Reward:  -3.769 | Epsilon: 0.0100 | Loss: 1707.5632
Episode 31000 | Reward:  -5.121 | Epsilon: 0.0100 | Loss: 1215.6276
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:07).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:07).dict
Episode 31050 | Reward:  -6.974 | Epsilon: 0.0100 | Loss: 1255.8600
Episode 31100 | Reward:  -7.089 | Epsilon: 0.0100 | Loss: 1147.1716
Episode 31150 | Reward:  -9.870 | Epsilon: 0.0100 | Loss: 1062.9949
Episode 31200 | Reward:  -9.783 | Epsilon: 0.0100 | Loss: 1215.2916
Episode 31250 | Reward:  -9.612 | Epsilon: 0.0100 | Loss: 1499.0232
Episode 31300 | Reward:  -7.262 | Epsilon: 0.0100 | Loss: 1500.1201
Episode 31350 | Reward:  -4.412 | Epsilon: 0.0100 | Loss: 1255.3511
Episode 31400 | Reward:  -7.375 | Epsilon: 0.0100 | Loss: 1169.1760
Episode 31450 | Reward:  -4.953 | Epsilon: 0.0100 | Loss: 1519.4917
Episode 31500 | Reward:  -6.585 | Epsilon: 0.0100 | Loss: 1976.8743
Episode 31550 | Reward:  -7.158 | Epsilon: 0.0100 | Loss: 1549.1267
Episode 31600 | Reward:  -4.290 | Epsilon: 0.0100 | Loss: 1302.9540
Episode 31650 | Reward:  -6.419 | Epsilon: 0.0100 | Loss: 1520.5503
Episode 31700 | Reward:  -6.612 | Epsilon: 0.0100 | Loss: 1680.0428
Episode 31750 | Reward:  -3.048 | Epsilon: 0.0100 | Loss: 1215.3721
Episode 31800 | Reward:  -6.405 | Epsilon: 0.0100 | Loss: 1478.4097
Episode 31850 | Reward:  -5.602 | Epsilon: 0.0100 | Loss: 1463.0703
Episode 31900 | Reward:  -9.211 | Epsilon: 0.0100 | Loss: 1314.6035
Episode 31950 | Reward:  -4.788 | Epsilon: 0.0100 | Loss: 1824.0708
Episode 32000 | Reward:  -4.357 | Epsilon: 0.0100 | Loss: 883.0880
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:11).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:11).dict
Episode 32050 | Reward:  -4.799 | Epsilon: 0.0100 | Loss: 1532.0288
Episode 32100 | Reward:  -5.704 | Epsilon: 0.0100 | Loss: 1390.2494
Episode 32150 | Reward:  -6.481 | Epsilon: 0.0100 | Loss: 1682.3308
Episode 32200 | Reward:  -5.357 | Epsilon: 0.0100 | Loss: 1325.9747
Episode 32250 | Reward:  -3.335 | Epsilon: 0.0100 | Loss: 1533.9604
Episode 32300 | Reward:  -5.227 | Epsilon: 0.0100 | Loss: 1580.4923
Episode 32350 | Reward:  -6.777 | Epsilon: 0.0100 | Loss: 1567.9414
Episode 32400 | Reward:  -6.586 | Epsilon: 0.0100 | Loss: 2158.2817
Episode 32450 | Reward:  -6.413 | Epsilon: 0.0100 | Loss: 2095.2334
Episode 32500 | Reward:  -3.312 | Epsilon: 0.0100 | Loss: 2235.6414
Episode 32550 | Reward:  -5.270 | Epsilon: 0.0100 | Loss: 2156.6306
Episode 32600 | Reward:  -5.651 | Epsilon: 0.0100 | Loss: 2020.0879
Episode 32650 | Reward:  -6.130 | Epsilon: 0.0100 | Loss: 1840.8168
Episode 32700 | Reward:  -3.162 | Epsilon: 0.0100 | Loss: 1695.4421
Episode 32750 | Reward:  -5.957 | Epsilon: 0.0100 | Loss: 1463.8779
Episode 32800 | Reward:  -6.199 | Epsilon: 0.0100 | Loss: 2534.6160
Episode 32850 | Reward:  -6.720 | Epsilon: 0.0100 | Loss: 1854.0479
Episode 32900 | Reward:  -9.298 | Epsilon: 0.0100 | Loss: 1890.8634
Episode 32950 | Reward:  -4.052 | Epsilon: 0.0100 | Loss: 1625.9816
Episode 33000 | Reward:  -2.429 | Epsilon: 0.0100 | Loss: 2070.5398
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:15).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:15).dict
Episode 33050 | Reward:  -3.657 | Epsilon: 0.0100 | Loss: 1855.7773
Episode 33100 | Reward:  -5.320 | Epsilon: 0.0100 | Loss: 1581.3059
Episode 33150 | Reward:  -6.369 | Epsilon: 0.0100 | Loss: 2214.1926
Episode 33200 | Reward:  -5.548 | Epsilon: 0.0100 | Loss: 2142.5701
Episode 33250 | Reward:   0.430 | Epsilon: 0.0100 | Loss: 1933.1803
Episode 33300 | Reward:  -4.729 | Epsilon: 0.0100 | Loss: 2071.8013
Episode 33350 | Reward:  -6.473 | Epsilon: 0.0100 | Loss: 2285.4326
Episode 33400 | Reward:  -7.259 | Epsilon: 0.0100 | Loss: 1648.8756
Episode 33450 | Reward:  -6.886 | Epsilon: 0.0100 | Loss: 2148.2617
Episode 33500 | Reward:  -6.952 | Epsilon: 0.0100 | Loss: 2488.4832
Episode 33550 | Reward:  -6.938 | Epsilon: 0.0100 | Loss: 2094.0066
Episode 33600 | Reward:  -4.427 | Epsilon: 0.0100 | Loss: 2264.7307
Episode 33650 | Reward:  -9.045 | Epsilon: 0.0100 | Loss: 2989.5322
Episode 33700 | Reward:  -5.977 | Epsilon: 0.0100 | Loss: 2645.5481
Episode 33750 | Reward:  -7.721 | Epsilon: 0.0100 | Loss: 2767.8848
Episode 33800 | Reward:  -7.488 | Epsilon: 0.0100 | Loss: 2301.1973
Episode 33850 | Reward:  -5.976 | Epsilon: 0.0100 | Loss: 1918.1543
Episode 33900 | Reward:  -7.694 | Epsilon: 0.0100 | Loss: 2806.8044
Episode 33950 | Reward:  -7.785 | Epsilon: 0.0100 | Loss: 2555.9199
Episode 34000 | Reward:  -3.837 | Epsilon: 0.0100 | Loss: 2637.6099
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:19).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:19).dict
Episode 34050 | Reward:  -4.428 | Epsilon: 0.0100 | Loss: 2862.5735
Episode 34100 | Reward:  -6.186 | Epsilon: 0.0100 | Loss: 3404.7661
Episode 34150 | Reward:  -8.520 | Epsilon: 0.0100 | Loss: 2668.0781
Episode 34200 | Reward:  -5.415 | Epsilon: 0.0100 | Loss: 2644.1782
Episode 34250 | Reward:  -4.567 | Epsilon: 0.0100 | Loss: 3417.2776
Episode 34300 | Reward:  -7.694 | Epsilon: 0.0100 | Loss: 2649.0146
Episode 34350 | Reward:  -5.545 | Epsilon: 0.0100 | Loss: 3236.7432
Episode 34400 | Reward:  -6.245 | Epsilon: 0.0100 | Loss: 3394.6091
Episode 34450 | Reward:  -8.005 | Epsilon: 0.0100 | Loss: 2628.3928
Episode 34500 | Reward:  -5.748 | Epsilon: 0.0100 | Loss: 2629.7778
Episode 34550 | Reward:  -5.505 | Epsilon: 0.0100 | Loss: 3005.6699
Episode 34600 | Reward:  -2.647 | Epsilon: 0.0100 | Loss: 3077.4407
Episode 34650 | Reward:  -6.412 | Epsilon: 0.0100 | Loss: 3338.9629
Episode 34700 | Reward:  -5.853 | Epsilon: 0.0100 | Loss: 2930.3513
Episode 34750 | Reward:  -7.799 | Epsilon: 0.0100 | Loss: 3306.0298
Episode 34800 | Reward:  -5.811 | Epsilon: 0.0100 | Loss: 3754.6548
Episode 34850 | Reward:  -6.489 | Epsilon: 0.0100 | Loss: 2879.6125
Episode 34900 | Reward:  -3.519 | Epsilon: 0.0100 | Loss: 3179.4136
Episode 34950 | Reward:  -5.725 | Epsilon: 0.0100 | Loss: 3894.1106
Episode 35000 | Reward:  -5.312 | Epsilon: 0.0100 | Loss: 3394.5398
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:23).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:23).dict
Episode 35050 | Reward:  -6.289 | Epsilon: 0.0100 | Loss: 4226.5542
Episode 35100 | Reward:  -2.622 | Epsilon: 0.0100 | Loss: 3946.9001
Episode 35150 | Reward:  -1.814 | Epsilon: 0.0100 | Loss: 3609.4768
Episode 35200 | Reward:  -4.422 | Epsilon: 0.0100 | Loss: 3224.4019
Episode 35250 | Reward:  -4.939 | Epsilon: 0.0100 | Loss: 4026.5032
Episode 35300 | Reward:  -4.580 | Epsilon: 0.0100 | Loss: 3803.9036
Episode 35350 | Reward:  -2.338 | Epsilon: 0.0100 | Loss: 2852.6001
Episode 35400 | Reward:  -4.780 | Epsilon: 0.0100 | Loss: 4232.7251
Episode 35450 | Reward:  -4.486 | Epsilon: 0.0100 | Loss: 3974.7915
Episode 35500 | Reward:  -3.127 | Epsilon: 0.0100 | Loss: 3404.4316
Episode 35550 | Reward:  -3.263 | Epsilon: 0.0100 | Loss: 3576.2710
Episode 35600 | Reward:  -5.497 | Epsilon: 0.0100 | Loss: 4434.9614
Episode 35650 | Reward:  -6.163 | Epsilon: 0.0100 | Loss: 4364.1270
Episode 35700 | Reward:  -5.685 | Epsilon: 0.0100 | Loss: 4470.0708
Episode 35750 | Reward:  -5.920 | Epsilon: 0.0100 | Loss: 4581.7349
Episode 35800 | Reward:  -4.540 | Epsilon: 0.0100 | Loss: 5216.8677
Episode 35850 | Reward:  -4.889 | Epsilon: 0.0100 | Loss: 4656.9575
Episode 35900 | Reward:  -5.349 | Epsilon: 0.0100 | Loss: 3791.1487
Episode 35950 | Reward:  -4.139 | Epsilon: 0.0100 | Loss: 3705.4331
Episode 36000 | Reward:  -7.292 | Epsilon: 0.0100 | Loss: 4738.3569
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:27).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:27).dict
Episode 36050 | Reward:  -1.198 | Epsilon: 0.0100 | Loss: 4928.9775
Episode 36100 | Reward:  -5.073 | Epsilon: 0.0100 | Loss: 4151.9302
Episode 36150 | Reward:  -7.261 | Epsilon: 0.0100 | Loss: 4844.2930
Episode 36200 | Reward:  -9.687 | Epsilon: 0.0100 | Loss: 3976.4453
Episode 36250 | Reward:  -6.142 | Epsilon: 0.0100 | Loss: 4819.1382
Episode 36300 | Reward:  -4.144 | Epsilon: 0.0100 | Loss: 5037.4312
Episode 36350 | Reward:  -4.524 | Epsilon: 0.0100 | Loss: 5219.8062
Episode 36400 | Reward:  -5.200 | Epsilon: 0.0100 | Loss: 5293.0435
Episode 36450 | Reward:  -6.921 | Epsilon: 0.0100 | Loss: 4111.7324
Episode 36500 | Reward:  -7.311 | Epsilon: 0.0100 | Loss: 3807.1470
Episode 36550 | Reward:  -6.272 | Epsilon: 0.0100 | Loss: 3753.8828
Episode 36600 | Reward:  -8.626 | Epsilon: 0.0100 | Loss: 5505.6230
Episode 36650 | Reward: -11.038 | Epsilon: 0.0100 | Loss: 3903.8044
Episode 36700 | Reward:  -9.577 | Epsilon: 0.0100 | Loss: 4713.3101
Episode 36750 | Reward:  -9.700 | Epsilon: 0.0100 | Loss: 4136.0347
Episode 36800 | Reward:  -8.129 | Epsilon: 0.0100 | Loss: 4463.0464
Episode 36850 | Reward:  -6.332 | Epsilon: 0.0100 | Loss: 5168.9111
Episode 36900 | Reward:  -5.165 | Epsilon: 0.0100 | Loss: 5698.0483
Episode 36950 | Reward:  -2.818 | Epsilon: 0.0100 | Loss: 4444.4141
Episode 37000 | Reward:  -4.910 | Epsilon: 0.0100 | Loss: 5187.4209
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:32).dict
Episode 37050 | Reward:  -4.962 | Epsilon: 0.0100 | Loss: 4910.3896
Episode 37100 | Reward:  -6.755 | Epsilon: 0.0100 | Loss: 5252.2808
Episode 37150 | Reward:  -5.763 | Epsilon: 0.0100 | Loss: 4712.2456
Episode 37200 | Reward:  -3.614 | Epsilon: 0.0100 | Loss: 5422.3706
Episode 37250 | Reward:  -7.391 | Epsilon: 0.0100 | Loss: 5012.5552
Episode 37300 | Reward:  -8.175 | Epsilon: 0.0100 | Loss: 4242.0669
Episode 37350 | Reward: -12.746 | Epsilon: 0.0100 | Loss: 4306.3716
Episode 37400 | Reward:  -9.353 | Epsilon: 0.0100 | Loss: 5313.5854
Episode 37450 | Reward:  -5.261 | Epsilon: 0.0100 | Loss: 6072.4297
Episode 37500 | Reward:  -2.988 | Epsilon: 0.0100 | Loss: 5787.5986
Episode 37550 | Reward:  -4.558 | Epsilon: 0.0100 | Loss: 5862.0010
Episode 37600 | Reward:  -8.781 | Epsilon: 0.0100 | Loss: 4524.1768
Episode 37650 | Reward:  -6.913 | Epsilon: 0.0100 | Loss: 5741.9541
Episode 37700 | Reward:  -5.266 | Epsilon: 0.0100 | Loss: 6345.5366
Episode 37750 | Reward:  -4.296 | Epsilon: 0.0100 | Loss: 6898.4712
Episode 37800 | Reward:  -1.191 | Epsilon: 0.0100 | Loss: 6108.6230
Episode 37850 | Reward:  -3.074 | Epsilon: 0.0100 | Loss: 5792.1826
Episode 37900 | Reward:  -3.971 | Epsilon: 0.0100 | Loss: 8816.5889
Episode 37950 | Reward:  -3.161 | Epsilon: 0.0100 | Loss: 6600.4458
Episode 38000 | Reward:  -8.767 | Epsilon: 0.0100 | Loss: 6213.2212
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:36).dict
Episode 38050 | Reward: -11.216 | Epsilon: 0.0100 | Loss: 5480.6724
Episode 38100 | Reward: -11.286 | Epsilon: 0.0100 | Loss: 7476.2227
Episode 38150 | Reward:  -9.900 | Epsilon: 0.0100 | Loss: 7300.3281
Episode 38200 | Reward:  -8.797 | Epsilon: 0.0100 | Loss: 7409.0996
Episode 38250 | Reward: -10.053 | Epsilon: 0.0100 | Loss: 6193.0522
Episode 38300 | Reward:  -7.980 | Epsilon: 0.0100 | Loss: 5268.0088
Episode 38350 | Reward:  -6.080 | Epsilon: 0.0100 | Loss: 7268.5161
Episode 38400 | Reward:  -5.749 | Epsilon: 0.0100 | Loss: 8095.7480
Episode 38450 | Reward:  -6.460 | Epsilon: 0.0100 | Loss: 9116.1660
Episode 38500 | Reward:  -7.477 | Epsilon: 0.0100 | Loss: 9598.4795
Episode 38550 | Reward:  -5.047 | Epsilon: 0.0100 | Loss: 8569.4160
Episode 38600 | Reward:  -7.999 | Epsilon: 0.0100 | Loss: 9749.5469
Episode 38650 | Reward:  -7.374 | Epsilon: 0.0100 | Loss: 9439.0078
Episode 38700 | Reward: -10.643 | Epsilon: 0.0100 | Loss: 9935.3379
Episode 38750 | Reward:  -7.439 | Epsilon: 0.0100 | Loss: 9592.2109
Episode 38800 | Reward:  -6.589 | Epsilon: 0.0100 | Loss: 11208.2793
Episode 38850 | Reward:  -8.952 | Epsilon: 0.0100 | Loss: 8293.6982
Episode 38900 | Reward:  -4.266 | Epsilon: 0.0100 | Loss: 10839.6396
Episode 38950 | Reward:  -6.117 | Epsilon: 0.0100 | Loss: 10737.9824
Episode 39000 | Reward:  -7.781 | Epsilon: 0.0100 | Loss: 13280.2139
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:40).dict
Episode 39050 | Reward:  -3.847 | Epsilon: 0.0100 | Loss: 11238.6533
Episode 39100 | Reward:  -7.824 | Epsilon: 0.0100 | Loss: 12440.7197
Episode 39150 | Reward:  -6.968 | Epsilon: 0.0100 | Loss: 12846.8809
Episode 39200 | Reward:  -4.346 | Epsilon: 0.0100 | Loss: 12414.8359
Episode 39250 | Reward:  -7.038 | Epsilon: 0.0100 | Loss: 11014.6660
Episode 39300 | Reward: -11.467 | Epsilon: 0.0100 | Loss: 9837.7754
Episode 39350 | Reward:  -9.541 | Epsilon: 0.0100 | Loss: 9771.1123
Episode 39400 | Reward:  -8.263 | Epsilon: 0.0100 | Loss: 11755.3975
Episode 39450 | Reward: -11.129 | Epsilon: 0.0100 | Loss: 15049.7207
Episode 39500 | Reward: -11.990 | Epsilon: 0.0100 | Loss: 11283.4404
Episode 39550 | Reward: -12.646 | Epsilon: 0.0100 | Loss: 15181.5400
Episode 39600 | Reward: -11.045 | Epsilon: 0.0100 | Loss: 11600.2607
Episode 39650 | Reward: -12.281 | Epsilon: 0.0100 | Loss: 16558.8105
Episode 39700 | Reward: -14.907 | Epsilon: 0.0100 | Loss: 18693.6328
Episode 39750 | Reward: -11.347 | Epsilon: 0.0100 | Loss: 19493.7422
Episode 39800 | Reward: -10.146 | Epsilon: 0.0100 | Loss: 17292.5098
Episode 39850 | Reward: -10.916 | Epsilon: 0.0100 | Loss: 20257.0508
Episode 39900 | Reward: -12.274 | Epsilon: 0.0100 | Loss: 18942.1719
Episode 39950 | Reward: -15.258 | Epsilon: 0.0100 | Loss: 16245.4395
Episode 40000 | Reward: -13.483 | Epsilon: 0.0100 | Loss: 24205.5195
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:44).dict
Episode 40050 | Reward: -14.127 | Epsilon: 0.0100 | Loss: 24120.5078
Episode 40100 | Reward:  -9.929 | Epsilon: 0.0100 | Loss: 15558.3096
Episode 40150 | Reward: -10.762 | Epsilon: 0.0100 | Loss: 25380.0781
Episode 40200 | Reward: -13.438 | Epsilon: 0.0100 | Loss: 21046.0918
Episode 40250 | Reward: -15.840 | Epsilon: 0.0100 | Loss: 24624.5410
Episode 40300 | Reward: -14.511 | Epsilon: 0.0100 | Loss: 32327.9727
Episode 40350 | Reward: -13.337 | Epsilon: 0.0100 | Loss: 22682.9531
Episode 40400 | Reward: -12.793 | Epsilon: 0.0100 | Loss: 26598.7988
Episode 40450 | Reward: -13.623 | Epsilon: 0.0100 | Loss: 30995.3750
Episode 40500 | Reward: -11.506 | Epsilon: 0.0100 | Loss: 30246.4219
Episode 40550 | Reward:  -9.798 | Epsilon: 0.0100 | Loss: 23840.7949
Episode 40600 | Reward: -13.053 | Epsilon: 0.0100 | Loss: 30179.7285
Episode 40650 | Reward: -10.767 | Epsilon: 0.0100 | Loss: 30811.2402
Episode 40700 | Reward: -13.900 | Epsilon: 0.0100 | Loss: 31205.8672
Episode 40750 | Reward: -13.194 | Epsilon: 0.0100 | Loss: 34830.4648
Episode 40800 | Reward: -15.465 | Epsilon: 0.0100 | Loss: 32120.2578
Episode 40850 | Reward: -10.270 | Epsilon: 0.0100 | Loss: 29083.7734
Episode 40900 | Reward: -11.802 | Epsilon: 0.0100 | Loss: 30309.8359
Episode 40950 | Reward: -15.277 | Epsilon: 0.0100 | Loss: 35579.2070
Episode 41000 | Reward: -11.173 | Epsilon: 0.0100 | Loss: 35242.9961
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:48).dict
Episode 41050 | Reward: -11.825 | Epsilon: 0.0100 | Loss: 40610.4492
Episode 41100 | Reward: -11.088 | Epsilon: 0.0100 | Loss: 40677.1328
Episode 41150 | Reward: -10.022 | Epsilon: 0.0100 | Loss: 38737.1680
Episode 41200 | Reward: -10.278 | Epsilon: 0.0100 | Loss: 47110.0000
Episode 41250 | Reward:  -8.304 | Epsilon: 0.0100 | Loss: 30085.4180
Episode 41300 | Reward: -10.610 | Epsilon: 0.0100 | Loss: 43543.2773
Episode 41350 | Reward:  -8.064 | Epsilon: 0.0100 | Loss: 38220.8047
Episode 41400 | Reward: -10.306 | Epsilon: 0.0100 | Loss: 35747.1875
Episode 41450 | Reward: -10.391 | Epsilon: 0.0100 | Loss: 44851.9648
Episode 41500 | Reward:  -9.193 | Epsilon: 0.0100 | Loss: 57954.8203
Episode 41550 | Reward:  -8.013 | Epsilon: 0.0100 | Loss: 45683.9922
Episode 41600 | Reward:  -6.066 | Epsilon: 0.0100 | Loss: 49007.1250
Episode 41650 | Reward: -10.335 | Epsilon: 0.0100 | Loss: 42657.1016
Episode 41700 | Reward:  -7.457 | Epsilon: 0.0100 | Loss: 35995.5000
Episode 41750 | Reward:  -9.467 | Epsilon: 0.0100 | Loss: 45938.8867
Episode 41800 | Reward:  -8.778 | Epsilon: 0.0100 | Loss: 51637.4844
Episode 41850 | Reward: -10.531 | Epsilon: 0.0100 | Loss: 50845.7969
Episode 41900 | Reward: -11.272 | Epsilon: 0.0100 | Loss: 63614.2227
Episode 41950 | Reward:  -6.151 | Epsilon: 0.0100 | Loss: 44922.7031
Episode 42000 | Reward:  -8.244 | Epsilon: 0.0100 | Loss: 54618.2422
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:52).dict
Episode 42050 | Reward:  -8.176 | Epsilon: 0.0100 | Loss: 53037.0430
Episode 42100 | Reward:  -7.418 | Epsilon: 0.0100 | Loss: 64218.1094
Episode 42150 | Reward:  -8.480 | Epsilon: 0.0100 | Loss: 52674.6953
Episode 42200 | Reward: -13.280 | Epsilon: 0.0100 | Loss: 49123.3750
Episode 42250 | Reward:  -6.683 | Epsilon: 0.0100 | Loss: 60284.7734
Episode 42300 | Reward:  -6.737 | Epsilon: 0.0100 | Loss: 62450.8281
Episode 42350 | Reward:  -4.121 | Epsilon: 0.0100 | Loss: 49531.7656
Episode 42400 | Reward:  -5.368 | Epsilon: 0.0100 | Loss: 66982.4844
Episode 42450 | Reward: -10.027 | Epsilon: 0.0100 | Loss: 67820.2109
Episode 42500 | Reward:  -8.985 | Epsilon: 0.0100 | Loss: 56570.3594
Episode 42550 | Reward: -10.334 | Epsilon: 0.0100 | Loss: 56630.4922
Episode 42600 | Reward:  -9.630 | Epsilon: 0.0100 | Loss: 72539.6719
Episode 42650 | Reward:  -4.004 | Epsilon: 0.0100 | Loss: 66514.6797
Episode 42700 | Reward:  -5.117 | Epsilon: 0.0100 | Loss: 61014.9922
Episode 42750 | Reward:  -5.767 | Epsilon: 0.0100 | Loss: 74055.8203
Episode 42800 | Reward:  -8.857 | Epsilon: 0.0100 | Loss: 71528.8828
Episode 42850 | Reward:  -9.671 | Epsilon: 0.0100 | Loss: 59550.3242
Episode 42900 | Reward:  -6.375 | Epsilon: 0.0100 | Loss: 57841.8945
Episode 42950 | Reward:  -6.564 | Epsilon: 0.0100 | Loss: 69269.3594
Episode 43000 | Reward:  -2.603 | Epsilon: 0.0100 | Loss: 85912.6172
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(03:56).dict
Episode 43050 | Reward:  -7.498 | Epsilon: 0.0100 | Loss: 73366.0469
Episode 43100 | Reward:  -2.036 | Epsilon: 0.0100 | Loss: 85229.6719
Episode 43150 | Reward:  -3.990 | Epsilon: 0.0100 | Loss: 80896.2578
Episode 43200 | Reward: -11.014 | Epsilon: 0.0100 | Loss: 68883.3984
Episode 43250 | Reward:  -8.838 | Epsilon: 0.0100 | Loss: 59699.8125
Episode 43300 | Reward:  -9.411 | Epsilon: 0.0100 | Loss: 68582.7891
Episode 43350 | Reward: -11.223 | Epsilon: 0.0100 | Loss: 74251.2578
Episode 43400 | Reward:  -9.702 | Epsilon: 0.0100 | Loss: 90038.8438
Episode 43450 | Reward:  -6.619 | Epsilon: 0.0100 | Loss: 84801.6016
Episode 43500 | Reward:  -6.829 | Epsilon: 0.0100 | Loss: 72038.4688
Episode 43550 | Reward:  -8.051 | Epsilon: 0.0100 | Loss: 76921.5312
Episode 43600 | Reward:  -7.639 | Epsilon: 0.0100 | Loss: 79391.4844
Episode 43650 | Reward: -10.233 | Epsilon: 0.0100 | Loss: 90764.2578
Episode 43700 | Reward: -12.210 | Epsilon: 0.0100 | Loss: 59564.9180
Episode 43750 | Reward: -11.187 | Epsilon: 0.0100 | Loss: 77021.1328
Episode 43800 | Reward:  -9.026 | Epsilon: 0.0100 | Loss: 80202.9453
Episode 43850 | Reward:  -8.077 | Epsilon: 0.0100 | Loss: 78293.2734
Episode 43900 | Reward:  -5.905 | Epsilon: 0.0100 | Loss: 105424.5938
Episode 43950 | Reward:  -4.926 | Epsilon: 0.0100 | Loss: 82251.8516
Episode 44000 | Reward:  -7.397 | Epsilon: 0.0100 | Loss: 91084.4062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:00).dict
Episode 44050 | Reward: -12.690 | Epsilon: 0.0100 | Loss: 74913.5312
Episode 44100 | Reward: -13.202 | Epsilon: 0.0100 | Loss: 91892.1016
Episode 44150 | Reward:  -9.843 | Epsilon: 0.0100 | Loss: 88971.6797
Episode 44200 | Reward:  -5.128 | Epsilon: 0.0100 | Loss: 92554.9609
Episode 44250 | Reward:  -4.509 | Epsilon: 0.0100 | Loss: 97177.0938
Episode 44300 | Reward:  -9.172 | Epsilon: 0.0100 | Loss: 127236.8125
Episode 44350 | Reward:  -9.791 | Epsilon: 0.0100 | Loss: 109630.7656
Episode 44400 | Reward: -10.643 | Epsilon: 0.0100 | Loss: 93485.5078
Episode 44450 | Reward:  -9.362 | Epsilon: 0.0100 | Loss: 113868.8828
Episode 44500 | Reward:  -9.588 | Epsilon: 0.0100 | Loss: 114808.2656
Episode 44550 | Reward: -12.108 | Epsilon: 0.0100 | Loss: 105608.8281
Episode 44600 | Reward: -12.170 | Epsilon: 0.0100 | Loss: 97346.3125
Episode 44650 | Reward:  -9.682 | Epsilon: 0.0100 | Loss: 125019.1250
Episode 44700 | Reward: -10.545 | Epsilon: 0.0100 | Loss: 102400.1094
Episode 44750 | Reward: -10.364 | Epsilon: 0.0100 | Loss: 126824.9531
Episode 44800 | Reward:  -9.380 | Epsilon: 0.0100 | Loss: 115664.9375
Episode 44850 | Reward:  -9.138 | Epsilon: 0.0100 | Loss: 94136.6250
Episode 44900 | Reward:  -7.620 | Epsilon: 0.0100 | Loss: 128798.5312
Episode 44950 | Reward: -11.827 | Epsilon: 0.0100 | Loss: 123622.9531
Episode 45000 | Reward: -11.645 | Epsilon: 0.0100 | Loss: 122679.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:04).dict
Episode 45050 | Reward:  -9.400 | Epsilon: 0.0100 | Loss: 94264.7812
Episode 45100 | Reward:  -7.267 | Epsilon: 0.0100 | Loss: 126956.2656
Episode 45150 | Reward:  -6.645 | Epsilon: 0.0100 | Loss: 116308.2891
Episode 45200 | Reward:  -8.108 | Epsilon: 0.0100 | Loss: 110204.9062
Episode 45250 | Reward:  -9.605 | Epsilon: 0.0100 | Loss: 129098.4531
Episode 45300 | Reward:  -6.744 | Epsilon: 0.0100 | Loss: 116592.5781
Episode 45350 | Reward:  -5.826 | Epsilon: 0.0100 | Loss: 117258.6406
Episode 45400 | Reward:  -7.016 | Epsilon: 0.0100 | Loss: 168124.9375
Episode 45450 | Reward: -11.670 | Epsilon: 0.0100 | Loss: 119660.2656
Episode 45500 | Reward: -12.881 | Epsilon: 0.0100 | Loss: 108581.7422
Episode 45550 | Reward: -10.279 | Epsilon: 0.0100 | Loss: 137802.6562
Episode 45600 | Reward: -13.484 | Epsilon: 0.0100 | Loss: 133524.7188
Episode 45650 | Reward: -11.298 | Epsilon: 0.0100 | Loss: 162596.4688
Episode 45700 | Reward: -10.478 | Epsilon: 0.0100 | Loss: 99370.0703
Episode 45750 | Reward: -12.640 | Epsilon: 0.0100 | Loss: 129430.0547
Episode 45800 | Reward: -13.527 | Epsilon: 0.0100 | Loss: 199784.1094
Episode 45850 | Reward: -14.426 | Epsilon: 0.0100 | Loss: 147078.4219
Episode 45900 | Reward:  -9.991 | Epsilon: 0.0100 | Loss: 126736.2188
Episode 45950 | Reward:  -8.311 | Epsilon: 0.0100 | Loss: 135037.9062
Episode 46000 | Reward:  -7.867 | Epsilon: 0.0100 | Loss: 107897.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:08).dict
Episode 46050 | Reward:  -8.344 | Epsilon: 0.0100 | Loss: 166496.7344
Episode 46100 | Reward:  -9.091 | Epsilon: 0.0100 | Loss: 141770.1719
Episode 46150 | Reward: -11.704 | Epsilon: 0.0100 | Loss: 166747.9219
Episode 46200 | Reward: -11.174 | Epsilon: 0.0100 | Loss: 159384.6562
Episode 46250 | Reward: -10.402 | Epsilon: 0.0100 | Loss: 164080.0469
Episode 46300 | Reward: -11.847 | Epsilon: 0.0100 | Loss: 166410.6562
Episode 46350 | Reward:  -8.227 | Epsilon: 0.0100 | Loss: 131164.3281
Episode 46400 | Reward: -11.992 | Epsilon: 0.0100 | Loss: 146919.5312
Episode 46450 | Reward: -13.328 | Epsilon: 0.0100 | Loss: 136137.5000
Episode 46500 | Reward: -13.186 | Epsilon: 0.0100 | Loss: 131850.4688
Episode 46550 | Reward:  -8.782 | Epsilon: 0.0100 | Loss: 133894.7656
Episode 46600 | Reward: -10.017 | Epsilon: 0.0100 | Loss: 127072.6797
Episode 46650 | Reward: -10.693 | Epsilon: 0.0100 | Loss: 181242.7656
Episode 46700 | Reward:  -9.402 | Epsilon: 0.0100 | Loss: 101980.4531
Episode 46750 | Reward: -12.308 | Epsilon: 0.0100 | Loss: 106999.6953
Episode 46800 | Reward:  -9.866 | Epsilon: 0.0100 | Loss: 132804.0625
Episode 46850 | Reward:  -9.086 | Epsilon: 0.0100 | Loss: 181126.4062
Episode 46900 | Reward: -12.746 | Epsilon: 0.0100 | Loss: 185026.2656
Episode 46950 | Reward: -13.622 | Epsilon: 0.0100 | Loss: 171342.2969
Episode 47000 | Reward: -13.469 | Epsilon: 0.0100 | Loss: 193862.7812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:12).dict
Episode 47050 | Reward:  -9.001 | Epsilon: 0.0100 | Loss: 198836.3438
Episode 47100 | Reward: -13.772 | Epsilon: 0.0100 | Loss: 118432.3047
Episode 47150 | Reward:  -9.394 | Epsilon: 0.0100 | Loss: 174619.5156
Episode 47200 | Reward:  -8.689 | Epsilon: 0.0100 | Loss: 144175.3281
Episode 47250 | Reward: -10.019 | Epsilon: 0.0100 | Loss: 140168.6875
Episode 47300 | Reward:  -7.308 | Epsilon: 0.0100 | Loss: 144469.2031
Episode 47350 | Reward:  -6.944 | Epsilon: 0.0100 | Loss: 164140.2812
Episode 47400 | Reward:  -7.229 | Epsilon: 0.0100 | Loss: 199684.9219
Episode 47450 | Reward: -11.692 | Epsilon: 0.0100 | Loss: 152761.0156
Episode 47500 | Reward:  -9.502 | Epsilon: 0.0100 | Loss: 145375.8438
Episode 47550 | Reward: -13.901 | Epsilon: 0.0100 | Loss: 163995.1719
Episode 47600 | Reward:  -4.944 | Epsilon: 0.0100 | Loss: 185076.7188
Episode 47650 | Reward:  -4.058 | Epsilon: 0.0100 | Loss: 173994.3906
Episode 47700 | Reward:  -7.378 | Epsilon: 0.0100 | Loss: 162172.3438
Episode 47750 | Reward:  -8.906 | Epsilon: 0.0100 | Loss: 207810.4062
Episode 47800 | Reward: -11.154 | Epsilon: 0.0100 | Loss: 166892.1250
Episode 47850 | Reward:  -7.446 | Epsilon: 0.0100 | Loss: 211776.9219
Episode 47900 | Reward:  -7.436 | Epsilon: 0.0100 | Loss: 210901.3750
Episode 47950 | Reward:  -5.190 | Epsilon: 0.0100 | Loss: 148256.2969
Episode 48000 | Reward:  -5.869 | Epsilon: 0.0100 | Loss: 224332.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:16).dict
Episode 48050 | Reward:  -5.592 | Epsilon: 0.0100 | Loss: 212460.8594
Episode 48100 | Reward:  -6.975 | Epsilon: 0.0100 | Loss: 194902.5625
Episode 48150 | Reward:  -7.421 | Epsilon: 0.0100 | Loss: 199228.7188
Episode 48200 | Reward:  -7.966 | Epsilon: 0.0100 | Loss: 168296.1875
Episode 48250 | Reward:  -8.205 | Epsilon: 0.0100 | Loss: 163151.0781
Episode 48300 | Reward:  -7.126 | Epsilon: 0.0100 | Loss: 202944.6562
Episode 48350 | Reward:  -8.214 | Epsilon: 0.0100 | Loss: 172642.9375
Episode 48400 | Reward: -12.822 | Epsilon: 0.0100 | Loss: 200423.0625
Episode 48450 | Reward: -10.625 | Epsilon: 0.0100 | Loss: 174560.6562
Episode 48500 | Reward:  -8.523 | Epsilon: 0.0100 | Loss: 167490.6562
Episode 48550 | Reward:  -9.396 | Epsilon: 0.0100 | Loss: 211862.4844
Episode 48600 | Reward:  -6.113 | Epsilon: 0.0100 | Loss: 208419.9062
Episode 48650 | Reward:  -7.904 | Epsilon: 0.0100 | Loss: 219395.7812
Episode 48700 | Reward: -12.729 | Epsilon: 0.0100 | Loss: 206713.8906
Episode 48750 | Reward:  -9.894 | Epsilon: 0.0100 | Loss: 228283.2656
Episode 48800 | Reward: -10.600 | Epsilon: 0.0100 | Loss: 170072.7812
Episode 48850 | Reward: -10.513 | Epsilon: 0.0100 | Loss: 193271.8594
Episode 48900 | Reward: -10.141 | Epsilon: 0.0100 | Loss: 202517.2188
Episode 48950 | Reward:  -9.262 | Epsilon: 0.0100 | Loss: 222227.2969
Episode 49000 | Reward:  -8.893 | Epsilon: 0.0100 | Loss: 211463.9531
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:20).dict
Episode 49050 | Reward:  -9.721 | Epsilon: 0.0100 | Loss: 153268.6719
Episode 49100 | Reward: -10.621 | Epsilon: 0.0100 | Loss: 183639.8750
Episode 49150 | Reward:  -7.344 | Epsilon: 0.0100 | Loss: 167270.0312
Episode 49200 | Reward:  -7.523 | Epsilon: 0.0100 | Loss: 204614.5938
Episode 49250 | Reward: -10.334 | Epsilon: 0.0100 | Loss: 223456.0781
Episode 49300 | Reward: -10.045 | Epsilon: 0.0100 | Loss: 120248.8828
Episode 49350 | Reward:  -9.017 | Epsilon: 0.0100 | Loss: 146413.0625
Episode 49400 | Reward:  -9.600 | Epsilon: 0.0100 | Loss: 152336.9062
Episode 49450 | Reward:  -9.066 | Epsilon: 0.0100 | Loss: 176169.1094
Episode 49500 | Reward:  -7.996 | Epsilon: 0.0100 | Loss: 178612.2188
Episode 49550 | Reward:  -3.588 | Epsilon: 0.0100 | Loss: 198203.5938
Episode 49600 | Reward:  -6.955 | Epsilon: 0.0100 | Loss: 212933.1094
Episode 49650 | Reward:  -6.437 | Epsilon: 0.0100 | Loss: 140256.6250
Episode 49700 | Reward:  -7.871 | Epsilon: 0.0100 | Loss: 179730.4844
Episode 49750 | Reward:  -8.635 | Epsilon: 0.0100 | Loss: 134381.9375
Episode 49800 | Reward:  -8.037 | Epsilon: 0.0100 | Loss: 220094.0000
Episode 49850 | Reward: -13.245 | Epsilon: 0.0100 | Loss: 190226.6250
Episode 49900 | Reward: -10.351 | Epsilon: 0.0100 | Loss: 160123.1875
Episode 49950 | Reward:  -8.950 | Epsilon: 0.0100 | Loss: 203787.6406
Episode 50000 | Reward:  -9.530 | Epsilon: 0.0100 | Loss: 146050.1875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:24).dict
Episode 50050 | Reward:  -9.314 | Epsilon: 0.0100 | Loss: 138554.8906
Episode 50100 | Reward:  -6.401 | Epsilon: 0.0100 | Loss: 142453.9062
Episode 50150 | Reward: -10.045 | Epsilon: 0.0100 | Loss: 156993.6875
Episode 50200 | Reward:  -9.632 | Epsilon: 0.0100 | Loss: 151140.3125
Episode 50250 | Reward:  -7.571 | Epsilon: 0.0100 | Loss: 125278.4688
Episode 50300 | Reward:  -8.289 | Epsilon: 0.0100 | Loss: 162505.7188
Episode 50350 | Reward:  -9.615 | Epsilon: 0.0100 | Loss: 140309.4375
Episode 50400 | Reward: -11.602 | Epsilon: 0.0100 | Loss: 163554.9531
Episode 50450 | Reward:  -9.310 | Epsilon: 0.0100 | Loss: 162504.4062
Episode 50500 | Reward:  -5.596 | Epsilon: 0.0100 | Loss: 116435.6094
Episode 50550 | Reward:  -8.724 | Epsilon: 0.0100 | Loss: 135100.5781
Episode 50600 | Reward:  -7.800 | Epsilon: 0.0100 | Loss: 144062.7812
Episode 50650 | Reward:  -8.569 | Epsilon: 0.0100 | Loss: 138117.0625
Episode 50700 | Reward:  -5.282 | Epsilon: 0.0100 | Loss: 113519.8750
Episode 50750 | Reward:  -8.381 | Epsilon: 0.0100 | Loss: 172752.7031
Episode 50800 | Reward:  -9.060 | Epsilon: 0.0100 | Loss: 105211.5938
Episode 50850 | Reward:  -5.365 | Epsilon: 0.0100 | Loss: 115746.3359
Episode 50900 | Reward:  -3.352 | Epsilon: 0.0100 | Loss: 126664.7812
Episode 50950 | Reward:  -5.610 | Epsilon: 0.0100 | Loss: 142508.8750
Episode 51000 | Reward:  -5.639 | Epsilon: 0.0100 | Loss: 90437.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:28).dict
Episode 51050 | Reward:  -6.400 | Epsilon: 0.0100 | Loss: 144850.4219
Episode 51100 | Reward:  -6.574 | Epsilon: 0.0100 | Loss: 141208.3594
Episode 51150 | Reward:  -8.452 | Epsilon: 0.0100 | Loss: 124819.2031
Episode 51200 | Reward:  -7.347 | Epsilon: 0.0100 | Loss: 155190.6250
Episode 51250 | Reward:  -5.712 | Epsilon: 0.0100 | Loss: 145164.4375
Episode 51300 | Reward:  -6.417 | Epsilon: 0.0100 | Loss: 133747.3594
Episode 51350 | Reward:  -4.763 | Epsilon: 0.0100 | Loss: 140694.7812
Episode 51400 | Reward:  -3.454 | Epsilon: 0.0100 | Loss: 125184.8359
Episode 51450 | Reward:  -6.114 | Epsilon: 0.0100 | Loss: 124761.5000
Episode 51500 | Reward:  -4.404 | Epsilon: 0.0100 | Loss: 130097.4844
Episode 51550 | Reward:  -6.737 | Epsilon: 0.0100 | Loss: 126413.0234
Episode 51600 | Reward:  -4.158 | Epsilon: 0.0100 | Loss: 137110.2500
Episode 51650 | Reward:  -5.326 | Epsilon: 0.0100 | Loss: 139354.1406
Episode 51700 | Reward:  -6.525 | Epsilon: 0.0100 | Loss: 143527.9219
Episode 51750 | Reward:  -7.412 | Epsilon: 0.0100 | Loss: 135180.1562
Episode 51800 | Reward: -10.326 | Epsilon: 0.0100 | Loss: 156952.8594
Episode 51850 | Reward:  -9.473 | Epsilon: 0.0100 | Loss: 110876.2422
Episode 51900 | Reward:  -8.262 | Epsilon: 0.0100 | Loss: 117443.8359
Episode 51950 | Reward:  -6.023 | Epsilon: 0.0100 | Loss: 131885.1562
Episode 52000 | Reward:  -7.283 | Epsilon: 0.0100 | Loss: 111539.4141
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:32).dict
Episode 52050 | Reward:  -6.971 | Epsilon: 0.0100 | Loss: 120579.1875
Episode 52100 | Reward:  -8.328 | Epsilon: 0.0100 | Loss: 114642.0391
Episode 52150 | Reward: -11.152 | Epsilon: 0.0100 | Loss: 151595.8281
Episode 52200 | Reward:  -6.489 | Epsilon: 0.0100 | Loss: 142495.4375
Episode 52250 | Reward:  -8.121 | Epsilon: 0.0100 | Loss: 154035.9375
Episode 52300 | Reward:  -7.858 | Epsilon: 0.0100 | Loss: 140980.2344
Episode 52350 | Reward:  -5.633 | Epsilon: 0.0100 | Loss: 157770.2969
Episode 52400 | Reward:  -5.885 | Epsilon: 0.0100 | Loss: 100741.9297
Episode 52450 | Reward:  -9.961 | Epsilon: 0.0100 | Loss: 123873.1953
Episode 52500 | Reward:  -8.623 | Epsilon: 0.0100 | Loss: 116782.1719
Episode 52550 | Reward:  -8.398 | Epsilon: 0.0100 | Loss: 119985.3672
Episode 52600 | Reward:  -9.221 | Epsilon: 0.0100 | Loss: 140869.4062
Episode 52650 | Reward:  -6.311 | Epsilon: 0.0100 | Loss: 144430.1250
Episode 52700 | Reward:  -8.270 | Epsilon: 0.0100 | Loss: 128223.8906
Episode 52750 | Reward:  -8.497 | Epsilon: 0.0100 | Loss: 153209.4844
Episode 52800 | Reward:  -5.062 | Epsilon: 0.0100 | Loss: 133919.0312
Episode 52850 | Reward:  -7.032 | Epsilon: 0.0100 | Loss: 115608.1172
Episode 52900 | Reward:  -6.809 | Epsilon: 0.0100 | Loss: 119303.8984
Episode 52950 | Reward:  -3.679 | Epsilon: 0.0100 | Loss: 144939.5000
Episode 53000 | Reward:  -3.606 | Epsilon: 0.0100 | Loss: 111353.7422
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:36).dict
Episode 53050 | Reward:  -8.682 | Epsilon: 0.0100 | Loss: 153676.1875
Episode 53100 | Reward:  -6.787 | Epsilon: 0.0100 | Loss: 122665.9922
Episode 53150 | Reward:  -5.713 | Epsilon: 0.0100 | Loss: 118683.7969
Episode 53200 | Reward:  -4.808 | Epsilon: 0.0100 | Loss: 153703.8438
Episode 53250 | Reward:  -6.661 | Epsilon: 0.0100 | Loss: 136501.5469
Episode 53300 | Reward:  -4.215 | Epsilon: 0.0100 | Loss: 134440.2656
Episode 53350 | Reward:  -5.241 | Epsilon: 0.0100 | Loss: 126069.9922
Episode 53400 | Reward:  -5.672 | Epsilon: 0.0100 | Loss: 128286.2812
Episode 53450 | Reward:  -7.129 | Epsilon: 0.0100 | Loss: 160294.9062
Episode 53500 | Reward:  -6.772 | Epsilon: 0.0100 | Loss: 156441.0000
Episode 53550 | Reward:  -6.189 | Epsilon: 0.0100 | Loss: 168007.7500
Episode 53600 | Reward:  -6.145 | Epsilon: 0.0100 | Loss: 135771.5469
Episode 53650 | Reward:  -8.960 | Epsilon: 0.0100 | Loss: 113440.0234
Episode 53700 | Reward:  -9.068 | Epsilon: 0.0100 | Loss: 156311.8438
Episode 53750 | Reward:  -8.248 | Epsilon: 0.0100 | Loss: 149925.9375
Episode 53800 | Reward:  -7.472 | Epsilon: 0.0100 | Loss: 146534.1094
Episode 53850 | Reward:  -6.807 | Epsilon: 0.0100 | Loss: 114945.6094
Episode 53900 | Reward:  -9.119 | Epsilon: 0.0100 | Loss: 146358.6250
Episode 53950 | Reward:  -9.680 | Epsilon: 0.0100 | Loss: 167952.6562
Episode 54000 | Reward:  -7.190 | Epsilon: 0.0100 | Loss: 119742.0312
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:40).dict
Episode 54050 | Reward:  -7.781 | Epsilon: 0.0100 | Loss: 182616.5312
Episode 54100 | Reward:  -7.659 | Epsilon: 0.0100 | Loss: 112582.7344
Episode 54150 | Reward: -10.864 | Epsilon: 0.0100 | Loss: 106289.3906
Episode 54200 | Reward:  -9.596 | Epsilon: 0.0100 | Loss: 105020.6172
Episode 54250 | Reward:  -6.049 | Epsilon: 0.0100 | Loss: 121535.7109
Episode 54300 | Reward:  -8.301 | Epsilon: 0.0100 | Loss: 128059.1797
Episode 54350 | Reward:  -7.294 | Epsilon: 0.0100 | Loss: 147741.8438
Episode 54400 | Reward:  -4.426 | Epsilon: 0.0100 | Loss: 113883.6875
Episode 54450 | Reward:  -8.453 | Epsilon: 0.0100 | Loss: 139471.4531
Episode 54500 | Reward:  -6.377 | Epsilon: 0.0100 | Loss: 130083.6406
Episode 54550 | Reward:  -8.592 | Epsilon: 0.0100 | Loss: 101478.8438
Episode 54600 | Reward:  -6.557 | Epsilon: 0.0100 | Loss: 93383.6328
Episode 54650 | Reward:  -5.444 | Epsilon: 0.0100 | Loss: 122506.4688
Episode 54700 | Reward:  -7.740 | Epsilon: 0.0100 | Loss: 127409.7031
Episode 54750 | Reward:  -6.386 | Epsilon: 0.0100 | Loss: 147054.7812
Episode 54800 | Reward:  -5.527 | Epsilon: 0.0100 | Loss: 105885.0156
Episode 54850 | Reward:  -5.661 | Epsilon: 0.0100 | Loss: 134736.1562
Episode 54900 | Reward:  -6.117 | Epsilon: 0.0100 | Loss: 101545.2344
Episode 54950 | Reward:  -7.482 | Epsilon: 0.0100 | Loss: 128275.1562
Episode 55000 | Reward: -10.269 | Epsilon: 0.0100 | Loss: 145147.6094
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:44).dict
Episode 55050 | Reward:  -7.445 | Epsilon: 0.0100 | Loss: 141502.1562
Episode 55100 | Reward:  -5.614 | Epsilon: 0.0100 | Loss: 109196.0703
Episode 55150 | Reward:  -7.845 | Epsilon: 0.0100 | Loss: 126513.7578
Episode 55200 | Reward:  -7.400 | Epsilon: 0.0100 | Loss: 181398.6719
Episode 55250 | Reward:  -4.857 | Epsilon: 0.0100 | Loss: 134074.3750
Episode 55300 | Reward:  -6.552 | Epsilon: 0.0100 | Loss: 139681.0938
Episode 55350 | Reward:  -5.689 | Epsilon: 0.0100 | Loss: 137048.3125
Episode 55400 | Reward:  -4.722 | Epsilon: 0.0100 | Loss: 127722.7266
Episode 55450 | Reward:  -5.285 | Epsilon: 0.0100 | Loss: 99599.7188
Episode 55500 | Reward:  -5.176 | Epsilon: 0.0100 | Loss: 117438.5234
Episode 55550 | Reward:  -7.698 | Epsilon: 0.0100 | Loss: 104732.4297
Episode 55600 | Reward:  -5.041 | Epsilon: 0.0100 | Loss: 123906.6562
Episode 55650 | Reward:  -4.800 | Epsilon: 0.0100 | Loss: 113317.1875
Episode 55700 | Reward:  -5.093 | Epsilon: 0.0100 | Loss: 102794.5078
Episode 55750 | Reward:  -4.365 | Epsilon: 0.0100 | Loss: 136642.5625
Episode 55800 | Reward:  -4.507 | Epsilon: 0.0100 | Loss: 143058.0000
Episode 55850 | Reward:  -7.983 | Epsilon: 0.0100 | Loss: 110851.9531
Episode 55900 | Reward:  -9.217 | Epsilon: 0.0100 | Loss: 120400.7891
Episode 55950 | Reward:  -6.727 | Epsilon: 0.0100 | Loss: 99980.1094
Episode 56000 | Reward:  -8.006 | Epsilon: 0.0100 | Loss: 111900.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:48).dict
Episode 56050 | Reward:  -9.697 | Epsilon: 0.0100 | Loss: 115565.9844
Episode 56100 | Reward:  -8.937 | Epsilon: 0.0100 | Loss: 107366.8281
Episode 56150 | Reward:  -7.662 | Epsilon: 0.0100 | Loss: 115476.0234
Episode 56200 | Reward: -11.811 | Epsilon: 0.0100 | Loss: 117369.5938
Episode 56250 | Reward: -11.856 | Epsilon: 0.0100 | Loss: 96239.5625
Episode 56300 | Reward:  -8.049 | Epsilon: 0.0100 | Loss: 116489.7422
Episode 56350 | Reward:  -9.685 | Epsilon: 0.0100 | Loss: 112678.1406
Episode 56400 | Reward: -10.694 | Epsilon: 0.0100 | Loss: 131955.5938
Episode 56450 | Reward:  -9.616 | Epsilon: 0.0100 | Loss: 127300.4062
Episode 56500 | Reward:  -5.833 | Epsilon: 0.0100 | Loss: 116728.0859
Episode 56550 | Reward:  -5.710 | Epsilon: 0.0100 | Loss: 130390.6484
Episode 56600 | Reward:  -7.077 | Epsilon: 0.0100 | Loss: 123391.7969
Episode 56650 | Reward:  -5.300 | Epsilon: 0.0100 | Loss: 94874.0156
Episode 56700 | Reward:  -5.653 | Epsilon: 0.0100 | Loss: 104171.6875
Episode 56750 | Reward:  -5.183 | Epsilon: 0.0100 | Loss: 133061.9375
Episode 56800 | Reward:  -8.362 | Epsilon: 0.0100 | Loss: 108388.0625
Episode 56850 | Reward:  -8.076 | Epsilon: 0.0100 | Loss: 109066.4141
Episode 56900 | Reward:  -5.839 | Epsilon: 0.0100 | Loss: 87976.8125
Episode 56950 | Reward:  -7.186 | Epsilon: 0.0100 | Loss: 106378.2969
Episode 57000 | Reward:  -7.744 | Epsilon: 0.0100 | Loss: 106833.8984
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:52).dict
Episode 57050 | Reward:  -8.449 | Epsilon: 0.0100 | Loss: 112275.9375
Episode 57100 | Reward:  -4.297 | Epsilon: 0.0100 | Loss: 97756.4219
Episode 57150 | Reward:  -4.768 | Epsilon: 0.0100 | Loss: 127480.9688
Episode 57200 | Reward:  -6.802 | Epsilon: 0.0100 | Loss: 138352.0938
Episode 57250 | Reward:  -6.023 | Epsilon: 0.0100 | Loss: 105327.9844
Episode 57300 | Reward:  -9.272 | Epsilon: 0.0100 | Loss: 104341.8359
Episode 57350 | Reward:  -6.899 | Epsilon: 0.0100 | Loss: 104728.5859
Episode 57400 | Reward:  -7.246 | Epsilon: 0.0100 | Loss: 121762.4297
Episode 57450 | Reward:  -8.310 | Epsilon: 0.0100 | Loss: 118644.4688
Episode 57500 | Reward:  -3.541 | Epsilon: 0.0100 | Loss: 100989.6406
Episode 57550 | Reward:  -6.713 | Epsilon: 0.0100 | Loss: 94650.1562
Episode 57600 | Reward:  -5.352 | Epsilon: 0.0100 | Loss: 114916.2969
Episode 57650 | Reward:  -9.093 | Epsilon: 0.0100 | Loss: 115326.5781
Episode 57700 | Reward:  -8.800 | Epsilon: 0.0100 | Loss: 108685.2656
Episode 57750 | Reward:  -8.390 | Epsilon: 0.0100 | Loss: 122648.5469
Episode 57800 | Reward:  -7.031 | Epsilon: 0.0100 | Loss: 120943.9609
Episode 57850 | Reward:  -8.288 | Epsilon: 0.0100 | Loss: 99457.0781
Episode 57900 | Reward:  -6.439 | Epsilon: 0.0100 | Loss: 137346.4844
Episode 57950 | Reward:  -7.004 | Epsilon: 0.0100 | Loss: 116719.6484
Episode 58000 | Reward:  -7.851 | Epsilon: 0.0100 | Loss: 117145.1406
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(04:56).dict
Episode 58050 | Reward:  -7.855 | Epsilon: 0.0100 | Loss: 125424.7656
Episode 58100 | Reward:  -6.928 | Epsilon: 0.0100 | Loss: 147713.1250
Episode 58150 | Reward:  -6.417 | Epsilon: 0.0100 | Loss: 111854.0859
Episode 58200 | Reward:  -8.701 | Epsilon: 0.0100 | Loss: 127328.2031
Episode 58250 | Reward:  -5.102 | Epsilon: 0.0100 | Loss: 151751.5625
Episode 58300 | Reward:  -7.218 | Epsilon: 0.0100 | Loss: 104410.6641
Episode 58350 | Reward:  -8.880 | Epsilon: 0.0100 | Loss: 105364.8281
Episode 58400 | Reward:  -7.593 | Epsilon: 0.0100 | Loss: 135394.7500
Episode 58450 | Reward:  -9.609 | Epsilon: 0.0100 | Loss: 107591.5938
Episode 58500 | Reward: -10.453 | Epsilon: 0.0100 | Loss: 126930.6562
Episode 58550 | Reward:  -8.469 | Epsilon: 0.0100 | Loss: 104350.2188
Episode 58600 | Reward:  -7.051 | Epsilon: 0.0100 | Loss: 114047.7734
Episode 58650 | Reward:  -9.052 | Epsilon: 0.0100 | Loss: 117807.1641
Episode 58700 | Reward:  -5.083 | Epsilon: 0.0100 | Loss: 114946.5625
Episode 58750 | Reward:  -7.763 | Epsilon: 0.0100 | Loss: 84275.2734
Episode 58800 | Reward:  -6.904 | Epsilon: 0.0100 | Loss: 129426.2969
Episode 58850 | Reward:  -7.060 | Epsilon: 0.0100 | Loss: 100879.2500
Episode 58900 | Reward:  -9.717 | Epsilon: 0.0100 | Loss: 119743.5312
Episode 58950 | Reward: -10.819 | Epsilon: 0.0100 | Loss: 119557.9844
Episode 59000 | Reward:  -5.694 | Epsilon: 0.0100 | Loss: 137706.4531
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:00).dict
Episode 59050 | Reward:  -7.369 | Epsilon: 0.0100 | Loss: 101177.5625
Episode 59100 | Reward: -12.349 | Epsilon: 0.0100 | Loss: 151299.6094
Episode 59150 | Reward:  -5.657 | Epsilon: 0.0100 | Loss: 138654.0000
Episode 59200 | Reward:  -8.893 | Epsilon: 0.0100 | Loss: 153810.9062
Episode 59250 | Reward: -11.273 | Epsilon: 0.0100 | Loss: 165828.5312
Episode 59300 | Reward: -10.365 | Epsilon: 0.0100 | Loss: 112469.7734
Episode 59350 | Reward:  -7.110 | Epsilon: 0.0100 | Loss: 154132.7969
Episode 59400 | Reward:  -5.899 | Epsilon: 0.0100 | Loss: 143065.1406
Episode 59450 | Reward:  -8.642 | Epsilon: 0.0100 | Loss: 167206.0781
Episode 59500 | Reward:  -8.473 | Epsilon: 0.0100 | Loss: 156479.7188
Episode 59550 | Reward:  -9.551 | Epsilon: 0.0100 | Loss: 177921.2969
Episode 59600 | Reward: -10.314 | Epsilon: 0.0100 | Loss: 194794.5000
Episode 59650 | Reward:  -8.373 | Epsilon: 0.0100 | Loss: 218594.0938
Episode 59700 | Reward: -13.261 | Epsilon: 0.0100 | Loss: 220845.5469
Episode 59750 | Reward: -13.823 | Epsilon: 0.0100 | Loss: 178449.5938
Episode 59800 | Reward:  -8.404 | Epsilon: 0.0100 | Loss: 201334.4531
Episode 59850 | Reward: -10.578 | Epsilon: 0.0100 | Loss: 252600.9375
Episode 59900 | Reward: -13.976 | Epsilon: 0.0100 | Loss: 234505.7969
Episode 59950 | Reward: -13.774 | Epsilon: 0.0100 | Loss: 228932.9375
Episode 60000 | Reward: -11.435 | Epsilon: 0.0100 | Loss: 238275.7344
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:04).dict
Episode 60050 | Reward: -10.828 | Epsilon: 0.0100 | Loss: 255993.0000
Episode 60100 | Reward:  -8.775 | Epsilon: 0.0100 | Loss: 297778.5938
Episode 60150 | Reward: -12.404 | Epsilon: 0.0100 | Loss: 263247.4375
Episode 60200 | Reward:  -9.438 | Epsilon: 0.0100 | Loss: 240910.0469
Episode 60250 | Reward: -12.675 | Epsilon: 0.0100 | Loss: 295441.3750
Episode 60300 | Reward:  -8.425 | Epsilon: 0.0100 | Loss: 279790.5625
Episode 60350 | Reward: -10.430 | Epsilon: 0.0100 | Loss: 337665.2500
Episode 60400 | Reward: -12.130 | Epsilon: 0.0100 | Loss: 331688.6250
Episode 60450 | Reward: -11.679 | Epsilon: 0.0100 | Loss: 377330.3750
Episode 60500 | Reward:  -7.595 | Epsilon: 0.0100 | Loss: 245541.3594
Episode 60550 | Reward:  -8.957 | Epsilon: 0.0100 | Loss: 258101.0312
Episode 60600 | Reward:  -7.197 | Epsilon: 0.0100 | Loss: 323444.3125
Episode 60650 | Reward:  -9.959 | Epsilon: 0.0100 | Loss: 258488.0312
Episode 60700 | Reward: -10.542 | Epsilon: 0.0100 | Loss: 256894.6094
Episode 60750 | Reward:  -9.588 | Epsilon: 0.0100 | Loss: 369316.2812
Episode 60800 | Reward: -16.447 | Epsilon: 0.0100 | Loss: 343720.1250
Episode 60850 | Reward: -11.251 | Epsilon: 0.0100 | Loss: 305338.6562
Episode 60900 | Reward:  -7.056 | Epsilon: 0.0100 | Loss: 381487.5938
Episode 60950 | Reward:  -3.678 | Epsilon: 0.0100 | Loss: 409716.4375
Episode 61000 | Reward: -10.612 | Epsilon: 0.0100 | Loss: 298149.5938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:08).dict
Episode 61050 | Reward:  -8.470 | Epsilon: 0.0100 | Loss: 399314.6250
Episode 61100 | Reward:  -7.142 | Epsilon: 0.0100 | Loss: 373569.3750
Episode 61150 | Reward:  -8.771 | Epsilon: 0.0100 | Loss: 381191.0312
Episode 61200 | Reward:  -8.813 | Epsilon: 0.0100 | Loss: 258514.2344
Episode 61250 | Reward:  -5.744 | Epsilon: 0.0100 | Loss: 396472.1875
Episode 61300 | Reward:  -7.551 | Epsilon: 0.0100 | Loss: 330104.0000
Episode 61350 | Reward:  -6.992 | Epsilon: 0.0100 | Loss: 359344.0938
Episode 61400 | Reward:  -5.042 | Epsilon: 0.0100 | Loss: 479762.3438
Episode 61450 | Reward:  -8.019 | Epsilon: 0.0100 | Loss: 373330.4062
Episode 61500 | Reward:  -8.302 | Epsilon: 0.0100 | Loss: 310255.3125
Episode 61550 | Reward:  -7.749 | Epsilon: 0.0100 | Loss: 415103.3125
Episode 61600 | Reward:  -5.969 | Epsilon: 0.0100 | Loss: 449127.6250
Episode 61650 | Reward:  -5.623 | Epsilon: 0.0100 | Loss: 374815.1875
Episode 61700 | Reward:  -5.265 | Epsilon: 0.0100 | Loss: 420863.1875
Episode 61750 | Reward:  -3.240 | Epsilon: 0.0100 | Loss: 392661.3125
Episode 61800 | Reward:  -6.810 | Epsilon: 0.0100 | Loss: 455368.5938
Episode 61850 | Reward:  -9.246 | Epsilon: 0.0100 | Loss: 371551.5000
Episode 61900 | Reward: -11.130 | Epsilon: 0.0100 | Loss: 473401.0625
Episode 61950 | Reward:  -8.074 | Epsilon: 0.0100 | Loss: 445737.6250
Episode 62000 | Reward: -12.678 | Epsilon: 0.0100 | Loss: 406376.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:12).dict
Episode 62050 | Reward:  -7.127 | Epsilon: 0.0100 | Loss: 423888.5938
Episode 62100 | Reward: -10.226 | Epsilon: 0.0100 | Loss: 613341.3750
Episode 62150 | Reward:  -9.885 | Epsilon: 0.0100 | Loss: 345165.3125
Episode 62200 | Reward: -10.251 | Epsilon: 0.0100 | Loss: 547945.5000
Episode 62250 | Reward: -13.156 | Epsilon: 0.0100 | Loss: 497049.9688
Episode 62300 | Reward: -13.851 | Epsilon: 0.0100 | Loss: 515359.1875
Episode 62350 | Reward: -10.897 | Epsilon: 0.0100 | Loss: 422619.4375
Episode 62400 | Reward: -12.436 | Epsilon: 0.0100 | Loss: 605542.3750
Episode 62450 | Reward: -13.088 | Epsilon: 0.0100 | Loss: 510199.3750
Episode 62500 | Reward:  -9.995 | Epsilon: 0.0100 | Loss: 556896.7500
Episode 62550 | Reward:  -6.403 | Epsilon: 0.0100 | Loss: 604348.5000
Episode 62600 | Reward:  -4.953 | Epsilon: 0.0100 | Loss: 569695.8750
Episode 62650 | Reward:  -7.301 | Epsilon: 0.0100 | Loss: 504432.5312
Episode 62700 | Reward:  -8.171 | Epsilon: 0.0100 | Loss: 544126.5000
Episode 62750 | Reward:  -9.435 | Epsilon: 0.0100 | Loss: 623932.6875
Episode 62800 | Reward:  -9.794 | Epsilon: 0.0100 | Loss: 617128.0000
Episode 62850 | Reward: -10.732 | Epsilon: 0.0100 | Loss: 444972.9375
Episode 62900 | Reward:  -9.522 | Epsilon: 0.0100 | Loss: 839598.0000
Episode 62950 | Reward:  -9.616 | Epsilon: 0.0100 | Loss: 743834.3750
Episode 63000 | Reward:  -7.455 | Epsilon: 0.0100 | Loss: 638733.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:16).dict
Episode 63050 | Reward:  -8.160 | Epsilon: 0.0100 | Loss: 722254.0000
Episode 63100 | Reward:  -9.791 | Epsilon: 0.0100 | Loss: 704146.2500
Episode 63150 | Reward: -11.001 | Epsilon: 0.0100 | Loss: 712833.3125
Episode 63200 | Reward: -14.048 | Epsilon: 0.0100 | Loss: 699980.5625
Episode 63250 | Reward: -13.008 | Epsilon: 0.0100 | Loss: 715013.0625
Episode 63300 | Reward:  -9.082 | Epsilon: 0.0100 | Loss: 756820.3750
Episode 63350 | Reward: -11.960 | Epsilon: 0.0100 | Loss: 751139.5625
Episode 63400 | Reward:  -8.184 | Epsilon: 0.0100 | Loss: 898103.7500
Episode 63450 | Reward: -13.824 | Epsilon: 0.0100 | Loss: 627046.4375
Episode 63500 | Reward: -14.496 | Epsilon: 0.0100 | Loss: 816863.1875
Episode 63550 | Reward: -12.640 | Epsilon: 0.0100 | Loss: 1081163.2500
Episode 63600 | Reward: -11.782 | Epsilon: 0.0100 | Loss: 1056168.3750
Episode 63650 | Reward: -10.425 | Epsilon: 0.0100 | Loss: 1111844.7500
Episode 63700 | Reward: -12.588 | Epsilon: 0.0100 | Loss: 895853.3750
Episode 63750 | Reward: -13.123 | Epsilon: 0.0100 | Loss: 755430.0625
Episode 63800 | Reward: -10.446 | Epsilon: 0.0100 | Loss: 915566.8125
Episode 63850 | Reward: -14.397 | Epsilon: 0.0100 | Loss: 882173.8125
Episode 63900 | Reward: -16.792 | Epsilon: 0.0100 | Loss: 865460.8125
Episode 63950 | Reward: -10.945 | Epsilon: 0.0100 | Loss: 906738.1875
Episode 64000 | Reward: -11.644 | Epsilon: 0.0100 | Loss: 888096.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:20).dict
Episode 64050 | Reward:  -9.399 | Epsilon: 0.0100 | Loss: 793422.3125
Episode 64100 | Reward: -11.332 | Epsilon: 0.0100 | Loss: 951187.1875
Episode 64150 | Reward: -12.355 | Epsilon: 0.0100 | Loss: 727029.8750
Episode 64200 | Reward:  -9.942 | Epsilon: 0.0100 | Loss: 920303.6250
Episode 64250 | Reward: -11.350 | Epsilon: 0.0100 | Loss: 801573.6250
Episode 64300 | Reward: -11.952 | Epsilon: 0.0100 | Loss: 1046671.7500
Episode 64350 | Reward:  -8.286 | Epsilon: 0.0100 | Loss: 1105708.6250
Episode 64400 | Reward:  -9.730 | Epsilon: 0.0100 | Loss: 1023851.9375
Episode 64450 | Reward: -10.112 | Epsilon: 0.0100 | Loss: 1080370.2500
Episode 64500 | Reward:  -9.215 | Epsilon: 0.0100 | Loss: 1186449.6250
Episode 64550 | Reward: -13.395 | Epsilon: 0.0100 | Loss: 1234176.1250
Episode 64600 | Reward: -10.964 | Epsilon: 0.0100 | Loss: 1053632.5000
Episode 64650 | Reward: -10.838 | Epsilon: 0.0100 | Loss: 938506.0625
Episode 64700 | Reward: -11.036 | Epsilon: 0.0100 | Loss: 1219236.7500
Episode 64750 | Reward: -10.164 | Epsilon: 0.0100 | Loss: 1101042.1250
Episode 64800 | Reward: -14.416 | Epsilon: 0.0100 | Loss: 1198463.2500
Episode 64850 | Reward: -14.253 | Epsilon: 0.0100 | Loss: 1338801.3750
Episode 64900 | Reward: -15.137 | Epsilon: 0.0100 | Loss: 1644822.2500
Episode 64950 | Reward: -12.729 | Epsilon: 0.0100 | Loss: 1077651.5000
Episode 65000 | Reward: -12.777 | Epsilon: 0.0100 | Loss: 1073489.8750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:24).dict
Episode 65050 | Reward: -14.110 | Epsilon: 0.0100 | Loss: 1160138.0000
Episode 65100 | Reward: -13.750 | Epsilon: 0.0100 | Loss: 1614953.1250
Episode 65150 | Reward: -13.331 | Epsilon: 0.0100 | Loss: 1328082.8750
Episode 65200 | Reward: -14.163 | Epsilon: 0.0100 | Loss: 1223697.3750
Episode 65250 | Reward: -14.772 | Epsilon: 0.0100 | Loss: 1184348.0000
Episode 65300 | Reward: -10.576 | Epsilon: 0.0100 | Loss: 1377697.7500
Episode 65350 | Reward: -13.040 | Epsilon: 0.0100 | Loss: 1197293.1250
Episode 65400 | Reward: -16.753 | Epsilon: 0.0100 | Loss: 1431197.1250
Episode 65450 | Reward: -16.478 | Epsilon: 0.0100 | Loss: 1439911.5000
Episode 65500 | Reward: -18.372 | Epsilon: 0.0100 | Loss: 1263166.0000
Episode 65550 | Reward: -10.628 | Epsilon: 0.0100 | Loss: 1652417.7500
Episode 65600 | Reward:  -8.875 | Epsilon: 0.0100 | Loss: 1203614.5000
Episode 65650 | Reward: -12.650 | Epsilon: 0.0100 | Loss: 1606597.1250
Episode 65700 | Reward:  -9.218 | Epsilon: 0.0100 | Loss: 1025740.6250
Episode 65750 | Reward:  -7.106 | Epsilon: 0.0100 | Loss: 1340396.6250
Episode 65800 | Reward:  -5.958 | Epsilon: 0.0100 | Loss: 1536619.5000
Episode 65850 | Reward:  -8.318 | Epsilon: 0.0100 | Loss: 1408167.7500
Episode 65900 | Reward:  -6.601 | Epsilon: 0.0100 | Loss: 932679.3125
Episode 65950 | Reward: -11.080 | Epsilon: 0.0100 | Loss: 1525058.8750
Episode 66000 | Reward: -10.503 | Epsilon: 0.0100 | Loss: 1648264.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:28).dict
Episode 66050 | Reward: -11.545 | Epsilon: 0.0100 | Loss: 1498014.0000
Episode 66100 | Reward: -11.323 | Epsilon: 0.0100 | Loss: 1270686.5000
Episode 66150 | Reward: -12.682 | Epsilon: 0.0100 | Loss: 1046476.6875
Episode 66200 | Reward:  -9.715 | Epsilon: 0.0100 | Loss: 1369944.6250
Episode 66250 | Reward: -12.598 | Epsilon: 0.0100 | Loss: 1845370.5000
Episode 66300 | Reward: -12.210 | Epsilon: 0.0100 | Loss: 1790594.1250
Episode 66350 | Reward: -13.268 | Epsilon: 0.0100 | Loss: 1245712.6250
Episode 66400 | Reward: -11.150 | Epsilon: 0.0100 | Loss: 1206564.0000
Episode 66450 | Reward:  -9.932 | Epsilon: 0.0100 | Loss: 1321998.7500
Episode 66500 | Reward: -12.887 | Epsilon: 0.0100 | Loss: 1920188.6250
Episode 66550 | Reward: -10.785 | Epsilon: 0.0100 | Loss: 1353097.8750
Episode 66600 | Reward: -16.655 | Epsilon: 0.0100 | Loss: 1726721.2500
Episode 66650 | Reward:  -9.117 | Epsilon: 0.0100 | Loss: 1256700.2500
Episode 66700 | Reward: -13.665 | Epsilon: 0.0100 | Loss: 1305710.1250
Episode 66750 | Reward: -11.424 | Epsilon: 0.0100 | Loss: 1169802.7500
Episode 66800 | Reward: -11.485 | Epsilon: 0.0100 | Loss: 1287774.2500
Episode 66850 | Reward: -13.780 | Epsilon: 0.0100 | Loss: 1406587.0000
Episode 66900 | Reward: -12.319 | Epsilon: 0.0100 | Loss: 1407967.7500
Episode 66950 | Reward: -15.215 | Epsilon: 0.0100 | Loss: 1146576.6250
Episode 67000 | Reward: -15.545 | Epsilon: 0.0100 | Loss: 1215551.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:32).dict
Episode 67050 | Reward: -16.599 | Epsilon: 0.0100 | Loss: 1235151.5000
Episode 67100 | Reward: -13.537 | Epsilon: 0.0100 | Loss: 1426277.8750
Episode 67150 | Reward: -10.324 | Epsilon: 0.0100 | Loss: 1241535.7500
Episode 67200 | Reward: -13.866 | Epsilon: 0.0100 | Loss: 1671907.0000
Episode 67250 | Reward: -13.412 | Epsilon: 0.0100 | Loss: 1716569.2500
Episode 67300 | Reward:  -9.008 | Epsilon: 0.0100 | Loss: 1142247.0000
Episode 67350 | Reward: -13.491 | Epsilon: 0.0100 | Loss: 1067158.1250
Episode 67400 | Reward: -11.857 | Epsilon: 0.0100 | Loss: 1674020.8750
Episode 67450 | Reward: -11.245 | Epsilon: 0.0100 | Loss: 1457279.1250
Episode 67500 | Reward: -10.444 | Epsilon: 0.0100 | Loss: 1411896.0000
Episode 67550 | Reward: -12.706 | Epsilon: 0.0100 | Loss: 1056967.2500
Episode 67600 | Reward: -13.512 | Epsilon: 0.0100 | Loss: 1205226.5000
Episode 67650 | Reward:  -7.925 | Epsilon: 0.0100 | Loss: 1414054.7500
Episode 67700 | Reward: -12.062 | Epsilon: 0.0100 | Loss: 1305762.5000
Episode 67750 | Reward: -13.185 | Epsilon: 0.0100 | Loss: 1330844.7500
Episode 67800 | Reward: -14.078 | Epsilon: 0.0100 | Loss: 982504.8750
Episode 67850 | Reward: -13.876 | Epsilon: 0.0100 | Loss: 1003535.8125
Episode 67900 | Reward:  -9.815 | Epsilon: 0.0100 | Loss: 1135144.7500
Episode 67950 | Reward: -13.571 | Epsilon: 0.0100 | Loss: 999230.1250
Episode 68000 | Reward: -11.663 | Epsilon: 0.0100 | Loss: 1153484.6250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:36).dict
Episode 68050 | Reward: -13.037 | Epsilon: 0.0100 | Loss: 992882.3125
Episode 68100 | Reward:  -9.822 | Epsilon: 0.0100 | Loss: 1193637.6250
Episode 68150 | Reward: -14.127 | Epsilon: 0.0100 | Loss: 926877.3125
Episode 68200 | Reward: -16.902 | Epsilon: 0.0100 | Loss: 1428711.3750
Episode 68250 | Reward: -14.486 | Epsilon: 0.0100 | Loss: 911775.9375
Episode 68300 | Reward: -14.728 | Epsilon: 0.0100 | Loss: 1184674.1250
Episode 68350 | Reward: -16.896 | Epsilon: 0.0100 | Loss: 1042177.6250
Episode 68400 | Reward: -17.392 | Epsilon: 0.0100 | Loss: 757442.7500
Episode 68450 | Reward: -13.750 | Epsilon: 0.0100 | Loss: 1122684.7500
Episode 68500 | Reward:  -8.616 | Epsilon: 0.0100 | Loss: 1190554.7500
Episode 68550 | Reward:  -8.928 | Epsilon: 0.0100 | Loss: 1117072.6250
Episode 68600 | Reward: -11.548 | Epsilon: 0.0100 | Loss: 1191316.0000
Episode 68650 | Reward: -11.092 | Epsilon: 0.0100 | Loss: 1271688.0000
Episode 68700 | Reward:  -9.623 | Epsilon: 0.0100 | Loss: 829480.3750
Episode 68750 | Reward: -11.869 | Epsilon: 0.0100 | Loss: 1130239.5000
Episode 68800 | Reward: -11.893 | Epsilon: 0.0100 | Loss: 783767.8750
Episode 68850 | Reward:  -9.678 | Epsilon: 0.0100 | Loss: 713747.7500
Episode 68900 | Reward: -14.349 | Epsilon: 0.0100 | Loss: 1429833.7500
Episode 68950 | Reward: -18.293 | Epsilon: 0.0100 | Loss: 1177482.6250
Episode 69000 | Reward: -15.424 | Epsilon: 0.0100 | Loss: 922917.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:40).dict
Episode 69050 | Reward: -15.225 | Epsilon: 0.0100 | Loss: 1093720.3750
Episode 69100 | Reward: -13.648 | Epsilon: 0.0100 | Loss: 914488.0000
Episode 69150 | Reward: -13.049 | Epsilon: 0.0100 | Loss: 826196.2500
Episode 69200 | Reward: -12.322 | Epsilon: 0.0100 | Loss: 825246.5625
Episode 69250 | Reward: -12.873 | Epsilon: 0.0100 | Loss: 972523.1875
Episode 69300 | Reward:  -8.975 | Epsilon: 0.0100 | Loss: 1039708.0625
Episode 69350 | Reward: -14.114 | Epsilon: 0.0100 | Loss: 996237.1875
Episode 69400 | Reward: -13.750 | Epsilon: 0.0100 | Loss: 765385.4375
Episode 69450 | Reward: -12.349 | Epsilon: 0.0100 | Loss: 1008104.7500
Episode 69500 | Reward:  -9.830 | Epsilon: 0.0100 | Loss: 926967.3125
Episode 69550 | Reward:  -9.928 | Epsilon: 0.0100 | Loss: 1140301.1250
Episode 69600 | Reward: -11.263 | Epsilon: 0.0100 | Loss: 894302.0000
Episode 69650 | Reward:  -9.211 | Epsilon: 0.0100 | Loss: 1218306.8750
Episode 69700 | Reward: -11.947 | Epsilon: 0.0100 | Loss: 855799.0000
Episode 69750 | Reward: -13.746 | Epsilon: 0.0100 | Loss: 947769.3750
Episode 69800 | Reward: -11.418 | Epsilon: 0.0100 | Loss: 962223.3125
Episode 69850 | Reward: -11.147 | Epsilon: 0.0100 | Loss: 880151.7500
Episode 69900 | Reward: -13.248 | Epsilon: 0.0100 | Loss: 814450.5000
Episode 69950 | Reward: -13.889 | Epsilon: 0.0100 | Loss: 820783.7500
Episode 70000 | Reward: -11.985 | Epsilon: 0.0100 | Loss: 1119446.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:44).dict
Episode 70050 | Reward: -11.696 | Epsilon: 0.0100 | Loss: 972667.5625
Episode 70100 | Reward: -11.217 | Epsilon: 0.0100 | Loss: 918446.5000
Episode 70150 | Reward: -13.099 | Epsilon: 0.0100 | Loss: 1183638.2500
Episode 70200 | Reward: -14.949 | Epsilon: 0.0100 | Loss: 1068325.2500
Episode 70250 | Reward: -12.414 | Epsilon: 0.0100 | Loss: 1345435.8750
Episode 70300 | Reward:  -9.363 | Epsilon: 0.0100 | Loss: 1061845.1250
Episode 70350 | Reward: -12.785 | Epsilon: 0.0100 | Loss: 1040614.8750
Episode 70400 | Reward: -12.728 | Epsilon: 0.0100 | Loss: 1351929.7500
Episode 70450 | Reward: -10.538 | Epsilon: 0.0100 | Loss: 1043561.8750
Episode 70500 | Reward: -10.228 | Epsilon: 0.0100 | Loss: 987601.0000
Episode 70550 | Reward: -11.270 | Epsilon: 0.0100 | Loss: 1045651.3125
Episode 70600 | Reward:  -8.068 | Epsilon: 0.0100 | Loss: 847647.4375
Episode 70650 | Reward: -11.027 | Epsilon: 0.0100 | Loss: 999579.4375
Episode 70700 | Reward:  -7.662 | Epsilon: 0.0100 | Loss: 1047725.0000
Episode 70750 | Reward: -14.318 | Epsilon: 0.0100 | Loss: 1127777.7500
Episode 70800 | Reward: -11.932 | Epsilon: 0.0100 | Loss: 1097774.0000
Episode 70850 | Reward:  -7.586 | Epsilon: 0.0100 | Loss: 1156390.1250
Episode 70900 | Reward: -10.120 | Epsilon: 0.0100 | Loss: 787807.5000
Episode 70950 | Reward: -10.544 | Epsilon: 0.0100 | Loss: 1088124.2500
Episode 71000 | Reward:  -7.131 | Epsilon: 0.0100 | Loss: 1266917.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:48).dict
Episode 71050 | Reward:  -8.110 | Epsilon: 0.0100 | Loss: 981386.5625
Episode 71100 | Reward: -10.924 | Epsilon: 0.0100 | Loss: 1087775.2500
Episode 71150 | Reward: -13.762 | Epsilon: 0.0100 | Loss: 815371.5000
Episode 71200 | Reward: -10.107 | Epsilon: 0.0100 | Loss: 1284143.1250
Episode 71250 | Reward: -14.662 | Epsilon: 0.0100 | Loss: 1077385.0000
Episode 71300 | Reward: -10.511 | Epsilon: 0.0100 | Loss: 877078.5000
Episode 71350 | Reward:  -7.548 | Epsilon: 0.0100 | Loss: 1526164.2500
Episode 71400 | Reward: -11.774 | Epsilon: 0.0100 | Loss: 1003380.6250
Episode 71450 | Reward: -13.004 | Epsilon: 0.0100 | Loss: 1418505.0000
Episode 71500 | Reward: -12.247 | Epsilon: 0.0100 | Loss: 917914.4375
Episode 71550 | Reward: -15.472 | Epsilon: 0.0100 | Loss: 1198955.3750
Episode 71600 | Reward:  -9.690 | Epsilon: 0.0100 | Loss: 1259562.1250
Episode 71650 | Reward: -14.236 | Epsilon: 0.0100 | Loss: 1174153.2500
Episode 71700 | Reward: -13.684 | Epsilon: 0.0100 | Loss: 1432162.2500
Episode 71750 | Reward: -13.416 | Epsilon: 0.0100 | Loss: 1184927.2500
Episode 71800 | Reward: -12.663 | Epsilon: 0.0100 | Loss: 926470.6250
Episode 71850 | Reward: -13.187 | Epsilon: 0.0100 | Loss: 1150219.2500
Episode 71900 | Reward: -12.286 | Epsilon: 0.0100 | Loss: 1267416.1250
Episode 71950 | Reward: -11.480 | Epsilon: 0.0100 | Loss: 960393.6250
Episode 72000 | Reward: -13.269 | Epsilon: 0.0100 | Loss: 1279880.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:52).dict
Episode 72050 | Reward: -13.251 | Epsilon: 0.0100 | Loss: 939434.3750
Episode 72100 | Reward:  -8.433 | Epsilon: 0.0100 | Loss: 858712.2500
Episode 72150 | Reward: -14.100 | Epsilon: 0.0100 | Loss: 1260376.5000
Episode 72200 | Reward: -11.798 | Epsilon: 0.0100 | Loss: 921632.1250
Episode 72250 | Reward: -13.092 | Epsilon: 0.0100 | Loss: 977822.2500
Episode 72300 | Reward: -11.269 | Epsilon: 0.0100 | Loss: 1025844.9375
Episode 72350 | Reward: -11.297 | Epsilon: 0.0100 | Loss: 842023.0000
Episode 72400 | Reward:  -7.582 | Epsilon: 0.0100 | Loss: 933372.9375
Episode 72450 | Reward: -12.434 | Epsilon: 0.0100 | Loss: 555092.8125
Episode 72500 | Reward: -14.241 | Epsilon: 0.0100 | Loss: 849346.8750
Episode 72550 | Reward: -17.016 | Epsilon: 0.0100 | Loss: 564579.0625
Episode 72600 | Reward: -14.552 | Epsilon: 0.0100 | Loss: 812752.3750
Episode 72650 | Reward:  -9.689 | Epsilon: 0.0100 | Loss: 778096.1250
Episode 72700 | Reward: -13.003 | Epsilon: 0.0100 | Loss: 941457.3125
Episode 72750 | Reward: -13.184 | Epsilon: 0.0100 | Loss: 694128.9375
Episode 72800 | Reward: -13.963 | Epsilon: 0.0100 | Loss: 971374.5000
Episode 72850 | Reward: -11.202 | Epsilon: 0.0100 | Loss: 863201.1250
Episode 72900 | Reward: -10.798 | Epsilon: 0.0100 | Loss: 677541.6250
Episode 72950 | Reward: -14.792 | Epsilon: 0.0100 | Loss: 713254.6250
Episode 73000 | Reward: -15.422 | Epsilon: 0.0100 | Loss: 894679.3125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(05:56).dict
Episode 73050 | Reward: -16.963 | Epsilon: 0.0100 | Loss: 812232.1250
Episode 73100 | Reward: -12.741 | Epsilon: 0.0100 | Loss: 727125.4375
Episode 73150 | Reward: -10.404 | Epsilon: 0.0100 | Loss: 489809.7188
Episode 73200 | Reward: -12.043 | Epsilon: 0.0100 | Loss: 713892.5000
Episode 73250 | Reward: -13.300 | Epsilon: 0.0100 | Loss: 669080.1875
Episode 73300 | Reward: -10.613 | Epsilon: 0.0100 | Loss: 539689.9375
Episode 73350 | Reward:  -9.600 | Epsilon: 0.0100 | Loss: 673401.8750
Episode 73400 | Reward: -15.039 | Epsilon: 0.0100 | Loss: 508598.6250
Episode 73450 | Reward: -12.722 | Epsilon: 0.0100 | Loss: 795940.5000
Episode 73500 | Reward:  -8.954 | Epsilon: 0.0100 | Loss: 656043.1875
Episode 73550 | Reward: -12.269 | Epsilon: 0.0100 | Loss: 708988.5000
Episode 73600 | Reward: -12.521 | Epsilon: 0.0100 | Loss: 670982.3750
Episode 73650 | Reward: -12.038 | Epsilon: 0.0100 | Loss: 666247.6250
Episode 73700 | Reward: -13.663 | Epsilon: 0.0100 | Loss: 598932.5000
Episode 73750 | Reward: -10.220 | Epsilon: 0.0100 | Loss: 529180.6250
Episode 73800 | Reward: -13.457 | Epsilon: 0.0100 | Loss: 648413.8125
Episode 73850 | Reward: -13.249 | Epsilon: 0.0100 | Loss: 637920.3125
Episode 73900 | Reward: -11.727 | Epsilon: 0.0100 | Loss: 542909.5000
Episode 73950 | Reward:  -8.266 | Epsilon: 0.0100 | Loss: 416607.8438
Episode 74000 | Reward: -11.009 | Epsilon: 0.0100 | Loss: 656465.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:00).dict
Episode 74050 | Reward: -15.000 | Epsilon: 0.0100 | Loss: 567606.3750
Episode 74100 | Reward: -12.700 | Epsilon: 0.0100 | Loss: 518345.6875
Episode 74150 | Reward: -12.315 | Epsilon: 0.0100 | Loss: 644262.8125
Episode 74200 | Reward: -12.030 | Epsilon: 0.0100 | Loss: 693002.6250
Episode 74250 | Reward: -11.215 | Epsilon: 0.0100 | Loss: 626209.1250
Episode 74300 | Reward: -12.511 | Epsilon: 0.0100 | Loss: 588252.0000
Episode 74350 | Reward: -10.474 | Epsilon: 0.0100 | Loss: 456599.5938
Episode 74400 | Reward: -10.119 | Epsilon: 0.0100 | Loss: 414878.2188
Episode 74450 | Reward: -12.679 | Epsilon: 0.0100 | Loss: 495165.7812
Episode 74500 | Reward: -10.930 | Epsilon: 0.0100 | Loss: 437275.0938
Episode 74550 | Reward: -11.500 | Epsilon: 0.0100 | Loss: 590608.6250
Episode 74600 | Reward:  -9.420 | Epsilon: 0.0100 | Loss: 596574.0000
Episode 74650 | Reward: -12.460 | Epsilon: 0.0100 | Loss: 622419.0625
Episode 74700 | Reward:  -8.578 | Epsilon: 0.0100 | Loss: 589614.8750
Episode 74750 | Reward: -17.279 | Epsilon: 0.0100 | Loss: 473354.9375
Episode 74800 | Reward: -10.861 | Epsilon: 0.0100 | Loss: 533559.0000
Episode 74850 | Reward:  -7.788 | Epsilon: 0.0100 | Loss: 462807.0938
Episode 74900 | Reward: -12.535 | Epsilon: 0.0100 | Loss: 439719.1562
Episode 74950 | Reward: -11.420 | Epsilon: 0.0100 | Loss: 538983.7500
Episode 75000 | Reward: -11.621 | Epsilon: 0.0100 | Loss: 484495.7812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:04).dict
Episode 75050 | Reward:  -8.850 | Epsilon: 0.0100 | Loss: 534598.0000
Episode 75100 | Reward: -12.987 | Epsilon: 0.0100 | Loss: 494165.6250
Episode 75150 | Reward: -10.438 | Epsilon: 0.0100 | Loss: 398742.9375
Episode 75200 | Reward: -10.614 | Epsilon: 0.0100 | Loss: 466026.2812
Episode 75250 | Reward: -10.742 | Epsilon: 0.0100 | Loss: 513974.4688
Episode 75300 | Reward: -13.072 | Epsilon: 0.0100 | Loss: 646055.8750
Episode 75350 | Reward: -12.020 | Epsilon: 0.0100 | Loss: 494025.8750
Episode 75400 | Reward: -12.653 | Epsilon: 0.0100 | Loss: 561141.9375
Episode 75450 | Reward:  -7.999 | Epsilon: 0.0100 | Loss: 413326.5000
Episode 75500 | Reward:  -6.867 | Epsilon: 0.0100 | Loss: 517532.2812
Episode 75550 | Reward: -13.753 | Epsilon: 0.0100 | Loss: 499761.8125
Episode 75600 | Reward:  -7.383 | Epsilon: 0.0100 | Loss: 441456.5938
Episode 75650 | Reward: -15.137 | Epsilon: 0.0100 | Loss: 495075.9688
Episode 75700 | Reward: -15.466 | Epsilon: 0.0100 | Loss: 552917.6250
Episode 75750 | Reward: -14.989 | Epsilon: 0.0100 | Loss: 409345.5312
Episode 75800 | Reward: -12.915 | Epsilon: 0.0100 | Loss: 451897.5625
Episode 75850 | Reward:  -9.366 | Epsilon: 0.0100 | Loss: 413242.9062
Episode 75900 | Reward: -13.305 | Epsilon: 0.0100 | Loss: 476104.5312
Episode 75950 | Reward:  -9.359 | Epsilon: 0.0100 | Loss: 686990.0000
Episode 76000 | Reward: -13.551 | Epsilon: 0.0100 | Loss: 461353.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:08).dict
Episode 76050 | Reward: -13.933 | Epsilon: 0.0100 | Loss: 550879.0625
Episode 76100 | Reward: -14.400 | Epsilon: 0.0100 | Loss: 496490.3438
Episode 76150 | Reward: -14.927 | Epsilon: 0.0100 | Loss: 435120.3750
Episode 76200 | Reward: -12.784 | Epsilon: 0.0100 | Loss: 412621.3125
Episode 76250 | Reward: -10.346 | Epsilon: 0.0100 | Loss: 508171.3125
Episode 76300 | Reward: -10.144 | Epsilon: 0.0100 | Loss: 470726.4375
Episode 76350 | Reward: -10.242 | Epsilon: 0.0100 | Loss: 530311.0625
Episode 76400 | Reward: -13.394 | Epsilon: 0.0100 | Loss: 545991.3125
Episode 76450 | Reward: -16.361 | Epsilon: 0.0100 | Loss: 413182.8438
Episode 76500 | Reward: -14.869 | Epsilon: 0.0100 | Loss: 297426.9062
Episode 76550 | Reward: -13.247 | Epsilon: 0.0100 | Loss: 453944.8438
Episode 76600 | Reward: -13.692 | Epsilon: 0.0100 | Loss: 591870.2500
Episode 76650 | Reward: -12.754 | Epsilon: 0.0100 | Loss: 540661.3750
Episode 76700 | Reward: -14.027 | Epsilon: 0.0100 | Loss: 441743.6875
Episode 76750 | Reward: -12.741 | Epsilon: 0.0100 | Loss: 499096.7188
Episode 76800 | Reward: -11.652 | Epsilon: 0.0100 | Loss: 456650.7188
Episode 76850 | Reward:  -8.168 | Epsilon: 0.0100 | Loss: 487656.7500
Episode 76900 | Reward:  -9.685 | Epsilon: 0.0100 | Loss: 387745.0938
Episode 76950 | Reward: -10.347 | Epsilon: 0.0100 | Loss: 450520.2500
Episode 77000 | Reward: -12.484 | Epsilon: 0.0100 | Loss: 550428.6875
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:12).dict
Episode 77050 | Reward: -15.067 | Epsilon: 0.0100 | Loss: 437296.6250
Episode 77100 | Reward:  -9.150 | Epsilon: 0.0100 | Loss: 408457.9375
Episode 77150 | Reward: -16.832 | Epsilon: 0.0100 | Loss: 511802.6562
Episode 77200 | Reward: -17.010 | Epsilon: 0.0100 | Loss: 492255.2188
Episode 77250 | Reward: -13.822 | Epsilon: 0.0100 | Loss: 498127.8750
Episode 77300 | Reward: -10.758 | Epsilon: 0.0100 | Loss: 429136.6875
Episode 77350 | Reward: -17.021 | Epsilon: 0.0100 | Loss: 578866.6250
Episode 77400 | Reward: -17.003 | Epsilon: 0.0100 | Loss: 424854.6250
Episode 77450 | Reward: -16.307 | Epsilon: 0.0100 | Loss: 445049.0938
Episode 77500 | Reward: -15.467 | Epsilon: 0.0100 | Loss: 652386.5000
Episode 77550 | Reward: -18.918 | Epsilon: 0.0100 | Loss: 531931.6875
Episode 77600 | Reward: -13.941 | Epsilon: 0.0100 | Loss: 442418.8438
Episode 77650 | Reward: -11.036 | Epsilon: 0.0100 | Loss: 421371.8750
Episode 77700 | Reward: -14.276 | Epsilon: 0.0100 | Loss: 383052.0625
Episode 77750 | Reward: -12.524 | Epsilon: 0.0100 | Loss: 454407.2500
Episode 77800 | Reward: -12.111 | Epsilon: 0.0100 | Loss: 537446.3750
Episode 77850 | Reward: -17.554 | Epsilon: 0.0100 | Loss: 508083.0000
Episode 77900 | Reward: -11.300 | Epsilon: 0.0100 | Loss: 524956.4375
Episode 77950 | Reward: -14.276 | Epsilon: 0.0100 | Loss: 589889.6875
Episode 78000 | Reward: -10.487 | Epsilon: 0.0100 | Loss: 620391.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:16).dict
Episode 78050 | Reward: -11.768 | Epsilon: 0.0100 | Loss: 557882.3750
Episode 78100 | Reward: -15.821 | Epsilon: 0.0100 | Loss: 465573.1875
Episode 78150 | Reward: -16.667 | Epsilon: 0.0100 | Loss: 622402.4375
Episode 78200 | Reward: -18.152 | Epsilon: 0.0100 | Loss: 732571.1250
Episode 78250 | Reward: -14.430 | Epsilon: 0.0100 | Loss: 483125.3125
Episode 78300 | Reward: -11.856 | Epsilon: 0.0100 | Loss: 579184.3125
Episode 78350 | Reward: -13.637 | Epsilon: 0.0100 | Loss: 543749.1250
Episode 78400 | Reward: -12.787 | Epsilon: 0.0100 | Loss: 538198.5000
Episode 78450 | Reward: -12.219 | Epsilon: 0.0100 | Loss: 506398.0000
Episode 78500 | Reward: -11.111 | Epsilon: 0.0100 | Loss: 555494.5625
Episode 78550 | Reward: -12.587 | Epsilon: 0.0100 | Loss: 622215.3125
Episode 78600 | Reward: -12.335 | Epsilon: 0.0100 | Loss: 563624.6250
Episode 78650 | Reward: -10.094 | Epsilon: 0.0100 | Loss: 615519.8750
Episode 78700 | Reward: -13.270 | Epsilon: 0.0100 | Loss: 598603.0000
Episode 78750 | Reward:  -6.428 | Epsilon: 0.0100 | Loss: 393374.4375
Episode 78800 | Reward: -11.230 | Epsilon: 0.0100 | Loss: 655085.5625
Episode 78850 | Reward: -13.126 | Epsilon: 0.0100 | Loss: 508317.4375
Episode 78900 | Reward: -16.248 | Epsilon: 0.0100 | Loss: 532058.0000
Episode 78950 | Reward: -15.382 | Epsilon: 0.0100 | Loss: 672846.8750
Episode 79000 | Reward: -12.150 | Epsilon: 0.0100 | Loss: 631264.5000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:20).dict
Episode 79050 | Reward: -14.316 | Epsilon: 0.0100 | Loss: 526347.1250
Episode 79100 | Reward: -12.886 | Epsilon: 0.0100 | Loss: 560735.5625
Episode 79150 | Reward: -10.941 | Epsilon: 0.0100 | Loss: 487056.2500
Episode 79200 | Reward: -10.721 | Epsilon: 0.0100 | Loss: 636771.3750
Episode 79250 | Reward: -13.243 | Epsilon: 0.0100 | Loss: 481106.2500
Episode 79300 | Reward: -11.683 | Epsilon: 0.0100 | Loss: 723306.6875
Episode 79350 | Reward:  -9.950 | Epsilon: 0.0100 | Loss: 530081.2500
Episode 79400 | Reward: -13.475 | Epsilon: 0.0100 | Loss: 515843.8125
Episode 79450 | Reward: -11.076 | Epsilon: 0.0100 | Loss: 591796.3750
Episode 79500 | Reward: -12.259 | Epsilon: 0.0100 | Loss: 423872.5000
Episode 79550 | Reward: -15.870 | Epsilon: 0.0100 | Loss: 539156.6250
Episode 79600 | Reward: -14.335 | Epsilon: 0.0100 | Loss: 607082.5000
Episode 79650 | Reward: -14.996 | Epsilon: 0.0100 | Loss: 472635.9062
Episode 79700 | Reward: -14.339 | Epsilon: 0.0100 | Loss: 645790.3125
Episode 79750 | Reward: -13.383 | Epsilon: 0.0100 | Loss: 625512.9375
Episode 79800 | Reward: -13.233 | Epsilon: 0.0100 | Loss: 532962.6875
Episode 79850 | Reward: -13.863 | Epsilon: 0.0100 | Loss: 531051.6875
Episode 79900 | Reward: -13.772 | Epsilon: 0.0100 | Loss: 770301.3125
Episode 79950 | Reward:  -8.621 | Epsilon: 0.0100 | Loss: 619064.0625
Episode 80000 | Reward: -12.507 | Epsilon: 0.0100 | Loss: 542839.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:24).dict
Episode 80050 | Reward: -15.375 | Epsilon: 0.0100 | Loss: 539225.3750
Episode 80100 | Reward: -15.339 | Epsilon: 0.0100 | Loss: 571970.4375
Episode 80150 | Reward:  -9.033 | Epsilon: 0.0100 | Loss: 700243.8125
Episode 80200 | Reward: -13.353 | Epsilon: 0.0100 | Loss: 672367.9375
Episode 80250 | Reward: -11.905 | Epsilon: 0.0100 | Loss: 553606.3750
Episode 80300 | Reward: -10.529 | Epsilon: 0.0100 | Loss: 613216.8750
Episode 80350 | Reward: -13.646 | Epsilon: 0.0100 | Loss: 419432.6562
Episode 80400 | Reward: -12.295 | Epsilon: 0.0100 | Loss: 632326.8750
Episode 80450 | Reward: -16.049 | Epsilon: 0.0100 | Loss: 615538.3750
Episode 80500 | Reward: -14.350 | Epsilon: 0.0100 | Loss: 504523.1250
Episode 80550 | Reward: -13.337 | Epsilon: 0.0100 | Loss: 624838.0000
Episode 80600 | Reward: -11.806 | Epsilon: 0.0100 | Loss: 651573.4375
Episode 80650 | Reward: -13.544 | Epsilon: 0.0100 | Loss: 522107.3750
Episode 80700 | Reward: -11.803 | Epsilon: 0.0100 | Loss: 657906.9375
Episode 80750 | Reward:  -9.902 | Epsilon: 0.0100 | Loss: 756075.1875
Episode 80800 | Reward: -12.843 | Epsilon: 0.0100 | Loss: 575236.4375
Episode 80850 | Reward: -13.845 | Epsilon: 0.0100 | Loss: 521954.2188
Episode 80900 | Reward: -10.246 | Epsilon: 0.0100 | Loss: 552651.1250
Episode 80950 | Reward: -10.375 | Epsilon: 0.0100 | Loss: 619705.3750
Episode 81000 | Reward: -11.068 | Epsilon: 0.0100 | Loss: 540519.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:28).dict
Episode 81050 | Reward:  -7.300 | Epsilon: 0.0100 | Loss: 617326.1875
Episode 81100 | Reward: -10.611 | Epsilon: 0.0100 | Loss: 619296.0625
Episode 81150 | Reward: -13.771 | Epsilon: 0.0100 | Loss: 588432.3125
Episode 81200 | Reward: -10.392 | Epsilon: 0.0100 | Loss: 520632.8125
Episode 81250 | Reward: -11.120 | Epsilon: 0.0100 | Loss: 486850.0000
Episode 81300 | Reward:  -7.027 | Epsilon: 0.0100 | Loss: 537261.9375
Episode 81350 | Reward:  -9.855 | Epsilon: 0.0100 | Loss: 714355.8750
Episode 81400 | Reward: -12.354 | Epsilon: 0.0100 | Loss: 703640.8125
Episode 81450 | Reward: -12.430 | Epsilon: 0.0100 | Loss: 600657.6875
Episode 81500 | Reward: -10.850 | Epsilon: 0.0100 | Loss: 514961.8125
Episode 81550 | Reward: -10.075 | Epsilon: 0.0100 | Loss: 609180.2500
Episode 81600 | Reward:  -8.158 | Epsilon: 0.0100 | Loss: 537468.6250
Episode 81650 | Reward:  -9.318 | Epsilon: 0.0100 | Loss: 540978.4375
Episode 81700 | Reward: -12.533 | Epsilon: 0.0100 | Loss: 409194.8750
Episode 81750 | Reward: -14.440 | Epsilon: 0.0100 | Loss: 457904.4062
Episode 81800 | Reward: -11.690 | Epsilon: 0.0100 | Loss: 472694.3125
Episode 81850 | Reward: -10.980 | Epsilon: 0.0100 | Loss: 394143.3750
Episode 81900 | Reward:  -9.998 | Epsilon: 0.0100 | Loss: 588921.3750
Episode 81950 | Reward: -12.611 | Epsilon: 0.0100 | Loss: 427046.3125
Episode 82000 | Reward:  -9.350 | Epsilon: 0.0100 | Loss: 477462.1562
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:32).dict
Episode 82050 | Reward: -10.187 | Epsilon: 0.0100 | Loss: 484322.5000
Episode 82100 | Reward:  -9.827 | Epsilon: 0.0100 | Loss: 539484.1250
Episode 82150 | Reward: -12.478 | Epsilon: 0.0100 | Loss: 748265.5625
Episode 82200 | Reward:  -9.872 | Epsilon: 0.0100 | Loss: 388296.4688
Episode 82250 | Reward: -13.917 | Epsilon: 0.0100 | Loss: 432058.5938
Episode 82300 | Reward: -17.096 | Epsilon: 0.0100 | Loss: 448971.9375
Episode 82350 | Reward: -12.046 | Epsilon: 0.0100 | Loss: 468694.3125
Episode 82400 | Reward: -12.835 | Epsilon: 0.0100 | Loss: 508554.3125
Episode 82450 | Reward: -10.982 | Epsilon: 0.0100 | Loss: 477604.4062
Episode 82500 | Reward: -17.676 | Epsilon: 0.0100 | Loss: 485653.4375
Episode 82550 | Reward: -15.922 | Epsilon: 0.0100 | Loss: 503554.6250
Episode 82600 | Reward: -14.212 | Epsilon: 0.0100 | Loss: 531009.5000
Episode 82650 | Reward: -12.394 | Epsilon: 0.0100 | Loss: 530395.3125
Episode 82700 | Reward:  -9.904 | Epsilon: 0.0100 | Loss: 482477.2188
Episode 82750 | Reward: -14.879 | Epsilon: 0.0100 | Loss: 412194.2812
Episode 82800 | Reward: -12.983 | Epsilon: 0.0100 | Loss: 457097.4375
Episode 82850 | Reward: -11.380 | Epsilon: 0.0100 | Loss: 541823.1250
Episode 82900 | Reward: -13.505 | Epsilon: 0.0100 | Loss: 576116.0000
Episode 82950 | Reward: -11.528 | Epsilon: 0.0100 | Loss: 500523.7500
Episode 83000 | Reward: -15.578 | Epsilon: 0.0100 | Loss: 448647.7188
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:36).dict
Episode 83050 | Reward: -12.403 | Epsilon: 0.0100 | Loss: 383409.0625
Episode 83100 | Reward: -13.854 | Epsilon: 0.0100 | Loss: 580869.5000
Episode 83150 | Reward: -10.404 | Epsilon: 0.0100 | Loss: 432419.8125
Episode 83200 | Reward: -12.546 | Epsilon: 0.0100 | Loss: 437355.9062
Episode 83250 | Reward:  -8.327 | Epsilon: 0.0100 | Loss: 525909.0625
Episode 83300 | Reward: -13.184 | Epsilon: 0.0100 | Loss: 441860.0312
Episode 83350 | Reward:  -9.575 | Epsilon: 0.0100 | Loss: 333057.8750
Episode 83400 | Reward: -14.729 | Epsilon: 0.0100 | Loss: 398398.2500
Episode 83450 | Reward: -16.642 | Epsilon: 0.0100 | Loss: 540032.8125
Episode 83500 | Reward: -16.867 | Epsilon: 0.0100 | Loss: 404646.7812
Episode 83550 | Reward: -14.539 | Epsilon: 0.0100 | Loss: 420861.9688
Episode 83600 | Reward: -15.134 | Epsilon: 0.0100 | Loss: 574364.9375
Episode 83650 | Reward: -15.248 | Epsilon: 0.0100 | Loss: 399749.6875
Episode 83700 | Reward: -10.533 | Epsilon: 0.0100 | Loss: 459322.0625
Episode 83750 | Reward:  -9.526 | Epsilon: 0.0100 | Loss: 500486.8750
Episode 83800 | Reward: -13.079 | Epsilon: 0.0100 | Loss: 479104.7188
Episode 83850 | Reward: -13.382 | Epsilon: 0.0100 | Loss: 399185.8125
Episode 83900 | Reward: -13.233 | Epsilon: 0.0100 | Loss: 554943.2500
Episode 83950 | Reward: -10.869 | Epsilon: 0.0100 | Loss: 443262.9375
Episode 84000 | Reward: -10.108 | Epsilon: 0.0100 | Loss: 406800.7500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:40).dict
Episode 84050 | Reward: -10.754 | Epsilon: 0.0100 | Loss: 540095.9375
Episode 84100 | Reward: -14.466 | Epsilon: 0.0100 | Loss: 399120.3125
Episode 84150 | Reward: -17.492 | Epsilon: 0.0100 | Loss: 489406.1250
Episode 84200 | Reward: -14.728 | Epsilon: 0.0100 | Loss: 445886.1250
Episode 84250 | Reward: -11.179 | Epsilon: 0.0100 | Loss: 408636.0312
Episode 84300 | Reward: -15.475 | Epsilon: 0.0100 | Loss: 455686.5312
Episode 84350 | Reward: -14.483 | Epsilon: 0.0100 | Loss: 623616.8750
Episode 84400 | Reward: -13.941 | Epsilon: 0.0100 | Loss: 501736.8125
Episode 84450 | Reward: -16.957 | Epsilon: 0.0100 | Loss: 525334.5000
Episode 84500 | Reward: -12.883 | Epsilon: 0.0100 | Loss: 578317.7500
Episode 84550 | Reward: -10.829 | Epsilon: 0.0100 | Loss: 349582.8750
Episode 84600 | Reward: -13.963 | Epsilon: 0.0100 | Loss: 448471.6250
Episode 84650 | Reward: -11.833 | Epsilon: 0.0100 | Loss: 489889.6250
Episode 84700 | Reward: -10.565 | Epsilon: 0.0100 | Loss: 487628.0000
Episode 84750 | Reward:  -8.373 | Epsilon: 0.0100 | Loss: 614753.5000
Episode 84800 | Reward:  -9.545 | Epsilon: 0.0100 | Loss: 537052.9375
Episode 84850 | Reward: -12.436 | Epsilon: 0.0100 | Loss: 488470.9062
Episode 84900 | Reward: -13.827 | Epsilon: 0.0100 | Loss: 485524.8438
Episode 84950 | Reward: -13.574 | Epsilon: 0.0100 | Loss: 559686.3750
Episode 85000 | Reward: -13.273 | Epsilon: 0.0100 | Loss: 604940.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:44).dict
Episode 85050 | Reward: -14.153 | Epsilon: 0.0100 | Loss: 508731.2188
Episode 85100 | Reward: -10.714 | Epsilon: 0.0100 | Loss: 493416.6875
Episode 85150 | Reward:  -7.472 | Epsilon: 0.0100 | Loss: 465809.2812
Episode 85200 | Reward: -12.501 | Epsilon: 0.0100 | Loss: 391641.6875
Episode 85250 | Reward: -12.837 | Epsilon: 0.0100 | Loss: 371414.1250
Episode 85300 | Reward: -12.416 | Epsilon: 0.0100 | Loss: 499847.0312
Episode 85350 | Reward: -14.166 | Epsilon: 0.0100 | Loss: 491671.1250
Episode 85400 | Reward: -17.882 | Epsilon: 0.0100 | Loss: 392837.8125
Episode 85450 | Reward: -12.959 | Epsilon: 0.0100 | Loss: 440104.0938
Episode 85500 | Reward: -16.861 | Epsilon: 0.0100 | Loss: 660599.0625
Episode 85550 | Reward: -10.137 | Epsilon: 0.0100 | Loss: 618501.9375
Episode 85600 | Reward: -15.472 | Epsilon: 0.0100 | Loss: 463428.1875
Episode 85650 | Reward: -17.065 | Epsilon: 0.0100 | Loss: 574857.0000
Episode 85700 | Reward: -16.064 | Epsilon: 0.0100 | Loss: 605577.2500
Episode 85750 | Reward: -11.340 | Epsilon: 0.0100 | Loss: 566345.8125
Episode 85800 | Reward: -14.358 | Epsilon: 0.0100 | Loss: 535545.0000
Episode 85850 | Reward: -15.129 | Epsilon: 0.0100 | Loss: 579840.0625
Episode 85900 | Reward: -14.069 | Epsilon: 0.0100 | Loss: 605761.5625
Episode 85950 | Reward: -15.012 | Epsilon: 0.0100 | Loss: 592708.2500
Episode 86000 | Reward: -12.444 | Epsilon: 0.0100 | Loss: 461075.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:48).dict
Episode 86050 | Reward: -13.239 | Epsilon: 0.0100 | Loss: 578341.8125
Episode 86100 | Reward: -14.759 | Epsilon: 0.0100 | Loss: 492543.3125
Episode 86150 | Reward: -14.215 | Epsilon: 0.0100 | Loss: 523019.3125
Episode 86200 | Reward: -12.990 | Epsilon: 0.0100 | Loss: 441165.5625
Episode 86250 | Reward: -10.220 | Epsilon: 0.0100 | Loss: 538294.7500
Episode 86300 | Reward: -10.618 | Epsilon: 0.0100 | Loss: 497564.3125
Episode 86350 | Reward: -10.997 | Epsilon: 0.0100 | Loss: 539075.2500
Episode 86400 | Reward: -16.173 | Epsilon: 0.0100 | Loss: 549652.7500
Episode 86450 | Reward: -14.956 | Epsilon: 0.0100 | Loss: 356293.6875
Episode 86500 | Reward: -16.213 | Epsilon: 0.0100 | Loss: 492703.3125
Episode 86550 | Reward: -15.594 | Epsilon: 0.0100 | Loss: 449517.7812
Episode 86600 | Reward: -12.466 | Epsilon: 0.0100 | Loss: 510523.2188
Episode 86650 | Reward: -13.371 | Epsilon: 0.0100 | Loss: 375863.2500
Episode 86700 | Reward: -14.003 | Epsilon: 0.0100 | Loss: 534165.1250
Episode 86750 | Reward: -13.973 | Epsilon: 0.0100 | Loss: 404034.0625
Episode 86800 | Reward: -11.995 | Epsilon: 0.0100 | Loss: 502576.1562
Episode 86850 | Reward: -14.426 | Epsilon: 0.0100 | Loss: 504276.1250
Episode 86900 | Reward: -14.144 | Epsilon: 0.0100 | Loss: 424101.8438
Episode 86950 | Reward: -12.400 | Epsilon: 0.0100 | Loss: 603909.6250
Episode 87000 | Reward: -13.236 | Epsilon: 0.0100 | Loss: 493630.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:52).dict
Episode 87050 | Reward: -14.893 | Epsilon: 0.0100 | Loss: 672963.7500
Episode 87100 | Reward: -14.706 | Epsilon: 0.0100 | Loss: 414510.8125
Episode 87150 | Reward: -15.234 | Epsilon: 0.0100 | Loss: 486531.9375
Episode 87200 | Reward:  -7.579 | Epsilon: 0.0100 | Loss: 418448.3125
Episode 87250 | Reward: -10.305 | Epsilon: 0.0100 | Loss: 605369.3125
Episode 87300 | Reward: -12.204 | Epsilon: 0.0100 | Loss: 633913.1250
Episode 87350 | Reward: -12.014 | Epsilon: 0.0100 | Loss: 394129.7812
Episode 87400 | Reward: -12.319 | Epsilon: 0.0100 | Loss: 386045.6875
Episode 87450 | Reward: -15.484 | Epsilon: 0.0100 | Loss: 552837.8750
Episode 87500 | Reward: -11.649 | Epsilon: 0.0100 | Loss: 604487.7500
Episode 87550 | Reward: -13.610 | Epsilon: 0.0100 | Loss: 635843.2500
Episode 87600 | Reward: -13.728 | Epsilon: 0.0100 | Loss: 361627.4688
Episode 87650 | Reward: -12.374 | Epsilon: 0.0100 | Loss: 503405.9375
Episode 87700 | Reward: -10.097 | Epsilon: 0.0100 | Loss: 475495.6562
Episode 87750 | Reward: -14.260 | Epsilon: 0.0100 | Loss: 397420.1875
Episode 87800 | Reward: -13.520 | Epsilon: 0.0100 | Loss: 503141.6562
Episode 87850 | Reward: -12.782 | Epsilon: 0.0100 | Loss: 554734.5625
Episode 87900 | Reward: -12.274 | Epsilon: 0.0100 | Loss: 472270.4688
Episode 87950 | Reward: -13.306 | Epsilon: 0.0100 | Loss: 526001.5625
Episode 88000 | Reward: -13.295 | Epsilon: 0.0100 | Loss: 510639.2812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:56).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(06:56).dict
Episode 88050 | Reward:  -9.056 | Epsilon: 0.0100 | Loss: 585809.0000
Episode 88100 | Reward: -10.631 | Epsilon: 0.0100 | Loss: 518388.7812
Episode 88150 | Reward: -13.756 | Epsilon: 0.0100 | Loss: 623583.1875
Episode 88200 | Reward: -12.248 | Epsilon: 0.0100 | Loss: 410156.8125
Episode 88250 | Reward:  -8.446 | Epsilon: 0.0100 | Loss: 607139.5625
Episode 88300 | Reward: -11.033 | Epsilon: 0.0100 | Loss: 513561.8125
Episode 88350 | Reward: -10.434 | Epsilon: 0.0100 | Loss: 454243.3750
Episode 88400 | Reward: -11.408 | Epsilon: 0.0100 | Loss: 412435.2812
Episode 88450 | Reward:  -9.527 | Epsilon: 0.0100 | Loss: 600372.9375
Episode 88500 | Reward:  -9.287 | Epsilon: 0.0100 | Loss: 594233.4375
Episode 88550 | Reward: -11.013 | Epsilon: 0.0100 | Loss: 374787.6250
Episode 88600 | Reward: -12.449 | Epsilon: 0.0100 | Loss: 526477.4375
Episode 88650 | Reward:  -9.899 | Epsilon: 0.0100 | Loss: 508768.6875
Episode 88700 | Reward: -10.954 | Epsilon: 0.0100 | Loss: 452946.7188
Episode 88750 | Reward: -12.029 | Epsilon: 0.0100 | Loss: 606137.7500
Episode 88800 | Reward: -11.057 | Epsilon: 0.0100 | Loss: 437217.0625
Episode 88850 | Reward: -13.269 | Epsilon: 0.0100 | Loss: 565994.0000
Episode 88900 | Reward: -11.180 | Epsilon: 0.0100 | Loss: 369906.7812
Episode 88950 | Reward:  -9.819 | Epsilon: 0.0100 | Loss: 459856.3125
Episode 89000 | Reward: -10.624 | Epsilon: 0.0100 | Loss: 411050.4688
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:00).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:00).dict
Episode 89050 | Reward: -12.813 | Epsilon: 0.0100 | Loss: 575245.3750
Episode 89100 | Reward: -13.927 | Epsilon: 0.0100 | Loss: 462397.7188
Episode 89150 | Reward:  -8.602 | Epsilon: 0.0100 | Loss: 503792.5625
Episode 89200 | Reward: -14.974 | Epsilon: 0.0100 | Loss: 537365.2500
Episode 89250 | Reward: -15.029 | Epsilon: 0.0100 | Loss: 463760.1250
Episode 89300 | Reward: -14.574 | Epsilon: 0.0100 | Loss: 396843.0625
Episode 89350 | Reward: -17.506 | Epsilon: 0.0100 | Loss: 426338.5312
Episode 89400 | Reward: -17.134 | Epsilon: 0.0100 | Loss: 409404.8750
Episode 89450 | Reward: -17.027 | Epsilon: 0.0100 | Loss: 343881.3125
Episode 89500 | Reward: -14.905 | Epsilon: 0.0100 | Loss: 431778.7812
Episode 89550 | Reward: -12.919 | Epsilon: 0.0100 | Loss: 397673.4062
Episode 89600 | Reward: -14.440 | Epsilon: 0.0100 | Loss: 509534.2812
Episode 89650 | Reward: -13.687 | Epsilon: 0.0100 | Loss: 403943.9375
Episode 89700 | Reward:  -9.478 | Epsilon: 0.0100 | Loss: 355606.3750
Episode 89750 | Reward: -14.462 | Epsilon: 0.0100 | Loss: 507983.1562
Episode 89800 | Reward: -12.922 | Epsilon: 0.0100 | Loss: 446897.4688
Episode 89850 | Reward: -12.298 | Epsilon: 0.0100 | Loss: 349800.5000
Episode 89900 | Reward: -11.827 | Epsilon: 0.0100 | Loss: 397530.0312
Episode 89950 | Reward: -14.152 | Epsilon: 0.0100 | Loss: 409946.4375
Episode 90000 | Reward: -11.648 | Epsilon: 0.0100 | Loss: 405351.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:04).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:04).dict
Episode 90050 | Reward: -11.420 | Epsilon: 0.0100 | Loss: 357248.4375
Episode 90100 | Reward: -10.830 | Epsilon: 0.0100 | Loss: 391171.5000
Episode 90150 | Reward: -11.446 | Epsilon: 0.0100 | Loss: 390526.3125
Episode 90200 | Reward: -11.426 | Epsilon: 0.0100 | Loss: 487759.1875
Episode 90250 | Reward: -13.254 | Epsilon: 0.0100 | Loss: 456900.4062
Episode 90300 | Reward: -14.460 | Epsilon: 0.0100 | Loss: 424449.9062
Episode 90350 | Reward:  -9.813 | Epsilon: 0.0100 | Loss: 455851.2500
Episode 90400 | Reward: -12.604 | Epsilon: 0.0100 | Loss: 434206.2500
Episode 90450 | Reward: -15.596 | Epsilon: 0.0100 | Loss: 433215.9062
Episode 90500 | Reward:  -8.367 | Epsilon: 0.0100 | Loss: 445144.1875
Episode 90550 | Reward:  -8.277 | Epsilon: 0.0100 | Loss: 429990.8750
Episode 90600 | Reward:  -7.984 | Epsilon: 0.0100 | Loss: 509192.8750
Episode 90650 | Reward: -14.016 | Epsilon: 0.0100 | Loss: 462090.3125
Episode 90700 | Reward: -11.126 | Epsilon: 0.0100 | Loss: 398107.8125
Episode 90750 | Reward:  -8.369 | Epsilon: 0.0100 | Loss: 380089.1250
Episode 90800 | Reward: -14.980 | Epsilon: 0.0100 | Loss: 477197.6562
Episode 90850 | Reward: -11.352 | Epsilon: 0.0100 | Loss: 471372.2500
Episode 90900 | Reward: -14.056 | Epsilon: 0.0100 | Loss: 414989.1250
Episode 90950 | Reward: -13.820 | Epsilon: 0.0100 | Loss: 474505.4062
Episode 91000 | Reward:  -9.151 | Epsilon: 0.0100 | Loss: 390118.5312
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:08).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:08).dict
Episode 91050 | Reward: -12.520 | Epsilon: 0.0100 | Loss: 454950.2500
Episode 91100 | Reward: -12.741 | Epsilon: 0.0100 | Loss: 506063.0000
Episode 91150 | Reward: -16.320 | Epsilon: 0.0100 | Loss: 447362.3438
Episode 91200 | Reward: -16.724 | Epsilon: 0.0100 | Loss: 479922.2500
Episode 91250 | Reward: -13.734 | Epsilon: 0.0100 | Loss: 548345.6875
Episode 91300 | Reward: -15.321 | Epsilon: 0.0100 | Loss: 379692.3125
Episode 91350 | Reward: -12.733 | Epsilon: 0.0100 | Loss: 515671.2812
Episode 91400 | Reward:  -8.992 | Epsilon: 0.0100 | Loss: 427510.6562
Episode 91450 | Reward:  -8.245 | Epsilon: 0.0100 | Loss: 390393.0000
Episode 91500 | Reward:  -8.685 | Epsilon: 0.0100 | Loss: 366555.0625
Episode 91550 | Reward: -12.163 | Epsilon: 0.0100 | Loss: 429958.0625
Episode 91600 | Reward: -11.855 | Epsilon: 0.0100 | Loss: 393516.6250
Episode 91650 | Reward:  -9.909 | Epsilon: 0.0100 | Loss: 463713.0938
Episode 91700 | Reward:  -9.884 | Epsilon: 0.0100 | Loss: 498683.1562
Episode 91750 | Reward: -14.998 | Epsilon: 0.0100 | Loss: 417280.1562
Episode 91800 | Reward: -10.834 | Epsilon: 0.0100 | Loss: 332121.0625
Episode 91850 | Reward:  -8.754 | Epsilon: 0.0100 | Loss: 390616.4688
Episode 91900 | Reward:  -9.538 | Epsilon: 0.0100 | Loss: 327746.2188
Episode 91950 | Reward: -11.737 | Epsilon: 0.0100 | Loss: 410735.5312
Episode 92000 | Reward: -10.388 | Epsilon: 0.0100 | Loss: 295051.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:12).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:12).dict
Episode 92050 | Reward: -11.226 | Epsilon: 0.0100 | Loss: 459986.3750
Episode 92100 | Reward: -12.855 | Epsilon: 0.0100 | Loss: 383446.1250
Episode 92150 | Reward: -10.051 | Epsilon: 0.0100 | Loss: 476094.0000
Episode 92200 | Reward: -10.531 | Epsilon: 0.0100 | Loss: 382137.9688
Episode 92250 | Reward: -10.713 | Epsilon: 0.0100 | Loss: 333000.3125
Episode 92300 | Reward: -12.173 | Epsilon: 0.0100 | Loss: 372958.4375
Episode 92350 | Reward: -14.341 | Epsilon: 0.0100 | Loss: 466321.2812
Episode 92400 | Reward: -11.535 | Epsilon: 0.0100 | Loss: 230770.4219
Episode 92450 | Reward: -15.629 | Epsilon: 0.0100 | Loss: 466854.5000
Episode 92500 | Reward: -15.986 | Epsilon: 0.0100 | Loss: 371974.6562
Episode 92550 | Reward: -12.970 | Epsilon: 0.0100 | Loss: 423603.1875
Episode 92600 | Reward: -13.099 | Epsilon: 0.0100 | Loss: 358512.9375
Episode 92650 | Reward: -12.692 | Epsilon: 0.0100 | Loss: 464491.5312
Episode 92700 | Reward: -14.322 | Epsilon: 0.0100 | Loss: 368032.9375
Episode 92750 | Reward: -13.032 | Epsilon: 0.0100 | Loss: 417824.0938
Episode 92800 | Reward: -12.545 | Epsilon: 0.0100 | Loss: 472928.3750
Episode 92850 | Reward: -11.712 | Epsilon: 0.0100 | Loss: 334970.4375
Episode 92900 | Reward: -11.415 | Epsilon: 0.0100 | Loss: 392256.3750
Episode 92950 | Reward: -10.734 | Epsilon: 0.0100 | Loss: 453267.7500
Episode 93000 | Reward: -11.124 | Epsilon: 0.0100 | Loss: 446627.9062
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:16).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:16).dict
Episode 93050 | Reward: -13.267 | Epsilon: 0.0100 | Loss: 499876.0625
Episode 93100 | Reward:  -9.235 | Epsilon: 0.0100 | Loss: 387816.6875
Episode 93150 | Reward: -12.024 | Epsilon: 0.0100 | Loss: 417608.7812
Episode 93200 | Reward: -10.458 | Epsilon: 0.0100 | Loss: 483887.3438
Episode 93250 | Reward:  -8.709 | Epsilon: 0.0100 | Loss: 460116.9688
Episode 93300 | Reward:  -8.749 | Epsilon: 0.0100 | Loss: 517454.6875
Episode 93350 | Reward: -10.339 | Epsilon: 0.0100 | Loss: 400054.7188
Episode 93400 | Reward: -18.464 | Epsilon: 0.0100 | Loss: 614014.2500
Episode 93450 | Reward: -14.503 | Epsilon: 0.0100 | Loss: 462315.1875
Episode 93500 | Reward: -11.964 | Epsilon: 0.0100 | Loss: 464035.2500
Episode 93550 | Reward:  -9.075 | Epsilon: 0.0100 | Loss: 433985.7812
Episode 93600 | Reward: -12.819 | Epsilon: 0.0100 | Loss: 471097.9688
Episode 93650 | Reward: -10.934 | Epsilon: 0.0100 | Loss: 502841.5938
Episode 93700 | Reward:  -8.199 | Epsilon: 0.0100 | Loss: 411426.2188
Episode 93750 | Reward:  -8.723 | Epsilon: 0.0100 | Loss: 341710.3125
Episode 93800 | Reward: -12.288 | Epsilon: 0.0100 | Loss: 423475.3125
Episode 93850 | Reward: -14.048 | Epsilon: 0.0100 | Loss: 286723.4062
Episode 93900 | Reward: -15.551 | Epsilon: 0.0100 | Loss: 318465.5625
Episode 93950 | Reward: -14.778 | Epsilon: 0.0100 | Loss: 453737.0938
Episode 94000 | Reward: -11.358 | Epsilon: 0.0100 | Loss: 458205.2500
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:20).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:20).dict
Episode 94050 | Reward: -12.867 | Epsilon: 0.0100 | Loss: 336876.5938
Episode 94100 | Reward: -12.161 | Epsilon: 0.0100 | Loss: 359335.4688
Episode 94150 | Reward: -16.761 | Epsilon: 0.0100 | Loss: 493211.9062
Episode 94200 | Reward: -11.783 | Epsilon: 0.0100 | Loss: 381463.9688
Episode 94250 | Reward: -14.664 | Epsilon: 0.0100 | Loss: 378087.8125
Episode 94300 | Reward: -15.525 | Epsilon: 0.0100 | Loss: 435900.9062
Episode 94350 | Reward: -10.559 | Epsilon: 0.0100 | Loss: 472273.3750
Episode 94400 | Reward: -13.288 | Epsilon: 0.0100 | Loss: 470636.9375
Episode 94450 | Reward: -16.461 | Epsilon: 0.0100 | Loss: 450026.5938
Episode 94500 | Reward: -14.423 | Epsilon: 0.0100 | Loss: 411887.8125
Episode 94550 | Reward: -12.476 | Epsilon: 0.0100 | Loss: 369010.5000
Episode 94600 | Reward:  -8.789 | Epsilon: 0.0100 | Loss: 333390.8125
Episode 94650 | Reward: -10.564 | Epsilon: 0.0100 | Loss: 372831.0000
Episode 94700 | Reward: -12.754 | Epsilon: 0.0100 | Loss: 429812.4688
Episode 94750 | Reward: -13.388 | Epsilon: 0.0100 | Loss: 421430.6562
Episode 94800 | Reward: -14.237 | Epsilon: 0.0100 | Loss: 461271.5938
Episode 94850 | Reward: -12.584 | Epsilon: 0.0100 | Loss: 406046.7500
Episode 94900 | Reward: -11.984 | Epsilon: 0.0100 | Loss: 474866.1875
Episode 94950 | Reward:  -7.887 | Epsilon: 0.0100 | Loss: 443907.4688
Episode 95000 | Reward: -11.156 | Epsilon: 0.0100 | Loss: 536109.5625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:24).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:24).dict
Episode 95050 | Reward: -12.677 | Epsilon: 0.0100 | Loss: 364866.0938
Episode 95100 | Reward: -12.681 | Epsilon: 0.0100 | Loss: 371350.6875
Episode 95150 | Reward: -14.609 | Epsilon: 0.0100 | Loss: 449965.5625
Episode 95200 | Reward: -13.738 | Epsilon: 0.0100 | Loss: 311924.1875
Episode 95250 | Reward: -13.892 | Epsilon: 0.0100 | Loss: 450139.5625
Episode 95300 | Reward: -11.517 | Epsilon: 0.0100 | Loss: 330615.3438
Episode 95350 | Reward: -11.174 | Epsilon: 0.0100 | Loss: 344139.0000
Episode 95400 | Reward: -13.356 | Epsilon: 0.0100 | Loss: 358722.3750
Episode 95450 | Reward: -12.282 | Epsilon: 0.0100 | Loss: 420346.9375
Episode 95500 | Reward: -12.829 | Epsilon: 0.0100 | Loss: 354322.6875
Episode 95550 | Reward: -10.210 | Epsilon: 0.0100 | Loss: 448609.7188
Episode 95600 | Reward: -12.578 | Epsilon: 0.0100 | Loss: 411327.3438
Episode 95650 | Reward: -14.880 | Epsilon: 0.0100 | Loss: 370283.4062
Episode 95700 | Reward: -12.325 | Epsilon: 0.0100 | Loss: 375769.3438
Episode 95750 | Reward:  -6.358 | Epsilon: 0.0100 | Loss: 388321.5625
Episode 95800 | Reward:  -9.442 | Epsilon: 0.0100 | Loss: 350115.4375
Episode 95850 | Reward: -14.659 | Epsilon: 0.0100 | Loss: 501456.8750
Episode 95900 | Reward: -14.349 | Epsilon: 0.0100 | Loss: 359620.4688
Episode 95950 | Reward:  -9.139 | Epsilon: 0.0100 | Loss: 408196.7188
Episode 96000 | Reward: -15.942 | Epsilon: 0.0100 | Loss: 352303.4375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:28).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:28).dict
Episode 96050 | Reward: -13.288 | Epsilon: 0.0100 | Loss: 416401.2500
Episode 96100 | Reward: -17.524 | Epsilon: 0.0100 | Loss: 299913.2500
Episode 96150 | Reward:  -9.959 | Epsilon: 0.0100 | Loss: 292551.9375
Episode 96200 | Reward: -12.563 | Epsilon: 0.0100 | Loss: 432148.0000
Episode 96250 | Reward: -14.232 | Epsilon: 0.0100 | Loss: 313960.2188
Episode 96300 | Reward: -14.454 | Epsilon: 0.0100 | Loss: 366136.9375
Episode 96350 | Reward: -13.849 | Epsilon: 0.0100 | Loss: 395525.2500
Episode 96400 | Reward: -11.142 | Epsilon: 0.0100 | Loss: 417906.8750
Episode 96450 | Reward:  -9.569 | Epsilon: 0.0100 | Loss: 343236.6250
Episode 96500 | Reward: -14.461 | Epsilon: 0.0100 | Loss: 357126.5938
Episode 96550 | Reward: -12.453 | Epsilon: 0.0100 | Loss: 369008.4062
Episode 96600 | Reward: -14.871 | Epsilon: 0.0100 | Loss: 454324.1875
Episode 96650 | Reward: -10.711 | Epsilon: 0.0100 | Loss: 387896.7500
Episode 96700 | Reward: -12.087 | Epsilon: 0.0100 | Loss: 359882.4062
Episode 96750 | Reward: -11.407 | Epsilon: 0.0100 | Loss: 388027.6875
Episode 96800 | Reward: -12.753 | Epsilon: 0.0100 | Loss: 334313.2812
Episode 96850 | Reward: -14.513 | Epsilon: 0.0100 | Loss: 318921.6875
Episode 96900 | Reward: -14.553 | Epsilon: 0.0100 | Loss: 438542.8438
Episode 96950 | Reward: -11.708 | Epsilon: 0.0100 | Loss: 313467.5938
Episode 97000 | Reward: -12.198 | Epsilon: 0.0100 | Loss: 379642.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:32).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:32).dict
Episode 97050 | Reward: -15.497 | Epsilon: 0.0100 | Loss: 358612.2500
Episode 97100 | Reward: -13.296 | Epsilon: 0.0100 | Loss: 378229.1250
Episode 97150 | Reward: -15.607 | Epsilon: 0.0100 | Loss: 472812.4375
Episode 97200 | Reward: -12.340 | Epsilon: 0.0100 | Loss: 406071.0000
Episode 97250 | Reward: -11.862 | Epsilon: 0.0100 | Loss: 340079.4375
Episode 97300 | Reward: -13.279 | Epsilon: 0.0100 | Loss: 397241.5938
Episode 97350 | Reward: -10.482 | Epsilon: 0.0100 | Loss: 302162.3750
Episode 97400 | Reward: -14.196 | Epsilon: 0.0100 | Loss: 372489.9688
Episode 97450 | Reward: -15.424 | Epsilon: 0.0100 | Loss: 393592.7500
Episode 97500 | Reward: -11.141 | Epsilon: 0.0100 | Loss: 365049.4375
Episode 97550 | Reward:  -8.152 | Epsilon: 0.0100 | Loss: 387302.3125
Episode 97600 | Reward: -12.652 | Epsilon: 0.0100 | Loss: 270255.5625
Episode 97650 | Reward: -14.849 | Epsilon: 0.0100 | Loss: 321879.1562
Episode 97700 | Reward: -11.598 | Epsilon: 0.0100 | Loss: 308952.3438
Episode 97750 | Reward: -13.310 | Epsilon: 0.0100 | Loss: 446750.2188
Episode 97800 | Reward: -11.356 | Epsilon: 0.0100 | Loss: 394488.6250
Episode 97850 | Reward:  -8.453 | Epsilon: 0.0100 | Loss: 334902.9062
Episode 97900 | Reward: -10.710 | Epsilon: 0.0100 | Loss: 295240.0312
Episode 97950 | Reward: -12.658 | Epsilon: 0.0100 | Loss: 360066.2188
Episode 98000 | Reward:  -7.531 | Epsilon: 0.0100 | Loss: 314999.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:36).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:36).dict
Episode 98050 | Reward: -13.904 | Epsilon: 0.0100 | Loss: 339086.1562
Episode 98100 | Reward: -14.248 | Epsilon: 0.0100 | Loss: 259850.5000
Episode 98150 | Reward:  -9.476 | Epsilon: 0.0100 | Loss: 347144.8750
Episode 98200 | Reward:  -9.362 | Epsilon: 0.0100 | Loss: 390979.0312
Episode 98250 | Reward: -14.127 | Epsilon: 0.0100 | Loss: 267407.4375
Episode 98300 | Reward: -11.384 | Epsilon: 0.0100 | Loss: 376736.7812
Episode 98350 | Reward: -14.055 | Epsilon: 0.0100 | Loss: 312125.9688
Episode 98400 | Reward: -12.377 | Epsilon: 0.0100 | Loss: 256210.5000
Episode 98450 | Reward: -12.251 | Epsilon: 0.0100 | Loss: 291188.8438
Episode 98500 | Reward: -15.206 | Epsilon: 0.0100 | Loss: 391010.2500
Episode 98550 | Reward: -14.778 | Epsilon: 0.0100 | Loss: 307890.2812
Episode 98600 | Reward: -13.280 | Epsilon: 0.0100 | Loss: 279907.6562
Episode 98650 | Reward: -11.361 | Epsilon: 0.0100 | Loss: 236286.0312
Episode 98700 | Reward: -11.993 | Epsilon: 0.0100 | Loss: 321415.6250
Episode 98750 | Reward:  -9.657 | Epsilon: 0.0100 | Loss: 248531.5781
Episode 98800 | Reward: -15.159 | Epsilon: 0.0100 | Loss: 259945.3594
Episode 98850 | Reward: -13.296 | Epsilon: 0.0100 | Loss: 316438.7812
Episode 98900 | Reward:  -5.898 | Epsilon: 0.0100 | Loss: 414001.9688
Episode 98950 | Reward:  -9.280 | Epsilon: 0.0100 | Loss: 347372.2188
Episode 99000 | Reward:  -9.436 | Epsilon: 0.0100 | Loss: 389570.8125
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:40).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:40).dict
Episode 99050 | Reward: -11.860 | Epsilon: 0.0100 | Loss: 394505.0938
Episode 99100 | Reward: -11.668 | Epsilon: 0.0100 | Loss: 337816.3125
Episode 99150 | Reward: -11.258 | Epsilon: 0.0100 | Loss: 255902.3438
Episode 99200 | Reward:  -8.003 | Epsilon: 0.0100 | Loss: 337594.3438
Episode 99250 | Reward: -12.552 | Epsilon: 0.0100 | Loss: 466724.9062
Episode 99300 | Reward: -10.487 | Epsilon: 0.0100 | Loss: 316438.8750
Episode 99350 | Reward:  -7.431 | Epsilon: 0.0100 | Loss: 273495.6250
Episode 99400 | Reward: -10.220 | Epsilon: 0.0100 | Loss: 319167.0000
Episode 99450 | Reward:  -8.192 | Epsilon: 0.0100 | Loss: 360979.5000
Episode 99500 | Reward: -13.385 | Epsilon: 0.0100 | Loss: 351991.6250
Episode 99550 | Reward: -11.408 | Epsilon: 0.0100 | Loss: 342553.6562
Episode 99600 | Reward: -12.993 | Epsilon: 0.0100 | Loss: 384437.9375
Episode 99650 | Reward:  -7.426 | Epsilon: 0.0100 | Loss: 406034.1875
Episode 99700 | Reward: -13.034 | Epsilon: 0.0100 | Loss: 318125.5312
Episode 99750 | Reward: -10.318 | Epsilon: 0.0100 | Loss: 414336.8125
Episode 99800 | Reward:  -9.297 | Epsilon: 0.0100 | Loss: 254730.3438
Episode 99850 | Reward: -10.119 | Epsilon: 0.0100 | Loss: 393407.8750
Episode 99900 | Reward: -10.754 | Epsilon: 0.0100 | Loss: 236511.6406
Episode 99950 | Reward: -14.431 | Epsilon: 0.0100 | Loss: 303374.3125
Episode 100000 | Reward: -16.629 | Epsilon: 0.0100 | Loss: 419563.5938
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:44).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:44).dict
Episode 100050 | Reward: -12.887 | Epsilon: 0.0100 | Loss: 320332.3750
Episode 100100 | Reward: -10.289 | Epsilon: 0.0100 | Loss: 365834.7500
Episode 100150 | Reward: -12.191 | Epsilon: 0.0100 | Loss: 377510.3750
Episode 100200 | Reward: -13.201 | Epsilon: 0.0100 | Loss: 259644.1094
Episode 100250 | Reward: -13.921 | Epsilon: 0.0100 | Loss: 292999.5625
Episode 100300 | Reward: -13.234 | Epsilon: 0.0100 | Loss: 304193.0000
Episode 100350 | Reward: -11.791 | Epsilon: 0.0100 | Loss: 387316.0938
Episode 100400 | Reward: -13.789 | Epsilon: 0.0100 | Loss: 445741.5312
Episode 100450 | Reward: -13.966 | Epsilon: 0.0100 | Loss: 315831.8750
Episode 100500 | Reward: -14.350 | Epsilon: 0.0100 | Loss: 383051.5312
Episode 100550 | Reward:  -9.176 | Epsilon: 0.0100 | Loss: 385351.5312
Episode 100600 | Reward: -15.953 | Epsilon: 0.0100 | Loss: 332170.2500
Episode 100650 | Reward: -10.465 | Epsilon: 0.0100 | Loss: 450910.3750
Episode 100700 | Reward: -12.497 | Epsilon: 0.0100 | Loss: 365862.9375
Episode 100750 | Reward: -14.880 | Epsilon: 0.0100 | Loss: 358247.3125
Episode 100800 | Reward: -15.414 | Epsilon: 0.0100 | Loss: 510754.4688
Episode 100850 | Reward: -16.393 | Epsilon: 0.0100 | Loss: 287265.0625
Episode 100900 | Reward: -15.043 | Epsilon: 0.0100 | Loss: 512906.7188
Episode 100950 | Reward: -16.143 | Epsilon: 0.0100 | Loss: 387140.8750
Episode 101000 | Reward: -11.393 | Epsilon: 0.0100 | Loss: 399587.2812
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:48).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:48).dict
Episode 101050 | Reward: -11.653 | Epsilon: 0.0100 | Loss: 370873.9375
Episode 101100 | Reward: -11.599 | Epsilon: 0.0100 | Loss: 403476.4375
Episode 101150 | Reward: -12.820 | Epsilon: 0.0100 | Loss: 350466.4688
Episode 101200 | Reward: -13.043 | Epsilon: 0.0100 | Loss: 445486.4688
Episode 101250 | Reward: -13.261 | Epsilon: 0.0100 | Loss: 432563.5625
Episode 101300 | Reward: -14.979 | Epsilon: 0.0100 | Loss: 448136.5000
Episode 101350 | Reward: -14.720 | Epsilon: 0.0100 | Loss: 563577.5625
Episode 101400 | Reward: -14.111 | Epsilon: 0.0100 | Loss: 435080.0000
Episode 101450 | Reward: -14.240 | Epsilon: 0.0100 | Loss: 454172.4375
Episode 101500 | Reward: -11.753 | Epsilon: 0.0100 | Loss: 387630.9375
Episode 101550 | Reward: -16.525 | Epsilon: 0.0100 | Loss: 477057.4375
Episode 101600 | Reward: -12.902 | Epsilon: 0.0100 | Loss: 527751.5000
Episode 101650 | Reward: -11.208 | Epsilon: 0.0100 | Loss: 410683.5000
Episode 101700 | Reward: -11.503 | Epsilon: 0.0100 | Loss: 474056.5625
Episode 101750 | Reward: -13.712 | Epsilon: 0.0100 | Loss: 432437.8125
Episode 101800 | Reward:  -8.829 | Epsilon: 0.0100 | Loss: 352059.1250
Episode 101850 | Reward: -15.155 | Epsilon: 0.0100 | Loss: 503975.3125
Episode 101900 | Reward: -11.818 | Epsilon: 0.0100 | Loss: 636151.3750
Episode 101950 | Reward: -15.978 | Epsilon: 0.0100 | Loss: 562292.8750
Episode 102000 | Reward: -16.853 | Epsilon: 0.0100 | Loss: 543402.1250
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:52).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:52).dict
Episode 102050 | Reward: -14.356 | Epsilon: 0.0100 | Loss: 557271.2500
Episode 102100 | Reward: -13.230 | Epsilon: 0.0100 | Loss: 476858.6250
Episode 102150 | Reward: -10.965 | Epsilon: 0.0100 | Loss: 441753.4062
Episode 102200 | Reward: -13.981 | Epsilon: 0.0100 | Loss: 464901.3125
Episode 102250 | Reward: -12.177 | Epsilon: 0.0100 | Loss: 594222.8125
Episode 102300 | Reward: -10.245 | Epsilon: 0.0100 | Loss: 624763.1875
Episode 102350 | Reward: -10.086 | Epsilon: 0.0100 | Loss: 611889.4375
Episode 102400 | Reward: -10.954 | Epsilon: 0.0100 | Loss: 560124.6875
Episode 102450 | Reward: -12.116 | Epsilon: 0.0100 | Loss: 526236.6250
Episode 102500 | Reward:  -9.532 | Epsilon: 0.0100 | Loss: 575252.8750
Episode 102550 | Reward: -11.937 | Epsilon: 0.0100 | Loss: 483563.6562
Episode 102600 | Reward: -10.129 | Epsilon: 0.0100 | Loss: 441107.1875
Episode 102650 | Reward: -12.148 | Epsilon: 0.0100 | Loss: 522018.3750
Episode 102700 | Reward: -12.883 | Epsilon: 0.0100 | Loss: 581461.3125
Episode 102750 | Reward: -12.857 | Epsilon: 0.0100 | Loss: 625926.7500
Episode 102800 | Reward: -14.427 | Epsilon: 0.0100 | Loss: 554940.8750
Episode 102850 | Reward: -10.096 | Epsilon: 0.0100 | Loss: 434366.3125
Episode 102900 | Reward:  -9.538 | Epsilon: 0.0100 | Loss: 530428.3125
Episode 102950 | Reward: -14.834 | Epsilon: 0.0100 | Loss: 427333.5000
Episode 103000 | Reward: -17.122 | Epsilon: 0.0100 | Loss: 699762.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:57).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(07:57).dict
Episode 103050 | Reward: -14.393 | Epsilon: 0.0100 | Loss: 640756.6250
Episode 103100 | Reward: -11.569 | Epsilon: 0.0100 | Loss: 518677.6250
Episode 103150 | Reward: -13.384 | Epsilon: 0.0100 | Loss: 628205.6250
Episode 103200 | Reward:  -9.025 | Epsilon: 0.0100 | Loss: 561463.2500
Episode 103250 | Reward: -12.862 | Epsilon: 0.0100 | Loss: 525601.5625
Episode 103300 | Reward: -12.358 | Epsilon: 0.0100 | Loss: 570597.5625
Episode 103350 | Reward: -11.938 | Epsilon: 0.0100 | Loss: 530803.4375
Episode 103400 | Reward: -15.019 | Epsilon: 0.0100 | Loss: 525035.1250
Episode 103450 | Reward: -15.416 | Epsilon: 0.0100 | Loss: 614328.3750
Episode 103500 | Reward: -10.804 | Epsilon: 0.0100 | Loss: 423066.8750
Episode 103550 | Reward: -12.404 | Epsilon: 0.0100 | Loss: 551168.4375
Episode 103600 | Reward: -12.667 | Epsilon: 0.0100 | Loss: 514156.9062
Episode 103650 | Reward: -15.656 | Epsilon: 0.0100 | Loss: 476290.9375
Episode 103700 | Reward: -10.483 | Epsilon: 0.0100 | Loss: 485591.0312
Episode 103750 | Reward: -12.561 | Epsilon: 0.0100 | Loss: 638493.8125
Episode 103800 | Reward: -11.441 | Epsilon: 0.0100 | Loss: 576876.0625
Episode 103850 | Reward: -16.821 | Epsilon: 0.0100 | Loss: 578499.3750
Episode 103900 | Reward:  -9.741 | Epsilon: 0.0100 | Loss: 678725.1875
Episode 103950 | Reward:  -9.977 | Epsilon: 0.0100 | Loss: 517517.5312
Episode 104000 | Reward: -10.868 | Epsilon: 0.0100 | Loss: 326473.8750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:01).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:01).dict
Episode 104050 | Reward: -11.923 | Epsilon: 0.0100 | Loss: 564594.4375
Episode 104100 | Reward: -12.480 | Epsilon: 0.0100 | Loss: 693793.8750
Episode 104150 | Reward:  -7.292 | Epsilon: 0.0100 | Loss: 633672.3125
Episode 104200 | Reward:  -7.662 | Epsilon: 0.0100 | Loss: 476221.3750
Episode 104250 | Reward: -10.024 | Epsilon: 0.0100 | Loss: 496470.5938
Episode 104300 | Reward:  -9.615 | Epsilon: 0.0100 | Loss: 716216.3750
Episode 104350 | Reward: -10.393 | Epsilon: 0.0100 | Loss: 385049.6875
Episode 104400 | Reward: -10.482 | Epsilon: 0.0100 | Loss: 618401.5000
Episode 104450 | Reward: -12.592 | Epsilon: 0.0100 | Loss: 577399.5000
Episode 104500 | Reward: -10.301 | Epsilon: 0.0100 | Loss: 469447.7188
Episode 104550 | Reward: -13.914 | Epsilon: 0.0100 | Loss: 470489.0000
Episode 104600 | Reward: -11.017 | Epsilon: 0.0100 | Loss: 532974.3125
Episode 104650 | Reward: -12.970 | Epsilon: 0.0100 | Loss: 521380.7500
Episode 104700 | Reward:  -8.952 | Epsilon: 0.0100 | Loss: 729014.9375
Episode 104750 | Reward: -13.357 | Epsilon: 0.0100 | Loss: 529705.0000
Episode 104800 | Reward: -10.665 | Epsilon: 0.0100 | Loss: 646121.3125
Episode 104850 | Reward: -11.934 | Epsilon: 0.0100 | Loss: 629191.8125
Episode 104900 | Reward: -13.279 | Epsilon: 0.0100 | Loss: 545020.5000
Episode 104950 | Reward: -12.004 | Epsilon: 0.0100 | Loss: 680965.6875
Episode 105000 | Reward: -11.083 | Epsilon: 0.0100 | Loss: 459815.9375
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:05).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:05).dict
Episode 105050 | Reward: -12.731 | Epsilon: 0.0100 | Loss: 509184.3750
Episode 105100 | Reward: -10.274 | Epsilon: 0.0100 | Loss: 609432.3750
Episode 105150 | Reward: -10.264 | Epsilon: 0.0100 | Loss: 522502.5625
Episode 105200 | Reward:  -8.795 | Epsilon: 0.0100 | Loss: 374209.0938
Episode 105250 | Reward: -10.670 | Epsilon: 0.0100 | Loss: 548427.0000
Episode 105300 | Reward: -12.035 | Epsilon: 0.0100 | Loss: 438158.6875
Episode 105350 | Reward: -11.584 | Epsilon: 0.0100 | Loss: 577973.7500
Episode 105400 | Reward: -13.312 | Epsilon: 0.0100 | Loss: 636896.5625
Episode 105450 | Reward: -10.987 | Epsilon: 0.0100 | Loss: 615156.0625
Episode 105500 | Reward: -12.973 | Epsilon: 0.0100 | Loss: 416905.2188
Episode 105550 | Reward: -11.777 | Epsilon: 0.0100 | Loss: 386716.9688
Episode 105600 | Reward: -13.096 | Epsilon: 0.0100 | Loss: 364770.0625
Episode 105650 | Reward: -11.988 | Epsilon: 0.0100 | Loss: 302461.9062
Episode 105700 | Reward:  -9.060 | Epsilon: 0.0100 | Loss: 475893.6875
Episode 105750 | Reward: -11.149 | Epsilon: 0.0100 | Loss: 403203.6562
Episode 105800 | Reward:  -9.632 | Epsilon: 0.0100 | Loss: 489958.1250
Episode 105850 | Reward:  -8.919 | Epsilon: 0.0100 | Loss: 410463.7500
Episode 105900 | Reward: -10.108 | Epsilon: 0.0100 | Loss: 475718.3125
Episode 105950 | Reward: -11.472 | Epsilon: 0.0100 | Loss: 379149.5625
Episode 106000 | Reward: -11.695 | Epsilon: 0.0100 | Loss: 439768.0000
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:09).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:09).dict
Episode 106050 | Reward: -11.284 | Epsilon: 0.0100 | Loss: 475910.4062
Episode 106100 | Reward: -10.526 | Epsilon: 0.0100 | Loss: 461737.4688
Episode 106150 | Reward: -13.136 | Epsilon: 0.0100 | Loss: 288121.3125
Episode 106200 | Reward: -15.476 | Epsilon: 0.0100 | Loss: 416111.5938
Episode 106250 | Reward:  -7.920 | Epsilon: 0.0100 | Loss: 351985.4375
Episode 106300 | Reward: -10.797 | Epsilon: 0.0100 | Loss: 419699.0625
Episode 106350 | Reward: -16.622 | Epsilon: 0.0100 | Loss: 281227.5000
Episode 106400 | Reward: -17.512 | Epsilon: 0.0100 | Loss: 511750.8750
Episode 106450 | Reward: -14.857 | Epsilon: 0.0100 | Loss: 379138.3750
Episode 106500 | Reward: -11.719 | Epsilon: 0.0100 | Loss: 342593.6562
Episode 106550 | Reward: -11.649 | Epsilon: 0.0100 | Loss: 295301.3750
Episode 106600 | Reward: -13.409 | Epsilon: 0.0100 | Loss: 388746.5000
Episode 106650 | Reward: -12.126 | Epsilon: 0.0100 | Loss: 360811.6875
Episode 106700 | Reward:  -8.849 | Epsilon: 0.0100 | Loss: 414983.0312
Episode 106750 | Reward:  -8.699 | Epsilon: 0.0100 | Loss: 407247.2812
Episode 106800 | Reward:  -6.744 | Epsilon: 0.0100 | Loss: 369466.2812
Episode 106850 | Reward: -15.173 | Epsilon: 0.0100 | Loss: 403429.4375
Episode 106900 | Reward: -11.869 | Epsilon: 0.0100 | Loss: 376925.5625
Episode 106950 | Reward:  -8.887 | Epsilon: 0.0100 | Loss: 329070.7500
Episode 107000 | Reward:  -8.298 | Epsilon: 0.0100 | Loss: 332593.3750
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:13).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:13).dict
Episode 107050 | Reward: -10.679 | Epsilon: 0.0100 | Loss: 360906.1875
Episode 107100 | Reward: -12.415 | Epsilon: 0.0100 | Loss: 376392.5625
Episode 107150 | Reward: -10.655 | Epsilon: 0.0100 | Loss: 438398.9688
Episode 107200 | Reward: -10.362 | Epsilon: 0.0100 | Loss: 349529.2812
Episode 107250 | Reward:  -5.432 | Epsilon: 0.0100 | Loss: 483585.9375
Episode 107300 | Reward:  -4.640 | Epsilon: 0.0100 | Loss: 480183.5000
Episode 107350 | Reward: -10.975 | Epsilon: 0.0100 | Loss: 319538.4062
Episode 107400 | Reward: -12.101 | Epsilon: 0.0100 | Loss: 483451.3438
Episode 107450 | Reward: -11.112 | Epsilon: 0.0100 | Loss: 240655.8594
Episode 107500 | Reward: -11.786 | Epsilon: 0.0100 | Loss: 426578.0000
Episode 107550 | Reward: -11.279 | Epsilon: 0.0100 | Loss: 276994.2500
Episode 107600 | Reward: -11.987 | Epsilon: 0.0100 | Loss: 486761.8125
Episode 107650 | Reward: -12.623 | Epsilon: 0.0100 | Loss: 337807.6250
Episode 107700 | Reward:  -8.830 | Epsilon: 0.0100 | Loss: 298737.2188
Episode 107750 | Reward: -11.604 | Epsilon: 0.0100 | Loss: 429703.7188
Episode 107800 | Reward: -12.431 | Epsilon: 0.0100 | Loss: 430678.8750
Episode 107850 | Reward: -13.665 | Epsilon: 0.0100 | Loss: 464842.2812
Episode 107900 | Reward: -14.634 | Epsilon: 0.0100 | Loss: 399980.5625
Episode 107950 | Reward: -14.285 | Epsilon: 0.0100 | Loss: 486429.4688
Episode 108000 | Reward: -13.592 | Epsilon: 0.0100 | Loss: 467886.0625
Model saved to PyTorch_models/model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:17).dict.dict
✓ Model saved: model.DQN.logic_with_vars.AlgebraicLogic.AlgebraicLogic.M=8x(J=2,I=3,L=2).30-11-2025(08:17).dict
Episode 108050 | Reward: -12.435 | Epsilon: 0.0100 | Loss: 396431.4062
Episode 108100 | Reward: -15.759 | Epsilon: 0.0100 | Loss: 411620.2812
Episode 108150 | Reward: -12.664 | Epsilon: 0.0100 | Loss: 343959.9688
Episode 108200 | Reward: -10.885 | Epsilon: 0.0100 | Loss: 458808.2812
Episode 108250 | Reward: -12.093 | Epsilon: 0.0100 | Loss: 420603.4688
Episode 108300 | Reward: -10.834 | Epsilon: 0.0100 | Loss: 386683.5000
Episode 108350 | Reward: -10.596 | Epsilon: 0.0100 | Loss: 433236.6562
Episode 108400 | Reward: -11.846 | Epsilon: 0.0100 | Loss: 357505.7188
Episode 108450 | Reward: -12.402 | Epsilon: 0.0100 | Loss: 432148.6875
Episode 108500 | Reward: -11.528 | Epsilon: 0.0100 | Loss: 385950.8750
Episode 108550 | Reward: -11.821 | Epsilon: 0.0100 | Loss: 450751.1250
Episode 108600 | Reward: -11.318 | Epsilon: 0.0100 | Loss: 491056.0312
Episode 108650 | Reward: -12.781 | Epsilon: 0.0100 | Loss: 396137.0312
Episode 108700 | Reward:  -7.573 | Epsilon: 0.0100 | Loss: 351269.1562
Episode 108750 | Reward: -11.950 | Epsilon: 0.0100 | Loss: 459647.7812
Episode 108800 | Reward: -14.230 | Epsilon: 0.0100 | Loss: 500211.1875
Episode 108850 | Reward: -11.478 | Epsilon: 0.0100 | Loss: 466737.3438
Episode 108900 | Reward: -11.683 | Epsilon: 0.0100 | Loss: 354217.2812
